diff --git a/Makefile.toml b/Makefile.toml
index d7aa0338..b1f92162 100644
--- a/Makefile.toml
+++ b/Makefile.toml
@@ -30,15 +30,14 @@ default_to_workspace = false # by default, we run cargo commands on top level in
 skip_core_tasks = true       # we are not using the predefined cargo-make flows, instead redefine here for more clarity
 
 [env]
-JUNIT_OPTS = "--nocapture --report-time"
-JUNIT_OPTS_WIN = "--report-time"
+JUNIT_OPTS = ""
 AWS_EC2_METADATA_DISABLED = "true"
 
 [env.ci]
 CARGO_INCREMENTAL = "false"
 # CARGO_LOG="cargo::core::compiler::fingerprint=trace"
-JUNIT_OPTS = "--nocapture --report-time --format junit --logfile target/report.xml"
-JUNIT_OPTS_WIN = "--color=never --test-threads=1 --report-time --format junit"
+JUNIT_OPTS = "--format junit --logfile target/report.xml"
+CI = "true"
 
 [tasks.default]
 description = "This is the task that gets executed by 'cargo make' when no task is specified"
@@ -61,17 +60,16 @@ dependencies = [
 # WIT DEPENDENCIES
 [tasks.wit]
 description = "Fetches the WIT dependencies based on wit/deps.toml"
-condition = { files_modified = { input = [
-    "wit/deps.toml",
-], output = [
-    "wit/deps.done",
-] } }
 run_task = [
     { name = [
         "remove-wit-deps",
-        "wit-host",
         "wit-wasm-rpc",
-        "wit-done",
+        "wit-golem-common",
+        "wit-golem-cli",
+        "wit-template-golem-agent-ts",
+        "wit-test-components",
+        "wit-golem-templates",
+        "wit-sdks"
     ] },
 ]
 
@@ -81,30 +79,89 @@ script_runner = "@duckscript"
 script = """
 rm -r wasm-rpc/wit/deps
 mkdir wasm-rpc/wit/deps
-cp -v wit/deps/io wasm-rpc/wit/deps
-cp -v wit/deps/clocks wasm-rpc/wit/deps
-cp -v wit/deps/golem-1.x wasm-rpc/wit/deps
-cp -v wit/deps/golem-rpc wasm-rpc/wit/deps
+cp wit/deps/io wasm-rpc/wit/deps
+cp wit/deps/clocks wasm-rpc/wit/deps
+cp wit/deps/golem-1.x wasm-rpc/wit/deps
+cp wit/deps/golem-rpc wasm-rpc/wit/deps
 """
 
-[tasks.wit-host]
+[tasks.wit-golem-common]
 private = true
-install_crate = { crate_name = "wit-deps-cli", binary = "wit-deps", test_arg = "--help" }
-command = "wit-deps"
-args = ["update"]
+script_runner = "@duckscript"
+script = """
+rm -r golem-common/wit/deps
+mkdir golem-common/wit/deps
+cp wit/deps/io golem-common/wit/deps
+cp wit/deps/clocks golem-common/wit/deps
+cp wit/deps/golem-1.x golem-common/wit/deps
+cp wit/deps/golem-rpc golem-common/wit/deps
+cp wit/deps/golem-agent golem-common/wit/deps
+"""
+
+[tasks.wit-golem-templates]
+private = true
+script_runner = "@duckscript"
+script = """
+rm -r cli/golem-templates/wit/deps
+mkdir cli/golem-templates/wit/deps
+glob_cp wit/deps/**/* cli/golem-templates/wit/deps
+"""
 
-[tasks.wit-done]
+[tasks.wit-sdks]
 private = true
 script_runner = "@duckscript"
-script = "touch wit/deps.done"
+script = """
+rm -r sdks/rust/golem-rust/wit/deps
+rm -r sdks/ts/wit/deps
+mkdir sdks/rust/golem-rust/wit/deps
+mkdir sdks/ts/wit/deps
+glob_cp wit/deps/**/* sdks/rust/golem-rust/wit/deps
+glob_cp wit/deps/**/* sdks/ts/wit/deps
+"""
+
+[tasks.wit-golem-cli]
+private = true
+script_runner = "@duckscript"
+script = """
+rm -r cli/golem-cli/wit/deps
+mkdir cli/golem-cli/wit/deps
+cp wit/deps/clocks cli/golem-cli/wit/deps
+cp wit/deps/io cli/golem-cli/wit/deps
+cp wit/deps/golem-1.x cli/golem-cli/wit/deps
+cp wit/deps/golem-rpc cli/golem-cli/wit/deps
+cp wit/deps/golem-agent cli/golem-cli/wit/deps
+"""
+
+[tasks.wit-template-golem-agent-ts]
+private = true
+script_runner = "@duckscript"
+script = """
+rm -r cli/template-golem-agent-ts/wit/deps
+mkdir cli/template-golem-agent-ts/wit/deps
+glob_cp wit/deps/**/* cli/template-golem-agent-ts/wit/deps
+"""
+
+[tasks.wit-test-components]
+private = true
+script_runner = "@duckscript"
+script = """
+components = array blob-store-service component-resolve component-transformer-example1/adapter custom-durability file-service high-volume-logging http-client ifs-update ifs-update-inside-exported-function invocation-context js-1 js-4 key-value-service networking oplog-processor promise python-http-client rdbms-service rpc runtime-service scheduled-invocation shopping-cart tinygo-wasi tinygo-wasi-http ts-rpc update-test-env-var update-test-v2-11 update-test-v3-11 update-test-v3-sdk update-test-v4 wasi-config wasi-http-incoming-request-handler wasi-http-incoming-request-handler-echo wasi-http-incoming-request-handler-state low-level-agent
+
+for component in ${components}
+    echo "Updating wit directory for test component ${component}"
+    rm -r test-components/${component}/wit/deps
+    mkdir test-components/${component}/wit/deps
+    glob_cp wit/deps/**/* test-components/${component}/wit/deps
+end
+"""
 
 [tasks.remove-wit-deps]
 private = true
 script_runner = "@duckscript"
 script = """
-rm -rf wit/deps.done
-rm -rf wit/deps
 rm -rf wasm-rpc/wit/deps
+rm -rf golem-common/wit/deps
+rm -rf cli/golem-cli/wit/deps
 """
 
 [tasks.diff-wit]
@@ -128,23 +185,43 @@ description = "Builds all executables in debug mode"
 command = "cargo"
 args = ["build", "--workspace", "--bins", "--exclude", "integration-tests"]
 
+[tasks.build-bins-non-ci]
+private = true
+condition = { env_not_set = ["CI"] }
+run_task = [{ name = ["build-bins"] }]
+
 [tasks.build-worker-service]
 dependencies = ["wit"]
 description = "Builds the worker-service"
 command = "cargo"
 args = ["build", "-p", "golem-worker-service"]
 
+[tasks.build-worker-service-non-ci]
+private = true
+condition = { env_not_set = ["CI"] }
+run_task = [{ name = ["build-worker-service"] }]
+
 [tasks.build-component-service]
 dependencies = ["wit"]
 description = "Builds the component-service"
 command = "cargo"
 args = ["build", "-p", "golem-component-service"]
 
+[tasks.build-component-service-non-ci]
+private = true
+condition = { env_not_set = ["CI"] }
+run_task = [{ name = ["build-component-service"] }]
+
 [tasks.build-cloud-service]
 description = "Builds cloud service"
 command = "cargo"
 args = ["build", "-p", "cloud-service"]
 
+[tasks.build-cloud-service-non-ci]
+private = true
+condition = { env_not_set = ["CI"] }
+run_task = [{ name = ["build-cloud-service"] }]
+
 [tasks.build-release]
 description = """This is the top-level task that builds everything in release mode. PLATFORM_OVERRIDE env variable can be used
 to build for other target than the current one, can be linux/amd64 or linux/arm64. This is used for cross-compiling
@@ -238,17 +315,8 @@ dependencies = [
 dependencies = ["wit"]
 description = "Runs unit tests only"
 script = '''
-cargo test --workspace --lib --all-features --exclude golem-wasm-rpc-derive -- $JUNIT_OPTS
-cargo test -p golem-wasm-ast --tests --all-features -- $JUNIT_OPTS
-'''
-
-[tasks.unit-tests.windows]
-script_runner = "pwsh"
-script_extension = "ps1"
-script = '''
-$additional_params = $env:JUNIT_OPTS_WIN.split(' ')
-cargo test --workspace --lib --all-features --exclude golem-wasm-rpc-derive -- $additional_params > ./target/raw-report-unit-tests.xml
-cargo test -p golem-wasm-ast --tests --all-features -- $additional_params >> ./target/raw-report-unit-tests.xml
+cargo test --workspace --lib --all-features --exclude golem-wasm-rpc-derive -- --nocapture --report-time $JUNIT_OPTS
+cargo test -p golem-wasm-ast --tests --all-features -- --nocapture --report-time $JUNIT_OPTS
 '''
 
 [tasks.worker-executor-tests]
@@ -274,13 +342,12 @@ script = '''
 cargo test --package golem-worker-executor --test integration :tag: -- --report-time --nocapture $JUNIT_OPTS
 '''
 
-[tasks.worker-executor-tests-untagged.windows]
-script_runner = "pwsh"
-script_extension = "ps1"
+[tasks.worker-executor-tests-rdbms-service]
+dependencies = ["wit"]
+description = "Runs only untagged worker-executor-tests"
 env = { "RUST_BACKTRACE" = "1", "WASMTIME_BACKTRACE_DETAILS" = "1", "RUST_LOG" = "info", "RUST_TEST_TIME_INTEGRATION" = "5000,30000" }
 script = '''
-$additional_params = $env:JUNIT_OPTS_WIN.split(' ')
-cargo test --package golem-worker-executor --test integration :tag: -- --report-time --nocapture $additional_params
+cargo test --package golem-worker-executor --test integration :tag:rdbms-service -- --flaky-run=5 --report-time --nocapture $JUNIT_OPTS
 '''
 
 [tasks.worker-executor-tests-group1]
@@ -291,15 +358,6 @@ script = '''
 cargo test --package golem-worker-executor --test integration :tag:group1 -- --report-time --nocapture $JUNIT_OPTS
 '''
 
-[tasks.worker-executor-tests-group1.windows]
-script_runner = "pwsh"
-script_extension = "ps1"
-env = { "RUST_BACKTRACE" = "1", "WASMTIME_BACKTRACE_DETAILS" = "1", "RUST_LOG" = "info", "RUST_TEST_TIME_INTEGRATION" = "5000,30000" }
-script = '''
-$additional_params = $env:JUNIT_OPTS_WIN.split(' ')
-cargo test --package golem-worker-executor --test integration :tag:group1 -- --report-time --nocapture $additional_params
-'''
-
 [tasks.worker-executor-tests-group2]
 dependencies = ["wit"]
 description = "Runs worker executor tests only (group 2/8)"
@@ -308,15 +366,6 @@ script = '''
 cargo test --package golem-worker-executor --test integration :tag:group2 -- --report-time --nocapture $JUNIT_OPTS
 '''
 
-[tasks.worker-executor-tests-group2.windows]
-script_runner = "pwsh"
-script_extension = "ps1"
-env = { "RUST_BACKTRACE" = "1", "WASMTIME_BACKTRACE_DETAILS" = "1", "RUST_LOG" = "info", "RUST_TEST_TIME_INTEGRATION" = "5000,30000" }
-script = '''
-$additional_params = $env:JUNIT_OPTS_WIN.split(' ')
-cargo test --package golem-worker-executor --test integration :tag:group2 -- --report-time --nocapture $additional_params
-'''
-
 [tasks.worker-executor-tests-group3]
 dependencies = ["wit"]
 description = "Runs worker executor tests only (group 3/8)"
@@ -325,15 +374,6 @@ script = '''
 cargo test --package golem-worker-executor --test integration :tag:group3 -- --report-time --nocapture $JUNIT_OPTS
 '''
 
-[tasks.worker-executor-tests-group3.windows]
-script_runner = "pwsh"
-script_extension = "ps1"
-env = { "RUST_BACKTRACE" = "1", "WASMTIME_BACKTRACE_DETAILS" = "1", "RUST_LOG" = "info", "RUST_TEST_TIME_INTEGRATION" = "5000,30000" }
-script = '''
-$additional_params = $env:JUNIT_OPTS_WIN.split(' ')
-cargo test --package golem-worker-executor --test integration :tag:group3 -- --report-time --nocapture $additional_params
-'''
-
 [tasks.worker-executor-tests-group4]
 dependencies = ["wit"]
 description = "Runs worker executor tests only (group 4/8)"
@@ -342,15 +382,6 @@ script = '''
 cargo test --package golem-worker-executor --test integration :tag:group4 -- --report-time --nocapture $JUNIT_OPTS
 '''
 
-[tasks.worker-executor-tests-group4.windows]
-script_runner = "pwsh"
-script_extension = "ps1"
-env = { "RUST_BACKTRACE" = "1", "WASMTIME_BACKTRACE_DETAILS" = "1", "RUST_LOG" = "info", "RUST_TEST_TIME_INTEGRATION" = "5000,30000" }
-script = '''
-$additional_params = $env:JUNIT_OPTS_WIN.split(' ')
-cargo test --package golem-worker-executor --test integration :tag:group4 -- --report-time --nocapture $additional_params
-'''
-
 [tasks.worker-executor-tests-group5]
 dependencies = ["wit"]
 description = "Runs worker executor tests only (group 5/8)"
@@ -359,66 +390,6 @@ script = '''
 cargo test --package golem-worker-executor --test integration :tag:group5 -- --report-time --nocapture $JUNIT_OPTS
 '''
 
-[tasks.worker-executor-tests-group5.windows]
-script_runner = "pwsh"
-script_extension = "ps1"
-env = { "RUST_BACKTRACE" = "1", "WASMTIME_BACKTRACE_DETAILS" = "1", "RUST_LOG" = "info", "RUST_TEST_TIME_INTEGRATION" = "5000,30000" }
-script = '''
-$additional_params = $env:JUNIT_OPTS_WIN.split(' ')
-cargo test --package golem-worker-executor --test integration :tag:group5 -- --report-time --nocapture $additional_params
-'''
-
-[tasks.worker-executor-tests-group6]
-dependencies = ["wit"]
-description = "Runs worker executor tests only (group 6/8)"
-env = { "RUST_BACKTRACE" = "1", "WASMTIME_BACKTRACE_DETAILS" = "1", "RUST_LOG" = "info", "RUST_TEST_TIME_INTEGRATION" = "5000,30000" }
-script = '''
-cargo test --package golem-worker-executor --test integration :tag:group6 -- --report-time --nocapture $JUNIT_OPTS
-'''
-
-[tasks.worker-executor-tests-group6.windows]
-script_runner = "pwsh"
-script_extension = "ps1"
-env = { "RUST_BACKTRACE" = "1", "WASMTIME_BACKTRACE_DETAILS" = "1", "RUST_LOG" = "info", "RUST_TEST_TIME_INTEGRATION" = "5000,30000" }
-script = '''
-$additional_params = $env:JUNIT_OPTS_WIN.split(' ')
-cargo test --package golem-worker-executor --test integration :tag:group6 -- --report-time --nocapture $additional_params
-'''
-
-[tasks.worker-executor-tests-group7]
-dependencies = ["wit"]
-description = "Runs worker executor tests only (group 7/8)"
-env = { "RUST_BACKTRACE" = "1", "WASMTIME_BACKTRACE_DETAILS" = "1", "RUST_LOG" = "info", "RUST_TEST_TIME_INTEGRATION" = "5000,30000" }
-script = '''
-cargo test --package golem-worker-executor --test integration :tag:group7 -- --report-time --nocapture $JUNIT_OPTS
-'''
-
-[tasks.worker-executor-tests-group7.windows]
-script_runner = "pwsh"
-script_extension = "ps1"
-env = { "RUST_BACKTRACE" = "1", "WASMTIME_BACKTRACE_DETAILS" = "1", "RUST_LOG" = "info", "RUST_TEST_TIME_INTEGRATION" = "5000,30000" }
-script = '''
-$additional_params = $env:JUNIT_OPTS_WIN.split(' ')
-cargo test --package golem-worker-executor --test integration :tag:group7 -- --report-time --nocapture $additional_params
-'''
-
-[tasks.worker-executor-tests-group8]
-dependencies = ["wit"]
-description = "Runs worker executor tests only (group 8/8)"
-env = { "RUST_BACKTRACE" = "1", "WASMTIME_BACKTRACE_DETAILS" = "1", "RUST_LOG" = "info", "RUST_TEST_TIME_INTEGRATION" = "5000,30000" }
-script = '''
-cargo test --package golem-worker-executor --test integration :tag:group8 -- --report-time --nocapture $JUNIT_OPTS
-'''
-
-[tasks.worker-executor-tests-group8.windows]
-script_runner = "pwsh"
-script_extension = "ps1"
-env = { "RUST_BACKTRACE" = "1", "WASMTIME_BACKTRACE_DETAILS" = "1", "RUST_LOG" = "info", "RUST_TEST_TIME_INTEGRATION" = "5000,30000" }
-script = '''
-$additional_params = $env:JUNIT_OPTS_WIN.split(' ')
-cargo test --package golem-worker-executor --test integration :tag:group8 -- --report-time --nocapture $additional_params
-'''
-
 [tasks.integration-tests]
 description = "Runs all integration tests"
 dependencies = [
@@ -427,6 +398,8 @@ dependencies = [
     "integration-tests-group3",
     "integration-tests-group4",
     "integration-tests-group5",
+    "cli-integration-tests",
+    "template-integration-tests"
 ]
 
 [tasks.integration-tests-group1]
@@ -434,16 +407,7 @@ description = "Runs integration tests only"
 dependencies = ["build-bins"]
 env = { "RUST_LOG" = "info", "RUST_BACKTRACE" = "1" }
 script = '''
-cargo test --package integration-tests --test integration -- $JUNIT_OPTS
-'''
-
-[tasks.integration-tests-group1.windows]
-script_runner = "pwsh"
-script_extension = "ps1"
-env = { "RUST_LOG" = "info", "RUST_BACKTRACE" = "1" }
-script = '''
-$additional_params = $env:JUNIT_OPTS_WIN.split(' ')
-cargo test --package integration-tests --test integration -- $additional_params
+cargo test --package integration-tests --test integration -- --nocapture --report-time $JUNIT_OPTS
 '''
 
 [tasks.integration-tests-group2]
@@ -451,16 +415,7 @@ description = "Runs component service integration tests only"
 dependencies = ["wit"]
 env = { "RUST_LOG" = "info", "RUST_BACKTRACE" = "1" }
 script = '''
-cargo test --package golem-component-service --test tests -- $JUNIT_OPTS
-'''
-
-[tasks.integration-tests-group2.windows]
-script_runner = "pwsh"
-script_extension = "ps1"
-env = { "RUST_LOG" = "info", "RUST_BACKTRACE" = "1" }
-script = '''
-$additional_params = $env:JUNIT_OPTS_WIN.split(' ')
-cargo test --package golem-component-service --test tests -- $additional_params
+cargo test --package golem-component-service --test tests -- --nocapture --report-time $JUNIT_OPTS
 '''
 
 [tasks.integration-tests-group3]
@@ -468,18 +423,9 @@ description = "Runs worker service integration tests only"
 dependencies = ["wit"]
 env = { "RUST_LOG" = "info", "RUST_BACKTRACE" = "1" }
 script = '''
-cargo test --package golem-worker-service --test services_tests -- $JUNIT_OPTS
-cargo test --package golem-worker-service --test api_gateway_end_to_end_tests -- $JUNIT_OPTS
-'''
-
-[tasks.integration-tests-group3.windows]
-script_runner = "pwsh"
-script_extension = "ps1"
-env = { "RUST_LOG" = "info", "RUST_BACKTRACE" = "1" }
-script = '''
-$additional_params = $env:JUNIT_OPTS_WIN.split(' ')
-cargo test --package golem-worker-service --test services_tests -- $additional_params
-cargo test --package golem-worker-service --test api_gateway_end_to_end_tests -- $additional_params
+cargo test --package golem-worker-service --test services_tests -- --nocapture --report-time $JUNIT_OPTS
+cargo test --package golem-worker-service --test api_gateway_end_to_end_tests -- --nocapture --report-time $JUNIT_OPTS
+cargo test --package golem-worker-service --test api_oas_convert_tests -- --nocapture
 '''
 
 [tasks.integration-tests-group4]
@@ -487,24 +433,11 @@ description = "Runs golem-service-base integration tests only"
 dependencies = ["wit"]
 env = { "RUST_LOG" = "info", "RUST_BACKTRACE" = "1" }
 script = '''
-cargo test --package golem-service-base --test integration -- $JUNIT_OPTS
-cargo test --package golem-worker-service --test '*' -- $JUNIT_OPTS
-cargo test --package cloud-service --test '*' -- $JUNIT_OPTS
+cargo test --package golem-service-base --test integration -- --nocapture --report-time $JUNIT_OPTS
+cargo test --package cloud-service --test '*' -- --nocapture --report-time $JUNIT_OPTS
 cargo test --package golem-debugging-service --test 'integration' -- --report-time $JUNIT_OPTS
 '''
 
-[tasks.integration-tests-group4.windows]
-script_runner = "pwsh"
-script_extension = "ps1"
-env = { "RUST_LOG" = "info", "RUST_BACKTRACE" = "1" }
-script = '''
-$additional_params = $env:JUNIT_OPTS_WIN.split(' ')
-cargo test --package golem-service-base --test integration -- $additional_params
-cargo test --package golem-worker-service --test '*' -- $additional_params
-cargo test --package cloud-service --test '*' -- $additional_params
-cargo test --package golem-debugging-service --test 'integration' -- --report-time $additional_params
-'''
-
 [tasks.integration-tests-group5]
 description = "Runs sharding integration tests only"
 dependencies = ["build-bins"]
@@ -513,20 +446,29 @@ script = '''
 cargo test --package integration-tests --test sharding -- --report-time $JUNIT_OPTS
 '''
 
-[tasks.integration-tests-group5.windows]
-script_runner = "pwsh"
-script_extension = "ps1"
-env = { "RUST_LOG" = "info", "RUST_BACKTRACE" = "1" }
+[tasks.cli-integration-tests]
+dependencies = ["build"]
+description = "Run CLI integration tests"
+script_runner = "@duckscript"
 script = '''
-$additional_params = $env:JUNIT_OPTS_WIN.split(' ')
-cargo test --package integration-tests --test sharding -- --report-time $additional_params
+exec --fail-on-error cargo test --package golem-cli :tag: --test integration -- --nocapture --report-time %{JUNIT_OPTS}
+exec --fail-on-error cargo test --package golem-cli :tag:app --test integration -- --nocapture --test-threads=1 --report-time %{JUNIT_OPTS}
+exec --fail-on-error cargo test --package golem-cli :tag:uses_cargo --test integration -- --nocapture --test-threads=1 --report-time %{JUNIT_OPTS}
+'''
+
+[tasks.template-integration-tests]
+dependencies = ["build"]
+description = "Run template integration tests"
+script_runner = "@duckscript"
+script = '''
+exec --fail-on-error cargo test --package golem-templates --test integration -- --nocapture --test-threads=1 --report-time %{JUNIT_OPTS}
 '''
 
 [tasks.sharding-tests-debug]
 dependencies = ["build-bins"]
 script = '''
 rm -rf logs data
-mkdir -p logs data
+mkdir -pv logs data
 
 export RUST_LOG=info,golem_test_framework::components=WARN
 export RUST_BACKTRACE=1
@@ -540,29 +482,6 @@ cargo test \
 -- --nocapture --test-threads=1
 '''
 
-[tasks.sharding-tests-debug.windows]
-script_runner = "pwsh"
-script_extension = "ps1"
-dependencies = ["build-bins"]
-script = '''
-Remove-Item -Recurse -Force logs, data -ErrorAction SilentlyContinue
-New-Item -ItemType Directory -Force -Path "logs"
-New-Item -ItemType Directory -Force -Path "data"
-
-$env:RUST_LOG="info,golem_test_framework::components=WARN"
-$env:RUST_BACKTRACE="1"
-$env:GOLEM__TRACING__FILE_DIR="..\\logs"
-$env:GOLEM__TRACING__FILE_TRUNCATE="false"
-$env:GOLEM__TRACING__FILE__ENABLED="true"
-
-$test_args = $args
-
-cargo test `
---package integration-tests `
---test sharding $test_args `
--- --nocapture --test-threads=1
-'''
-
 [tasks.api-tests]
 description = "Runs all API tests"
 dependencies = ["api-tests-http", "api-tests-grpc"]
@@ -572,16 +491,7 @@ description = "Runs API HTTP tests only"
 dependencies = ["build-bins"]
 env = { "RUST_LOG" = "info", "RUST_BACKTRACE" = "1", "GOLEM_CLIENT_PROTOCOL" = "http" }
 script = '''
-cargo test --package integration-tests --test api -- $JUNIT_OPTS
-'''
-
-[tasks.api-tests-http.windows]
-script_runner = "pwsh"
-script_extension = "ps1"
-env = { "RUST_LOG" = "info", "RUST_BACKTRACE" = "1", "GOLEM_CLIENT_PROTOCOL" = "http" }
-script = '''
-$additional_params = $env:JUNIT_OPTS_WIN.split(' ')
-cargo test --package integration-tests --test api -- $additional_params
+cargo test --package integration-tests --test api -- --nocapture --report-time $JUNIT_OPTS
 '''
 
 [tasks.api-tests-grpc]
@@ -589,16 +499,7 @@ description = "Runs API GRPC tests only"
 dependencies = ["build-bins"]
 env = { "RUST_LOG" = "info", "RUST_BACKTRACE" = "1", "GOLEM_CLIENT_PROTOCOL" = "grpc" }
 script = '''
-cargo test --package integration-tests --test api -- :tag: $JUNIT_OPTS
-'''
-
-[tasks.api-tests-grpc.windows]
-script_runner = "pwsh"
-script_extension = "ps1"
-env = { "RUST_LOG" = "info", "RUST_BACKTRACE" = "1", "GOLEM_CLIENT_PROTOCOL" = "grpc" }
-script = '''
-$additional_params = $env:JUNIT_OPTS_WIN.split(' ')
-cargo test --package integration-tests --test api -- :tag: $additional_params
+cargo test --package integration-tests --test api -- :tag: --nocapture --report-time $JUNIT_OPTS
 '''
 
 ## ** CHECK-OPENAPI **
@@ -650,39 +551,6 @@ script = '''
   fi
 '''
 
-[tasks.diff-openapi.windows]
-dependencies = ["merge-openapi"]
-script_runner = "pwsh"
-script_extension = "ps1"
-script = '''
-function Test-OpenApiSpec {
-    param (
-        [string]$SourceFile,
-        [string]$TargetFile,
-        [string]$ServiceName
-    )
-
-    # Execute diff command ignoring line endings
-    & diff.exe --strip-trailing-cr $SourceFile $TargetFile *>$null
-
-    if ($LASTEXITCODE -eq 0) {
-        Write-Host "Latest $($ServiceName) OpenAPI spec version detected."
-    } else {
-        Write-Error "$($SourceFile) is not the same as produced by $($ServiceName)."
-        Write-Error "Run cargo make generate-openapi to generate new spec."
-        
-        if ($SourceFile -eq "openapi/golem-service.yaml") {
-            & diff.exe $SourceFile $TargetFile
-        }
-    }
-}
-
-Test-OpenApiSpec -SourceFile "openapi/golem-service.yaml" -TargetFile "target/golem-service.yaml" -ServiceName "golem-service-yaml"
-Test-OpenApiSpec -SourceFile "openapi/cloud-spec.yaml" -TargetFile "target/cloud-spec.yaml" -ServiceName "cloud-service"
-Test-OpenApiSpec -SourceFile "openapi/golem-component-service.yaml" -TargetFile "target/golem-component-service.yaml" -ServiceName "golem-component-service"
-Test-OpenApiSpec -SourceFile "openapi/golem-worker-service.yaml" -TargetFile "target/golem-worker-service.yaml" -ServiceName "golem-worker-service"
-'''
-
 ## ** GENERATE-OPENAPI **
 
 [tasks.generate-openapi]
@@ -694,61 +562,31 @@ description = "Generates openapi spec from the code and saves it to the openapi
 
 [tasks.generate-worker-service-openapi]
 description = "Generates openapi spec for worker service"
-dependencies = [ "build-worker-service" ]
+dependencies = ["build-worker-service-non-ci"]
 cwd = "./target/debug"
 script = '''
-mkdir -p ../data
+mkdir -pv ../data
 ./golem-worker-service --dump-openapi-yaml > ../golem-worker-service.yaml
 '''
 
-[tasks.generate-worker-service-openapi.windows]
-script_runner = "pwsh"
-script_extension = "ps1"
-dependencies = [ "build-worker-service" ]
-cwd = "./target/debug"
-script = '''
-New-Item -ItemType Directory -Force -Path "..\data"
-.\golem-worker-service.exe --dump-openapi-yaml | Out-File "..\golem-worker-service.yaml"
-'''
-
 [tasks.generate-component-service-openapi]
 description = "Generates openapi spec for component service"
-dependencies = [ "build-component-service" ]
+dependencies = ["build-component-service-non-ci"]
 cwd = "./target/debug"
 script = '''
-mkdir -p ../data
+mkdir -pv ../data
 ./golem-component-service --dump-openapi-yaml > ../golem-component-service.yaml
 '''
 
-[tasks.generate-component-service-openapi.windows]
-script_runner = "pwsh"
-script_extension = "ps1"
-dependencies = [ "build-component-service" ]
-cwd = "./target/debug"
-script = '''
-New-Item -ItemType Directory -Force -Path "..\data"
-.\golem-component-service.exe --dump-openapi-yaml | Out-File "..\golem-component-service.yaml"
-'''
-
 [tasks.generate-cloud-service-openapi]
 description = "Generates openapi spec for cloud service"
-dependencies = [ "build-cloud-service" ]
+dependencies = ["build-cloud-service-non-ci"]
 cwd = "./target/debug"
 script = '''
-mkdir -p ../data
+mkdir -pv ../data
 ./cloud-service --dump-openapi-yaml > ../cloud-spec.yaml
 '''
 
-[tasks.generate-cloud-service-openapi.windows]
-script_runner = "pwsh"
-script_extension = "ps1"
-dependencies = [ "build-cloud-service" ]
-cwd = "./target/debug"
-script = '''
-New-Item -ItemType Directory -Force -Path "..\data"
-.\cloud-service.exe --dump-openapi-yaml | Out-File "..\cloud-spec.yaml"
-'''
-
 [tasks.merge-openapi]
 dependencies = [
     "generate-worker-service-openapi",
@@ -791,7 +629,8 @@ dependencies = [
     "publish-golem-client",
     "publish-golem-service-base",
     "publish-golem-test-framework",
-    "publish-golem-rib-repl"
+    "publish-golem-rib-repl",
+    "publish-golem-cli"
 ]
 
 [tasks.set-version]
@@ -927,6 +766,33 @@ description = "Publishes golem-rib package to crates.io"
 command = "cargo"
 args = ["publish", "-p", "golem-rib-repl", "--allow-dirty", "--no-verify"]
 
+[tasks.publish-golem-templates]
+description = "Publishes golem-templates package to crates.io"
+command = "cargo"
+args = [
+    "publish",
+    "-p",
+    "golem-templates",
+    "--all-features",
+    "--allow-dirty",
+    "--no-verify",
+]
+
+[tasks.publish-golem-cli]
+description = "Publishes golem-cli package to crates.io"
+dependencies = [
+    "publish-golem-templates",
+]
+command = "cargo"
+args = [
+    "publish",
+    "-p",
+    "golem-cli",
+    "--all-features",
+    "--allow-dirty",
+    "--no-verify",
+]
+
 ## ** PACKAGE RELEASE **
 
 # There are three variants of package-release, and only one of them will run based on the value of
@@ -1000,7 +866,7 @@ script = { file = "./local-run/start.sh" }
 description = "Runs all the services locally with the oauth2 login system enabled"
 dependencies = ["build"]
 
-condition = { env_set = [ "GITHUB_CLIENT_ID", "GITHUB_CLIENT_SECRET"], fail_message = "Requires lnav, nginx and redis on path. Install them with your package manager. GITHUB_CLIENT_ID and GITHUB_CLIENT_SECRET env vars must be set." }
+condition = { env_set = ["GITHUB_CLIENT_ID", "GITHUB_CLIENT_SECRET"], fail_message = "Requires lnav, nginx and redis on path. Install them with your package manager. GITHUB_CLIENT_ID and GITHUB_CLIENT_SECRET env vars must be set." }
 
 condition_script = [
     "nginx -v",
@@ -1017,7 +883,7 @@ script = { file = "./local-run/start.sh" }
 
 [tasks.generate-configs]
 description = "Generates default and exmaple config files"
-dependencies = ["build-bins"]
+dependencies = ["build-bins-non-ci"]
 
 script = '''
 export RUST_BACKTRACE=1
@@ -1038,29 +904,6 @@ export RUST_BACKTRACE=1
 ./target/debug/cloud-service --dump-config-default-env-var > cloud-service/config/cloud-service.sample.env
 '''
 
-[tasks.generate-configs.windows]
-dependencies = ["build-bins"]
-script_runner = "pwsh"
-script_extension = "ps1"
-script = '''
-$env:RUST_BACKTRACE="1"
-
-.\target\debug\golem-shard-manager.exe --dump-config-default-toml | Out-File "golem-shard-manager\config\shard-manager.toml"
-.\target\debug\golem-shard-manager.exe --dump-config-default-env-var | Out-File "golem-shard-manager\config\shard-manager.sample.env"
-.\target\debug\golem-component-compilation-service.exe --dump-config-default-toml | Out-File "golem-component-compilation-service\config\component-compilation-service.toml"
-.\target\debug\golem-component-compilation-service.exe --dump-config-default-env-var | Out-File "golem-component-compilation-service\config\component-compilation-service.sample.env"
-.\target\debug\golem-component-service.exe --dump-config-default-toml | Out-File "golem-component-service\config\component-service.toml"
-.\target\debug\golem-component-service.exe --dump-config-default-env-var | Out-File "golem-component-service\config\component-service.sample.env"
-.\target\debug\golem-worker-service.exe --dump-config-default-toml | Out-File "golem-worker-service\config\worker-service.toml"
-.\target\debug\golem-worker-service.exe --dump-config-default-env-var | Out-File "golem-worker-service\config\worker-service.sample.env"
-.\target\debug\worker-executor.exe --dump-config-default-toml | Out-File "golem-worker-executor\config\worker-executor.toml"
-.\target\debug\worker-executor.exe --dump-config-default-env-var | Out-File "golem-worker-executor\config\worker-executor.sample.env"
-.\target\debug\golem-debugging-service.exe --dump-config-default-toml | Out-File "golem-debugging-service\config\debug-worker-executor.toml"
-.\target\debug\golem-debugging-service.exe --dump-config-default-env-var | Out-File "golem-debugging-service\config\debug-worker-executor.sample.env"
-.\target\debug\cloud-service.exe --dump-config-default-toml | Out-File "cloud-service\config\cloud-service.toml"
-.\target\debug\cloud-service.exe --dump-config-default-env-var | Out-File "cloud-service\config\cloud-service.sample.env"
-'''
-
 ## ** CHECK CONFIGS **
 
 [tasks.check-configs]
@@ -1085,28 +928,6 @@ git diff --exit-code \
     cloud-service/config/cloud-service.sample.env
 '''
 
-[tasks.check-configs.windows]
-dependencies = ["generate-configs"]
-script_runner = "pwsh"
-script_extension = "ps1"
-script = '''
-git diff --exit-code `
-    golem-shard-manager/config/shard-manager.toml `
-    golem-shard-manager/config/shard-manager.sample.env `
-    golem-component-compilation-service/config/component-compilation-service.toml `
-    golem-component-compilation-service/config/component-compilation-service.sample.env `
-    golem-component-service/config/component-service.toml `
-    golem-component-service/config/component-service.sample.env `
-    golem-worker-service/config/worker-service.toml `
-    golem-worker-service/config/worker-service.sample.env `
-    golem-worker-executor/config/worker-executor.toml `
-    golem-worker-executor/config/worker-executor.sample.env `
-    golem-debugging-service/config/debug-worker-executor.toml `
-    golem-debugging-service/config/debug-worker-executor.sample.env `
-    cloud-service/config/cloud-service.toml `
-    cloud-service/config/cloud-service.sample.env
-'''
-
 ## ** Elastic tasks **
 
 [tasks.elastic-up]
@@ -1126,3 +947,111 @@ description = "Stops and removes the elastic environment, including all data"
 script = '''
 docker compose --project-directory log-tools/elastic down --volumes
 '''
+
+## ** INSTALL - DEBUG **
+[tasks.install-debug]
+description = "Install bins in debug mode"
+dependencies = ["install-golem-cli-debug", "install-golem-debug"]
+
+[tasks.install-golem-cli-debug]
+description = "Install golem-cli (debug)"
+script_runner = "@duckscript"
+script = '''
+exec --fail-on-error cargo install --debug --path cli/golem-cli --bin golem-cli --target-dir target --locked --offline
+'''
+
+[tasks.install-golem-debug]
+description = "Install golem (debug)"
+script_runner = "@duckscript"
+script = '''
+exec --fail-on-error cargo install --debug --path cli/golem --bin golem --target-dir target --locked --offline
+'''
+
+## ** INSTALL - RELEASE **
+
+[tasks.install-release]
+description = "Install bins in debug mode"
+dependencies = ["install-golem-cli-release", "install-golem-release"]
+
+[tasks.install-golem-cli-release]
+description = "Install golem-cli (debug)"
+script_runner = "@duckscript"
+script = '''
+exec --fail-on-error cargo install --path cli/golem-cli --bin golem-cli --target-dir target --locked --offline
+'''
+
+[tasks.install-golem-release]
+description = "Install golem (debug)"
+script_runner = "@duckscript"
+script = '''
+exec --fail-on-error cargo install --path cli/golem --bin golem --target-dir target --locked --offline
+'''
+
+## ** DESKTOP APP **
+[tasks.desktop]
+description = "Builds the desktop application"
+dependencies = ["npm-install"]
+command = "npm"
+args = ["run", "tauri", "build"]
+cwd = ".cli//desktop-app"
+
+[tasks.dev-desktop]
+description = "Run the desktop application"
+dependencies = ["npm-install"]
+command = "npm"
+args = ["run", "tauri", "dev"]
+cwd = "./cli/desktop-app"
+
+[tasks.npm-install]
+description = "Install npm dependencies"
+command = "npm"
+args = ["install"]
+cwd = "./cli/desktop-app"
+
+## ** APP MANIFEST SCHEMA **
+[tasks.publish-app-manifest-json-schema]
+description = "Publish application manifest schemas to S3 (https://schema.golem.cloud)"
+command = "aws"
+args = [
+    "s3",
+    "sync",
+    "cli/schema.golem.cloud",
+    "s3://schema.golem.cloud",
+]
+
+[tasks.serve-app-manifest-json-schema]
+description = "Serve the schema.golem.cloud directory locally to help testing the schemas in editors"
+install_crate = "miniserve"
+command = "miniserve"
+args = ["--interfaces", "127.0.0.1", "--port", "41357", "schema.golem.cloud"]
+
+## Agent template management
+[tasks.rebuild-ts-agent-template]
+description = "Rebuilds the TypeScript agent template WASM"
+script_runner = "@duckscript"
+script = '''
+cd cli/template-golem-agent-ts
+exec --fail-on-error npm update
+exec --fail-on-error npm install
+exec --fail-on-error npm run generate
+exec --fail-on-error npm run build
+cp dist/wrapper/target/wasm32-wasip1/release/golem_agent.wasm ../golem-templates/templates/ts/ts-app-common/wasm/golem_agent.wasm
+'''
+
+## Cleanup
+[tasks.clear-v8]
+description = "Removes the v8 crate from the target directories"
+script_runner = "@duckscript"
+script = '''
+handle = glob_array ./target/**/build/v8*
+
+for path in ${handle}
+    rm -r ${path}
+end
+
+handle = glob_array ./target/**/deps/libv8*
+
+for path in ${handle}
+    rm -r ${path}
+end
+'''
\ No newline at end of file
diff --git a/cloud-service/tests/it_tests.rs b/cloud-service/tests/it_tests.rs
index 6c053e70..7e6aa5eb 100644
--- a/cloud-service/tests/it_tests.rs
+++ b/cloud-service/tests/it_tests.rs
@@ -19,9 +19,9 @@ use golem_common::model::{PlanId, ProjectGrantId, ProjectPolicyId, TokenId};
 use golem_service_base::db;
 use golem_service_base::migration::{Migrations, MigrationsDir};
 use std::collections::HashSet;
-use std::path::{Path, PathBuf};
+use std::path::Path;
 use std::sync::Arc;
-use std::{env, vec};
+use std::vec;
 use testcontainers::runners::AsyncRunner;
 use testcontainers::{ContainerAsync, ImageExt};
 use testcontainers_modules::postgres::Postgres;
@@ -79,9 +79,6 @@ async fn start_docker_postgres() -> (CloudServiceConfig, ContainerAsync<Postgres
         "/tmp/golem/components",
     );
 
-    env::set_current_dir(PathBuf::from(env!("CARGO_MANIFEST_DIR")))
-        .expect("Failed to set current directory");
-
     let config = make_config_loader()
         .load_or_dump_config()
         .expect("Failed to load config");
@@ -568,20 +565,14 @@ struct SqliteDb {
 impl Default for SqliteDb {
     fn default() -> Self {
         Self {
-            db_path: format!(
-                "{}/golem-{}.db",
-                env::temp_dir().as_path().display(),
-                Uuid::new_v4()
-            ),
+            db_path: format!("/tmp/golem-{}.db", Uuid::new_v4()),
         }
     }
 }
 
 impl Drop for SqliteDb {
     fn drop(&mut self) {
-        while std::fs::remove_file(&self.db_path).is_err() {
-            std::thread::sleep(std::time::Duration::from_millis(100));
-        }
+        std::fs::remove_file(&self.db_path).unwrap();
     }
 }
 
@@ -622,9 +613,6 @@ pub async fn test_sqlite_db() {
         "/tmp/golem/components",
     );
 
-    env::set_current_dir(PathBuf::from(env!("CARGO_MANIFEST_DIR")))
-        .expect("Failed to set current directory");
-
     let config = make_config_loader()
         .load_or_dump_config()
         .expect("Failed to load config");
diff --git a/golem-api-grpc/build.rs b/golem-api-grpc/build.rs
index 353e032a..acae49e9 100644
--- a/golem-api-grpc/build.rs
+++ b/golem-api-grpc/build.rs
@@ -1,124 +1,121 @@
 use cargo_metadata::MetadataCommand;
+use miette::miette;
+use protox::prost::Message;
 use std::env;
 use std::path::PathBuf;
 
 fn main() -> Result<(), Box<dyn std::error::Error>> {
-    let out_dir = PathBuf::from(env::var("OUT_DIR").unwrap());
-
     let wasm_rpc_root = find_package_root("golem-wasm-rpc");
     let wasm_ast_root = find_package_root("golem-wasm-ast");
 
-    tonic_build::configure()
-        .file_descriptor_set_path(out_dir.join("services.bin"))
+    let file_descriptors = protox::compile(
+        [
+            "proto/golem/account/account.proto",
+            "proto/golem/account/account_data.proto",
+            "proto/golem/account/v1/account_error.proto",
+            "proto/golem/account/v1/account_service.proto",
+            "proto/golem/apidefinition/api_definition.proto",
+            "proto/golem/auth/account_action.proto",
+            "proto/golem/auth/project_action.proto",
+            "proto/golem/auth/v1/auth_error.proto",
+            "proto/golem/auth/v1/auth_service.proto",
+            "proto/golem/common/account_id.proto",
+            "proto/golem/common/empty.proto",
+            "proto/golem/common/error_body.proto",
+            "proto/golem/common/plugin_installation_id.proto",
+            "proto/golem/common/project_id.proto",
+            "proto/golem/common/resource_limits.proto",
+            "proto/golem/common/uuid.proto",
+            "proto/golem/component/component.proto",
+            "proto/golem/component/component_constraints.proto",
+            "proto/golem/component/component_id.proto",
+            "proto/golem/component/component_metadata.proto",
+            "proto/golem/component/export.proto",
+            "proto/golem/component/export_function.proto",
+            "proto/golem/component/export_instance.proto",
+            "proto/golem/component/function_constraint.proto",
+            "proto/golem/component/function_parameter.proto",
+            "proto/golem/component/function_result.proto",
+            "proto/golem/component/plugin_definition.proto",
+            "proto/golem/component/producer_field.proto",
+            "proto/golem/component/producers.proto",
+            "proto/golem/component/v1/agent_types_service.proto",
+            "proto/golem/component/v1/component_error.proto",
+            "proto/golem/component/v1/component_service.proto",
+            "proto/golem/component/v1/plugin_service.proto",
+            "proto/golem/component/versioned_component_id.proto",
+            "proto/golem/component/versioned_name.proto",
+            "proto/golem/componentcompilation/v1/component_compilation_service.proto",
+            "proto/golem/limit/v1/batch_update_resource_limits.proto",
+            "proto/golem/limit/v1/limits_error.proto",
+            "proto/golem/limit/v1/limits_service.proto",
+            "proto/golem/project/project.proto",
+            "proto/golem/project/project_data.proto",
+            "proto/golem/project/project_type.proto",
+            "proto/golem/project/v1/project_error.proto",
+            "proto/golem/project/v1/project_service.proto",
+            "proto/golem/rib/compiler_output.proto",
+            "proto/golem/rib/expr.proto",
+            "proto/golem/rib/function_name.proto",
+            "proto/golem/rib/instance_type.proto",
+            "proto/golem/rib/ir.proto",
+            "proto/golem/rib/rib_byte_code.proto",
+            "proto/golem/rib/rib_input.proto",
+            "proto/golem/rib/rib_output.proto",
+            "proto/golem/rib/type_name.proto",
+            "proto/golem/rib/worker_functions_in_rib.proto",
+            "proto/golem/shardmanager/pod.proto",
+            "proto/golem/shardmanager/routing_table.proto",
+            "proto/golem/shardmanager/routing_table_entry.proto",
+            "proto/golem/shardmanager/shard_id.proto",
+            "proto/golem/shardmanager/v1/shard_manager_error.proto",
+            "proto/golem/shardmanager/v1/shard_manager_service.proto",
+            "proto/golem/token/create_token_dto.proto",
+            "proto/golem/token/token.proto",
+            "proto/golem/token/token_id.proto",
+            "proto/golem/token/token_secret.proto",
+            "proto/golem/token/unsafe_token.proto",
+            "proto/golem/token/v1/token_error.proto",
+            "proto/golem/token/v1/token_service.proto",
+            "proto/golem/worker/complete_parameters.proto",
+            "proto/golem/worker/idempotency_key.proto",
+            "proto/golem/worker/invoke_parameters.proto",
+            "proto/golem/worker/invoke_result.proto",
+            "proto/golem/worker/log_event.proto",
+            "proto/golem/worker/promise_id.proto",
+            "proto/golem/worker/public_oplog.proto",
+            "proto/golem/worker/update_mode.proto",
+            "proto/golem/worker/v1/worker_error.proto",
+            "proto/golem/worker/v1/worker_execution_error.proto",
+            "proto/golem/worker/v1/worker_service.proto",
+            "proto/golem/worker/wasi_config_vars.proto",
+            "proto/golem/worker/worker_error.proto",
+            "proto/golem/worker/worker_filter.proto",
+            "proto/golem/worker/worker_id.proto",
+            "proto/golem/worker/worker_metadata.proto",
+            "proto/golem/worker/worker_status.proto",
+            "proto/golem/workerexecutor/v1/worker_executor.proto",
+            "proto/grpc/health/v1/health.proto",
+        ],
+        [
+            &format!("{wasm_rpc_root}/proto"),
+            &format!("{wasm_ast_root}/proto"),
+            &"proto".to_string(),
+        ],
+    )?;
+
+    let out_dir = PathBuf::from(env::var("OUT_DIR").unwrap());
+    let fd_path = out_dir.join("services.bin");
+
+    std::fs::write(fd_path, file_descriptors.encode_to_vec())?;
+
+    tonic_prost_build::configure()
+        .build_server(true)
         .extern_path(".wasm.rpc", "::golem_wasm_rpc::protobuf")
         .extern_path(".wasm.ast", "::golem_wasm_ast::analysis::protobuf")
         .include_file("mod.rs")
-        .compile_protos(
-            &[
-                "proto/golem/account/account.proto",
-                "proto/golem/account/account_data.proto",
-                "proto/golem/account/v1/account_error.proto",
-                "proto/golem/account/v1/account_service.proto",
-                "proto/golem/accountsummary/v1/account_summary.proto",
-                "proto/golem/accountsummary/v1/account_summary_error.proto",
-                "proto/golem/accountsummary/v1/account_summary_service.proto",
-                "proto/golem/apidefinition/api_definition.proto",
-                "proto/golem/apidefinition/v1/api_definition_service.proto",
-                "proto/golem/auth/account_action.proto",
-                "proto/golem/auth/v1/auth_error.proto",
-                "proto/golem/auth/v1/auth_service.proto",
-                "proto/golem/common/account_id.proto",
-                "proto/golem/common/empty.proto",
-                "proto/golem/common/error_body.proto",
-                "proto/golem/common/plugin_installation_id.proto",
-                "proto/golem/common/project_id.proto",
-                "proto/golem/common/resource_limits.proto",
-                "proto/golem/common/uuid.proto",
-                "proto/golem/component/component.proto",
-                "proto/golem/component/component_constraints.proto",
-                "proto/golem/component/component_id.proto",
-                "proto/golem/component/component_metadata.proto",
-                "proto/golem/component/export.proto",
-                "proto/golem/component/export_function.proto",
-                "proto/golem/component/export_instance.proto",
-                "proto/golem/component/function_constraint.proto",
-                "proto/golem/component/function_parameter.proto",
-                "proto/golem/component/function_result.proto",
-                "proto/golem/component/plugin_definition.proto",
-                "proto/golem/component/producer_field.proto",
-                "proto/golem/component/producers.proto",
-                "proto/golem/component/v1/component_error.proto",
-                "proto/golem/component/v1/component_service.proto",
-                "proto/golem/component/v1/plugin_service.proto",
-                "proto/golem/component/versioned_component_id.proto",
-                "proto/golem/component/versioned_name.proto",
-                "proto/golem/componentcompilation/v1/component_compilation_service.proto",
-                "proto/golem/limit/v1/batch_update_resource_limits.proto",
-                "proto/golem/limit/v1/limits_error.proto",
-                "proto/golem/limit/v1/limits_service.proto",
-                "proto/golem/login/o_auth2_data.proto",
-                "proto/golem/login/v1/login_error.proto",
-                "proto/golem/login/v1/login_service.proto",
-                "proto/golem/plan/plan.proto",
-                "proto/golem/plan/plan_data.proto",
-                "proto/golem/plan/plan_id.proto",
-                "proto/golem/project/project.proto",
-                "proto/golem/project/project_data.proto",
-                "proto/golem/project/project_type.proto",
-                "proto/golem/project/v1/project_error.proto",
-                "proto/golem/project/v1/project_service.proto",
-                "proto/golem/projectgrant/project_grant_id.proto",
-                "proto/golem/projectpolicy/project_action.proto",
-                "proto/golem/projectpolicy/project_policy_id.proto",
-                "proto/golem/rib/compiler_output.proto",
-                "proto/golem/rib/expr.proto",
-                "proto/golem/rib/function_name.proto",
-                "proto/golem/rib/instance_type.proto",
-                "proto/golem/rib/ir.proto",
-                "proto/golem/rib/rib_byte_code.proto",
-                "proto/golem/rib/rib_input.proto",
-                "proto/golem/rib/rib_output.proto",
-                "proto/golem/rib/type_name.proto",
-                "proto/golem/rib/worker_functions_in_rib.proto",
-                "proto/golem/shardmanager/pod.proto",
-                "proto/golem/shardmanager/routing_table.proto",
-                "proto/golem/shardmanager/routing_table_entry.proto",
-                "proto/golem/shardmanager/shard_id.proto",
-                "proto/golem/shardmanager/v1/shard_manager_error.proto",
-                "proto/golem/shardmanager/v1/shard_manager_service.proto",
-                "proto/golem/token/create_token_dto.proto",
-                "proto/golem/token/token.proto",
-                "proto/golem/token/token_id.proto",
-                "proto/golem/token/token_secret.proto",
-                "proto/golem/token/unsafe_token.proto",
-                "proto/golem/token/v1/token_error.proto",
-                "proto/golem/token/v1/token_service.proto",
-                "proto/golem/worker/complete_parameters.proto",
-                "proto/golem/worker/idempotency_key.proto",
-                "proto/golem/worker/invoke_parameters.proto",
-                "proto/golem/worker/invoke_result.proto",
-                "proto/golem/worker/log_event.proto",
-                "proto/golem/worker/promise_id.proto",
-                "proto/golem/worker/public_oplog.proto",
-                "proto/golem/worker/update_mode.proto",
-                "proto/golem/worker/v1/worker_error.proto",
-                "proto/golem/worker/v1/worker_execution_error.proto",
-                "proto/golem/worker/v1/worker_service.proto",
-                "proto/golem/worker/worker_error.proto",
-                "proto/golem/worker/worker_filter.proto",
-                "proto/golem/worker/worker_id.proto",
-                "proto/golem/worker/worker_metadata.proto",
-                "proto/golem/worker/worker_status.proto",
-                "proto/golem/workerexecutor/v1/worker_executor.proto",
-                "proto/grpc/health/v1/health.proto",
-            ],
-            &[
-                &format!("{wasm_rpc_root}/proto"),
-                &format!("{wasm_ast_root}/proto"),
-                &"proto".to_string(),
-            ],
-        )
-        .unwrap();
+        .compile_fds(file_descriptors)
+        .map_err(|e| miette!(e))?;
 
     Ok(())
 }
@@ -128,6 +125,10 @@ fn find_package_root(name: &str) -> String {
         .manifest_path("./Cargo.toml")
         .exec()
         .unwrap();
-    let package = metadata.packages.iter().find(|p| p.name == name).unwrap();
+    let package = metadata
+        .packages
+        .iter()
+        .find(|p| p.name.as_str() == name)
+        .unwrap();
     package.manifest_path.parent().unwrap().to_string()
 }
diff --git a/golem-api-grpc/proto/golem/auth/v1/auth_service.proto b/golem-api-grpc/proto/golem/auth/v1/auth_service.proto
index 90ff12a4..69b5a48d 100644
--- a/golem-api-grpc/proto/golem/auth/v1/auth_service.proto
+++ b/golem-api-grpc/proto/golem/auth/v1/auth_service.proto
@@ -5,10 +5,8 @@ package golem.auth.v1;
 import public "golem/auth/account_action.proto";
 import public "golem/common/account_id.proto";
 import public "golem/common/empty.proto";
-import public "golem/project/project.proto";
-import public "golem/project/v1/project_error.proto";
 import public "golem/common/project_id.proto";
-import public "golem/projectpolicy/project_action.proto";
+import public "golem/auth/project_action.proto";
 import public "golem/auth/v1/auth_error.proto";
 
 service CloudAuthService {
@@ -34,7 +32,7 @@ message GetAccountSuccessResponse {
 
 message AuthorizeProjectActionRequest {
   golem.common.ProjectId projectId = 1;
-  golem.projectpolicy.ProjectAction action = 2;
+  golem.auth.ProjectAction action = 2;
 }
 
 message AuthorizeProjectActionResponse {
diff --git a/golem-api-grpc/proto/golem/worker/worker_metadata.proto b/golem-api-grpc/proto/golem/worker/worker_metadata.proto
index a78c7d56..dc1b0afd 100644
--- a/golem-api-grpc/proto/golem/worker/worker_metadata.proto
+++ b/golem-api-grpc/proto/golem/worker/worker_metadata.proto
@@ -3,14 +3,18 @@ syntax = "proto3";
 package golem.worker;
 
 import "golem/common/account_id.proto";
+import "golem/common/project_id.proto";
 import "golem/common/plugin_installation_id.proto";
+import "golem/component/agent.proto";
 import "golem/worker/worker_id.proto";
 import "golem/worker/worker_status.proto";
+import "golem/worker/wasi_config_vars.proto";
 import "google/protobuf/timestamp.proto";
+import "wasm/rpc/value_and_type.proto";
 
 message WorkerMetadata {
   WorkerId worker_id = 1;
-  golem.common.AccountId account_id = 2;
+  golem.common.AccountId created_by = 2;
   repeated string args = 3;
   map<string, string> env = 4;
   WorkerStatus status = 5;
@@ -22,10 +26,12 @@ message WorkerMetadata {
   optional string last_error = 11;
   uint64 component_size = 12;
   uint64 total_linear_memory_size = 13;
-  map<uint64, ResourceMetadata> owned_resources = 14;
+  repeated ResourceDescription owned_resources = 14;
   repeated golem.common.PluginInstallationId active_plugins = 15;
   repeated OplogRegion skipped_regions = 16;
   repeated OplogRegion deleted_regions = 17;
+  golem.common.ProjectId project_id = 18;
+  WasiConfigVars wasi_config_vars = 19;
 }
 
 message UpdateRecord {
@@ -48,17 +54,14 @@ message FailedUpdate {
 message SuccessfulUpdate {
 }
 
-message ResourceMetadata {
+message ResourceDescription {
   google.protobuf.Timestamp created_at = 1;
-  optional IndexedResourceMetadata indexed = 2;
-}
-
-message IndexedResourceMetadata {
-  string resource_name = 1;
-  repeated string resource_params = 2;
+  uint64 resource_id = 2;
+  string resource_owner = 3;
+  string resource_name = 4;
 }
 
 message OplogRegion {
   uint64 start = 1;
   uint64 end = 2;
-}
\ No newline at end of file
+}
diff --git a/golem-client/build.rs b/golem-client/build.rs
index 1540bcbe..69ddfc63 100644
--- a/golem-client/build.rs
+++ b/golem-client/build.rs
@@ -36,6 +36,13 @@ fn generate(yaml_path: PathBuf, out_dir: OsString) {
         false,
         true,
         &[
+            ("AgentType", "golem_common::model::agent::AgentType"),
+            ("DataSchema", "golem_common::model::agent::DataSchema"),
+            ("AgentInstanceKey", "golem_common::model::AgentInstanceKey"),
+            (
+                "AgentInstanceDescription",
+                "golem_common::model::AgentInstanceDescription",
+            ),
             ("AnalysedExport", "golem_wasm_ast::analysis::AnalysedExport"),
             ("AnalysedType", "golem_wasm_ast::analysis::AnalysedType"),
             ("PluginScope", "golem_common::model::plugin::PluginScope"),
@@ -48,6 +55,7 @@ fn generate(yaml_path: PathBuf, out_dir: OsString) {
                 "golem_common::model::ComponentFilePathWithPermissionsList",
             ),
             ("ComponentType", "golem_common::model::ComponentType"),
+            ("DataValue", "golem_common::model::agent::DataValue"),
             ("Empty", "golem_common::model::Empty"),
             (
                 "InitialComponentFile",
@@ -55,6 +63,14 @@ fn generate(yaml_path: PathBuf, out_dir: OsString) {
             ),
             ("ErrorBody", "golem_common::model::error::ErrorBody"),
             ("ErrorsBody", "golem_common::model::error::ErrorsBody"),
+            (
+                "ExportedResourceInstanceKey",
+                "golem_common::model::ExportedResourceInstanceKey",
+            ),
+            (
+                "ExportedResourceInstanceDescription",
+                "golem_common::model::ExportedResourceInstanceDescription",
+            ),
             ("GolemError", "golem_common::model::error::GolemError"),
             (
                 "PluginInstallationAction",
@@ -78,25 +94,38 @@ fn generate(yaml_path: PathBuf, out_dir: OsString) {
                 "PublicOplogEntry",
                 "golem_common::model::public_oplog::PublicOplogEntry",
             ),
-            ("ShardId", "golem_common::model::ShardId"),
             (
-                "TypeAnnotatedValue",
-                "golem_wasm_rpc::protobuf::type_annotated_value::TypeAnnotatedValue",
+                "RegisteredAgentType",
+                "golem_common::model::agent::RegisteredAgentType",
             ),
+            ("ShardId", "golem_common::model::ShardId"),
+            ("ValueAndType", "golem_wasm_rpc::ValueAndType"),
             (
                 "ValueAndOptionalType",
-                "golem_wasm_rpc::json::OptionallyTypeAnnotatedValueJson",
+                "golem_wasm_rpc::json::OptionallyValueAndTypeJson",
+            ),
+            (
+                "WasiConfigVarsEntry",
+                "golem_common::model::worker::WasiConfigVarsEntry",
             ),
             (
                 "WasmRpcTarget",
                 "golem_common::model::component_metadata::WasmRpcTarget",
             ),
+            (
+                "WorkerCreationRequest",
+                "golem_common::model::worker::WorkerCreationRequest",
+            ),
             ("WorkerFilter", "golem_common::model::WorkerFilter"),
             ("WorkerId", "golem_common::model::WorkerId"),
             (
                 "WorkerBindingType",
                 "golem_common::model::WorkerBindingType",
             ),
+            (
+                "WorkerResourceDescription",
+                "golem_common::model::WorkerResourceDescription",
+            ),
             ("WorkerStatus", "golem_common::model::WorkerStatus"),
         ],
         &["/v1/components/{component_id}/workers/{worker_name}/connect"],
diff --git a/golem-common/src/base_model.rs b/golem-common/src/base_model.rs
index 45d5bc76..d4e2721b 100644
--- a/golem-common/src/base_model.rs
+++ b/golem-common/src/base_model.rs
@@ -14,7 +14,6 @@
 
 use crate::newtype_uuid;
 use bincode::{Decode, Encode};
-use std::collections::HashSet;
 use std::fmt::{Display, Formatter};
 use std::str::FromStr;
 use uuid::Uuid;
@@ -33,15 +32,9 @@ newtype_uuid!(
     golem_api_grpc::proto::golem::common::PluginInstallationId
 );
 
-newtype_uuid!(PlanId, golem_api_grpc::proto::golem::plan::PlanId);
-newtype_uuid!(
-    ProjectGrantId,
-    golem_api_grpc::proto::golem::projectgrant::ProjectGrantId
-);
-newtype_uuid!(
-    ProjectPolicyId,
-    golem_api_grpc::proto::golem::projectpolicy::ProjectPolicyId
-);
+newtype_uuid!(PlanId, golem_api_grpc::proto::golem::account::PlanId);
+newtype_uuid!(ProjectGrantId);
+newtype_uuid!(ProjectPolicyId);
 newtype_uuid!(TokenId, golem_api_grpc::proto::golem::token::TokenId);
 
 #[derive(Clone, Copy, Debug, Eq, PartialEq, PartialOrd, Ord, Hash, Encode, Decode)]
@@ -129,14 +122,6 @@ impl WorkerId {
         format!("urn:worker:{}/{}", self.component_id, self.worker_name)
     }
 
-    /// The dual of `TargetWorkerId::into_worker_id`
-    pub fn into_target_worker_id(self) -> TargetWorkerId {
-        TargetWorkerId {
-            component_id: self.component_id,
-            worker_name: Some(self.worker_name),
-        }
-    }
-
     pub fn validate_worker_name(name: &str) -> Result<(), &'static str> {
         let length = name.len();
         if !(1..=512).contains(&length) {
@@ -205,118 +190,6 @@ impl golem_wasm_rpc::IntoValue for WorkerId {
     }
 }
 
-#[derive(Clone, Debug, Eq, PartialEq, Hash, Encode, Decode)]
-#[cfg_attr(feature = "model", derive(serde::Serialize, serde::Deserialize))]
-pub struct TargetWorkerId {
-    pub component_id: ComponentId,
-    pub worker_name: Option<String>,
-}
-
-impl TargetWorkerId {
-    /// Converts a `TargetWorkerId` to a `WorkerId` if the worker name is specified
-    pub fn try_into_worker_id(self) -> Option<WorkerId> {
-        self.worker_name.map(|worker_name| WorkerId {
-            component_id: self.component_id,
-            worker_name,
-        })
-    }
-
-    /// Converts a `TargetWorkerId` to a `WorkerId`. If the worker name was not specified,
-    /// it generates a new unique one, and if the `force_in_shard` set is not empty, it guarantees
-    /// that the generated worker ID will belong to one of the provided shards.
-    ///
-    /// If the worker name was specified, `force_in_shard` is ignored.
-    pub fn into_worker_id(
-        self,
-        force_in_shard: &HashSet<ShardId>,
-        number_of_shards: usize,
-    ) -> WorkerId {
-        let TargetWorkerId {
-            component_id,
-            worker_name,
-        } = self;
-        match worker_name {
-            Some(worker_name) => WorkerId {
-                component_id,
-                worker_name,
-            },
-            None => {
-                if force_in_shard.is_empty() || number_of_shards == 0 {
-                    let worker_name = Uuid::new_v4().to_string();
-                    WorkerId {
-                        component_id,
-                        worker_name,
-                    }
-                } else {
-                    let mut current = Uuid::new_v4().to_u128_le();
-                    loop {
-                        let uuid = Uuid::from_u128_le(current);
-                        let worker_name = uuid.to_string();
-                        let worker_id = WorkerId {
-                            component_id: component_id.clone(),
-                            worker_name,
-                        };
-                        let shard_id = ShardId::from_worker_id(&worker_id, number_of_shards);
-                        if force_in_shard.contains(&shard_id) {
-                            return worker_id;
-                        }
-                        current += 1;
-                    }
-                }
-            }
-        }
-    }
-
-    // NOTE: Deprecated, to be removed once the wasm-rpc constructor is changed to accept worker-id
-    pub fn parse_worker_urn(urn: &str) -> Option<TargetWorkerId> {
-        if !urn.starts_with("urn:worker:") {
-            None
-        } else {
-            let remaining = &urn[11..];
-            let parts: Vec<&str> = remaining.split('/').collect();
-            match parts.len() {
-                2 => {
-                    let component_id = ComponentId::from_str(parts[0]).ok()?;
-                    let worker_name = parts[1];
-                    Some(TargetWorkerId {
-                        component_id,
-                        worker_name: Some(worker_name.to_string()),
-                    })
-                }
-                1 => {
-                    let component_id = ComponentId::from_str(parts[0]).ok()?;
-                    Some(TargetWorkerId {
-                        component_id,
-                        worker_name: None,
-                    })
-                }
-                _ => None,
-            }
-        }
-    }
-}
-
-impl Display for TargetWorkerId {
-    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
-        match &self.worker_name {
-            Some(worker_name) => write!(f, "{}/{}", self.component_id, worker_name),
-            None => write!(f, "{}/*", self.component_id),
-        }
-    }
-}
-
-impl From<WorkerId> for TargetWorkerId {
-    fn from(value: WorkerId) -> Self {
-        value.into_target_worker_id()
-    }
-}
-
-impl From<&WorkerId> for TargetWorkerId {
-    fn from(value: &WorkerId) -> Self {
-        value.clone().into_target_worker_id()
-    }
-}
-
 #[derive(Clone, Debug, Eq, PartialEq, Hash, Encode, Decode)]
 #[cfg_attr(
     feature = "model",
@@ -373,6 +246,11 @@ impl OplogIndex {
     pub fn range_end(&self, count: u64) -> OplogIndex {
         OplogIndex(self.0 + count - 1)
     }
+
+    /// Check whether the oplog index is not None.
+    pub fn is_defined(&self) -> bool {
+        self.0 > 0
+    }
 }
 
 impl Display for OplogIndex {
@@ -386,35 +264,3 @@ impl From<OplogIndex> for u64 {
         value.0
     }
 }
-
-#[cfg(test)]
-mod tests {
-    use super::{ComponentId, TargetWorkerId};
-    use test_r::test;
-
-    #[test]
-    fn test_parse_worker_urn() {
-        let component_id = ComponentId::new_v4();
-
-        fn check(urn: String, expected: Option<TargetWorkerId>) {
-            assert_eq!(TargetWorkerId::parse_worker_urn(&urn), expected, "{urn}");
-        }
-
-        check(
-            format!("urn:worker:{component_id}"),
-            Some(TargetWorkerId {
-                component_id: component_id.clone(),
-                worker_name: None,
-            }),
-        );
-        check(
-            format!("urn:worker:{component_id}/worker1"),
-            Some(TargetWorkerId {
-                component_id: component_id.clone(),
-                worker_name: Some("worker1".to_string()),
-            }),
-        );
-        check(format!("urn:worker:{component_id}/worker1/worker2"), None);
-        check(format!("urn:component:{component_id}"), None);
-    }
-}
diff --git a/golem-common/src/config.rs b/golem-common/src/config.rs
index ff7bed27..00020b11 100644
--- a/golem-common/src/config.rs
+++ b/golem-common/src/config.rs
@@ -13,10 +13,12 @@
 // limitations under the License.
 
 use crate::model::RetryConfig;
+use crate::SafeDisplay;
 use figment::providers::{Env, Format, Serialized, Toml};
 use figment::value::Value;
 use figment::Figment;
 use serde::{Deserialize, Serialize};
+use std::fmt::Write;
 use std::path::{Path, PathBuf};
 use std::time::Duration;
 use url::Url;
@@ -24,8 +26,8 @@ use url::Url;
 const ENV_VAR_PREFIX: &str = "GOLEM__";
 const ENV_VAR_NESTED_SEPARATOR: &str = "__";
 
-pub trait ConfigLoaderConfig: Default + Serialize + Deserialize<'static> {}
-impl<T: Default + Serialize + Deserialize<'static>> ConfigLoaderConfig for T {}
+pub trait ConfigLoaderConfig: Default + Serialize + Deserialize<'static> + SafeDisplay {}
+impl<T: Default + Serialize + Deserialize<'static> + SafeDisplay> ConfigLoaderConfig for T {}
 
 pub type ConfigExample<T> = (&'static str, T);
 
@@ -85,7 +87,7 @@ impl<T: ConfigLoaderConfig> ConfigLoader<T> {
     }
 
     pub fn load(&self) -> figment::Result<T> {
-        self.figment().extract()
+        self.figment().extract::<T>()
     }
 
     fn default_dump_source(&self) -> dump::Source {
@@ -362,6 +364,27 @@ impl RedisConfig {
     }
 }
 
+impl SafeDisplay for RedisConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "host: {}", self.host);
+        let _ = writeln!(&mut result, "port: {}", self.port);
+        let _ = writeln!(&mut result, "database: {}", self.database);
+        let _ = writeln!(&mut result, "tracing: {}", self.tracing);
+        let _ = writeln!(&mut result, "pool size: {}", self.pool_size);
+        if !self.key_prefix.is_empty() {
+            let _ = writeln!(&mut result, "key prefix: {}", self.key_prefix);
+        }
+        if self.username.is_some() {
+            let _ = writeln!(&mut result, "username: ****");
+        }
+        if self.password.is_some() {
+            let _ = writeln!(&mut result, "password: ****");
+        }
+        result
+    }
+}
+
 impl Default for RedisConfig {
     fn default() -> Self {
         Self {
@@ -427,6 +450,23 @@ pub enum DbConfig {
     Sqlite(DbSqliteConfig),
 }
 
+impl SafeDisplay for DbConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        match self {
+            DbConfig::Postgres(postgres) => {
+                let _ = writeln!(&mut result, "postgres:");
+                let _ = writeln!(&mut result, "{}", postgres.to_safe_string_indented());
+            }
+            DbConfig::Sqlite(sqlite) => {
+                let _ = writeln!(&mut result, "sqlite:");
+                let _ = writeln!(&mut result, "{}", sqlite.to_safe_string_indented());
+            }
+        }
+        result
+    }
+}
+
 impl Default for DbConfig {
     fn default() -> Self {
         DbConfig::Sqlite(DbSqliteConfig {
@@ -466,6 +506,15 @@ impl DbSqliteConfig {
     }
 }
 
+impl SafeDisplay for DbSqliteConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "database: {}", self.database);
+        let _ = writeln!(&mut result, "max connections: {}", self.max_connections);
+        result
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct DbPostgresConfig {
     pub host: String,
@@ -488,3 +537,19 @@ impl DbPostgresConfig {
             .password(&self.password)
     }
 }
+
+impl SafeDisplay for DbPostgresConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "host: {}", self.host);
+        let _ = writeln!(&mut result, "port: {}", self.port);
+        let _ = writeln!(&mut result, "database: {}", self.database);
+        let _ = writeln!(&mut result, "username: ****");
+        let _ = writeln!(&mut result, "password: ****");
+        let _ = writeln!(&mut result, "max connections: {}", self.max_connections);
+        if let Some(schema) = &self.schema {
+            let _ = writeln!(&mut result, "schema: {}", schema);
+        }
+        result
+    }
+}
diff --git a/golem-common/src/model/auth.rs b/golem-common/src/model/auth.rs
index 1bd84667..0b5631b9 100644
--- a/golem-common/src/model/auth.rs
+++ b/golem-common/src/model/auth.rs
@@ -245,7 +245,7 @@ pub enum ProjectAction {
     UpdateApiDefinition = 13,
     DeleteApiDefinition = 14,
     DeleteProject = 15,
-    ViewProject = 161,
+    ViewProject = 16,
     ViewPluginInstallations = 17,
     CreatePluginInstallation = 18,
     UpdatePluginInstallation = 19,
@@ -261,6 +261,7 @@ pub enum ProjectAction {
     CreatePluginDefinition = 29,
     UpdatePluginDefinition = 30,
     DeletePluginDefinition = 31,
+    ExportApiDefinition = 32,
 }
 
 impl From<ProjectAction> for i32 {
@@ -311,6 +312,7 @@ impl Display for ProjectAction {
             Self::CreatePluginDefinition => write!(f, "CreatePluginDefinition"),
             Self::UpdatePluginDefinition => write!(f, "UpdatePluginDefinition"),
             Self::DeletePluginDefinition => write!(f, "DeletePluginDefinition"),
+            Self::ExportApiDefinition => write!(f, "ExportApiDefinition"),
         }
     }
 }
@@ -359,6 +361,7 @@ pub enum ProjectPermission {
     CreatePluginDefinition,
     UpdatePluginDefinition,
     DeletePluginDefinition,
+    ExportApiDefinition,
 }
 
 impl TryFrom<ProjectAction> for ProjectPermission {
@@ -399,6 +402,7 @@ impl TryFrom<ProjectAction> for ProjectPermission {
             ProjectAction::ViewProject | ProjectAction::BatchUpdatePluginInstallations => {
                 Err(format!("Unknown project permission: {value:?}"))
             }
+            ProjectAction::ExportApiDefinition => Ok(Self::ExportApiDefinition),
         }
     }
 }
@@ -442,6 +446,7 @@ impl Display for ProjectPermission {
             Self::CreatePluginDefinition => write!(f, "CreatePluginDefinition"),
             Self::UpdatePluginDefinition => write!(f, "UpdatePluginDefinition"),
             Self::DeletePluginDefinition => write!(f, "DeletePluginDefinition"),
+            Self::ExportApiDefinition => write!(f, "ExportApiDefinition"),
         }
     }
 }
@@ -481,6 +486,7 @@ impl FromStr for ProjectPermission {
             "CreatePluginDefinition" => Ok(Self::CreatePluginDefinition),
             "UpdatePluginDefinition" => Ok(Self::UpdatePluginDefinition),
             "DeletePluginDefinition" => Ok(Self::DeletePluginDefinition),
+            "ExportApiDefinition" => Ok(Self::ExportApiDefinition),
             _ => Err(format!("Unknown project permission: {s}")),
         }
     }
@@ -518,7 +524,7 @@ pub struct ProjectAuthorisedActions {
 #[cfg(feature = "protobuf")]
 mod protobuf {
     use super::AccountAction;
-    use super::ProjectAction;
+
     use super::TokenSecret;
 
     impl TryFrom<golem_api_grpc::proto::golem::token::TokenSecret> for TokenSecret {
@@ -556,22 +562,6 @@ mod protobuf {
             Self::try_from(value as i32).expect("Encoding AccountAction as protobuf")
         }
     }
-
-    impl TryFrom<golem_api_grpc::proto::golem::projectpolicy::ProjectAction> for ProjectAction {
-        type Error = String;
-
-        fn try_from(
-            value: golem_api_grpc::proto::golem::projectpolicy::ProjectAction,
-        ) -> Result<Self, Self::Error> {
-            Self::try_from(value as i32)
-        }
-    }
-
-    impl From<ProjectAction> for golem_api_grpc::proto::golem::projectpolicy::ProjectAction {
-        fn from(value: ProjectAction) -> Self {
-            Self::try_from(value as i32).expect("Encoding ProjectAction as protobuf")
-        }
-    }
 }
 
 #[cfg(test)]
diff --git a/golem-common/src/model/component_metadata.rs b/golem-common/src/model/component_metadata.rs
index 50d3d594..c1f20ca1 100644
--- a/golem-common/src/model/component_metadata.rs
+++ b/golem-common/src/model/component_metadata.rs
@@ -12,12 +12,19 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
+use crate::model::agent::{AgentConstructor, AgentMethod, AgentType};
 use crate::model::base64::Base64;
 use crate::model::ComponentType;
 use crate::{virtual_exports, SafeDisplay};
-use bincode::{Decode, Encode};
+use bincode::de::BorrowDecoder;
+use bincode::enc::Encoder;
+use bincode::error::{DecodeError, EncodeError};
+use bincode::{BorrowDecode, Decode, Encode};
 use golem_wasm_ast::analysis::wit_parser::WitAnalysisContext;
-use golem_wasm_ast::analysis::AnalysedFunctionParameter;
+use golem_wasm_ast::analysis::{
+    AnalysedFunctionParameter, AnalysedInstance, AnalysedResourceId, AnalysedResourceMode,
+    AnalysedType, TypeHandle,
+};
 use golem_wasm_ast::core::Mem;
 use golem_wasm_ast::metadata::Producers as WasmAstProducers;
 use golem_wasm_ast::{
@@ -25,16 +32,294 @@ use golem_wasm_ast::{
     component::Component,
     IgnoreAllButMetadata,
 };
-use rib::ParsedFunctionSite;
-use serde::{Deserialize, Serialize};
+use heck::ToKebabCase;
+use rib::{ParsedFunctionName, ParsedFunctionReference, ParsedFunctionSite, SemVer};
+use serde::{Deserialize, Serialize, Serializer};
 use std::collections::HashMap;
 use std::fmt::{self, Debug, Display, Formatter};
+use std::sync::Arc;
+use tokio::sync::Mutex;
 
-#[derive(Clone, PartialEq, Eq, Serialize, Deserialize, Encode, Decode)]
-#[cfg_attr(feature = "poem", derive(poem_openapi::Object))]
-#[cfg_attr(feature = "poem", oai(rename_all = "camelCase"))]
-#[serde(rename_all = "camelCase")]
+#[derive(Clone, Default)]
 pub struct ComponentMetadata {
+    data: Arc<ComponentMetadataInnerData>,
+    cache: Arc<Mutex<ComponentMetadataInnerCache>>,
+}
+
+impl ComponentMetadata {
+    pub fn analyse_component(
+        data: &[u8],
+        dynamic_linking: HashMap<String, DynamicLinkedInstance>,
+        agent_types: Vec<AgentType>,
+    ) -> Result<Self, ComponentProcessingError> {
+        let raw = RawComponentMetadata::analyse_component(data)?;
+        Ok(Self {
+            data: Arc::new(raw.into_metadata(dynamic_linking, agent_types)),
+            cache: Arc::new(Mutex::new(ComponentMetadataInnerCache::default())),
+        })
+    }
+
+    pub fn from_parts(
+        exports: Vec<AnalysedExport>,
+        memories: Vec<LinearMemory>,
+        dynamic_linking: HashMap<String, DynamicLinkedInstance>,
+        root_package_name: Option<String>,
+        root_package_version: Option<String>,
+        agent_types: Vec<AgentType>,
+    ) -> Self {
+        Self {
+            data: Arc::new(ComponentMetadataInnerData {
+                exports,
+                producers: vec![],
+                memories,
+                binary_wit: Base64(vec![]),
+                root_package_name,
+                root_package_version,
+                dynamic_linking,
+                agent_types,
+            }),
+            cache: Arc::new(Mutex::new(ComponentMetadataInnerCache::default())),
+        }
+    }
+
+    pub fn exports(&self) -> &[AnalysedExport] {
+        &self.data.exports
+    }
+
+    pub fn producers(&self) -> &[Producers] {
+        &self.data.producers
+    }
+
+    pub fn memories(&self) -> &[LinearMemory] {
+        &self.data.memories
+    }
+
+    pub fn binary_wit(&self) -> &Base64 {
+        &self.data.binary_wit
+    }
+
+    pub fn root_package_name(&self) -> &Option<String> {
+        &self.data.root_package_name
+    }
+
+    pub fn root_package_version(&self) -> &Option<String> {
+        &self.data.root_package_version
+    }
+
+    pub fn dynamic_linking(&self) -> &HashMap<String, DynamicLinkedInstance> {
+        &self.data.dynamic_linking
+    }
+
+    pub fn agent_types(&self) -> &[AgentType] {
+        &self.data.agent_types
+    }
+
+    pub fn is_agent(&self) -> bool {
+        !self.data.agent_types.is_empty()
+    }
+
+    pub async fn load_snapshot(&self) -> Result<Option<InvokableFunction>, String> {
+        self.cache.lock().await.load_snapshot(&self.data)
+    }
+
+    pub async fn save_snapshot(&self) -> Result<Option<InvokableFunction>, String> {
+        self.cache.lock().await.save_snapshot(&self.data)
+    }
+
+    pub async fn find_function(&self, name: &str) -> Result<Option<InvokableFunction>, String> {
+        self.cache.lock().await.find_function(&self.data, name)
+    }
+
+    pub async fn find_parsed_function(
+        &self,
+        parsed: &ParsedFunctionName,
+    ) -> Result<Option<InvokableFunction>, String> {
+        self.cache
+            .lock()
+            .await
+            .find_parsed_function(&self.data, parsed)
+    }
+
+    pub async fn find_agent_type(&self, agent_type: &str) -> Result<Option<AgentType>, String> {
+        self.cache
+            .lock()
+            .await
+            .find_agent_type(&self.data, agent_type)
+    }
+}
+
+impl Debug for ComponentMetadata {
+    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {
+        f.debug_struct("ComponentMetadata")
+            .field("exports", &self.data.exports)
+            .field("producers", &self.data.producers)
+            .field("memories", &self.data.memories)
+            .field("binary_wit_len", &self.data.binary_wit.len())
+            .field("root_package_name", &self.data.root_package_name)
+            .field("root_package_version", &self.data.root_package_version)
+            .field("dynamic_linking", &self.data.dynamic_linking)
+            .field("agent_types", &self.data.agent_types)
+            .finish()
+    }
+}
+
+impl PartialEq for ComponentMetadata {
+    fn eq(&self, other: &Self) -> bool {
+        self.data == other.data
+    }
+}
+
+impl Eq for ComponentMetadata {}
+
+impl Serialize for ComponentMetadata {
+    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
+    where
+        S: Serializer,
+    {
+        self.data.serialize(serializer)
+    }
+}
+
+impl<'de> Deserialize<'de> for ComponentMetadata {
+    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
+    where
+        D: serde::Deserializer<'de>,
+    {
+        let data = ComponentMetadataInnerData::deserialize(deserializer)?;
+        Ok(Self {
+            data: Arc::new(data),
+            cache: Arc::new(Mutex::new(ComponentMetadataInnerCache::default())),
+        })
+    }
+}
+
+impl Encode for ComponentMetadata {
+    fn encode<E: Encoder>(&self, encoder: &mut E) -> Result<(), EncodeError> {
+        self.data.encode(encoder)
+    }
+}
+
+impl<Context> Decode<Context> for ComponentMetadata {
+    fn decode<D: bincode::de::Decoder>(decoder: &mut D) -> Result<Self, DecodeError> {
+        let data = ComponentMetadataInnerData::decode(decoder)?;
+        Ok(Self {
+            data: Arc::new(data),
+            cache: Arc::new(Mutex::new(ComponentMetadataInnerCache::default())),
+        })
+    }
+}
+
+impl<'de, Context> BorrowDecode<'de, Context> for ComponentMetadata {
+    fn borrow_decode<D: BorrowDecoder<'de, Context = Context>>(
+        decoder: &mut D,
+    ) -> Result<Self, DecodeError> {
+        let data = ComponentMetadataInnerData::borrow_decode(decoder)?;
+        Ok(Self {
+            data: Arc::new(data),
+            cache: Arc::new(Mutex::new(ComponentMetadataInnerCache::default())),
+        })
+    }
+}
+
+#[cfg(feature = "poem")]
+impl poem_openapi::types::Type for ComponentMetadata {
+    const IS_REQUIRED: bool =
+        <ComponentMetadataInnerData as poem_openapi::types::Type>::IS_REQUIRED;
+    type RawValueType = <ComponentMetadataInnerData as poem_openapi::types::Type>::RawValueType;
+    type RawElementValueType =
+        <ComponentMetadataInnerData as poem_openapi::types::Type>::RawElementValueType;
+
+    fn name() -> std::borrow::Cow<'static, str> {
+        <ComponentMetadataInnerData as poem_openapi::types::Type>::name()
+    }
+
+    fn schema_ref() -> poem_openapi::registry::MetaSchemaRef {
+        <ComponentMetadataInnerData as poem_openapi::types::Type>::schema_ref()
+    }
+
+    fn register(registry: &mut poem_openapi::registry::Registry) {
+        <ComponentMetadataInnerData as poem_openapi::types::Type>::register(registry);
+    }
+
+    fn as_raw_value(&self) -> Option<&Self::RawValueType> {
+        <ComponentMetadataInnerData as poem_openapi::types::Type>::as_raw_value(&self.data)
+    }
+
+    fn raw_element_iter<'a>(
+        &'a self,
+    ) -> Box<dyn Iterator<Item = &'a Self::RawElementValueType> + 'a> {
+        <ComponentMetadataInnerData as poem_openapi::types::Type>::raw_element_iter(&self.data)
+    }
+}
+
+#[cfg(feature = "poem")]
+impl poem_openapi::types::IsObjectType for ComponentMetadata {}
+
+#[cfg(feature = "poem")]
+impl poem_openapi::types::ParseFromJSON for ComponentMetadata {
+    fn parse_from_json(value: Option<serde_json::Value>) -> poem_openapi::types::ParseResult<Self> {
+        let data =
+            ComponentMetadataInnerData::parse_from_json(value).map_err(|err| err.propagate())?;
+        Ok(Self {
+            data: Arc::new(data),
+            cache: Arc::new(Mutex::new(ComponentMetadataInnerCache::default())),
+        })
+    }
+}
+
+#[cfg(feature = "poem")]
+impl poem_openapi::types::ToJSON for ComponentMetadata {
+    fn to_json(&self) -> Option<serde_json::Value> {
+        self.data.to_json()
+    }
+}
+
+#[cfg(feature = "poem")]
+impl poem_openapi::types::ParseFromXML for ComponentMetadata {
+    fn parse_from_xml(value: Option<serde_json::Value>) -> poem_openapi::types::ParseResult<Self> {
+        let data =
+            ComponentMetadataInnerData::parse_from_xml(value).map_err(|err| err.propagate())?;
+        Ok(Self {
+            data: Arc::new(data),
+            cache: Arc::new(Mutex::new(ComponentMetadataInnerCache::default())),
+        })
+    }
+}
+
+#[cfg(feature = "poem")]
+impl poem_openapi::types::ToXML for ComponentMetadata {
+    fn to_xml(&self) -> Option<serde_json::Value> {
+        self.data.to_xml()
+    }
+}
+
+#[cfg(feature = "poem")]
+impl poem_openapi::types::ParseFromYAML for ComponentMetadata {
+    fn parse_from_yaml(value: Option<serde_json::Value>) -> poem_openapi::types::ParseResult<Self> {
+        let data =
+            ComponentMetadataInnerData::parse_from_yaml(value).map_err(|err| err.propagate())?;
+        Ok(Self {
+            data: Arc::new(data),
+            cache: Arc::new(Mutex::new(ComponentMetadataInnerCache::default())),
+        })
+    }
+}
+
+#[cfg(feature = "poem")]
+impl poem_openapi::types::ToYAML for ComponentMetadata {
+    fn to_yaml(&self) -> Option<serde_json::Value> {
+        self.data.to_yaml()
+    }
+}
+
+#[derive(Clone, Default, PartialEq, Eq, Serialize, Deserialize, Encode, Decode)]
+#[cfg_attr(feature = "poem", derive(poem_openapi::Object))]
+#[cfg_attr(
+    feature = "poem",
+    oai(rename = "ComponentMetadata", rename_all = "camelCase")
+)]
+#[serde(rename = "ComponentMetadata", rename_all = "camelCase")]
+pub struct ComponentMetadataInnerData {
     pub exports: Vec<AnalysedExport>,
     pub producers: Vec<Producers>,
     pub memories: Vec<LinearMemory>,
@@ -45,30 +330,314 @@ pub struct ComponentMetadata {
 
     #[serde(default)]
     pub dynamic_linking: HashMap<String, DynamicLinkedInstance>,
+
+    #[serde(default)]
+    pub agent_types: Vec<AgentType>,
 }
 
-impl ComponentMetadata {
-    pub fn analyse_component(
-        data: &[u8],
-        dynamic_linking: HashMap<String, DynamicLinkedInstance>,
-    ) -> Result<ComponentMetadata, ComponentProcessingError> {
-        let raw = RawComponentMetadata::analyse_component(data)?;
-        Ok(raw.into_metadata(dynamic_linking))
+impl ComponentMetadataInnerData {
+    pub fn load_snapshot(&self) -> Result<Option<InvokableFunction>, String> {
+        self.find_parsed_function_ignoring_version(&ParsedFunctionName::new(
+            ParsedFunctionSite::PackagedInterface {
+                namespace: "golem".to_string(),
+                package: "api".to_string(),
+                interface: "load-snapshot".to_string(),
+                version: None,
+            },
+            ParsedFunctionReference::Function {
+                function: "load".to_string(),
+            },
+        ))
+    }
+
+    pub fn save_snapshot(&self) -> Result<Option<InvokableFunction>, String> {
+        self.find_parsed_function_ignoring_version(&ParsedFunctionName::new(
+            ParsedFunctionSite::PackagedInterface {
+                namespace: "golem".to_string(),
+                package: "api".to_string(),
+                interface: "save-snapshot".to_string(),
+                version: None,
+            },
+            ParsedFunctionReference::Function {
+                function: "save".to_string(),
+            },
+        ))
+    }
+
+    pub fn find_function(&self, name: &str) -> Result<Option<InvokableFunction>, String> {
+        let parsed = ParsedFunctionName::parse(name)?;
+        self.find_parsed_function(&parsed)
+    }
+
+    pub fn find_parsed_function(
+        &self,
+        parsed: &ParsedFunctionName,
+    ) -> Result<Option<InvokableFunction>, String> {
+        Ok(self
+            .find_analysed_function(parsed)
+            .map(|analysed_export| {
+                self.find_agent_method_or_constructor(parsed)
+                    .map(|agent_method_or_constructor| {
+                        (analysed_export, agent_method_or_constructor)
+                    })
+            })
+            .transpose()?
+            .map(
+                |(analysed_export, agent_method_or_constructor)| InvokableFunction {
+                    name: parsed.clone(),
+                    analysed_export,
+                    agent_method_or_constructor,
+                },
+            ))
+    }
+
+    pub fn find_agent_type(&self, agent_type: &str) -> Result<Option<AgentType>, String> {
+        Ok(self
+            .agent_types
+            .iter()
+            .find(|t| t.type_name == agent_type)
+            .cloned())
+    }
+
+    /// Finds a function ignoring the function site's version. Returns None if it was not found.
+    fn find_parsed_function_ignoring_version(
+        &self,
+        name: &ParsedFunctionName,
+    ) -> Result<Option<InvokableFunction>, String> {
+        Ok(self
+            .exports
+            .iter()
+            .find_map(|export| {
+                if let AnalysedExport::Instance(instance) = export {
+                    if let Ok(site) = ParsedFunctionSite::parse(&instance.name) {
+                        if &site.unversioned() == name.site() {
+                            Self::find_function_in_instance(name, instance)
+                                .map(|func| (func, name.with_site(site)))
+                        } else {
+                            None
+                        }
+                    } else {
+                        None
+                    }
+                } else {
+                    None
+                }
+            })
+            .map(|(analysed_export, name)| {
+                self.find_agent_method_or_constructor(&name)
+                    .map(|agent_method_or_constructor| {
+                        (analysed_export, name, agent_method_or_constructor)
+                    })
+            })
+            .transpose()?
+            .map(
+                |(analysed_export, name, agent_method_or_constructor)| InvokableFunction {
+                    name,
+                    analysed_export,
+                    agent_method_or_constructor,
+                },
+            ))
+    }
+
+    fn find_analysed_function(&self, parsed: &ParsedFunctionName) -> Option<AnalysedFunction> {
+        match &parsed.site().interface_name() {
+            None => self.exports.iter().find_map(|f| match f {
+                AnalysedExport::Function(f) if f.name == parsed.function().function_name() => {
+                    Some(f.clone())
+                }
+                _ => None,
+            }),
+            Some(interface_name) => self
+                .exports
+                .iter()
+                .find_map(|instance| match instance {
+                    AnalysedExport::Instance(inst) if inst.name == *interface_name => Some(inst),
+                    _ => None,
+                })
+                .and_then(|instance| Self::find_function_in_instance(parsed, instance)),
+        }
+    }
+
+    fn find_function_in_instance(
+        parsed: &ParsedFunctionName,
+        instance: &AnalysedInstance,
+    ) -> Option<AnalysedFunction> {
+        match instance
+            .functions
+            .iter()
+            .find(|f| f.name == parsed.function().function_name())
+            .cloned()
+        {
+            Some(function) => Some(function),
+            None => match parsed.method_as_static() {
+                Some(parsed_static) => instance
+                    .functions
+                    .iter()
+                    .find(|f| f.name == parsed_static.function().function_name())
+                    .cloned(),
+                None => None,
+            },
+        }
+    }
+
+    fn find_agent_method_or_constructor(
+        &self,
+        parsed: &ParsedFunctionName,
+    ) -> Result<Option<AgentMethodOrConstructor>, String> {
+        if let Some(root_package_name) = &self.root_package_name {
+            if let Some((root_namespace, root_package)) = root_package_name.split_once(':') {
+                let static_agent_interface = ParsedFunctionSite::PackagedInterface {
+                    namespace: root_namespace.to_string(),
+                    package: root_package.to_string(),
+                    interface: "agent".to_string(),
+                    version: self
+                        .root_package_version
+                        .as_ref()
+                        .map(|v| SemVer::parse(v))
+                        .transpose()?,
+                };
+
+                if parsed.site() == &static_agent_interface {
+                    if let Some(resource_name) = parsed.is_method() {
+                        let agent = self
+                            .agent_types
+                            .iter()
+                            .find(|agent| agent.type_name.to_kebab_case() == resource_name);
+
+                        let method = agent.and_then(|agent| {
+                            agent
+                                .methods
+                                .iter()
+                                .find(|method| {
+                                    method.name.to_kebab_case() == parsed.function().function_name()
+                                })
+                                .cloned()
+                        });
+
+                        Ok(method.map(AgentMethodOrConstructor::Method))
+                    } else if let Some(resource_name) = parsed.is_static_method() {
+                        if parsed.function().function_name() == "create" {
+                            // this can be an agent constructor
+                            let agent = self
+                                .agent_types
+                                .iter()
+                                .find(|agent| agent.type_name.to_kebab_case() == resource_name);
+
+                            Ok(agent.map(|agent| {
+                                AgentMethodOrConstructor::Constructor(agent.constructor.clone())
+                            }))
+                        } else {
+                            Ok(None) // Not the agent constructor
+                        }
+                    } else {
+                        Ok(None) // Not a method or static method
+                    }
+                } else {
+                    Ok(None) // Not belonging to the static agent wrapper interface
+                }
+            } else {
+                Ok(None) // Not a valid root package name
+            }
+        } else {
+            Ok(None) // No root package name
+        }
     }
 }
 
-impl Debug for ComponentMetadata {
-    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {
-        f.debug_struct("ComponentMetadata")
-            .field("exports", &self.exports)
-            .field("producers", &self.producers)
-            .field("memories", &self.memories)
-            .field("binary_wit_len", &self.binary_wit.len())
-            .field("root_package_name", &self.root_package_name)
-            .field("root_package_version", &self.root_package_version)
-            .field("dynamic_linking", &self.dynamic_linking)
-            .finish()
+#[derive(Default)]
+struct ComponentMetadataInnerCache {
+    load_snapshot: Option<Result<Option<InvokableFunction>, String>>,
+    save_snapshot: Option<Result<Option<InvokableFunction>, String>>,
+    functions_unparsed: HashMap<String, Result<Option<InvokableFunction>, String>>,
+    functions_parsed: HashMap<ParsedFunctionName, Result<Option<InvokableFunction>, String>>,
+    agent_types: HashMap<String, Result<Option<AgentType>, String>>,
+}
+
+impl ComponentMetadataInnerCache {
+    pub fn load_snapshot(
+        &mut self,
+        data: &ComponentMetadataInnerData,
+    ) -> Result<Option<InvokableFunction>, String> {
+        if let Some(snapshot) = &self.load_snapshot {
+            snapshot.clone()
+        } else {
+            let result = data.load_snapshot();
+            self.load_snapshot = Some(result.clone());
+            result
+        }
+    }
+
+    pub fn save_snapshot(
+        &mut self,
+        data: &ComponentMetadataInnerData,
+    ) -> Result<Option<InvokableFunction>, String> {
+        if let Some(snapshot) = &self.save_snapshot {
+            snapshot.clone()
+        } else {
+            let result = data.save_snapshot();
+            self.save_snapshot = Some(result.clone());
+            result
+        }
+    }
+
+    pub fn find_function(
+        &mut self,
+        data: &ComponentMetadataInnerData,
+        name: &str,
+    ) -> Result<Option<InvokableFunction>, String> {
+        if let Some(cached) = self.functions_unparsed.get(name) {
+            cached.clone()
+        } else {
+            let parsed = ParsedFunctionName::parse(name)?;
+            let result = data.find_parsed_function(&parsed);
+            self.functions_unparsed
+                .insert(name.to_string(), result.clone());
+            result
+        }
+    }
+
+    pub fn find_parsed_function(
+        &mut self,
+        data: &ComponentMetadataInnerData,
+        parsed: &ParsedFunctionName,
+    ) -> Result<Option<InvokableFunction>, String> {
+        if let Some(cached) = self.functions_parsed.get(parsed) {
+            cached.clone()
+        } else {
+            let result = data.find_parsed_function(parsed);
+            self.functions_parsed.insert(parsed.clone(), result.clone());
+            result
+        }
     }
+
+    pub fn find_agent_type(
+        &mut self,
+        data: &ComponentMetadataInnerData,
+        agent_type: &str,
+    ) -> Result<Option<AgentType>, String> {
+        if let Some(cached) = self.agent_types.get(agent_type) {
+            cached.clone()
+        } else {
+            let result = data.find_agent_type(agent_type);
+            self.agent_types
+                .insert(agent_type.to_string(), result.clone());
+            result
+        }
+    }
+}
+
+#[derive(Debug, Clone)]
+pub enum AgentMethodOrConstructor {
+    Method(AgentMethod),
+    Constructor(AgentConstructor),
+}
+
+/// Describes an exported function that can be invoked on a worker
+#[derive(Debug, Clone)]
+pub struct InvokableFunction {
+    pub name: ParsedFunctionName,
+    pub analysed_export: AnalysedFunction,
+    pub agent_method_or_constructor: Option<AgentMethodOrConstructor>,
 }
 
 #[derive(Clone, Debug, PartialEq, Eq, Serialize, Deserialize, Encode, Decode)]
@@ -182,31 +751,7 @@ impl From<Mem> for LinearMemory {
     }
 }
 
-impl From<RawComponentMetadata> for ComponentMetadata {
-    fn from(value: RawComponentMetadata) -> Self {
-        let producers = value
-            .producers
-            .into_iter()
-            .map(|producers| producers.into())
-            .collect::<Vec<_>>();
-
-        let exports = value.exports.into_iter().collect::<Vec<_>>();
-
-        let memories = value.memories.into_iter().map(LinearMemory::from).collect();
-
-        ComponentMetadata {
-            exports,
-            producers,
-            memories,
-            dynamic_linking: HashMap::new(),
-            binary_wit: Base64(value.binary_wit),
-            root_package_name: value.root_package_name,
-            root_package_version: value.root_package_version,
-        }
-    }
-}
-
-// Metadata of Component in terms of golem_wasm_ast types
+/// Metadata of Component in terms of golem_wasm_ast types
 #[derive(Default)]
 pub struct RawComponentMetadata {
     pub exports: Vec<AnalysedExport>,
@@ -273,7 +818,8 @@ impl RawComponentMetadata {
     pub fn into_metadata(
         self,
         dynamic_linking: HashMap<String, DynamicLinkedInstance>,
-    ) -> ComponentMetadata {
+        agent_types: Vec<AgentType>,
+    ) -> ComponentMetadataInnerData {
         let producers = self
             .producers
             .into_iter()
@@ -284,7 +830,7 @@ impl RawComponentMetadata {
 
         let memories = self.memories.into_iter().map(LinearMemory::from).collect();
 
-        ComponentMetadata {
+        ComponentMetadataInnerData {
             exports,
             producers,
             memories,
@@ -292,6 +838,7 @@ impl RawComponentMetadata {
             binary_wit: Base64(self.binary_wit),
             root_package_name: self.root_package_name,
             root_package_version: self.root_package_version,
+            agent_types,
         }
     }
 }
@@ -379,48 +926,112 @@ impl Display for ComponentProcessingError {
     }
 }
 
+fn collect_resource_types(
+    resource_types: &mut HashMap<AnalysedResourceId, AnalysedFunction>,
+    fun: &AnalysedFunction,
+) {
+    if fun.is_constructor() {
+        if let AnalysedType::Handle(TypeHandle {
+            mode: AnalysedResourceMode::Owned,
+            resource_id,
+            ..
+        }) = &fun.result.as_ref().unwrap().typ
+        {
+            resource_types.insert(*resource_id, fun.clone());
+        }
+    } else if fun.is_method() {
+        if let AnalysedType::Handle(TypeHandle {
+            mode: AnalysedResourceMode::Borrowed,
+            resource_id,
+            ..
+        }) = &fun.parameters[0].typ
+        {
+            resource_types.insert(*resource_id, fun.clone());
+        }
+    }
+}
+
 fn add_resource_drops(exports: &mut Vec<AnalysedExport>) {
     // Components are not exporting explicit drop functions for exported resources, but
     // worker executor does. So we keep golem-wasm-ast as a universal library and extend
     // its result with the explicit drops here, for each resource, identified by an exported
     // constructor.
 
-    let mut to_add = Vec::new();
+    let mut top_level_resource_types = HashMap::new();
     for export in exports.iter_mut() {
         match export {
             AnalysedExport::Function(fun) => {
-                if fun.is_constructor() {
-                    to_add.push(AnalysedExport::Function(drop_from_constructor(fun)));
-                }
+                collect_resource_types(&mut top_level_resource_types, fun);
             }
             AnalysedExport::Instance(instance) => {
-                let mut to_add = Vec::new();
+                let mut instance_resource_types = HashMap::new();
                 for fun in &instance.functions {
-                    if fun.is_constructor() {
-                        to_add.push(drop_from_constructor(fun));
-                    }
+                    collect_resource_types(&mut instance_resource_types, fun);
+                }
+
+                for fun in instance_resource_types.values() {
+                    instance
+                        .functions
+                        .push(drop_from_constructor_or_method(fun));
                 }
-                instance.functions.extend(to_add.into_iter());
             }
         }
     }
 
-    exports.extend(to_add);
+    for fun in top_level_resource_types.values() {
+        exports.push(AnalysedExport::Function(drop_from_constructor_or_method(
+            fun,
+        )));
+    }
 }
 
-fn drop_from_constructor(constructor: &AnalysedFunction) -> AnalysedFunction {
-    let drop_name = constructor.name.replace("[constructor]", "[drop]");
-    AnalysedFunction {
-        name: drop_name,
-        parameters: constructor
-            .result
-            .iter()
-            .map(|result| AnalysedFunctionParameter {
-                name: "self".to_string(),
-                typ: result.typ.clone(),
-            })
-            .collect(),
-        result: None,
+fn drop_from_constructor_or_method(fun: &AnalysedFunction) -> AnalysedFunction {
+    if fun.is_constructor() {
+        let drop_name = fun.name.replace("[constructor]", "[drop]");
+        AnalysedFunction {
+            name: drop_name,
+            parameters: fun
+                .result
+                .iter()
+                .map(|result| AnalysedFunctionParameter {
+                    name: "self".to_string(),
+                    typ: result.typ.clone(),
+                })
+                .collect(),
+            result: None,
+        }
+    } else {
+        let name = fun.name.replace("[method]", "[drop]");
+        let (drop_name, _) = name.split_once('.').unwrap();
+        AnalysedFunction {
+            name: drop_name.to_string(),
+            parameters: fun
+                .parameters
+                .first()
+                .map(|param| AnalysedFunctionParameter {
+                    name: "self".to_string(),
+                    typ: {
+                        let AnalysedType::Handle(TypeHandle {
+                            mode: _,
+                            resource_id,
+                            name,
+                            owner,
+                        }) = &param.typ
+                        else {
+                            panic!("Expected handle type for resource drop")
+                        };
+                        AnalysedType::Handle(TypeHandle {
+                            mode: AnalysedResourceMode::Owned,
+                            resource_id: *resource_id,
+                            name: name.clone(),
+                            owner: owner.clone(),
+                        })
+                    },
+                })
+                .into_iter()
+                .collect(),
+            result: None,
+        }
     }
 }
 
@@ -439,10 +1050,13 @@ fn add_virtual_exports(exports: &mut Vec<AnalysedExport>) {
 mod protobuf {
     use crate::model::base64::Base64;
     use crate::model::component_metadata::{
-        ComponentMetadata, DynamicLinkedInstance, DynamicLinkedWasmRpc, LinearMemory,
-        ProducerField, Producers, VersionedName, WasmRpcTarget,
+        ComponentMetadata, ComponentMetadataInnerCache, ComponentMetadataInnerData,
+        DynamicLinkedInstance, DynamicLinkedWasmRpc, LinearMemory, ProducerField, Producers,
+        VersionedName, WasmRpcTarget,
     };
     use std::collections::HashMap;
+    use std::sync::Arc;
+    use tokio::sync::Mutex;
 
     impl From<golem_api_grpc::proto::golem::component::VersionedName> for VersionedName {
         fn from(value: golem_api_grpc::proto::golem::component::VersionedName) -> Self {
@@ -517,6 +1131,22 @@ mod protobuf {
     impl TryFrom<golem_api_grpc::proto::golem::component::ComponentMetadata> for ComponentMetadata {
         type Error = String;
 
+        fn try_from(
+            value: golem_api_grpc::proto::golem::component::ComponentMetadata,
+        ) -> Result<Self, Self::Error> {
+            let inner_data = ComponentMetadataInnerData::try_from(value)?;
+            Ok(Self {
+                data: Arc::new(inner_data),
+                cache: Arc::new(Mutex::new(ComponentMetadataInnerCache::default())),
+            })
+        }
+    }
+
+    impl TryFrom<golem_api_grpc::proto::golem::component::ComponentMetadata>
+        for ComponentMetadataInnerData
+    {
+        type Error = String;
+
         fn try_from(
             value: golem_api_grpc::proto::golem::component::ComponentMetadata,
         ) -> Result<Self, Self::Error> {
@@ -544,12 +1174,25 @@ mod protobuf {
                     .into_iter()
                     .map(|(k, v)| v.try_into().map(|v| (k, v)))
                     .collect::<Result<_, _>>()?,
+                agent_types: value
+                    .agent_types
+                    .into_iter()
+                    .map(|at| at.try_into())
+                    .collect::<Result<_, _>>()?,
             })
         }
     }
 
     impl From<ComponentMetadata> for golem_api_grpc::proto::golem::component::ComponentMetadata {
         fn from(value: ComponentMetadata) -> Self {
+            value.data.as_ref().clone().into()
+        }
+    }
+
+    impl From<ComponentMetadataInnerData>
+        for golem_api_grpc::proto::golem::component::ComponentMetadata
+    {
+        fn from(value: ComponentMetadataInnerData) -> Self {
             Self {
                 exports: value
                     .exports
@@ -575,6 +1218,7 @@ mod protobuf {
                 binary_wit: value.binary_wit.0,
                 root_package_name: value.root_package_name,
                 root_package_version: value.root_package_version,
+                agent_types: value.agent_types.into_iter().map(|at| at.into()).collect(),
             }
         }
     }
diff --git a/golem-common/src/model/mod.rs b/golem-common/src/model/mod.rs
index bf930632..5f274ecb 100644
--- a/golem-common/src/model/mod.rs
+++ b/golem-common/src/model/mod.rs
@@ -12,55 +12,54 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use crate::model::oplog::{IndexedResourceKey, TimestampedUpdateDescription, WorkerResourceId};
+pub mod agent;
+pub mod auth;
+pub mod base64;
+pub mod component;
+pub mod component_constraint;
+#[cfg(feature = "tokio")]
+pub mod component_metadata;
+pub mod error;
+pub mod exports;
+pub mod invocation_context;
+pub mod lucene;
+pub mod oplog;
+pub mod plugin;
+#[cfg(feature = "poem")]
+mod poem;
+pub mod project;
+#[cfg(feature = "protobuf")]
+pub mod protobuf;
+pub mod public_oplog;
+pub mod regions;
+pub mod trim_date;
+pub mod worker;
+
+pub use crate::base_model::*;
+use crate::model::invocation_context::InvocationContextStack;
+use crate::model::oplog::{TimestampedUpdateDescription, WorkerResourceId};
 use crate::model::regions::DeletedRegions;
+use crate::SafeDisplay;
 use bincode::de::{BorrowDecoder, Decoder};
 use bincode::enc::Encoder;
 use bincode::error::{DecodeError, EncodeError};
 use bincode::{BorrowDecode, Decode, Encode};
-
-pub use crate::base_model::*;
-use crate::model::invocation_context::InvocationContextStack;
 use golem_wasm_ast::analysis::analysed_type::{field, list, record, str, tuple, u32, u64};
 use golem_wasm_ast::analysis::AnalysedType;
 use golem_wasm_rpc::{IntoValue, Value};
 use golem_wasm_rpc_derive::IntoValue;
 use http::Uri;
 use rand::prelude::IteratorRandom;
-use serde::de::Unexpected;
 use serde::{de, Deserialize, Deserializer, Serialize, Serializer};
 use std::cmp::Ordering;
-use std::collections::{HashMap, HashSet, VecDeque};
-use std::fmt::{Display, Formatter};
+use std::collections::{BTreeMap, HashMap, HashSet, VecDeque};
+use std::fmt::{Display, Formatter, Write};
 use std::ops::Add;
 use std::str::FromStr;
 use std::time::{Duration, SystemTime};
 use typed_path::Utf8UnixPathBuf;
 use uuid::{uuid, Uuid};
 
-pub mod auth;
-pub mod base64;
-pub mod component;
-pub mod component_constraint;
-pub mod component_metadata;
-pub mod config;
-pub mod error;
-pub mod exports;
-pub mod invocation_context;
-pub mod lucene;
-pub mod oplog;
-pub mod plugin;
-pub mod project;
-pub mod public_oplog;
-pub mod regions;
-pub mod trim_date;
-
-#[cfg(feature = "poem")]
-mod poem;
-
-#[cfg(feature = "protobuf")]
-pub mod protobuf;
-
 #[cfg(feature = "poem")]
 pub trait PoemTypeRequirements:
     poem_openapi::types::Type + poem_openapi::types::ParseFromJSON + poem_openapi::types::ToJSON
@@ -206,17 +205,17 @@ impl IntoValue for Timestamp {
     }
 }
 
-/// Associates a worker-id with its owner account
+/// Associates a worker-id with its owner project
 #[derive(Clone, Debug, Eq, PartialEq, Hash, Encode, Decode)]
 pub struct OwnedWorkerId {
-    pub account_id: AccountId,
+    pub project_id: ProjectId,
     pub worker_id: WorkerId,
 }
 
 impl OwnedWorkerId {
-    pub fn new(account_id: &AccountId, worker_id: &WorkerId) -> Self {
+    pub fn new(project_id: &ProjectId, worker_id: &WorkerId) -> Self {
         Self {
-            account_id: account_id.clone(),
+            project_id: project_id.clone(),
             worker_id: worker_id.clone(),
         }
     }
@@ -225,8 +224,8 @@ impl OwnedWorkerId {
         self.worker_id.clone()
     }
 
-    pub fn account_id(&self) -> AccountId {
-        self.account_id.clone()
+    pub fn project_id(&self) -> ProjectId {
+        self.project_id.clone()
     }
 
     pub fn component_id(&self) -> ComponentId {
@@ -240,7 +239,7 @@ impl OwnedWorkerId {
 
 impl Display for OwnedWorkerId {
     fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
-        write!(f, "{}/{}", self.account_id, self.worker_id)
+        write!(f, "{}/{}", self.project_id, self.worker_id)
     }
 }
 
@@ -256,12 +255,14 @@ pub enum ScheduledAction {
     /// Completes a given promise
     CompletePromise {
         account_id: AccountId,
+        project_id: ProjectId,
         promise_id: PromiseId,
     },
     /// Archives all entries from the first non-empty layer of an oplog to the next layer,
     /// if the last oplog index did not change. If there are more layers below, schedules
     /// a next action to archive the next layer.
     ArchiveOplog {
+        account_id: AccountId,
         owned_worker_id: OwnedWorkerId,
         last_oplog_index: OplogIndex,
         next_after: Duration,
@@ -269,6 +270,7 @@ pub enum ScheduledAction {
     /// Invoke the given action on the worker. The invocation will only
     /// be persisted in the oplog when it's actually getting scheduled.
     Invoke {
+        account_id: AccountId,
         owned_worker_id: OwnedWorkerId,
         idempotency_key: IdempotencyKey,
         full_function_name: String,
@@ -281,9 +283,10 @@ impl ScheduledAction {
     pub fn owned_worker_id(&self) -> OwnedWorkerId {
         match self {
             ScheduledAction::CompletePromise {
-                account_id,
+                project_id,
                 promise_id,
-            } => OwnedWorkerId::new(account_id, &promise_id.worker_id),
+                ..
+            } => OwnedWorkerId::new(project_id, &promise_id.worker_id),
             ScheduledAction::ArchiveOplog {
                 owned_worker_id, ..
             } => owned_worker_id.clone(),
@@ -502,19 +505,27 @@ pub struct WorkerMetadata {
     pub worker_id: WorkerId,
     pub args: Vec<String>,
     pub env: Vec<(String, String)>,
-    pub account_id: AccountId,
+    pub project_id: ProjectId,
+    pub created_by: AccountId,
+    pub wasi_config_vars: BTreeMap<String, String>,
     pub created_at: Timestamp,
     pub parent: Option<WorkerId>,
     pub last_known_status: WorkerStatusRecord,
 }
 
 impl WorkerMetadata {
-    pub fn default(worker_id: WorkerId, account_id: AccountId) -> WorkerMetadata {
+    pub fn default(
+        worker_id: WorkerId,
+        created_by: AccountId,
+        project_id: ProjectId,
+    ) -> WorkerMetadata {
         WorkerMetadata {
             worker_id,
             args: vec![],
             env: vec![],
-            account_id,
+            project_id,
+            created_by,
+            wasi_config_vars: BTreeMap::new(),
             created_at: Timestamp::now_utc(),
             parent: None,
             last_known_status: WorkerStatusRecord::default(),
@@ -522,7 +533,7 @@ impl WorkerMetadata {
     }
 
     pub fn owned_worker_id(&self) -> OwnedWorkerId {
-        OwnedWorkerId::new(&self.account_id, &self.worker_id)
+        OwnedWorkerId::new(&self.project_id, &self.worker_id)
     }
 }
 
@@ -532,6 +543,7 @@ impl IntoValue for WorkerMetadata {
             self.worker_id.into_value(),
             self.args.into_value(),
             self.env.into_value(),
+            self.wasi_config_vars.into_value(),
             self.last_known_status.status.into_value(),
             self.last_known_status.component_version.into_value(),
             0u64.into_value(), // retry count could be computed from the worker status record here but we don't support it yet
@@ -543,6 +555,7 @@ impl IntoValue for WorkerMetadata {
             field("worker-id", WorkerId::get_type()),
             field("args", list(str())),
             field("env", list(tuple(vec![str(), str()]))),
+            field("wasi-config-vars", HashMap::<String, String>::get_type()),
             field("status", WorkerStatus::get_type()),
             field("component-version", u64()),
             field("retry-count", u64()),
@@ -550,10 +563,14 @@ impl IntoValue for WorkerMetadata {
     }
 }
 
-#[derive(Clone, Debug, PartialEq, Eq, Encode, Decode)]
+#[derive(Clone, Debug, PartialEq, Serialize, Deserialize, Encode, Decode)]
+#[serde(rename_all = "camelCase")]
+#[cfg_attr(feature = "poem", derive(poem_openapi::Object))]
+#[cfg_attr(feature = "poem", oai(rename_all = "camelCase"))]
 pub struct WorkerResourceDescription {
     pub created_at: Timestamp,
-    pub indexed_resource_key: Option<IndexedResourceKey>,
+    pub resource_owner: String,
+    pub resource_name: String,
 }
 
 #[derive(Clone, Debug, PartialEq, Serialize, Deserialize, Encode, Decode)]
@@ -567,6 +584,22 @@ pub struct RetryConfig {
     pub max_jitter_factor: Option<f64>,
 }
 
+impl SafeDisplay for RetryConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+
+        let _ = writeln!(&mut result, "max attempts: {}", self.max_attempts);
+        let _ = writeln!(&mut result, "min delay: {:?}", self.min_delay);
+        let _ = writeln!(&mut result, "max delay: {:?}", self.max_delay);
+        let _ = writeln!(&mut result, "multiplier: {}", self.multiplier);
+        if let Some(max_jitter_factor) = &self.max_jitter_factor {
+            let _ = writeln!(&mut result, "max jitter factor: {:?}", max_jitter_factor);
+        }
+
+        result
+    }
+}
+
 /// Contains status information about a worker according to a given oplog index.
 ///
 /// This status is just cached information, all fields must be computable by the oplog alone.
@@ -591,7 +624,7 @@ pub struct WorkerStatusRecord {
     pub active_plugins: HashSet<PluginInstallationId>,
     pub deleted_regions: DeletedRegions,
     /// The component version at the starting point of the replay. Will be the version of the Create oplog entry
-    /// if only automatic updates were used or the version of the latest snapshot based update
+    /// if only automatic updates were used or the version of the latest snapshot-based update
     pub component_version_for_replay: ComponentVersion,
 }
 
@@ -1075,6 +1108,36 @@ impl Display for WorkerEnvFilter {
     }
 }
 
+#[derive(Clone, Debug, PartialEq, Eq, Hash, Serialize, Deserialize, Encode, Decode)]
+#[cfg_attr(feature = "poem", derive(poem_openapi::Object))]
+#[cfg_attr(feature = "poem", oai(rename_all = "camelCase"))]
+#[serde(rename_all = "camelCase")]
+pub struct WorkerWasiConfigVarsFilter {
+    pub name: String,
+    pub comparator: StringFilterComparator,
+    pub value: String,
+}
+
+impl WorkerWasiConfigVarsFilter {
+    pub fn new(name: String, comparator: StringFilterComparator, value: String) -> Self {
+        Self {
+            name,
+            comparator,
+            value,
+        }
+    }
+}
+
+impl Display for WorkerWasiConfigVarsFilter {
+    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
+        write!(
+            f,
+            "wasi_config_vars.{} {} {}",
+            self.name, self.comparator, self.value
+        )
+    }
+}
+
 #[derive(Clone, Debug, PartialEq, Eq, Hash, Serialize, Deserialize, Encode, Decode)]
 #[cfg_attr(feature = "poem", derive(poem_openapi::Object))]
 #[cfg_attr(feature = "poem", oai(rename_all = "camelCase"))]
@@ -1166,6 +1229,7 @@ pub enum WorkerFilter {
     And(WorkerAndFilter),
     Or(WorkerOrFilter),
     Not(WorkerNotFilter),
+    WasiConfigVars(WorkerWasiConfigVarsFilter),
 }
 
 impl WorkerFilter {
@@ -1216,6 +1280,16 @@ impl WorkerFilter {
                 }
                 result
             }
+            WorkerFilter::WasiConfigVars(WorkerWasiConfigVarsFilter {
+                name,
+                comparator,
+                value,
+            }) => {
+                let env_value = metadata.wasi_config_vars.get(&name);
+                env_value
+                    .map(|ev| comparator.matches(ev, &value))
+                    .unwrap_or(false)
+            }
             WorkerFilter::CreatedAt(WorkerCreatedAtFilter { comparator, value }) => {
                 comparator.matches(&metadata.created_at, &value)
             }
@@ -1269,6 +1343,14 @@ impl WorkerFilter {
         WorkerFilter::Env(WorkerEnvFilter::new(name, comparator, value))
     }
 
+    pub fn new_wasi_config_vars(
+        name: String,
+        comparator: StringFilterComparator,
+        value: String,
+    ) -> Self {
+        WorkerFilter::WasiConfigVars(WorkerWasiConfigVarsFilter::new(name, comparator, value))
+    }
+
     pub fn new_version(comparator: FilterComparator, value: ComponentVersion) -> Self {
         WorkerFilter::Version(WorkerVersionFilter::new(comparator, value))
     }
@@ -1308,6 +1390,9 @@ impl Display for WorkerFilter {
             WorkerFilter::Env(filter) => {
                 write!(f, "{filter}")
             }
+            WorkerFilter::WasiConfigVars(filter) => {
+                write!(f, "{filter}")
+            }
             WorkerFilter::Not(filter) => {
                 write!(f, "{filter}")
             }
@@ -1876,6 +1961,13 @@ impl Display for ComponentFilePathWithPermissionsList {
     }
 }
 
+#[derive(Clone, Debug, PartialEq)]
+pub enum GetFileSystemNodeResult {
+    Ok(Vec<ComponentFileSystemNode>),
+    File(ComponentFileSystemNode),
+    NotFound,
+}
+
 #[derive(Clone, Debug, PartialEq)]
 pub enum ComponentFileSystemNodeDetails {
     File {
@@ -1892,7 +1984,8 @@ pub struct ComponentFileSystemNode {
     pub details: ComponentFileSystemNodeDetails,
 }
 
-#[derive(Debug, Clone, PartialEq, Serialize, Encode, Decode, Default)]
+// Custom Deserialize is replaced with Simple Deserialize
+#[derive(Debug, Clone, PartialEq, Serialize, Encode, Decode, Default, Deserialize)]
 #[cfg_attr(feature = "poem", derive(poem_openapi::Enum))]
 #[serde(rename_all = "kebab-case")]
 #[cfg_attr(feature = "poem", oai(rename_all = "kebab-case"))]
@@ -1902,38 +1995,7 @@ pub enum GatewayBindingType {
     FileServer,
     HttpHandler,
     CorsPreflight,
-}
-
-// To keep backward compatibility as we documented wit-worker to be default
-impl<'de> Deserialize<'de> for GatewayBindingType {
-    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
-    where
-        D: Deserializer<'de>,
-    {
-        struct GatewayBindingTypeVisitor;
-
-        impl de::Visitor<'_> for GatewayBindingTypeVisitor {
-            type Value = GatewayBindingType;
-
-            fn expecting(&self, formatter: &mut Formatter) -> std::fmt::Result {
-                formatter.write_str("a string representing the binding type")
-            }
-
-            fn visit_str<E>(self, value: &str) -> Result<Self::Value, E>
-            where
-                E: de::Error,
-            {
-                match value {
-                    "default" | "wit-worker" => Ok(GatewayBindingType::Default),
-                    "file-server" => Ok(GatewayBindingType::FileServer),
-                    "cors-preflight" => Ok(GatewayBindingType::CorsPreflight),
-                    _ => Err(de::Error::invalid_value(Unexpected::Str(value), &self)),
-                }
-            }
-        }
-
-        deserializer.deserialize_str(GatewayBindingTypeVisitor)
-    }
+    SwaggerUi,
 }
 
 impl TryFrom<String> for GatewayBindingType {
@@ -1948,8 +2010,8 @@ impl TryFrom<String> for GatewayBindingType {
     }
 }
 
-impl From<crate::model::WorkerId> for golem_wasm_rpc::WorkerId {
-    fn from(worker_id: crate::model::WorkerId) -> Self {
+impl From<WorkerId> for golem_wasm_rpc::WorkerId {
+    fn from(worker_id: WorkerId) -> Self {
         golem_wasm_rpc::WorkerId {
             component_id: worker_id.component_id.into(),
             worker_name: worker_id.worker_name,
@@ -1957,7 +2019,7 @@ impl From<crate::model::WorkerId> for golem_wasm_rpc::WorkerId {
     }
 }
 
-impl From<golem_wasm_rpc::WorkerId> for crate::model::WorkerId {
+impl From<golem_wasm_rpc::WorkerId> for WorkerId {
     fn from(host: golem_wasm_rpc::WorkerId) -> Self {
         Self {
             component_id: host.component_id.into(),
@@ -1966,17 +2028,17 @@ impl From<golem_wasm_rpc::WorkerId> for crate::model::WorkerId {
     }
 }
 
-impl From<golem_wasm_rpc::ComponentId> for crate::model::ComponentId {
+impl From<golem_wasm_rpc::ComponentId> for ComponentId {
     fn from(host: golem_wasm_rpc::ComponentId) -> Self {
         let high_bits = host.uuid.high_bits;
         let low_bits = host.uuid.low_bits;
 
-        Self(uuid::Uuid::from_u64_pair(high_bits, low_bits))
+        Self(Uuid::from_u64_pair(high_bits, low_bits))
     }
 }
 
-impl From<crate::model::ComponentId> for golem_wasm_rpc::ComponentId {
-    fn from(component_id: crate::model::ComponentId) -> Self {
+impl From<ComponentId> for golem_wasm_rpc::ComponentId {
+    fn from(component_id: ComponentId) -> Self {
         let (high_bits, low_bits) = component_id.0.as_u64_pair();
 
         golem_wasm_rpc::ComponentId {
@@ -1990,23 +2052,20 @@ impl From<crate::model::ComponentId> for golem_wasm_rpc::ComponentId {
 
 #[cfg(test)]
 mod tests {
-    use std::collections::HashSet;
+    use std::collections::BTreeMap;
     use std::str::FromStr;
-    use std::time::SystemTime;
     use std::vec;
     use test_r::test;
-    use tracing::info;
 
     use crate::model::oplog::OplogIndex;
 
     use crate::model::{
-        AccountId, ComponentFilePath, ComponentId, FilterComparator, IdempotencyKey, ShardId,
-        StringFilterComparator, TargetWorkerId, Timestamp, WorkerFilter, WorkerId, WorkerMetadata,
-        WorkerStatus, WorkerStatusRecord,
+        AccountId, ComponentFilePath, ComponentId, FilterComparator, IdempotencyKey, ProjectId,
+        StringFilterComparator, Timestamp, WorkerFilter, WorkerId, WorkerMetadata, WorkerStatus,
+        WorkerStatusRecord,
     };
     use bincode::{Decode, Encode};
 
-    use rand::{rng, Rng};
     use serde::{Deserialize, Serialize};
 
     #[test]
@@ -2180,9 +2239,11 @@ mod tests {
                 ("env1".to_string(), "value1".to_string()),
                 ("env2".to_string(), "value2".to_string()),
             ],
-            account_id: AccountId {
+            project_id: ProjectId::new_v4(),
+            created_by: AccountId {
                 value: "account-1".to_string(),
             },
+            wasi_config_vars: BTreeMap::from([("var1".to_string(), "value1".to_string())]),
             created_at: Timestamp::now_utc(),
             parent: None,
             last_known_status: WorkerStatusRecord {
@@ -2243,41 +2304,20 @@ mod tests {
                 "worker-2".to_string(),
             ))
             .matches(&worker_metadata));
-    }
 
-    #[test]
-    fn target_worker_id_force_shards() {
-        let mut rng = rng();
-        const SHARD_COUNT: usize = 1000;
-        const EXAMPLE_COUNT: usize = 1000;
-        for _ in 0..EXAMPLE_COUNT {
-            let mut shard_ids = HashSet::new();
-            let count = rng.random_range(0..100);
-            for _ in 0..count {
-                let shard_id = rng.random_range(0..SHARD_COUNT);
-                shard_ids.insert(ShardId {
-                    value: shard_id as i64,
-                });
-            }
+        assert!(WorkerFilter::new_wasi_config_vars(
+            "var1".to_string(),
+            StringFilterComparator::Equal,
+            "value1".to_string(),
+        )
+        .matches(&worker_metadata));
 
-            let component_id = ComponentId::new_v4();
-            let target_worker_id = TargetWorkerId {
-                component_id,
-                worker_name: None,
-            };
-
-            let start = SystemTime::now();
-            let worker_id = target_worker_id.into_worker_id(&shard_ids, SHARD_COUNT);
-            let end = SystemTime::now();
-            info!(
-                "Time with {count} valid shards: {:?}",
-                end.duration_since(start).unwrap()
-            );
-
-            if !shard_ids.is_empty() {
-                assert!(shard_ids.contains(&ShardId::from_worker_id(&worker_id, SHARD_COUNT)));
-            }
-        }
+        assert!(!WorkerFilter::new_wasi_config_vars(
+            "var1".to_string(),
+            StringFilterComparator::Equal,
+            "value2".to_string(),
+        )
+        .matches(&worker_metadata));
     }
 
     #[test]
diff --git a/golem-common/src/model/oplog.rs b/golem-common/src/model/oplog.rs
index 7425f01e..ca210089 100644
--- a/golem-common/src/model/oplog.rs
+++ b/golem-common/src/model/oplog.rs
@@ -15,21 +15,22 @@
 pub use crate::base_model::OplogIndex;
 use crate::model::invocation_context::{AttributeValue, InvocationContextSpan, SpanId, TraceId};
 use crate::model::regions::OplogRegion;
-use crate::model::RetryConfig;
 use crate::model::{
     AccountId, ComponentVersion, IdempotencyKey, PluginInstallationId, Timestamp, WorkerId,
     WorkerInvocation,
 };
+use crate::model::{ProjectId, RetryConfig};
 use bincode::de::read::Reader;
 use bincode::de::{BorrowDecoder, Decoder};
 use bincode::enc::write::Writer;
 use bincode::enc::Encoder;
 use bincode::error::{DecodeError, EncodeError};
 use bincode::{BorrowDecode, Decode, Encode};
+use golem_wasm_rpc::wasmtime::ResourceTypeId;
 use golem_wasm_rpc_derive::IntoValue;
 use nonempty_collections::NEVec;
 use serde::{Deserialize, Serialize};
-use std::collections::{HashMap, HashSet};
+use std::collections::{BTreeMap, HashMap, HashSet};
 use std::fmt::{Display, Formatter};
 use std::sync::atomic::AtomicU64;
 use std::sync::Arc;
@@ -196,12 +197,6 @@ impl Display for WorkerResourceId {
     }
 }
 
-#[derive(Debug, Clone, PartialEq, Eq, Hash, Encode, Decode)]
-pub struct IndexedResourceKey {
-    pub resource_name: String,
-    pub resource_params: Vec<String>,
-}
-
 /// Worker log levels including the special stdout and stderr channels
 #[derive(Copy, Clone, Debug, PartialEq, Encode, Decode, Serialize, Deserialize, IntoValue)]
 #[cfg_attr(feature = "poem", derive(poem_openapi::Enum))]
@@ -280,31 +275,6 @@ pub enum PersistenceLevel {
 
 #[derive(Clone, Debug, PartialEq, Encode, Decode)]
 pub enum OplogEntry {
-    CreateV1 {
-        timestamp: Timestamp,
-        worker_id: WorkerId,
-        component_version: ComponentVersion,
-        args: Vec<String>,
-        env: Vec<(String, String)>,
-        account_id: AccountId,
-        parent: Option<WorkerId>,
-        component_size: u64,
-        initial_total_linear_memory_size: u64,
-    },
-    /// The worker invoked a host function (original 1.0 version)
-    ImportedFunctionInvokedV1 {
-        timestamp: Timestamp,
-        function_name: String,
-        response: OplogPayload,
-        wrapped_function_type: DurableFunctionType, // TODO: rename in Golem 2.0
-    },
-    /// The worker has been invoked
-    ExportedFunctionInvokedV1 {
-        timestamp: Timestamp,
-        function_name: String,
-        request: OplogPayload,
-        idempotency_key: IdempotencyKey,
-    },
     /// The worker has completed an invocation
     ExportedFunctionCompleted {
         timestamp: Timestamp,
@@ -371,12 +341,6 @@ pub enum OplogEntry {
         timestamp: Timestamp,
         description: UpdateDescription,
     },
-    /// An update was successfully applied
-    SuccessfulUpdateV1 {
-        timestamp: Timestamp,
-        target_version: ComponentVersion,
-        new_component_size: u64,
-    },
     /// An update failed to be applied
     FailedUpdate {
         timestamp: Timestamp,
@@ -389,17 +353,13 @@ pub enum OplogEntry {
     CreateResource {
         timestamp: Timestamp,
         id: WorkerResourceId,
+        resource_type_id: ResourceTypeId,
     },
     /// Dropped a resource instance
     DropResource {
         timestamp: Timestamp,
         id: WorkerResourceId,
-    },
-    /// Adds additional information for a created resource instance
-    DescribeResource {
-        timestamp: Timestamp,
-        id: WorkerResourceId,
-        indexed_resource: IndexedResourceKey,
+        resource_type_id: ResourceTypeId,
     },
     /// The worker emitted a log message
     Log {
@@ -416,20 +376,22 @@ pub enum OplogEntry {
         function_name: String,
         request: OplogPayload,
         response: OplogPayload,
-        wrapped_function_type: DurableFunctionType, // TODO: rename in Golem 2.0
+        durable_function_type: DurableFunctionType,
     },
-    /// The current version of the Create entry (previous is CreateV1)
+    /// The first entry of every oplog
     Create {
         timestamp: Timestamp,
         worker_id: WorkerId,
         component_version: ComponentVersion,
         args: Vec<String>,
         env: Vec<(String, String)>,
-        account_id: AccountId,
+        project_id: ProjectId,
+        created_by: AccountId,
         parent: Option<WorkerId>,
         component_size: u64,
         initial_total_linear_memory_size: u64,
         initial_active_plugins: HashSet<PluginInstallationId>,
+        wasi_config_vars: BTreeMap<String, String>,
     },
     /// Activates a plugin for the worker
     ActivatePlugin {
@@ -501,7 +463,9 @@ impl OplogEntry {
         component_version: ComponentVersion,
         args: Vec<String>,
         env: Vec<(String, String)>,
-        account_id: AccountId,
+        wasi_config_vars: BTreeMap<String, String>,
+        project_id: ProjectId,
+        created_by: AccountId,
         parent: Option<WorkerId>,
         component_size: u64,
         initial_total_linear_memory_size: u64,
@@ -513,11 +477,13 @@ impl OplogEntry {
             component_version,
             args,
             env,
-            account_id,
+            project_id,
+            created_by,
             parent,
             component_size,
             initial_total_linear_memory_size,
             initial_active_plugins,
+            wasi_config_vars,
         }
     }
 
@@ -634,28 +600,19 @@ impl OplogEntry {
         }
     }
 
-    pub fn create_resource(id: WorkerResourceId) -> OplogEntry {
+    pub fn create_resource(id: WorkerResourceId, resource_type_id: ResourceTypeId) -> OplogEntry {
         OplogEntry::CreateResource {
             timestamp: Timestamp::now_utc(),
             id,
+            resource_type_id,
         }
     }
 
-    pub fn drop_resource(id: WorkerResourceId) -> OplogEntry {
+    pub fn drop_resource(id: WorkerResourceId, resource_type_id: ResourceTypeId) -> OplogEntry {
         OplogEntry::DropResource {
             timestamp: Timestamp::now_utc(),
             id,
-        }
-    }
-
-    pub fn describe_resource(
-        id: WorkerResourceId,
-        indexed_resource: IndexedResourceKey,
-    ) -> OplogEntry {
-        OplogEntry::DescribeResource {
-            timestamp: Timestamp::now_utc(),
-            id,
-            indexed_resource,
+            resource_type_id,
         }
     }
 
@@ -754,9 +711,9 @@ impl OplogEntry {
     pub fn no_concurrent_side_effect(&self, idx: OplogIndex) -> bool {
         match self {
             OplogEntry::ImportedFunctionInvoked {
-                wrapped_function_type,
+                durable_function_type,
                 ..
-            } => match wrapped_function_type {
+            } => match durable_function_type {
                 DurableFunctionType::WriteRemoteBatched(Some(begin_index))
                     if *begin_index == idx =>
                 {
@@ -783,12 +740,10 @@ impl OplogEntry {
                 | OplogEntry::PendingWorkerInvocation { .. }
                 | OplogEntry::PendingUpdate { .. }
                 | OplogEntry::SuccessfulUpdate { .. }
-                | OplogEntry::SuccessfulUpdateV1 { .. }
                 | OplogEntry::FailedUpdate { .. }
                 | OplogEntry::GrowMemory { .. }
                 | OplogEntry::CreateResource { .. }
                 | OplogEntry::DropResource { .. }
-                | OplogEntry::DescribeResource { .. }
                 | OplogEntry::Log { .. }
                 | OplogEntry::Restart { .. }
                 | OplogEntry::ActivatePlugin { .. }
@@ -801,8 +756,6 @@ impl OplogEntry {
     pub fn timestamp(&self) -> Timestamp {
         match self {
             OplogEntry::Create { timestamp, .. }
-            | OplogEntry::ImportedFunctionInvokedV1 { timestamp, .. }
-            | OplogEntry::ExportedFunctionInvokedV1 { timestamp, .. }
             | OplogEntry::ExportedFunctionCompleted { timestamp, .. }
             | OplogEntry::Suspend { timestamp }
             | OplogEntry::Error { timestamp, .. }
@@ -822,12 +775,9 @@ impl OplogEntry {
             | OplogEntry::GrowMemory { timestamp, .. }
             | OplogEntry::CreateResource { timestamp, .. }
             | OplogEntry::DropResource { timestamp, .. }
-            | OplogEntry::DescribeResource { timestamp, .. }
             | OplogEntry::Log { timestamp, .. }
             | OplogEntry::Restart { timestamp }
             | OplogEntry::ImportedFunctionInvoked { timestamp, .. }
-            | OplogEntry::CreateV1 { timestamp, .. }
-            | OplogEntry::SuccessfulUpdateV1 { timestamp, .. }
             | OplogEntry::ActivatePlugin { timestamp, .. }
             | OplogEntry::DeactivatePlugin { timestamp, .. }
             | OplogEntry::Revert { timestamp, .. }
@@ -845,48 +795,25 @@ impl OplogEntry {
             OplogEntry::Create {
                 component_version, ..
             } => Some(*component_version),
-            OplogEntry::CreateV1 {
-                component_version, ..
-            } => Some(*component_version),
             OplogEntry::SuccessfulUpdate { target_version, .. } => Some(*target_version),
-            OplogEntry::SuccessfulUpdateV1 { target_version, .. } => Some(*target_version),
             _ => None,
         }
     }
 
     pub fn update_worker_id(&self, worker_id: &WorkerId) -> Option<OplogEntry> {
         match self {
-            OplogEntry::CreateV1 {
-                timestamp,
-                component_version,
-                args,
-                env,
-                account_id,
-                parent,
-                component_size,
-                initial_total_linear_memory_size,
-                worker_id: _,
-            } => Some(OplogEntry::CreateV1 {
-                timestamp: *timestamp,
-                worker_id: worker_id.clone(),
-                component_version: *component_version,
-                args: args.clone(),
-                env: env.clone(),
-                account_id: account_id.clone(),
-                parent: parent.clone(),
-                component_size: *component_size,
-                initial_total_linear_memory_size: *initial_total_linear_memory_size,
-            }),
             OplogEntry::Create {
                 timestamp,
                 component_version,
                 args,
                 env,
-                account_id,
+                project_id,
+                created_by,
                 parent,
                 component_size,
                 initial_total_linear_memory_size,
                 initial_active_plugins,
+                wasi_config_vars,
                 worker_id: _,
             } => Some(OplogEntry::Create {
                 timestamp: *timestamp,
@@ -894,11 +821,13 @@ impl OplogEntry {
                 component_version: *component_version,
                 args: args.clone(),
                 env: env.clone(),
-                account_id: account_id.clone(),
+                project_id: project_id.clone(),
+                created_by: created_by.clone(),
                 parent: parent.clone(),
                 component_size: *component_size,
                 initial_total_linear_memory_size: *initial_total_linear_memory_size,
                 initial_active_plugins: initial_active_plugins.clone(),
+                wasi_config_vars: wasi_config_vars.clone(),
             }),
             _ => None,
         }
@@ -1000,25 +929,7 @@ impl WorkerError {
 #[cfg(feature = "protobuf")]
 mod protobuf {
     use super::WorkerError;
-    use crate::model::oplog::{IndexedResourceKey, PersistenceLevel};
-
-    impl From<IndexedResourceKey> for golem_api_grpc::proto::golem::worker::IndexedResourceMetadata {
-        fn from(value: IndexedResourceKey) -> Self {
-            golem_api_grpc::proto::golem::worker::IndexedResourceMetadata {
-                resource_name: value.resource_name,
-                resource_params: value.resource_params,
-            }
-        }
-    }
-
-    impl From<golem_api_grpc::proto::golem::worker::IndexedResourceMetadata> for IndexedResourceKey {
-        fn from(value: golem_api_grpc::proto::golem::worker::IndexedResourceMetadata) -> Self {
-            IndexedResourceKey {
-                resource_name: value.resource_name,
-                resource_params: value.resource_params,
-            }
-        }
-    }
+    use crate::model::oplog::PersistenceLevel;
 
     impl From<PersistenceLevel> for golem_api_grpc::proto::golem::worker::PersistenceLevel {
         fn from(value: PersistenceLevel) -> Self {
diff --git a/golem-common/src/model/protobuf.rs b/golem-common/src/model/protobuf.rs
index fb8e8848..b0c2fa02 100644
--- a/golem-common/src/model/protobuf.rs
+++ b/golem-common/src/model/protobuf.rs
@@ -12,15 +12,15 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use crate::model::oplog::OplogIndex;
+use super::{WorkerResourceDescription, WorkerWasiConfigVarsFilter};
+use crate::model::oplog::{OplogIndex, WorkerResourceId};
 use crate::model::{
     AccountId, ComponentFilePath, ComponentFilePermissions, ComponentFileSystemNode,
-    ComponentFileSystemNodeDetails, ComponentType, FilterComparator, GatewayBindingType,
-    IdempotencyKey, InitialComponentFile, InitialComponentFileKey, LogLevel, NumberOfShards, Pod,
-    PromiseId, RoutingTable, RoutingTableEntry, ScanCursor, ShardId, StringFilterComparator,
-    TargetWorkerId, Timestamp, WorkerCreatedAtFilter, WorkerEnvFilter, WorkerEvent, WorkerFilter,
-    WorkerId, WorkerNameFilter, WorkerNotFilter, WorkerStatus, WorkerStatusFilter,
-    WorkerVersionFilter,
+    ComponentFileSystemNodeDetails, ComponentType, FilterComparator, IdempotencyKey,
+    InitialComponentFile, InitialComponentFileKey, LogLevel, NumberOfShards, Pod, PromiseId,
+    RoutingTable, RoutingTableEntry, ScanCursor, ShardId, StringFilterComparator, Timestamp,
+    WorkerCreatedAtFilter, WorkerEnvFilter, WorkerEvent, WorkerFilter, WorkerId, WorkerNameFilter,
+    WorkerNotFilter, WorkerStatus, WorkerStatusFilter, WorkerVersionFilter,
 };
 use golem_api_grpc::proto::golem;
 use golem_api_grpc::proto::golem::shardmanager::{
@@ -73,29 +73,6 @@ impl TryFrom<golem_api_grpc::proto::golem::worker::WorkerId> for WorkerId {
     }
 }
 
-impl TryFrom<golem::worker::TargetWorkerId> for TargetWorkerId {
-    type Error = String;
-
-    fn try_from(value: golem::worker::TargetWorkerId) -> Result<Self, Self::Error> {
-        Ok(Self {
-            component_id: value
-                .component_id
-                .ok_or("Missing component_id")?
-                .try_into()?,
-            worker_name: value.name,
-        })
-    }
-}
-
-impl From<TargetWorkerId> for golem::worker::TargetWorkerId {
-    fn from(value: TargetWorkerId) -> Self {
-        Self {
-            component_id: Some(value.component_id.into()),
-            name: value.worker_name,
-        }
-    }
-}
-
 impl From<PromiseId> for golem_api_grpc::proto::golem::worker::PromiseId {
     fn from(value: PromiseId) -> Self {
         Self {
@@ -239,6 +216,13 @@ impl TryFrom<golem_api_grpc::proto::golem::worker::WorkerFilter> for WorkerFilte
                 golem_api_grpc::proto::golem::worker::worker_filter::Filter::Env(filter) => Ok(
                     WorkerFilter::new_env(filter.name, filter.comparator.try_into()?, filter.value),
                 ),
+                golem_api_grpc::proto::golem::worker::worker_filter::Filter::WasiConfigVars(
+                    filter,
+                ) => Ok(WorkerFilter::new_wasi_config_vars(
+                    filter.name,
+                    filter.comparator.try_into()?,
+                    filter.value,
+                )),
                 golem_api_grpc::proto::golem::worker::worker_filter::Filter::Not(filter) => {
                     let filter = *filter.filter.ok_or_else(|| "Missing filter".to_string())?;
                     Ok(WorkerFilter::new_not(filter.try_into()?))
@@ -301,6 +285,17 @@ impl From<WorkerFilter> for golem_api_grpc::proto::golem::worker::WorkerFilter {
                     value,
                 },
             ),
+            WorkerFilter::WasiConfigVars(WorkerWasiConfigVarsFilter {
+                name,
+                comparator,
+                value,
+            }) => golem_api_grpc::proto::golem::worker::worker_filter::Filter::WasiConfigVars(
+                golem_api_grpc::proto::golem::worker::WorkerWasiConfigVarsFilter {
+                    name,
+                    comparator: comparator.into(),
+                    value,
+                },
+            ),
             WorkerFilter::Status(WorkerStatusFilter { comparator, value }) => {
                 golem_api_grpc::proto::golem::worker::worker_filter::Filter::Status(
                     golem_api_grpc::proto::golem::worker::WorkerStatusFilter {
@@ -740,43 +735,26 @@ impl TryFrom<golem_api_grpc::proto::golem::worker::FileSystemNode> for Component
     }
 }
 
-impl From<golem_api_grpc::proto::golem::apidefinition::GatewayBindingType> for GatewayBindingType {
-    fn from(value: golem_api_grpc::proto::golem::apidefinition::GatewayBindingType) -> Self {
-        match value {
-            golem_api_grpc::proto::golem::apidefinition::GatewayBindingType::Default => {
-                GatewayBindingType::Default
-            }
-            golem_api_grpc::proto::golem::apidefinition::GatewayBindingType::FileServer => {
-                GatewayBindingType::FileServer
-            }
-            golem_api_grpc::proto::golem::apidefinition::GatewayBindingType::HttpHandler => {
-                GatewayBindingType::HttpHandler
-            }
-            golem_api_grpc::proto::golem::apidefinition::GatewayBindingType::CorsPreflight => {
-                GatewayBindingType::CorsPreflight
-            }
-            golem_api_grpc::proto::golem::apidefinition::GatewayBindingType::AuthCallBack => {
-                GatewayBindingType::CorsPreflight
-            }
-        }
+pub fn to_protobuf_resource_description(
+    key: WorkerResourceId,
+    description: WorkerResourceDescription,
+) -> golem::worker::ResourceDescription {
+    golem::worker::ResourceDescription {
+        created_at: Some(description.created_at.into()),
+        resource_id: key.0,
+        resource_owner: description.resource_owner,
+        resource_name: description.resource_name,
     }
 }
 
-impl From<GatewayBindingType> for golem_api_grpc::proto::golem::apidefinition::GatewayBindingType {
-    fn from(value: GatewayBindingType) -> Self {
-        match value {
-            GatewayBindingType::Default => {
-                golem_api_grpc::proto::golem::apidefinition::GatewayBindingType::Default
-            }
-            GatewayBindingType::FileServer => {
-                golem_api_grpc::proto::golem::apidefinition::GatewayBindingType::FileServer
-            }
-            GatewayBindingType::HttpHandler => {
-                golem_api_grpc::proto::golem::apidefinition::GatewayBindingType::HttpHandler
-            }
-            GatewayBindingType::CorsPreflight => {
-                golem_api_grpc::proto::golem::apidefinition::GatewayBindingType::CorsPreflight
-            }
-        }
-    }
+pub fn from_protobuf_resource_description(
+    description: golem::worker::ResourceDescription,
+) -> Result<(WorkerResourceId, WorkerResourceDescription), String> {
+    let key = WorkerResourceId(description.resource_id);
+    let value = WorkerResourceDescription {
+        created_at: description.created_at.ok_or("Missing created_at")?.into(),
+        resource_owner: description.resource_owner,
+        resource_name: description.resource_name,
+    };
+    Ok((key, value))
 }
diff --git a/golem-common/src/tracing.rs b/golem-common/src/tracing.rs
index 1c8ec02c..bdf9e33f 100644
--- a/golem-common/src/tracing.rs
+++ b/golem-common/src/tracing.rs
@@ -31,6 +31,7 @@ use tracing_subscriber::Registry;
 
 use crate::config::env_config_provider;
 use crate::tracing::format::JsonFlattenSpanFormatter;
+use crate::SafeDisplay;
 
 pub enum Output {
     Stdout,
@@ -133,6 +134,42 @@ impl OutputConfig {
     }
 }
 
+impl SafeDisplay for OutputConfig {
+    fn to_safe_string(&self) -> String {
+        let mut flags = Vec::new();
+
+        if self.ansi {
+            flags.push("ansi");
+        }
+        if self.compact {
+            flags.push("compact");
+        }
+        if self.json {
+            flags.push("json");
+        }
+        if self.json_flatten {
+            flags.push("json_flatten");
+        }
+        if self.json_flatten_span {
+            flags.push("json_flatten_span");
+        }
+        if self.pretty {
+            flags.push("pretty");
+        }
+        if self.without_time {
+            flags.push("without_time");
+        }
+        if self.span_events_active {
+            flags.push("span_events_active");
+        }
+        if self.span_events_full {
+            flags.push("span_events_full");
+        }
+
+        flags.join(", ")
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct TracingConfig {
     pub stdout: OutputConfig,
@@ -201,6 +238,34 @@ impl TracingConfig {
     }
 }
 
+impl SafeDisplay for TracingConfig {
+    fn to_safe_string(&self) -> String {
+        use std::fmt::Write;
+
+        let mut result = String::new();
+
+        if self.stdout.enabled {
+            let _ = writeln!(&mut result, "stdout:");
+            let _ = writeln!(&mut result, "{}", self.stdout.to_safe_string_indented());
+        }
+        if self.file.enabled {
+            let _ = writeln!(&mut result, "file:");
+            let _ = writeln!(&mut result, "{}", self.file.to_safe_string_indented());
+        }
+        if let Some(dir) = &self.file_dir {
+            let _ = writeln!(&mut result, "file directory: {dir}");
+        }
+        if let Some(file) = &self.file_name {
+            let _ = writeln!(&mut result, "file name: {file}");
+        }
+        let _ = writeln!(&mut result, "console: {}", self.console);
+        let _ = writeln!(&mut result, "file truncate: {}", self.file_truncate);
+        let _ = writeln!(&mut result, "destructor friendly: {}", self.dtor_friendly);
+
+        result
+    }
+}
+
 impl Default for TracingConfig {
     fn default() -> Self {
         Self {
diff --git a/golem-component-compilation-service/src/config.rs b/golem-component-compilation-service/src/config.rs
index 1749a455..c9340cef 100644
--- a/golem-component-compilation-service/src/config.rs
+++ b/golem-component-compilation-service/src/config.rs
@@ -15,6 +15,7 @@
 use http::Uri;
 use serde::{Deserialize, Serialize};
 use std::fmt::Debug;
+use std::fmt::Write;
 use std::net::{Ipv4Addr, SocketAddrV4};
 use std::path::Path;
 use std::time::Duration;
@@ -23,6 +24,7 @@ use uuid::Uuid;
 use golem_common::config::{ConfigExample, ConfigLoader, HasConfigExamples};
 use golem_common::model::RetryConfig;
 use golem_common::tracing::TracingConfig;
+use golem_common::SafeDisplay;
 use golem_service_base::config::BlobStorageConfig;
 use golem_worker_executor::services::golem_config::CompiledComponentServiceConfig;
 
@@ -48,6 +50,43 @@ pub struct ServerConfig {
     pub http_port: u16,
 }
 
+impl SafeDisplay for ServerConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "tracing:");
+        let _ = writeln!(&mut result, "{}", self.tracing.to_safe_string_indented());
+        let _ = writeln!(&mut result, "component service:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.component_service.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "compiled component service:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.compiled_component_service.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "blob storage:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.blob_storage.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "compile worker:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.compile_worker.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "gRPC host: {}", self.grpc_host);
+        let _ = writeln!(&mut result, "gRPC port: {}", self.grpc_port);
+        let _ = writeln!(&mut result, "HTTP host: {}", self.http_host);
+        let _ = writeln!(&mut result, "HTTP port: {}", self.http_port);
+        result
+    }
+}
+
 impl ServerConfig {
     pub fn http_addr(&self) -> Option<SocketAddrV4> {
         let address = self.http_host.parse::<Ipv4Addr>().ok()?;
@@ -71,6 +110,23 @@ impl ComponentServiceConfig {
     }
 }
 
+impl SafeDisplay for ComponentServiceConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        match self {
+            ComponentServiceConfig::Static(inner) => {
+                let _ = writeln!(&mut result, "static:");
+                let _ = writeln!(&mut result, "{}", inner.to_safe_string_indented());
+            }
+            ComponentServiceConfig::Dynamic(inner) => {
+                let _ = writeln!(&mut result, "dynamic:");
+                let _ = writeln!(&mut result, "{}", inner.to_safe_string_indented());
+            }
+        }
+        result
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct StaticComponentServiceConfig {
     pub host: String,
@@ -89,11 +145,29 @@ impl StaticComponentServiceConfig {
     }
 }
 
+impl SafeDisplay for StaticComponentServiceConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "host: {}", self.host);
+        let _ = writeln!(&mut result, "port: {}", self.port);
+        let _ = writeln!(&mut result, "access_token: ****");
+        result
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct DynamicComponentServiceConfig {
     pub access_token: Uuid,
 }
 
+impl SafeDisplay for DynamicComponentServiceConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "access_token: ****");
+        result
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct CompileWorkerConfig {
     pub retries: RetryConfig,
@@ -101,6 +175,21 @@ pub struct CompileWorkerConfig {
     pub connect_timeout: Duration,
 }
 
+impl SafeDisplay for CompileWorkerConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(
+            &mut result,
+            "max component size: {}",
+            self.max_component_size
+        );
+        let _ = writeln!(&mut result, "connect timeout: {:?}", self.connect_timeout);
+        let _ = writeln!(&mut result, "retries:");
+        let _ = writeln!(&mut result, "{}", self.retries.to_safe_string_indented());
+        result
+    }
+}
+
 impl Default for ServerConfig {
     fn default() -> Self {
         Self {
@@ -172,17 +261,12 @@ pub fn make_config_loader() -> ConfigLoader<ServerConfig> {
 
 #[cfg(test)]
 mod tests {
-    use std::env;
-    use std::path::PathBuf;
     use test_r::test;
 
     use crate::config::make_config_loader;
 
     #[test]
     pub fn config_is_loadable() {
-        env::set_current_dir(PathBuf::from(env!("CARGO_MANIFEST_DIR")))
-            .expect("Failed to set current directory");
-
         make_config_loader().load().expect("Failed to load config");
     }
 }
diff --git a/golem-component-compilation-service/src/lib.rs b/golem-component-compilation-service/src/lib.rs
index 767f795a..59e5b9df 100644
--- a/golem-component-compilation-service/src/lib.rs
+++ b/golem-component-compilation-service/src/lib.rs
@@ -58,14 +58,9 @@ pub async fn run(
 ) -> anyhow::Result<RunDetails> {
     let blob_storage: Arc<dyn BlobStorage + Send + Sync> = match &config.blob_storage {
         BlobStorageConfig::S3(config) => {
-            info!("Using S3 for blob storage");
             Arc::new(S3BlobStorage::new(config.clone()).await)
         }
         BlobStorageConfig::LocalFileSystem(config) => {
-            info!(
-                "Using local file system for blob storage at {:?}",
-                config.root
-            );
             Arc::new(
                 golem_service_base::storage::blob::fs::FileSystemBlobStorage::new(&config.root)
                     .await
@@ -73,14 +68,12 @@ pub async fn run(
             )
         }
         BlobStorageConfig::InMemory(_) => {
-            info!("Using in-memory blob storage");
             Arc::new(golem_service_base::storage::blob::memory::InMemoryBlobStorage::new())
         }
         BlobStorageConfig::KVStoreSqlite(_) => {
             Err(anyhow!("KVStoreSqlite configuration option is not supported - use an explicit Sqlite configuration instead"))?
         }
         BlobStorageConfig::Sqlite(sqlite) => {
-            info!("Using Sqlite for blob storage at {}", sqlite.database);
             let pool = SqlitePool::configured(sqlite)
                 .await
                 .map_err(|err| anyhow!(err))?;
@@ -141,7 +134,7 @@ async fn start_grpc_server(
     component_service_config: ComponentServiceConfig,
     join_set: &mut JoinSet<anyhow::Result<()>>,
 ) -> anyhow::Result<u16> {
-    let (mut health_reporter, health_service) = tonic_health::server::health_reporter();
+    let (health_reporter, health_service) = tonic_health::server::health_reporter();
 
     let listener = TcpListener::bind(addr).await?;
     let grpc_port = listener.local_addr()?.port();
diff --git a/golem-component-compilation-service/src/service/compile_service.rs b/golem-component-compilation-service/src/service/compile_service.rs
index bb1ecf9d..48f8295f 100644
--- a/golem-component-compilation-service/src/service/compile_service.rs
+++ b/golem-component-compilation-service/src/service/compile_service.rs
@@ -16,7 +16,7 @@ use super::*;
 use crate::config::{CompileWorkerConfig, ComponentServiceConfig, StaticComponentServiceConfig};
 use crate::model::*;
 use async_trait::async_trait;
-use golem_common::model::ComponentId;
+use golem_common::model::{ComponentId, ProjectId};
 use golem_worker_executor::services::compiled_component::CompiledComponentService;
 use std::sync::Arc;
 use tokio::sync::mpsc;
@@ -28,6 +28,7 @@ pub trait CompilationService {
         &self,
         component_id: ComponentId,
         component_version: u64,
+        project_id: ProjectId,
         sender: Option<StaticComponentServiceConfig>,
     ) -> Result<(), CompilationError>;
 }
@@ -71,6 +72,7 @@ impl CompilationService for ComponentCompilationServiceImpl {
         &self,
         component_id: ComponentId,
         component_version: u64,
+        project_id: ProjectId,
         sender: Option<StaticComponentServiceConfig>,
     ) -> Result<(), CompilationError> {
         tracing::info!(
@@ -83,6 +85,7 @@ impl CompilationService for ComponentCompilationServiceImpl {
                 id: component_id,
                 version: component_version,
             },
+            project_id,
             sender,
         };
         self.queue.send(request).await?;
diff --git a/golem-component-compilation-service/src/service/compile_worker.rs b/golem-component-compilation-service/src/service/compile_worker.rs
index 6f33ea11..4534ed52 100644
--- a/golem-component-compilation-service/src/service/compile_worker.rs
+++ b/golem-component-compilation-service/src/service/compile_worker.rs
@@ -14,15 +14,15 @@
 
 use crate::config::{CompileWorkerConfig, StaticComponentServiceConfig};
 use crate::model::*;
-use futures_util::TryStreamExt;
+use futures::TryStreamExt;
 use golem_api_grpc::proto::golem::component::v1::component_service_client::ComponentServiceClient;
 use golem_api_grpc::proto::golem::component::v1::download_component_response;
 use golem_api_grpc::proto::golem::component::v1::ComponentError;
 use golem_api_grpc::proto::golem::component::v1::DownloadComponentRequest;
 use golem_common::client::{GrpcClient, GrpcClientConfig};
 use golem_common::metrics::external_calls::record_external_call_response_size_bytes;
-use golem_common::model::ComponentId;
 use golem_common::model::RetryConfig;
+use golem_common::model::{ComponentId, ProjectId};
 use golem_common::retries::with_retries;
 use golem_worker_executor::grpc::authorised_grpc_request;
 use golem_worker_executor::grpc::is_grpc_retriable;
@@ -85,7 +85,9 @@ impl CompileWorker {
                         }
                     }
 
-                    let result = worker.compile_component(&request.component).await;
+                    let result = worker
+                        .compile_component(&request.component, &request.project_id)
+                        .await;
                     match result {
                         Err(error) => {
                             warn!(
@@ -100,6 +102,7 @@ impl CompileWorker {
                                 .send(CompiledComponent {
                                     component_and_version: request.component,
                                     component,
+                                    project_id: request.project_id,
                                 })
                                 .await;
 
@@ -146,6 +149,7 @@ impl CompileWorker {
     async fn compile_component(
         &self,
         component_with_version: &ComponentWithVersion,
+        project_id: &ProjectId,
     ) -> Result<Component, CompilationError> {
         let engine = self.engine.clone();
 
@@ -153,6 +157,7 @@ impl CompileWorker {
         let result = self
             .compiled_component_service
             .get(
+                project_id,
                 &component_with_version.id,
                 component_with_version.version,
                 &engine,
diff --git a/golem-component-compilation-service/src/service/upload_worker.rs b/golem-component-compilation-service/src/service/upload_worker.rs
index a9035ed3..8044460b 100644
--- a/golem-component-compilation-service/src/service/upload_worker.rs
+++ b/golem-component-compilation-service/src/service/upload_worker.rs
@@ -52,11 +52,13 @@ impl UploadWorker {
         let CompiledComponent {
             component_and_version,
             component,
+            project_id,
         } = compiled_component;
 
         let upload_result = self
             .compiled_component_service
             .put(
+                &project_id,
                 &component_and_version.id,
                 component_and_version.version,
                 &component,
diff --git a/golem-component-service/src/api/component.rs b/golem-component-service/src/api/component.rs
index df6bdeb6..dbc800f3 100644
--- a/golem-component-service/src/api/component.rs
+++ b/golem-component-service/src/api/component.rs
@@ -20,7 +20,8 @@ use crate::model::{
     ComponentEnv, DynamicLinking, InitialComponentFilesArchiveAndPermissions, UpdatePayload,
 };
 use crate::model::{ComponentQuery, ComponentSearch};
-use futures_util::{stream, StreamExt, TryStreamExt};
+use futures::{stream, StreamExt, TryStreamExt};
+use golem_common::model::agent::AgentTypes;
 use golem_common::model::auth::AuthCtx;
 use golem_common::model::component::VersionedComponentId;
 use golem_common::model::error::{ErrorBody, ErrorsBody};
@@ -53,6 +54,7 @@ pub struct UploadPayload {
     files: Option<TempFileUpload>,
     dynamic_linking: Option<JsonField<DynamicLinking>>,
     env: Option<JsonField<ComponentEnv>>,
+    agent_types: Option<JsonField<AgentTypes>>,
 }
 
 pub struct ComponentApi {
@@ -162,6 +164,7 @@ impl ComponentApi {
                 HashMap::new(),
                 &auth,
                 HashMap::new(),
+                vec![],
             )
             .await?;
 
@@ -226,6 +229,10 @@ impl ComponentApi {
                     .dynamic_linking,
                 &auth,
                 env,
+                payload
+                    .agent_types
+                    .map(|types| types.0.types)
+                    .unwrap_or_default(),
             )
             .await?;
 
@@ -243,6 +250,7 @@ impl ComponentApi {
         token: GolemSecurityScheme,
     ) -> Result<Json<dto::Component>> {
         let auth = AuthCtx::new(token.secret());
+
         let record = recorded_http_api_request!(
             "create_component",
             component_name = payload.query.0.component_name.to_string(),
@@ -292,6 +300,10 @@ impl ComponentApi {
                     .dynamic_linking,
                 &auth,
                 env,
+                payload
+                    .agent_types
+                    .map(|types| types.0.types)
+                    .unwrap_or_default(),
             )
             .await?;
 
@@ -493,6 +505,7 @@ impl ComponentApi {
         token: GolemSecurityScheme,
     ) -> Result<Json<Vec<dto::Component>>> {
         let auth = AuthCtx::new(token.secret());
+
         let record = recorded_http_api_request!(
             "search_components",
             search_components = components_search
@@ -706,9 +719,9 @@ impl ComponentApi {
     #[oai(
         path = "/:component_id/versions/latest/plugins/installs/batch",
         method = "post",
-        operation_id = "bath_update_installed_plugins"
+        operation_id = "batch_update_installed_plugins"
     )]
-    async fn bath_update_installed_plugins(
+    async fn batch_update_installed_plugins(
         &self,
         component_id: Path<ComponentId>,
         updates: Json<BatchPluginInstallationUpdates>,
diff --git a/golem-component-service/src/api/mod.rs b/golem-component-service/src/api/mod.rs
index ced87f5b..e899df18 100644
--- a/golem-component-service/src/api/mod.rs
+++ b/golem-component-service/src/api/mod.rs
@@ -12,6 +12,7 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
+pub mod agent_types;
 pub mod common;
 pub mod component;
 pub mod dto;
@@ -27,7 +28,12 @@ use poem::error::ReadBodyError;
 use poem_openapi::payload::Json;
 use poem_openapi::{ApiResponse, OpenApiService};
 
-pub type Apis = (HealthcheckApi, component::ComponentApi, plugin::PluginApi);
+pub type Apis = (
+    HealthcheckApi,
+    component::ComponentApi,
+    plugin::PluginApi,
+    agent_types::AgentTypesApi,
+);
 
 pub fn make_open_api_service(services: &Services) -> OpenApiService<Apis, ()> {
     OpenApiService::new(
@@ -38,6 +44,7 @@ pub fn make_open_api_service(services: &Services) -> OpenApiService<Apis, ()> {
                 services.api_mapper.clone(),
             ),
             plugin::PluginApi::new(services.plugin_service.clone()),
+            agent_types::AgentTypesApi::new(services.agent_types_service.clone()),
         ),
         "Golem API",
         "1.0",
diff --git a/golem-component-service/src/authed/component.rs b/golem-component-service/src/authed/component.rs
index 3c8dc41b..6e1e0c06 100644
--- a/golem-component-service/src/authed/component.rs
+++ b/golem-component-service/src/authed/component.rs
@@ -12,15 +12,18 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
+use crate::authed::{
+    is_authorized_by_component, is_authorized_by_project, is_authorized_by_project_or_default,
+};
 use crate::error::ComponentError;
 use crate::model::InitialComponentFilesArchiveAndPermissions;
 use crate::model::{Component, ComponentByNameAndVersion, ComponentConstraints};
 use crate::service::component::ComponentService;
 use bytes::Bytes;
-use futures_util::stream::BoxStream;
+use futures::stream::BoxStream;
+use golem_common::model::agent::AgentType;
 use golem_common::model::auth::AuthCtx;
 use golem_common::model::auth::ProjectAction;
-use golem_common::model::component::ComponentOwner;
 use golem_common::model::component::VersionedComponentId;
 use golem_common::model::component_constraint::FunctionConstraints;
 use golem_common::model::component_metadata::DynamicLinkedInstance;
@@ -57,61 +60,6 @@ impl AuthedComponentService {
         }
     }
 
-    async fn is_authorized_by_project(
-        &self,
-        auth: &AuthCtx,
-        project_id: &ProjectId,
-        action: &ProjectAction,
-    ) -> Result<ComponentOwner, ComponentError> {
-        let namespace = self
-            .auth_service
-            .authorize_project_action(project_id, action.clone(), auth)
-            .await?;
-
-        Ok(ComponentOwner {
-            account_id: namespace.account_id,
-            project_id: namespace.project_id,
-        })
-    }
-
-    async fn is_authorized_by_project_or_default(
-        &self,
-        auth: &AuthCtx,
-        project_id: Option<ProjectId>,
-        action: &ProjectAction,
-    ) -> Result<ComponentOwner, ComponentError> {
-        if let Some(project_id) = project_id.clone() {
-            self.is_authorized_by_project(auth, &project_id, action)
-                .await
-        } else {
-            let project = self.project_service.get_default(&auth.token_secret).await?;
-            Ok(ComponentOwner {
-                account_id: project.owner_account_id,
-                project_id: project.id,
-            })
-        }
-    }
-
-    async fn is_authorized_by_component(
-        &self,
-        auth: &AuthCtx,
-        component_id: &ComponentId,
-        action: &ProjectAction,
-    ) -> Result<ComponentOwner, ComponentError> {
-        let owner = self.component_service.get_owner(component_id).await?;
-
-        match owner {
-            Some(owner) => {
-                self.is_authorized_by_project(auth, &owner.project_id, action)
-                    .await
-            }
-            None => Err(ComponentError::Unauthorized(format!(
-                "Account unauthorized to perform action on component {}: {}",
-                component_id.0, action
-            ))),
-        }
-    }
-
     pub async fn create(
         &self,
         project_id: Option<ProjectId>,
@@ -122,11 +70,17 @@ impl AuthedComponentService {
         dynamic_linking: HashMap<String, DynamicLinkedInstance>,
         auth: &AuthCtx,
         env: HashMap<String, String>,
+        agent_types: Vec<AgentType>,
     ) -> Result<Component, ComponentError> {
         let component_id = ComponentId::new_v4();
-        let owner = self
-            .is_authorized_by_project_or_default(auth, project_id, &ProjectAction::CreateComponent)
-            .await?;
+        let owner = is_authorized_by_project_or_default(
+            &self.auth_service,
+            &self.project_service,
+            auth,
+            project_id,
+            &ProjectAction::CreateComponent,
+        )
+        .await?;
 
         let component = self
             .component_service
@@ -140,6 +94,7 @@ impl AuthedComponentService {
                 dynamic_linking,
                 &owner,
                 env,
+                agent_types,
             )
             .await?;
 
@@ -156,11 +111,17 @@ impl AuthedComponentService {
         dynamic_linking: HashMap<String, DynamicLinkedInstance>,
         auth: &AuthCtx,
         env: HashMap<String, String>,
+        agent_types: Vec<AgentType>,
     ) -> Result<Component, ComponentError> {
         let component_id = ComponentId::new_v4();
-        let owner = self
-            .is_authorized_by_project_or_default(auth, project_id, &ProjectAction::CreateComponent)
-            .await?;
+        let owner = is_authorized_by_project_or_default(
+            &self.auth_service,
+            &self.project_service,
+            auth,
+            project_id,
+            &ProjectAction::CreateComponent,
+        )
+        .await?;
 
         let component = self
             .component_service
@@ -174,6 +135,7 @@ impl AuthedComponentService {
                 dynamic_linking,
                 &owner,
                 env,
+                agent_types,
             )
             .await?;
 
@@ -189,10 +151,16 @@ impl AuthedComponentService {
         dynamic_linking: HashMap<String, DynamicLinkedInstance>,
         auth: &AuthCtx,
         env: HashMap<String, String>,
+        agent_types: Vec<AgentType>,
     ) -> Result<Component, ComponentError> {
-        let owner = self
-            .is_authorized_by_component(auth, component_id, &ProjectAction::UpdateComponent)
-            .await?;
+        let owner = is_authorized_by_component(
+            &self.auth_service,
+            &self.component_service,
+            auth,
+            component_id,
+            &ProjectAction::UpdateComponent,
+        )
+        .await?;
 
         let component = self
             .component_service
@@ -204,6 +172,7 @@ impl AuthedComponentService {
                 dynamic_linking,
                 &owner,
                 env,
+                agent_types,
             )
             .await?;
 
@@ -219,10 +188,16 @@ impl AuthedComponentService {
         dynamic_linking: HashMap<String, DynamicLinkedInstance>,
         auth: &AuthCtx,
         env: HashMap<String, String>,
+        agent_types: Vec<AgentType>,
     ) -> Result<Component, ComponentError> {
-        let owner = self
-            .is_authorized_by_component(auth, component_id, &ProjectAction::UpdateComponent)
-            .await?;
+        let owner = is_authorized_by_component(
+            &self.auth_service,
+            &self.component_service,
+            auth,
+            component_id,
+            &ProjectAction::UpdateComponent,
+        )
+        .await?;
 
         let component = self
             .component_service
@@ -234,6 +209,7 @@ impl AuthedComponentService {
                 dynamic_linking,
                 &owner,
                 env,
+                agent_types,
             )
             .await?;
 
@@ -246,9 +222,14 @@ impl AuthedComponentService {
         version: Option<u64>,
         auth: &AuthCtx,
     ) -> Result<Vec<u8>, ComponentError> {
-        let namespace = self
-            .is_authorized_by_component(auth, component_id, &ProjectAction::ViewComponent)
-            .await?;
+        let namespace = is_authorized_by_component(
+            &self.auth_service,
+            &self.component_service,
+            auth,
+            component_id,
+            &ProjectAction::ViewComponent,
+        )
+        .await?;
 
         let data = self
             .component_service
@@ -264,9 +245,14 @@ impl AuthedComponentService {
         version: Option<u64>,
         auth: &AuthCtx,
     ) -> Result<BoxStream<'static, Result<Vec<u8>, anyhow::Error>>, ComponentError> {
-        let owner = self
-            .is_authorized_by_component(auth, component_id, &ProjectAction::ViewComponent)
-            .await?;
+        let owner = is_authorized_by_component(
+            &self.auth_service,
+            &self.component_service,
+            auth,
+            component_id,
+            &ProjectAction::ViewComponent,
+        )
+        .await?;
 
         let stream = self
             .component_service
@@ -281,9 +267,14 @@ impl AuthedComponentService {
         component_name: Option<ComponentName>,
         auth: &AuthCtx,
     ) -> Result<Vec<Component>, ComponentError> {
-        let owner = self
-            .is_authorized_by_project_or_default(auth, project_id, &ProjectAction::ViewComponent)
-            .await?;
+        let owner = is_authorized_by_project_or_default(
+            &self.auth_service,
+            &self.project_service,
+            auth,
+            project_id,
+            &ProjectAction::ViewComponent,
+        )
+        .await?;
 
         let result = self
             .component_service
@@ -299,9 +290,14 @@ impl AuthedComponentService {
         component_names: Vec<ComponentByNameAndVersion>,
         auth: &AuthCtx,
     ) -> Result<Vec<Component>, ComponentError> {
-        let owner = self
-            .is_authorized_by_project_or_default(auth, project_id, &ProjectAction::ViewComponent)
-            .await?;
+        let owner = is_authorized_by_project_or_default(
+            &self.auth_service,
+            &self.project_service,
+            auth,
+            project_id,
+            &ProjectAction::ViewComponent,
+        )
+        .await?;
 
         let result = self
             .component_service
@@ -316,9 +312,13 @@ impl AuthedComponentService {
         project_id: &ProjectId,
         auth: &AuthCtx,
     ) -> Result<Vec<Component>, ComponentError> {
-        let owner = self
-            .is_authorized_by_project(auth, project_id, &ProjectAction::ViewComponent)
-            .await?;
+        let owner = is_authorized_by_project(
+            &self.auth_service,
+            auth,
+            project_id,
+            &ProjectAction::ViewComponent,
+        )
+        .await?;
 
         let result = self.component_service.find_by_name(None, &owner).await?;
         Ok(result)
@@ -329,13 +329,14 @@ impl AuthedComponentService {
         component_id: &VersionedComponentId,
         auth: &AuthCtx,
     ) -> Result<Option<Component>, ComponentError> {
-        let owner = self
-            .is_authorized_by_component(
-                auth,
-                &component_id.component_id,
-                &ProjectAction::ViewComponent,
-            )
-            .await?;
+        let owner = is_authorized_by_component(
+            &self.auth_service,
+            &self.component_service,
+            auth,
+            &component_id.component_id,
+            &ProjectAction::ViewComponent,
+        )
+        .await?;
 
         let result = self
             .component_service
@@ -350,9 +351,14 @@ impl AuthedComponentService {
         component_id: &ComponentId,
         auth: &AuthCtx,
     ) -> Result<Option<Component>, ComponentError> {
-        let owner = self
-            .is_authorized_by_component(auth, component_id, &ProjectAction::ViewComponent)
-            .await?;
+        let owner = is_authorized_by_component(
+            &self.auth_service,
+            &self.component_service,
+            auth,
+            component_id,
+            &ProjectAction::ViewComponent,
+        )
+        .await?;
 
         let result = self
             .component_service
@@ -366,12 +372,16 @@ impl AuthedComponentService {
         component_id: &ComponentId,
         auth: &AuthCtx,
     ) -> Result<Vec<Component>, ComponentError> {
-        let owner = self
-            .is_authorized_by_component(auth, component_id, &ProjectAction::ViewComponent)
-            .await?;
+        let owner = is_authorized_by_component(
+            &self.auth_service,
+            &self.component_service,
+            auth,
+            component_id,
+            &ProjectAction::ViewComponent,
+        )
+        .await?;
 
         let result = self.component_service.get(component_id, &owner).await?;
-
         Ok(result)
     }
 
@@ -381,9 +391,14 @@ impl AuthedComponentService {
         constraints: FunctionConstraints,
         auth: &AuthCtx,
     ) -> Result<ComponentConstraints, ComponentError> {
-        let owner = self
-            .is_authorized_by_component(auth, &component_id, &ProjectAction::UpdateComponent)
-            .await?;
+        let owner = is_authorized_by_component(
+            &self.auth_service,
+            &self.component_service,
+            auth,
+            &component_id,
+            &ProjectAction::UpdateComponent,
+        )
+        .await?;
 
         let component_constraints = ComponentConstraints {
             owner,
@@ -405,9 +420,14 @@ impl AuthedComponentService {
         constraints: FunctionConstraints,
         auth: &AuthCtx,
     ) -> Result<ComponentConstraints, ComponentError> {
-        let owner = self
-            .is_authorized_by_component(auth, &component_id, &ProjectAction::UpdateComponent)
-            .await?;
+        let owner = is_authorized_by_component(
+            &self.auth_service,
+            &self.component_service,
+            auth,
+            &component_id,
+            &ProjectAction::UpdateComponent,
+        )
+        .await?;
 
         let constraints = ComponentConstraints {
             owner: owner.clone(),
@@ -433,9 +453,14 @@ impl AuthedComponentService {
         component_id: &ComponentId,
         component_version: ComponentVersion,
     ) -> Result<Vec<PluginInstallation>, ComponentError> {
-        let owner = self
-            .is_authorized_by_component(auth, component_id, &ProjectAction::UpdateComponent)
-            .await?;
+        let owner = is_authorized_by_component(
+            &self.auth_service,
+            &self.component_service,
+            auth,
+            component_id,
+            &ProjectAction::UpdateComponent,
+        )
+        .await?;
 
         let installations = self
             .component_service
@@ -451,9 +476,14 @@ impl AuthedComponentService {
         component_id: &ComponentId,
         installation: PluginInstallationCreation,
     ) -> Result<PluginInstallation, ComponentError> {
-        let owner = self
-            .is_authorized_by_component(auth, component_id, &ProjectAction::UpdateComponent)
-            .await?;
+        let owner = is_authorized_by_component(
+            &self.auth_service,
+            &self.component_service,
+            auth,
+            component_id,
+            &ProjectAction::UpdateComponent,
+        )
+        .await?;
 
         let installation = self
             .component_service
@@ -470,9 +500,14 @@ impl AuthedComponentService {
         component_id: &ComponentId,
         update: PluginInstallationUpdate,
     ) -> Result<(), ComponentError> {
-        let owner = self
-            .is_authorized_by_component(auth, component_id, &ProjectAction::UpdateComponent)
-            .await?;
+        let owner = is_authorized_by_component(
+            &self.auth_service,
+            &self.component_service,
+            auth,
+            component_id,
+            &ProjectAction::UpdateComponent,
+        )
+        .await?;
 
         self.component_service
             .update_plugin_installation_for_component(&owner, installation_id, component_id, update)
@@ -485,9 +520,14 @@ impl AuthedComponentService {
         installation_id: &PluginInstallationId,
         component_id: &ComponentId,
     ) -> Result<(), ComponentError> {
-        let owner = self
-            .is_authorized_by_component(auth, component_id, &ProjectAction::UpdateComponent)
-            .await?;
+        let owner = is_authorized_by_component(
+            &self.auth_service,
+            &self.component_service,
+            auth,
+            component_id,
+            &ProjectAction::UpdateComponent,
+        )
+        .await?;
 
         self.component_service
             .delete_plugin_installation_for_component(&owner, installation_id, component_id)
@@ -500,9 +540,14 @@ impl AuthedComponentService {
         component_id: &ComponentId,
         actions: &[PluginInstallationAction],
     ) -> Result<Vec<Option<PluginInstallation>>, ComponentError> {
-        let owner = self
-            .is_authorized_by_component(auth, component_id, &ProjectAction::UpdateComponent)
-            .await?;
+        let owner = is_authorized_by_component(
+            &self.auth_service,
+            &self.component_service,
+            auth,
+            component_id,
+            &ProjectAction::UpdateComponent,
+        )
+        .await?;
 
         self.component_service
             .batch_update_plugin_installations_for_component(&owner, component_id, actions)
@@ -516,9 +561,14 @@ impl AuthedComponentService {
         version: ComponentVersion,
         path: &str,
     ) -> Result<BoxStream<'static, Result<Bytes, ComponentError>>, ComponentError> {
-        let owner = self
-            .is_authorized_by_component(auth, component_id, &ProjectAction::ViewComponent)
-            .await?;
+        let owner = is_authorized_by_component(
+            &self.auth_service,
+            &self.component_service,
+            auth,
+            component_id,
+            &ProjectAction::ViewComponent,
+        )
+        .await?;
 
         self.component_service
             .get_file_contents(component_id, version, path, &owner)
diff --git a/golem-component-service/src/bootstrap.rs b/golem-component-service/src/bootstrap.rs
index 5f1b5cb6..a3323b63 100644
--- a/golem-component-service/src/bootstrap.rs
+++ b/golem-component-service/src/bootstrap.rs
@@ -13,9 +13,13 @@
 // limitations under the License.
 
 use crate::api::dto::ApiMapper;
+use crate::authed::agent_types::AuthedAgentTypesService;
+use crate::authed::component::AuthedComponentService;
+use crate::authed::plugin::AuthedPluginService;
 use crate::config::{ComponentCompilationConfig, ComponentServiceConfig};
 use crate::repo::component::{ComponentRepo, DbComponentRepo, LoggedComponentRepo};
 use crate::repo::plugin::{DbPluginRepo, LoggedPluginRepo, PluginRepo};
+use crate::service::agent_types::AgentTypesService;
 use crate::service::component::ComponentServiceDefault;
 use crate::service::component::LazyComponentService;
 use crate::service::component_compilation::{
@@ -25,6 +29,8 @@ use crate::service::component_compilation::{
 use crate::service::component_object_store::{
     BlobStorageComponentObjectStore, ComponentObjectStore,
 };
+use crate::service::plugin::PluginService;
+use crate::service::transformer_plugin_caller::TransformerPluginCallerDefault;
 use golem_common::config::DbConfig;
 use golem_service_base::clients::auth::AuthService;
 use golem_service_base::clients::limit::{LimitService, LimitServiceDefault};
@@ -37,17 +43,13 @@ use golem_service_base::service::plugin_wasm_files::PluginWasmFilesService;
 use golem_service_base::storage::blob::sqlite::SqliteBlobStorage;
 use golem_service_base::storage::blob::BlobStorage;
 use std::sync::Arc;
-// use self::plugin::{PluginServiceDefault};
-use crate::authed::component::AuthedComponentService;
-use crate::authed::plugin::AuthedPluginService;
-use crate::service::plugin::PluginService;
-use crate::service::transformer_plugin_caller::TransformerPluginCallerDefault;
 
 #[derive(Clone)]
 pub struct Services {
     pub component_service: Arc<AuthedComponentService>,
     pub compilation_service: Arc<dyn ComponentCompilationService>,
     pub plugin_service: Arc<AuthedPluginService>,
+    pub agent_types_service: Arc<AuthedAgentTypesService>,
     pub api_mapper: Arc<ApiMapper>,
 }
 
@@ -145,6 +147,10 @@ impl Services {
             config.plugin_transformations.clone(),
         ));
 
+        let agent_types: Arc<dyn AgentTypesService> = Arc::new(
+            crate::service::agent_types::AgentTypesServiceDefault::new(component_service.clone()),
+        );
+
         component_service
             .set_implementation(ComponentServiceDefault::new(
                 component_repo.clone(),
@@ -168,15 +174,23 @@ impl Services {
         let authed_plugin_service: Arc<AuthedPluginService> = Arc::new(AuthedPluginService::new(
             plugin_service.clone(),
             auth_service.clone(),
-            component_service,
+            component_service.clone(),
         ));
 
+        let authed_agent_types_service: Arc<AuthedAgentTypesService> =
+            Arc::new(AuthedAgentTypesService::new(
+                agent_types,
+                auth_service.clone(),
+                project_service.clone(),
+            ));
+
         let api_mapper: Arc<ApiMapper> = Arc::new(ApiMapper::new(plugin_service.clone()));
 
         Ok(Services {
             component_service: authed_component_service,
             compilation_service,
             plugin_service: authed_plugin_service,
+            agent_types_service: authed_agent_types_service,
             api_mapper,
         })
     }
diff --git a/golem-component-service/src/config.rs b/golem-component-service/src/config.rs
index 40ab9864..cef238b4 100644
--- a/golem-component-service/src/config.rs
+++ b/golem-component-service/src/config.rs
@@ -15,10 +15,12 @@
 use golem_common::config::{ConfigExample, ConfigLoader, DbConfig, HasConfigExamples};
 use golem_common::model::{Empty, RetryConfig};
 use golem_common::tracing::TracingConfig;
+use golem_common::SafeDisplay;
 use golem_service_base::clients::RemoteServiceConfig;
 use golem_service_base::config::BlobStorageConfig;
 use http::Uri;
 use serde::{Deserialize, Serialize};
+use std::fmt::Write;
 use std::path::PathBuf;
 use std::time::Duration;
 
@@ -37,6 +39,47 @@ pub struct ComponentServiceConfig {
     pub cors_origin_regex: String,
 }
 
+impl SafeDisplay for ComponentServiceConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "tracing:");
+        let _ = writeln!(&mut result, "{}", self.tracing.to_safe_string_indented());
+        let _ = writeln!(&mut result, "environment: {}", self.environment);
+        let _ = writeln!(&mut result, "workspace: {}", self.workspace);
+        let _ = writeln!(&mut result, "HTTP port: {}", self.http_port);
+        let _ = writeln!(&mut result, "gRPC port: {}", self.grpc_port);
+        let _ = writeln!(&mut result, "DB:");
+        let _ = writeln!(&mut result, "{}", self.db.to_safe_string_indented());
+        let _ = writeln!(&mut result, "compilation:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.compilation.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "cloud service:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.cloud_service.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "blob storage:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.blob_storage.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "plugin transformations:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.plugin_transformations.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "CORS origin regex: {}", self.cors_origin_regex);
+
+        result
+    }
+}
+
 impl Default for ComponentServiceConfig {
     fn default() -> Self {
         Self {
@@ -72,6 +115,22 @@ pub enum ComponentCompilationConfig {
     Disabled(Empty),
 }
 
+impl SafeDisplay for ComponentCompilationConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        match self {
+            ComponentCompilationConfig::Enabled(inner) => {
+                let _ = writeln!(&mut result, "enabled:");
+                let _ = writeln!(&mut result, "{}", inner.to_safe_string_indented());
+            }
+            ComponentCompilationConfig::Disabled(_) => {
+                let _ = writeln!(&mut result, "disabled");
+            }
+        }
+        result
+    }
+}
+
 impl Default for ComponentCompilationConfig {
     fn default() -> Self {
         Self::Enabled(ComponentCompilationEnabledConfig {
@@ -92,6 +151,18 @@ pub struct ComponentCompilationEnabledConfig {
     pub connect_timeout: Duration,
 }
 
+impl SafeDisplay for ComponentCompilationEnabledConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "host: {}", self.host);
+        let _ = writeln!(&mut result, "port: {}", self.port);
+        let _ = writeln!(&mut result, "connect timeout: {:?}", self.connect_timeout);
+        let _ = writeln!(&mut result, "retries:");
+        let _ = writeln!(&mut result, "{}", self.retries.to_safe_string_indented());
+        result
+    }
+}
+
 impl ComponentCompilationEnabledConfig {
     pub fn uri(&self) -> Uri {
         Uri::builder()
@@ -105,30 +176,31 @@ impl ComponentCompilationEnabledConfig {
 
 #[derive(Clone, Debug, Serialize, Deserialize, Default)]
 pub struct PluginTransformationsConfig {
-    pub(crate) retries: RetryConfig,
+    pub retries: RetryConfig,
+}
+
+impl SafeDisplay for PluginTransformationsConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "retries:");
+        let _ = writeln!(&mut result, "{}", self.retries.to_safe_string_indented());
+        result
+    }
 }
 
 #[cfg(test)]
 mod tests {
-    use std::env;
-    use std::path::PathBuf;
     use test_r::test;
 
     use crate::config::make_config_loader;
 
     #[test]
     pub fn config_is_loadable() {
-        env::set_current_dir(PathBuf::from(env!("CARGO_MANIFEST_DIR")))
-            .expect("Failed to set current directory");
-
         make_config_loader().load().expect("Failed to load config");
     }
 
     #[test]
     pub fn compilation_can_be_disabled() {
-        env::set_current_dir(PathBuf::from(env!("CARGO_MANIFEST_DIR")))
-            .expect("Failed to set current directory");
-
         std::env::set_var("GOLEM__COMPILATION__TYPE", "Disabled");
         let cfg = make_config_loader().load().expect("Failed to load config");
         std::env::remove_var("GOLEM__COMPILATION__TYPE");
diff --git a/golem-component-service/src/grpcapi/component.rs b/golem-component-service/src/grpcapi/component.rs
index 1b039163..5bb1f9e4 100644
--- a/golem-component-service/src/grpcapi/component.rs
+++ b/golem-component-service/src/grpcapi/component.rs
@@ -16,9 +16,9 @@ use crate::api::common::ComponentTraceErrorKind;
 use crate::authed::component::AuthedComponentService;
 use crate::grpcapi::{auth, bad_request_error, internal_error, require_component_id};
 use async_trait::async_trait;
-use futures_util::stream::BoxStream;
-use futures_util::StreamExt;
-use futures_util::TryStreamExt;
+use futures::stream::BoxStream;
+use futures::StreamExt;
+use futures::TryStreamExt;
 use golem_api_grpc::proto::golem::common::{Empty, ErrorBody};
 use golem_api_grpc::proto::golem::component::v1::component_service_server::ComponentService as GrpcComponentService;
 use golem_api_grpc::proto::golem::component::v1::{
@@ -178,6 +178,13 @@ impl ComponentGrpcApi {
                 })?,
         );
 
+        let agent_types = request
+            .agent_types
+            .iter()
+            .map(|agent_type| agent_type.clone().try_into())
+            .collect::<Result<Vec<_>, _>>()
+            .map_err(|e| bad_request_error(&format!("Invalid agent types: {e}")))?;
+
         let result = self
             .component_service
             .create_internal(
@@ -189,6 +196,7 @@ impl ComponentGrpcApi {
                 dynamic_linking,
                 &auth,
                 request.env,
+                agent_types,
             )
             .await?;
 
@@ -233,6 +241,13 @@ impl ComponentGrpcApi {
                 })?,
         );
 
+        let agent_types = request
+            .agent_types
+            .iter()
+            .map(|agent_type| agent_type.clone().try_into())
+            .collect::<Result<Vec<_>, _>>()
+            .map_err(|e| bad_request_error(&format!("Invalid agent types: {e}")))?;
+
         let result = self
             .component_service
             .update_internal(
@@ -243,6 +258,7 @@ impl ComponentGrpcApi {
                 dynamic_linking,
                 &auth,
                 request.env,
+                agent_types,
             )
             .await?;
 
diff --git a/golem-component-service/src/model/component.rs b/golem-component-service/src/model/component.rs
index 0909618a..d16f56fb 100644
--- a/golem-component-service/src/model/component.rs
+++ b/golem-component-service/src/model/component.rs
@@ -14,6 +14,7 @@
 
 use super::ComponentSearchParameters;
 use chrono::Utc;
+use golem_common::model::agent::AgentType;
 use golem_common::model::component::{ComponentOwner, VersionedComponentId};
 use golem_common::model::component_constraint::{
     FunctionConstraints, FunctionSignature, FunctionUsageConstraint,
@@ -61,8 +62,9 @@ impl Component {
         dynamic_linking: HashMap<String, DynamicLinkedInstance>,
         owner: ComponentOwner,
         env: HashMap<String, String>,
+        agent_types: Vec<AgentType>,
     ) -> Result<Component, ComponentProcessingError> {
-        let metadata = ComponentMetadata::analyse_component(data, dynamic_linking)?;
+        let metadata = ComponentMetadata::analyse_component(data, dynamic_linking, agent_types)?;
 
         let versioned_component_id = VersionedComponentId {
             component_id: component_id.clone(),
@@ -91,7 +93,7 @@ impl Component {
         format!("{}:user", self.object_store_key)
     }
 
-    pub fn protected_object_store_key(&self) -> String {
+    pub fn transformed_object_store_key(&self) -> String {
         format!("{}:protected", self.transformed_object_store_key)
     }
 
diff --git a/golem-component-service/src/repo/component.rs b/golem-component-service/src/repo/component.rs
index a7af5163..2d6ee6b6 100644
--- a/golem-component-service/src/repo/component.rs
+++ b/golem-component-service/src/repo/component.rs
@@ -127,8 +127,8 @@ impl ComponentRecord {
                     )
                 })
                 .collect::<Result<Vec<_>, _>>()?,
-            root_package_name: value.metadata.root_package_name,
-            root_package_version: value.metadata.root_package_version,
+            root_package_name: value.metadata.root_package_name().clone(),
+            root_package_version: value.metadata.root_package_version().clone(),
             env: Json(value.env),
             transformed_env: Json(value.transformed_env),
         })
diff --git a/golem-component-service/src/service/component.rs b/golem-component-service/src/service/component.rs
index 8f896466..74e0e48a 100644
--- a/golem-component-service/src/service/component.rs
+++ b/golem-component-service/src/service/component.rs
@@ -28,8 +28,9 @@ use async_trait::async_trait;
 use async_zip::tokio::read::seek::ZipFileReader;
 use async_zip::ZipEntry;
 use bytes::Bytes;
+use futures::stream::BoxStream;
 use futures::TryStreamExt;
-use futures_util::stream::BoxStream;
+use golem_common::model::agent::AgentType;
 use golem_common::model::component::ComponentOwner;
 use golem_common::model::component::VersionedComponentId;
 use golem_common::model::component_constraint::FunctionConstraints;
@@ -45,8 +46,8 @@ use golem_common::model::plugin::{
     PluginInstallation, PluginInstallationAction, PluginInstallationCreation,
     PluginInstallationUpdate,
 };
-use golem_common::model::AccountId;
 use golem_common::model::InitialComponentFile;
+use golem_common::model::ProjectId;
 use golem_common::model::{ComponentFilePath, ComponentFilePermissions};
 use golem_common::model::{ComponentId, ComponentType, ComponentVersion, PluginInstallationId};
 use golem_common::repo::ComponentOwnerRow;
@@ -89,6 +90,7 @@ pub trait ComponentService: Debug + Send + Sync {
         dynamic_linking: HashMap<String, DynamicLinkedInstance>,
         owner: &ComponentOwner,
         env: HashMap<String, String>,
+        agent_types: Vec<AgentType>,
     ) -> Result<Component, ComponentError>;
 
     // Files must have been uploaded to the blob store before calling this method
@@ -103,6 +105,7 @@ pub trait ComponentService: Debug + Send + Sync {
         dynamic_linking: HashMap<String, DynamicLinkedInstance>,
         owner: &ComponentOwner,
         env: HashMap<String, String>,
+        agent_types: Vec<AgentType>,
     ) -> Result<Component, ComponentError>;
 
     async fn update(
@@ -114,6 +117,7 @@ pub trait ComponentService: Debug + Send + Sync {
         dynamic_linking: HashMap<String, DynamicLinkedInstance>,
         owner: &ComponentOwner,
         env: HashMap<String, String>,
+        agent_types: Vec<AgentType>,
     ) -> Result<Component, ComponentError>;
 
     // Files must have been uploaded to the blob store before calling this method
@@ -127,6 +131,7 @@ pub trait ComponentService: Debug + Send + Sync {
         dynamic_linking: HashMap<String, DynamicLinkedInstance>,
         owner: &ComponentOwner,
         env: HashMap<String, String>,
+        agent_types: Vec<AgentType>,
     ) -> Result<Component, ComponentError>;
 
     async fn download(
@@ -286,6 +291,7 @@ impl ComponentService for LazyComponentService {
         dynamic_linking: HashMap<String, DynamicLinkedInstance>,
         owner: &ComponentOwner,
         env: HashMap<String, String>,
+        agent_types: Vec<AgentType>,
     ) -> Result<Component, ComponentError> {
         let lock = self.0.read().await;
         lock.as_ref()
@@ -300,6 +306,7 @@ impl ComponentService for LazyComponentService {
                 dynamic_linking,
                 owner,
                 env,
+                agent_types,
             )
             .await
     }
@@ -316,6 +323,7 @@ impl ComponentService for LazyComponentService {
         dynamic_linking: HashMap<String, DynamicLinkedInstance>,
         owner: &ComponentOwner,
         env: HashMap<String, String>,
+        agent_types: Vec<AgentType>,
     ) -> Result<Component, ComponentError> {
         let lock = self.0.read().await;
         lock.as_ref()
@@ -330,6 +338,7 @@ impl ComponentService for LazyComponentService {
                 dynamic_linking,
                 owner,
                 env,
+                agent_types,
             )
             .await
     }
@@ -343,6 +352,7 @@ impl ComponentService for LazyComponentService {
         dynamic_linking: HashMap<String, DynamicLinkedInstance>,
         owner: &ComponentOwner,
         env: HashMap<String, String>,
+        agent_types: Vec<AgentType>,
     ) -> Result<Component, ComponentError> {
         let lock = self.0.read().await;
         lock.as_ref()
@@ -355,6 +365,7 @@ impl ComponentService for LazyComponentService {
                 dynamic_linking,
                 owner,
                 env,
+                agent_types,
             )
             .await
     }
@@ -370,6 +381,7 @@ impl ComponentService for LazyComponentService {
         dynamic_linking: HashMap<String, DynamicLinkedInstance>,
         owner: &ComponentOwner,
         env: HashMap<String, String>,
+        agent_types: Vec<AgentType>,
     ) -> Result<Component, ComponentError> {
         let lock = self.0.read().await;
         lock.as_ref()
@@ -382,6 +394,7 @@ impl ComponentService for LazyComponentService {
                 dynamic_linking,
                 owner,
                 env,
+                agent_types,
             )
             .await
     }
@@ -717,7 +730,7 @@ impl ComponentServiceDefault {
 
     async fn upload_component_files(
         &self,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         payload: InitialComponentFilesArchiveAndPermissions,
     ) -> Result<Vec<InitialComponentFile>, ComponentError> {
         let path_permissions: HashMap<ComponentFilePath, ComponentFilePermissions> =
@@ -737,7 +750,7 @@ impl ComponentServiceDefault {
                 info!("Uploading file: {}", path.to_string());
 
                 self.initial_component_files_service
-                    .put_if_not_exists(account_id, &stream)
+                    .put_if_not_exists(project_id, &stream)
                     .await
                     .map_err(|e| {
                         ComponentError::initial_component_file_upload_error(
@@ -846,6 +859,7 @@ impl ComponentServiceDefault {
         dynamic_linking: HashMap<String, DynamicLinkedInstance>,
         owner: &ComponentOwner,
         env: HashMap<String, String>,
+        agent_types: Vec<AgentType>,
     ) -> Result<Component, ComponentError> {
         let component_size: u64 = data.len() as u64;
 
@@ -864,19 +878,20 @@ impl ComponentServiceDefault {
             dynamic_linking,
             owner.clone(),
             env,
+            agent_types,
         )?;
 
         info!(
             owner = %owner,
-            exports = ?component.metadata.exports,
-            dynamic_linking = ?component.metadata.dynamic_linking,
+            exports = ?component.metadata.exports(),
+            dynamic_linking = ?component.metadata.dynamic_linking(),
             "Uploaded component",
         );
 
         let (component, transformed_data) =
             self.apply_transformations(component, data.clone()).await?;
 
-        if let Some(known_root_package_name) = &component.metadata.root_package_name {
+        if let Some(known_root_package_name) = &component.metadata.root_package_name() {
             if &component_name.0 != known_root_package_name {
                 Err(ComponentError::InvalidComponentName {
                     actual: component_name.0.clone(),
@@ -903,7 +918,11 @@ impl ComponentServiceDefault {
         };
 
         self.component_compilation
-            .enqueue_compilation(component_id, component.versioned_component_id.version)
+            .enqueue_compilation(
+                &owner.project_id,
+                component_id,
+                component.versioned_component_id.version,
+            )
             .await;
 
         Ok(component)
@@ -918,6 +937,7 @@ impl ComponentServiceDefault {
         dynamic_linking: HashMap<String, DynamicLinkedInstance>,
         owner: &ComponentOwner,
         env: HashMap<String, String>,
+        agent_types: Vec<AgentType>,
     ) -> Result<Component, ComponentError> {
         let component_size: u64 = data.len() as u64;
 
@@ -926,7 +946,7 @@ impl ComponentServiceDefault {
             .update_component_limit(&owner.account_id, component_id, 0, component_size as i64)
             .await?;
 
-        let metadata = ComponentMetadata::analyse_component(&data, dynamic_linking)
+        let metadata = ComponentMetadata::analyse_component(&data, dynamic_linking, agent_types)
             .map_err(ComponentError::ComponentProcessingError)?;
 
         let constraints = self
@@ -934,7 +954,7 @@ impl ComponentServiceDefault {
             .get_constraint(&owner.to_string(), component_id.0)
             .await?;
 
-        let new_type_registry = FunctionDictionary::from_exports(&metadata.exports)
+        let new_type_registry = FunctionDictionary::from_exports(metadata.exports())
             .map_err(|e| ComponentError::conversion_error("exports", e))?;
 
         if let Some(constraints) = constraints {
@@ -947,8 +967,8 @@ impl ComponentServiceDefault {
 
         info!(
             owner = %owner,
-            exports = ?metadata.exports,
-            dynamic_linking = ?metadata.dynamic_linking,
+            exports = ?metadata.exports(),
+            dynamic_linking = ?metadata.dynamic_linking(),
             "Uploaded component",
         );
 
@@ -980,6 +1000,7 @@ impl ComponentServiceDefault {
             .map_err(|e| ComponentError::conversion_error("record", e))?;
 
         let result = self.component_repo.create(&record).await;
+
         match result {
             Err(RepoError::UniqueViolation(_)) => Err(ComponentError::ConcurrentUpdate {
                 component_id: component_id.clone(),
@@ -990,7 +1011,11 @@ impl ComponentServiceDefault {
         };
 
         self.component_compilation
-            .enqueue_compilation(component_id, component.versioned_component_id.version)
+            .enqueue_compilation(
+                &owner.project_id,
+                component_id,
+                component.versioned_component_id.version,
+            )
             .await;
 
         Ok(component)
@@ -1002,7 +1027,11 @@ impl ComponentServiceDefault {
         data: Vec<u8>,
     ) -> Result<(), ComponentError> {
         self.object_store
-            .put(&component.user_object_store_key(), data)
+            .put(
+                &component.owner.project_id,
+                &component.user_object_store_key(),
+                data,
+            )
             .await
             .map_err(|e| {
                 ComponentError::component_store_error("Failed to upload user component", e)
@@ -1015,7 +1044,11 @@ impl ComponentServiceDefault {
         data: Vec<u8>,
     ) -> Result<(), ComponentError> {
         self.object_store
-            .put(&component.protected_object_store_key(), data)
+            .put(
+                &component.owner.project_id,
+                &component.transformed_object_store_key(),
+                data,
+            )
             .await
             .map_err(|e| {
                 ComponentError::component_store_error("Failed to upload protected component", e)
@@ -1086,9 +1119,12 @@ impl ComponentServiceDefault {
             }
         }
 
-        component.metadata =
-            ComponentMetadata::analyse_component(&data, component.metadata.dynamic_linking)
-                .map_err(ComponentError::ComponentProcessingError)?;
+        component.metadata = ComponentMetadata::analyse_component(
+            &data,
+            component.metadata.dynamic_linking().clone(),
+            component.metadata.agent_types().to_vec(),
+        )
+        .map_err(ComponentError::ComponentProcessingError)?;
 
         Ok((component, data))
     }
@@ -1122,7 +1158,7 @@ impl ComponentServiceDefault {
 
             let key = self
                 .initial_component_files_service
-                .put_if_not_exists(&component.owner.account_id, content_stream)
+                .put_if_not_exists(&component.owner.project_id, content_stream)
                 .await
                 .map_err(|e| {
                     ComponentError::initial_component_file_upload_error(
@@ -1221,6 +1257,7 @@ impl ComponentService for ComponentServiceDefault {
         dynamic_linking: HashMap<String, DynamicLinkedInstance>,
         owner: &ComponentOwner,
         env: HashMap<String, String>,
+        agent_types: Vec<AgentType>,
     ) -> Result<Component, ComponentError> {
         info!(owner = %owner, "Create component");
 
@@ -1230,7 +1267,7 @@ impl ComponentService for ComponentServiceDefault {
 
         let uploaded_files = match files {
             Some(files) => {
-                self.upload_component_files(&owner.account_id, files)
+                self.upload_component_files(&owner.project_id, files)
                     .await?
             }
             None => vec![],
@@ -1246,6 +1283,7 @@ impl ComponentService for ComponentServiceDefault {
             dynamic_linking,
             owner,
             env,
+            agent_types,
         )
         .await
     }
@@ -1261,6 +1299,7 @@ impl ComponentService for ComponentServiceDefault {
         dynamic_linking: HashMap<String, DynamicLinkedInstance>,
         owner: &ComponentOwner,
         env: HashMap<String, String>,
+        agent_types: Vec<AgentType>,
     ) -> Result<Component, ComponentError> {
         info!(owner = %owner, "Create component");
 
@@ -1271,7 +1310,7 @@ impl ComponentService for ComponentServiceDefault {
         for file in &files {
             let exists = self
                 .initial_component_files_service
-                .exists(&owner.account_id, &file.key)
+                .exists(&owner.project_id, &file.key)
                 .await
                 .map_err(|e| {
                     ComponentError::initial_component_file_upload_error(
@@ -1297,6 +1336,7 @@ impl ComponentService for ComponentServiceDefault {
             dynamic_linking,
             owner,
             env,
+            agent_types,
         )
         .await
     }
@@ -1310,12 +1350,13 @@ impl ComponentService for ComponentServiceDefault {
         dynamic_linking: HashMap<String, DynamicLinkedInstance>,
         owner: &ComponentOwner,
         env: HashMap<String, String>,
+        agent_types: Vec<AgentType>,
     ) -> Result<Component, ComponentError> {
         info!(owner = %owner, "Update component");
 
         let uploaded_files = match files {
             Some(files) => Some(
-                self.upload_component_files(&owner.account_id, files)
+                self.upload_component_files(&owner.project_id, files)
                     .await?,
             ),
             None => None,
@@ -1329,6 +1370,7 @@ impl ComponentService for ComponentServiceDefault {
             dynamic_linking,
             owner,
             env,
+            agent_types,
         )
         .await
     }
@@ -1342,13 +1384,14 @@ impl ComponentService for ComponentServiceDefault {
         dynamic_linking: HashMap<String, DynamicLinkedInstance>,
         owner: &ComponentOwner,
         env: HashMap<String, String>,
+        agent_types: Vec<AgentType>,
     ) -> Result<Component, ComponentError> {
         info!(owner = %owner, "Update component");
 
         for file in files.iter().flatten() {
             let exists = self
                 .initial_component_files_service
-                .exists(&owner.account_id, &file.key)
+                .exists(&owner.project_id, &file.key)
                 .await
                 .map_err(|e| {
                     ComponentError::initial_component_file_upload_error(
@@ -1372,6 +1415,7 @@ impl ComponentService for ComponentServiceDefault {
             dynamic_linking,
             owner,
             env,
+            agent_types,
         )
         .await
     }
@@ -1400,7 +1444,10 @@ impl ComponentService for ComponentServiceDefault {
             info!(owner = %owner, component_id = %component.versioned_component_id, "Download component");
 
             self.object_store
-                .get(&component.protected_object_store_key())
+                .get(
+                    &component.owner.project_id,
+                    &component.transformed_object_store_key(),
+                )
                 .await
                 .tap_err(|e| error!(owner = %owner, "Error downloading component - error: {}", e))
                 .map_err(|e| {
@@ -1432,7 +1479,7 @@ impl ComponentService for ComponentServiceDefault {
         };
 
         if let Some(component) = component {
-            let protected_object_store_key = component.protected_object_store_key();
+            let protected_object_store_key = component.transformed_object_store_key();
 
             info!(
                 owner = %owner,
@@ -1442,7 +1489,7 @@ impl ComponentService for ComponentServiceDefault {
             );
 
             self.object_store
-                .get_stream(&protected_object_store_key)
+                .get_stream(&component.owner.project_id, &protected_object_store_key)
                 .await
                 .map_err(|e| {
                     ComponentError::component_store_error("Error downloading component", e)
@@ -1479,7 +1526,7 @@ impl ComponentService for ComponentServiceDefault {
 
             let stream = self
                 .initial_component_files_service
-                .get(&owner.account_id, &file.key)
+                .get(&owner.project_id, &file.key)
                 .await
                 .map_err(|e| {
                     ComponentError::initial_component_file_upload_error(
@@ -1669,19 +1716,29 @@ impl ComponentService for ComponentServiceDefault {
         let mut object_store_keys = Vec::new();
 
         for component in components {
-            object_store_keys.push(component.protected_object_store_key());
-            object_store_keys.push(component.user_object_store_key());
+            object_store_keys.push((
+                component.owner.project_id.clone(),
+                component.transformed_object_store_key(),
+            ));
+            object_store_keys.push((
+                component.owner.project_id.clone(),
+                component.user_object_store_key(),
+            ));
         }
 
         if !object_store_keys.is_empty() {
-            for key in object_store_keys {
-                self.object_store.delete(&key).await.map_err(|e| {
-                    ComponentError::component_store_error("Failed to delete component data", e)
-                })?;
+            for (project_id, key) in object_store_keys {
+                self.object_store
+                    .delete(&project_id, &key)
+                    .await
+                    .map_err(|e| {
+                        ComponentError::component_store_error("Failed to delete component data", e)
+                    })?;
             }
             self.component_repo
                 .delete(&owner.to_string(), component_id.0)
                 .await?;
+
             Ok(())
         } else {
             Err(ComponentError::UnknownComponentId(component_id.clone()))
@@ -1916,7 +1973,6 @@ impl ComponentService for ComponentServiceDefault {
 
                     existing.priority = update.priority;
                     existing.parameters = update.parameters.clone();
-
                     result.push(None);
                 }
                 PluginInstallationAction::Uninstall(uninstallation) => {
@@ -1939,7 +1995,10 @@ impl ComponentService for ComponentServiceDefault {
 
         let data = self
             .object_store
-            .get(&component.user_object_store_key())
+            .get(
+                &component.owner.project_id,
+                &component.user_object_store_key(),
+            )
             .await
             .map_err(|err| {
                 ComponentError::component_store_error("Failed to download user component", err)
@@ -1948,7 +2007,11 @@ impl ComponentService for ComponentServiceDefault {
         let (component, transformed_data) = self.apply_transformations(component, data).await?;
 
         self.object_store
-            .put(&component.protected_object_store_key(), transformed_data)
+            .put(
+                &component.owner.project_id,
+                &component.transformed_object_store_key(),
+                transformed_data,
+            )
             .await
             .map_err(|e| {
                 ComponentError::component_store_error("Failed to upload protected component", e)
@@ -1983,8 +2046,8 @@ impl ZipEntryStream {
 }
 
 impl ReplayableStream for ZipEntryStream {
-    type Error = String;
     type Item = Result<Bytes, String>;
+    type Error = String;
 
     async fn make_stream(&self) -> Result<impl Stream<Item = Self::Item> + Send + 'static, String> {
         let reopened = self
diff --git a/golem-component-service/src/service/plugin.rs b/golem-component-service/src/service/plugin.rs
index fbcc1fd9..b8f7d005 100644
--- a/golem-component-service/src/service/plugin.rs
+++ b/golem-component-service/src/service/plugin.rs
@@ -121,7 +121,7 @@ impl PluginService {
 
         let implements_oplog_processor_interface = component
             .metadata
-            .exports
+            .exports()
             .iter()
             .any(is_valid_oplog_processor_implementation);
 
diff --git a/golem-component-service/tests/all/repo/mod.rs b/golem-component-service/tests/all/repo/mod.rs
index 64d8315e..fbf35e85 100644
--- a/golem-component-service/tests/all/repo/mod.rs
+++ b/golem-component-service/tests/all/repo/mod.rs
@@ -28,7 +28,6 @@ use golem_component_service::repo::plugin::PluginRepo;
 use golem_service_base::model::ComponentName;
 use golem_service_base::repo::RepoError;
 use std::collections::HashMap;
-use std::slice::from_ref;
 use std::sync::Arc;
 use test_r::{inherit_test_dep, sequential_suite};
 use tracing::info;
@@ -83,6 +82,7 @@ async fn test_repo_component_id_unique(component_repo: Arc<dyn ComponentRepo>) {
         HashMap::new(),
         owner1.clone(),
         HashMap::new(),
+        vec![],
     )
     .unwrap();
 
@@ -128,6 +128,7 @@ async fn test_repo_component_name_unique_in_namespace(component_repo: Arc<dyn Co
         HashMap::new(),
         owner1.clone(),
         HashMap::new(),
+        vec![],
     )
     .unwrap();
     let component2 = Component::new(
@@ -140,6 +141,7 @@ async fn test_repo_component_name_unique_in_namespace(component_repo: Arc<dyn Co
         HashMap::new(),
         owner2.clone(),
         HashMap::new(),
+        vec![],
     )
     .unwrap();
 
@@ -190,6 +192,7 @@ async fn test_repo_component_find_by_names(component_repo: Arc<dyn ComponentRepo
         HashMap::new(),
         test_component_owner(),
         HashMap::new(),
+        vec![],
     )
     .unwrap();
 
@@ -211,6 +214,7 @@ async fn test_repo_component_find_by_names(component_repo: Arc<dyn ComponentRepo
         HashMap::new(),
         test_component_owner(),
         HashMap::new(),
+        vec![],
     )
     .unwrap();
 
@@ -440,6 +444,7 @@ async fn test_repo_component_delete(component_repo: Arc<dyn ComponentRepo>) {
         HashMap::new(),
         test_component_owner(),
         HashMap::new(),
+        vec![],
     )
     .unwrap();
 
@@ -499,6 +504,7 @@ async fn test_repo_component_constraints(component_repo: Arc<dyn ComponentRepo>)
         HashMap::new(),
         owner1.clone(),
         HashMap::new(),
+        vec![],
     )
     .unwrap();
 
@@ -595,6 +601,7 @@ async fn test_default_plugin_repo(
         HashMap::new(),
         owner.clone(),
         HashMap::new(),
+        vec![],
     )
     .unwrap();
     let component2 = Component::new(
@@ -607,6 +614,7 @@ async fn test_default_plugin_repo(
         HashMap::new(),
         owner.clone(),
         HashMap::new(),
+        vec![],
     )
     .unwrap();
 
@@ -619,7 +627,7 @@ async fn test_default_plugin_repo(
 
     let all1 = plugin_repo.get_all(&plugin_owner_row).await?;
     let scoped1 = plugin_repo
-        .get_for_scope(&plugin_owner_row, from_ref(&scope1))
+        .get_for_scope(&plugin_owner_row, std::slice::from_ref(&scope1))
         .await?;
     let named1 = plugin_repo
         .get_all_with_name(&plugin_owner_row, "plugin1")
@@ -668,7 +676,7 @@ async fn test_default_plugin_repo(
 
     let all2 = plugin_repo.get_all(&plugin_owner_row).await?;
     let scoped2 = plugin_repo
-        .get_for_scope(&plugin_owner_row, from_ref(&scope1))
+        .get_for_scope(&plugin_owner_row, std::slice::from_ref(&scope1))
         .await?;
     let named2 = plugin_repo
         .get_all_with_name(&plugin_owner_row, "plugin1")
diff --git a/golem-component-service/tests/all/service/mod.rs b/golem-component-service/tests/all/service/mod.rs
index 067ff584..9cd0c8e9 100644
--- a/golem-component-service/tests/all/service/mod.rs
+++ b/golem-component-service/tests/all/service/mod.rs
@@ -64,7 +64,6 @@ use golem_wasm_ast::analysis::{AnalysedExport, AnalysedInstance};
 use http::StatusCode;
 use rib::{FullyQualifiedFunctionName, FunctionName, InterfaceName, PackageName};
 use std::collections::{HashMap, HashSet};
-use std::env;
 use std::path::PathBuf;
 use std::sync::Arc;
 use test_r::{inherit_test_dep, test, test_dep};
@@ -105,13 +104,9 @@ fn component_compilation_service() -> Arc<dyn ComponentCompilationService> {
 #[test_dep]
 async fn blob_storage() -> Arc<dyn BlobStorage + Send + Sync> {
     Arc::new(
-        FileSystemBlobStorage::new(&PathBuf::from(format!(
-            "{}/blob-{}",
-            env::temp_dir().display(),
-            Uuid::new_v4()
-        )))
-        .await
-        .expect("Failed to create blob storage"),
+        FileSystemBlobStorage::new(&PathBuf::from(format!("/tmp/blob-{}", Uuid::new_v4())))
+            .await
+            .expect("Failed to create blob storage"),
     )
 }
 
@@ -217,6 +212,7 @@ async fn test_services(component_service: &Arc<dyn ComponentService>) {
             HashMap::new(),
             &test_component_owner(),
             HashMap::new(),
+            vec![],
         )
         .await
         .unwrap();
@@ -232,6 +228,7 @@ async fn test_services(component_service: &Arc<dyn ComponentService>) {
             HashMap::new(),
             &test_component_owner(),
             HashMap::new(),
+            vec![],
         )
         .await
         .unwrap();
@@ -313,6 +310,7 @@ async fn test_services(component_service: &Arc<dyn ComponentService>) {
             HashMap::new(),
             &test_component_owner(),
             HashMap::new(),
+            vec![],
         )
         .await
         .map_err(|err| err.to_string())
@@ -575,6 +573,7 @@ async fn test_initial_component_file_upload(component_service: &Arc<dyn Componen
             HashMap::new(),
             &test_component_owner(),
             HashMap::new(),
+            vec![],
         )
         .await
         .unwrap();
@@ -628,6 +627,7 @@ async fn test_initial_component_file_data_sharing(component_service: &Arc<dyn Co
             HashMap::new(),
             &test_component_owner(),
             HashMap::new(),
+            vec![],
         )
         .await
         .unwrap();
@@ -650,6 +650,7 @@ async fn test_initial_component_file_data_sharing(component_service: &Arc<dyn Co
             HashMap::new(),
             &test_component_owner(),
             HashMap::new(),
+            vec![],
         )
         .await
         .unwrap();
@@ -690,6 +691,7 @@ async fn test_component_constraint_incompatible_updates(
             HashMap::new(),
             &test_component_owner(),
             HashMap::new(),
+            vec![],
         )
         .await
         .unwrap();
@@ -724,6 +726,7 @@ async fn test_component_constraint_incompatible_updates(
             HashMap::new(),
             &test_component_owner(),
             HashMap::new(),
+            vec![],
         )
         .await
         .unwrap_err()
@@ -786,6 +789,7 @@ async fn test_component_oplog_process_plugin_creation(
             HashMap::new(),
             &test_component_owner(),
             HashMap::new(),
+            vec![],
         )
         .await
         .unwrap();
@@ -826,6 +830,7 @@ async fn test_component_oplog_process_plugin_creation(
             HashMap::new(),
             &test_component_owner(),
             HashMap::new(),
+            vec![],
         )
         .await
         .unwrap();
@@ -883,6 +888,7 @@ async fn test_component_oplog_process_plugin_creation_invalid_plugin(
             HashMap::new(),
             &test_component_owner(),
             HashMap::new(),
+            vec![],
         )
         .await
         .unwrap();
@@ -937,6 +943,7 @@ async fn test_failing_component_transformer_plugin(
             HashMap::new(),
             &test_component_owner(),
             HashMap::new(),
+            vec![],
         )
         .await
         .unwrap();
@@ -1007,6 +1014,7 @@ async fn test_library_plugin_creation(
             HashMap::new(),
             &test_component_owner(),
             HashMap::new(),
+            vec![],
         )
         .await
         .unwrap();
@@ -1062,7 +1070,7 @@ async fn test_library_plugin_creation(
         .unwrap()
         .expect("plugin not found");
 
-    let exports = final_component.metadata.exports;
+    let exports = final_component.metadata.exports();
 
     assert_eq!(exports.len(), 1);
     assert!(matches!(
@@ -1094,6 +1102,7 @@ async fn test_app_plugin_creation(
             HashMap::new(),
             &test_component_owner(),
             HashMap::new(),
+            vec![],
         )
         .await
         .unwrap();
@@ -1149,7 +1158,7 @@ async fn test_app_plugin_creation(
         .unwrap()
         .expect("plugin not found");
 
-    let exports = final_component.metadata.exports;
+    let exports = final_component.metadata.exports();
 
     assert_eq!(exports.len(), 1);
     assert!(matches!(
diff --git a/golem-debugging-service/Cargo.toml b/golem-debugging-service/Cargo.toml
index 8bb7bb78..1e2e89da 100644
--- a/golem-debugging-service/Cargo.toml
+++ b/golem-debugging-service/Cargo.toml
@@ -13,12 +13,13 @@ name = "golem-debugging-service"
 path = "src/server.rs"
 
 [dependencies]
-golem-worker-executor = { path = "../golem-worker-executor", version = "=0.0.0" }
-golem-common = { path = "../golem-common", version = "=0.0.0" }
-golem-api-grpc = { path = "../golem-api-grpc", version = "=0.0.0" }
-golem-service-base = { path = "../golem-service-base", version = "=0.0.0" }
-golem-wasm-ast = { path = "../wasm-ast", version = "=0.0.0" }
-golem-wasm-rpc = { path = "../wasm-rpc", version = "=0.0.0" }
+golem-worker-executor = { workspace = true }
+golem-common = { workspace = true, default-features = true }
+golem-api-grpc = { workspace = true }
+golem-rib = { workspace = true, default-features = true }
+golem-service-base = { workspace = true }
+golem-wasm-ast = { workspace = true, default-features = true }
+golem-wasm-rpc = { workspace = true, default-features = true }
 
 anyhow = { workspace = true }
 async-trait = { workspace = true }
@@ -27,7 +28,7 @@ async-dropper-simple = { workspace = true }
 axum-jrpc = { workspace = true }
 bincode = { workspace = true }
 bytes = { workspace = true }
-futures-util = { workspace = true }
+futures = { workspace = true }
 gethostname = { workspace = true }
 humansize = { workspace = true }
 log = { workspace = true }
@@ -39,6 +40,8 @@ serde_json = { workspace = true }
 tempfile = { workspace = true }
 tokio = { workspace = true }
 tokio-tungstenite = { workspace = true }
+tokio-util = { workspace = true }
+tokio-stream = { workspace = true }
 tonic = { workspace = true }
 tracing = { workspace = true }
 tracing-subscriber = { workspace = true }
@@ -46,14 +49,14 @@ thiserror = { workspace = true }
 uuid = { workspace = true }
 url = { workspace = true }
 
-wasmtime = { version = "=33.0.0", features = ["component-model"] }
-wasmtime-wasi = { version = "=33.0.0" }
-wasmtime-wasi-http = { version = "=33.0.0" }
+wasmtime = { workspace = true, features = ["component-model"] }
+wasmtime-wasi = { workspace = true }
+wasmtime-wasi-http = { workspace = true }
 
 
 [dev-dependencies]
 test-r = { workspace = true }
-golem-test-framework = { path = "../golem-test-framework", version = "=0.0.0" }
+golem-test-framework = { workspace = true }
 
 [[test]]
 name = "integration"
diff --git a/golem-debugging-service/config/debug-worker-executor.sample.env b/golem-debugging-service/config/debug-worker-executor.sample.env
index 4c06421c..eb5bec37 100644
--- a/golem-debugging-service/config/debug-worker-executor.sample.env
+++ b/golem-debugging-service/config/debug-worker-executor.sample.env
@@ -6,6 +6,17 @@ GOLEM__HTTP_PORT=8082
 GOLEM__TRACING_FILE_NAME_WITH_PORT=true
 GOLEM__ACTIVE_WORKERS__DROP_WHEN_FULL=0.25
 GOLEM__ACTIVE_WORKERS__TTL="8h"
+GOLEM__AGENT_TYPES_SERVICE__TYPE="Grpc"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__ACCESS_TOKEN="2a354594-7a63-4091-a46b-cc58d379f677"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__CACHE_TIME_TO_IDLE="1m"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__CONNECT_TIMEOUT="30s"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__HOST="localhost"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__PORT=9092
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__RETRIES__MAX_ATTEMPTS=3
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__RETRIES__MAX_DELAY="1s"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__RETRIES__MAX_JITTER_FACTOR=0.15
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__RETRIES__MIN_DELAY="100ms"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__RETRIES__MULTIPLIER=3.0
 GOLEM__BLOB_STORAGE__TYPE="LocalFileSystem"
 GOLEM__BLOB_STORAGE__CONFIG__ROOT="../data/blob_storage"
 GOLEM__CLOUD_SERVICE__ACCESS_TOKEN="5c832d93-ff85-4a8f-9803-513950fdfdb1"
@@ -20,7 +31,6 @@ GOLEM__COMPILED_COMPONENT_SERVICE__TYPE="Enabled"
 GOLEM__COMPONENT_CACHE__MAX_CAPACITY=32
 GOLEM__COMPONENT_CACHE__MAX_METADATA_CAPACITY=16384
 GOLEM__COMPONENT_CACHE__MAX_RESOLVED_COMPONENT_CAPACITY=1024
-GOLEM__COMPONENT_CACHE__MAX_RESOLVED_PROJECT_CAPACITY=1024
 GOLEM__COMPONENT_CACHE__TIME_TO_IDLE="12h"
 GOLEM__COMPONENT_SERVICE__ACCESS_TOKEN="2a354594-7a63-4091-a46b-cc58d379f677"
 GOLEM__COMPONENT_SERVICE__CONNECT_TIMEOUT="30s"
@@ -85,8 +95,10 @@ GOLEM__PLUGIN_SERVICE__CONFIG__RETRIES__MIN_DELAY="100ms"
 GOLEM__PLUGIN_SERVICE__CONFIG__RETRIES__MULTIPLIER=3.0
 GOLEM__PROJECT_SERVICE__TYPE="Grpc"
 GOLEM__PROJECT_SERVICE__CONFIG__ACCESS_TOKEN="2a354594-7a63-4091-a46b-cc58d379f677"
+GOLEM__PROJECT_SERVICE__CONFIG__CACHE_TIME_TO_IDLE="12h"
 GOLEM__PROJECT_SERVICE__CONFIG__CONNECT_TIMEOUT="30s"
 GOLEM__PROJECT_SERVICE__CONFIG__HOST="localhost"
+GOLEM__PROJECT_SERVICE__CONFIG__MAX_RESOLVED_PROJECT_CACHE_CAPACITY=1024
 GOLEM__PROJECT_SERVICE__CONFIG__PORT=9091
 GOLEM__PROJECT_SERVICE__CONFIG__RETRIES__MAX_ATTEMPTS=3
 GOLEM__PROJECT_SERVICE__CONFIG__RETRIES__MAX_DELAY="1s"
@@ -157,6 +169,17 @@ GOLEM__HTTP_PORT=8082
 GOLEM__TRACING_FILE_NAME_WITH_PORT=true
 GOLEM__ACTIVE_WORKERS__DROP_WHEN_FULL=0.25
 GOLEM__ACTIVE_WORKERS__TTL="8h"
+GOLEM__AGENT_TYPES_SERVICE__TYPE="Grpc"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__ACCESS_TOKEN="2a354594-7a63-4091-a46b-cc58d379f677"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__CACHE_TIME_TO_IDLE="1m"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__CONNECT_TIMEOUT="30s"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__HOST="localhost"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__PORT=9092
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__RETRIES__MAX_ATTEMPTS=3
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__RETRIES__MAX_DELAY="1s"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__RETRIES__MAX_JITTER_FACTOR=0.15
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__RETRIES__MIN_DELAY="100ms"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__RETRIES__MULTIPLIER=3.0
 GOLEM__BLOB_STORAGE__TYPE="LocalFileSystem"
 GOLEM__BLOB_STORAGE__CONFIG__ROOT="../data/blob_storage"
 GOLEM__CLOUD_SERVICE__ACCESS_TOKEN="5c832d93-ff85-4a8f-9803-513950fdfdb1"
@@ -171,7 +194,6 @@ GOLEM__COMPILED_COMPONENT_SERVICE__TYPE="Enabled"
 GOLEM__COMPONENT_CACHE__MAX_CAPACITY=32
 GOLEM__COMPONENT_CACHE__MAX_METADATA_CAPACITY=16384
 GOLEM__COMPONENT_CACHE__MAX_RESOLVED_COMPONENT_CAPACITY=1024
-GOLEM__COMPONENT_CACHE__MAX_RESOLVED_PROJECT_CAPACITY=1024
 GOLEM__COMPONENT_CACHE__TIME_TO_IDLE="12h"
 GOLEM__COMPONENT_SERVICE__ACCESS_TOKEN="2a354594-7a63-4091-a46b-cc58d379f677"
 GOLEM__COMPONENT_SERVICE__CONNECT_TIMEOUT="30s"
@@ -236,8 +258,10 @@ GOLEM__PLUGIN_SERVICE__CONFIG__RETRIES__MIN_DELAY="100ms"
 GOLEM__PLUGIN_SERVICE__CONFIG__RETRIES__MULTIPLIER=3.0
 GOLEM__PROJECT_SERVICE__TYPE="Grpc"
 GOLEM__PROJECT_SERVICE__CONFIG__ACCESS_TOKEN="2a354594-7a63-4091-a46b-cc58d379f677"
+GOLEM__PROJECT_SERVICE__CONFIG__CACHE_TIME_TO_IDLE="12h"
 GOLEM__PROJECT_SERVICE__CONFIG__CONNECT_TIMEOUT="30s"
 GOLEM__PROJECT_SERVICE__CONFIG__HOST="localhost"
+GOLEM__PROJECT_SERVICE__CONFIG__MAX_RESOLVED_PROJECT_CACHE_CAPACITY=1024
 GOLEM__PROJECT_SERVICE__CONFIG__PORT=9091
 GOLEM__PROJECT_SERVICE__CONFIG__RETRIES__MAX_ATTEMPTS=3
 GOLEM__PROJECT_SERVICE__CONFIG__RETRIES__MAX_DELAY="1s"
diff --git a/golem-debugging-service/config/debug-worker-executor.toml b/golem-debugging-service/config/debug-worker-executor.toml
index 1c86139e..7df62f8f 100644
--- a/golem-debugging-service/config/debug-worker-executor.toml
+++ b/golem-debugging-service/config/debug-worker-executor.toml
@@ -8,6 +8,23 @@ tracing_file_name_with_port = true
 drop_when_full = 0.25
 ttl = "8h"
 
+[agent_types_service]
+type = "Grpc"
+
+[agent_types_service.config]
+access_token = "2a354594-7a63-4091-a46b-cc58d379f677"
+cache_time_to_idle = "1m"
+connect_timeout = "30s"
+host = "localhost"
+port = 9092
+
+[agent_types_service.config.retries]
+max_attempts = 3
+max_delay = "1s"
+max_jitter_factor = 0.15
+min_delay = "100ms"
+multiplier = 3.0
+
 [blob_storage]
 type = "LocalFileSystem"
 
@@ -35,7 +52,6 @@ type = "Enabled"
 max_capacity = 32
 max_metadata_capacity = 16384
 max_resolved_component_capacity = 1024
-max_resolved_project_capacity = 1024
 time_to_idle = "12h"
 
 [component_service]
@@ -128,8 +144,10 @@ type = "Grpc"
 
 [project_service.config]
 access_token = "2a354594-7a63-4091-a46b-cc58d379f677"
+cache_time_to_idle = "12h"
 connect_timeout = "30s"
 host = "localhost"
+max_resolved_project_cache_capacity = 1024
 port = 9091
 
 [project_service.config.retries]
@@ -230,6 +248,23 @@ without_time = false
 # drop_when_full = 0.25
 # ttl = "8h"
 # 
+# [agent_types_service]
+# type = "Grpc"
+# 
+# [agent_types_service.config]
+# access_token = "2a354594-7a63-4091-a46b-cc58d379f677"
+# cache_time_to_idle = "1m"
+# connect_timeout = "30s"
+# host = "localhost"
+# port = 9092
+# 
+# [agent_types_service.config.retries]
+# max_attempts = 3
+# max_delay = "1s"
+# max_jitter_factor = 0.15
+# min_delay = "100ms"
+# multiplier = 3.0
+# 
 # [blob_storage]
 # type = "LocalFileSystem"
 # 
@@ -257,7 +292,6 @@ without_time = false
 # max_capacity = 32
 # max_metadata_capacity = 16384
 # max_resolved_component_capacity = 1024
-# max_resolved_project_capacity = 1024
 # time_to_idle = "12h"
 # 
 # [component_service]
@@ -350,8 +384,10 @@ without_time = false
 # 
 # [project_service.config]
 # access_token = "2a354594-7a63-4091-a46b-cc58d379f677"
+# cache_time_to_idle = "12h"
 # connect_timeout = "30s"
 # host = "localhost"
+# max_resolved_project_cache_capacity = 1024
 # port = 9091
 # 
 # [project_service.config.retries]
diff --git a/golem-debugging-service/src/auth.rs b/golem-debugging-service/src/auth.rs
index 3e21019e..1fc3e593 100644
--- a/golem-debugging-service/src/auth.rs
+++ b/golem-debugging-service/src/auth.rs
@@ -112,7 +112,7 @@ impl GrpcAuthService {
         component_service_grpc_config: ComponentServiceGrpcConfig,
     ) -> Self {
         let component_service_client = GrpcClient::new(
-            "auth_service",
+            "component_service",
             |channel| {
                 ComponentServiceClient::new(channel)
                     .send_compressed(CompressionEncoding::Gzip)
diff --git a/golem-debugging-service/src/config.rs b/golem-debugging-service/src/config.rs
index ae3ad095..83236680 100644
--- a/golem-debugging-service/src/config.rs
+++ b/golem-debugging-service/src/config.rs
@@ -15,17 +15,19 @@
 use golem_common::config::{ConfigExample, ConfigLoader, HasConfigExamples};
 use golem_common::model::RetryConfig;
 use golem_common::tracing::TracingConfig;
+use golem_common::SafeDisplay;
 use golem_service_base::clients::RemoteServiceConfig;
 use golem_service_base::config::BlobStorageConfig;
 use golem_worker_executor::services::golem_config::{
-    ActiveWorkersConfig, CompiledComponentServiceConfig, ComponentCacheConfig,
-    ComponentServiceConfig, ComponentServiceGrpcConfig, GolemConfig, IndexedStorageConfig,
-    KeyValueStorageConfig, Limits, MemoryConfig, OplogConfig, PluginServiceConfig,
-    ProjectServiceConfig, RdbmsConfig, ResourceLimitsConfig, SchedulerConfig,
+    ActiveWorkersConfig, AgentTypesServiceConfig, CompiledComponentServiceConfig,
+    ComponentCacheConfig, ComponentServiceConfig, ComponentServiceGrpcConfig, GolemConfig,
+    IndexedStorageConfig, KeyValueStorageConfig, Limits, MemoryConfig, OplogConfig,
+    PluginServiceConfig, ProjectServiceConfig, RdbmsConfig, ResourceLimitsConfig, SchedulerConfig,
     ShardManagerServiceConfig, ShardManagerServiceSingleShardConfig, SuspendConfig,
     WorkerServiceGrpcConfig,
 };
 use serde::{Deserialize, Serialize};
+use std::fmt::Write;
 use std::path::PathBuf;
 
 // A wrapper over golem config with a few custom behaviour
@@ -50,13 +52,14 @@ pub struct DebugConfig {
     pub rdbms: RdbmsConfig,
     pub http_address: String,
     pub http_port: u16,
-
-    // debug service specific fields
-    pub cloud_service: RemoteServiceConfig,
     pub component_service: ComponentServiceGrpcConfig,
     pub component_cache: ComponentCacheConfig,
     pub project_service: ProjectServiceConfig,
+    pub agent_types_service: AgentTypesServiceConfig,
     pub resource_limits: ResourceLimitsConfig,
+
+    // debug service specific fields
+    pub cloud_service: RemoteServiceConfig,
     pub cors_origin_regex: String,
 }
 
@@ -83,7 +86,8 @@ impl DebugConfig {
             resource_limits: self.resource_limits,
             component_service: ComponentServiceConfig::Grpc(self.component_service),
             component_cache: self.component_cache,
-            project_service: Default::default(),
+            project_service: self.project_service,
+            agent_types_service: self.agent_types_service,
             // unused
             grpc_address: default_golem_config.grpc_address,
             // unused
@@ -97,6 +101,25 @@ impl DebugConfig {
     }
 }
 
+impl SafeDisplay for DebugConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.clone().into_golem_config().to_safe_string()
+        );
+        let _ = writeln!(&mut result, "cloud service:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.cloud_service.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "CORS origin regex: {}", self.cors_origin_regex);
+        result
+    }
+}
+
 impl Default for DebugConfig {
     fn default() -> Self {
         let default_golem_config = GolemConfig::default();
@@ -123,6 +146,7 @@ impl Default for DebugConfig {
             component_cache: ComponentCacheConfig::default(),
             component_service: ComponentServiceGrpcConfig::default(),
             project_service: ProjectServiceConfig::default(),
+            agent_types_service: AgentTypesServiceConfig::default(),
             resource_limits: ResourceLimitsConfig::default(),
             cors_origin_regex: "https://*.golem.cloud".to_string(),
         }
diff --git a/golem-debugging-service/src/debug_context.rs b/golem-debugging-service/src/debug_context.rs
index 556ea00a..8c98e7c2 100644
--- a/golem-debugging-service/src/debug_context.rs
+++ b/golem-debugging-service/src/debug_context.rs
@@ -19,34 +19,34 @@ use golem_common::model::invocation_context::{
     self, AttributeValue, InvocationContextStack, SpanId,
 };
 use golem_common::model::oplog::UpdateDescription;
-use golem_common::model::oplog::WorkerResourceId;
 use golem_common::model::{
-    AccountId, ComponentFilePath, ComponentVersion, IdempotencyKey, OwnedWorkerId,
-    PluginInstallationId, TargetWorkerId, WorkerId, WorkerMetadata, WorkerStatus,
+    AccountId, ComponentFilePath, ComponentVersion, GetFileSystemNodeResult, IdempotencyKey,
+    OwnedWorkerId, PluginInstallationId, ProjectId, WorkerId, WorkerMetadata, WorkerStatus,
     WorkerStatusRecord,
 };
 use golem_service_base::error::worker_executor::{InterruptKind, WorkerExecutorError};
 use golem_wasm_rpc::golem_rpc_0_2_x::types::{
     Datetime, FutureInvokeResult, HostFutureInvokeResult, Pollable, WasmRpc,
 };
-use golem_wasm_rpc::wasmtime::ResourceStore;
-use golem_wasm_rpc::{CancellationTokenEntry, ComponentId, Value, ValueAndType};
+use golem_wasm_rpc::wasmtime::{ResourceStore, ResourceTypeId};
+use golem_wasm_rpc::{CancellationTokenEntry, Value, ValueAndType};
 use golem_wasm_rpc::{HostWasmRpc, RpcError, Uri, WitValue};
 use golem_worker_executor::durable_host::{
     DurableWorkerCtx, DurableWorkerCtxView, PublicDurableWorkerState,
 };
 use golem_worker_executor::model::{
-    CurrentResourceLimits, ExecutionStatus, LastError, ListDirectoryResult, ReadFileResult,
-    TrapType, WorkerConfig,
+    CurrentResourceLimits, ExecutionStatus, LastError, ReadFileResult, TrapType, WorkerConfig,
 };
 use golem_worker_executor::services::active_workers::ActiveWorkers;
+use golem_worker_executor::services::agent_types::AgentTypesService;
 use golem_worker_executor::services::blob_store::BlobStoreService;
-use golem_worker_executor::services::component::{ComponentMetadata, ComponentService};
+use golem_worker_executor::services::component::ComponentService;
 use golem_worker_executor::services::file_loader::FileLoader;
 use golem_worker_executor::services::golem_config::GolemConfig;
 use golem_worker_executor::services::key_value::KeyValueService;
 use golem_worker_executor::services::oplog::{Oplog, OplogService};
 use golem_worker_executor::services::plugins::Plugins;
+use golem_worker_executor::services::projects::ProjectService;
 use golem_worker_executor::services::promise::PromiseService;
 use golem_worker_executor::services::rdbms::RdbmsService;
 use golem_worker_executor::services::resource_limits::ResourceLimits;
@@ -59,11 +59,12 @@ use golem_worker_executor::services::worker_proxy::WorkerProxy;
 use golem_worker_executor::services::{worker_enumeration, HasAll, HasConfig, HasOplogService};
 use golem_worker_executor::worker::{RetryDecision, Worker};
 use golem_worker_executor::workerctx::{
-    DynamicLinking, ExternalOperations, FileSystemReading, FuelManagement, IndexedResourceStore,
-    InvocationContextManagement, InvocationHooks, InvocationManagement, StatusManagement,
-    UpdateManagement, WorkerCtx,
+    DynamicLinking, ExternalOperations, FileSystemReading, FuelManagement, HasWasiConfigVars,
+    InvocationContextManagement, InvocationHooks, InvocationManagement, LogEventEmitBehaviour,
+    StatusManagement, UpdateManagement, WorkerCtx,
 };
-use std::collections::HashSet;
+use std::collections::{BTreeMap, HashSet};
+use std::future::Future;
 use std::sync::{Arc, RwLock, Weak};
 use wasmtime::component::{Component, Instance, Linker, Resource, ResourceAny};
 use wasmtime::{AsContextMut, Engine, ResourceLimiterAsync};
@@ -129,8 +130,9 @@ impl ExternalOperations<Self> for DebugContext {
     async fn resume_replay(
         store: &mut (impl AsContextMut<Data = Self> + Send),
         instance: &Instance,
+        refresh_replay_target: bool,
     ) -> Result<RetryDecision, WorkerExecutorError> {
-        DurableWorkerCtx::<Self>::resume_replay(store, instance).await
+        DurableWorkerCtx::<Self>::resume_replay(store, instance, refresh_replay_target).await
     }
 
     async fn prepare_instance(
@@ -143,10 +145,10 @@ impl ExternalOperations<Self> for DebugContext {
 
     async fn record_last_known_limits<This: HasAll<Self> + Send + Sync>(
         this: &This,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         last_known_limits: &CurrentResourceLimits,
     ) -> Result<(), WorkerExecutorError> {
-        DurableWorkerCtx::<Self>::record_last_known_limits(this, account_id, last_known_limits)
+        DurableWorkerCtx::<Self>::record_last_known_limits(this, project_id, last_known_limits)
             .await
     }
 
@@ -159,18 +161,20 @@ impl ExternalOperations<Self> for DebugContext {
 
     async fn on_shard_assignment_changed<This: HasAll<Self> + Send + Sync + 'static>(
         this: &This,
-    ) -> Result<(), anyhow::Error> {
+    ) -> Result<(), Error> {
         DurableWorkerCtx::<Self>::on_shard_assignment_changed(this).await
     }
 
     async fn on_worker_update_failed_to_start<T: HasAll<Self> + Send + Sync>(
         this: &T,
+        account_id: &AccountId,
         owned_worker_id: &OwnedWorkerId,
         target_version: ComponentVersion,
         details: Option<String>,
     ) -> Result<(), WorkerExecutorError> {
         DurableWorkerCtx::<Self>::on_worker_update_failed_to_start(
             this,
+            account_id,
             owned_worker_id,
             target_version,
             details,
@@ -191,10 +195,6 @@ impl InvocationManagement for DebugContext {
         self.durable_ctx.get_current_idempotency_key().await
     }
 
-    async fn get_current_invocation_context(&self) -> InvocationContextStack {
-        self.durable_ctx.get_current_invocation_context().await
-    }
-
     async fn set_current_invocation_context(
         &mut self,
         stack: InvocationContextStack,
@@ -202,6 +202,10 @@ impl InvocationManagement for DebugContext {
         self.durable_ctx.set_current_invocation_context(stack).await
     }
 
+    async fn get_current_invocation_context(&self) -> InvocationContextStack {
+        self.durable_ctx.get_current_invocation_context().await
+    }
+
     fn is_live(&self) -> bool {
         self.durable_ctx.is_live()
     }
@@ -307,60 +311,32 @@ impl UpdateManagement for DebugContext {
     }
 }
 
-#[async_trait]
-impl IndexedResourceStore for DebugContext {
-    fn get_indexed_resource(
-        &self,
-        resource_name: &str,
-        resource_params: &[String],
-    ) -> Option<WorkerResourceId> {
-        self.durable_ctx
-            .get_indexed_resource(resource_name, resource_params)
-    }
-
-    async fn store_indexed_resource(
-        &mut self,
-        resource_name: &str,
-        resource_params: &[String],
-        resource: WorkerResourceId,
-    ) {
-        self.durable_ctx
-            .store_indexed_resource(resource_name, resource_params, resource)
-            .await
-    }
-
-    fn drop_indexed_resource(&mut self, resource_name: &str, resource_params: &[String]) {
-        self.durable_ctx
-            .drop_indexed_resource(resource_name, resource_params)
-    }
-}
-
 #[async_trait]
 impl ResourceStore for DebugContext {
     fn self_uri(&self) -> Uri {
         self.durable_ctx.self_uri()
     }
 
-    async fn add(&mut self, resource: ResourceAny) -> u64 {
-        self.durable_ctx.add(resource).await
+    async fn add(&mut self, resource: ResourceAny, name: ResourceTypeId) -> u64 {
+        self.durable_ctx.add(resource, name).await
     }
 
-    async fn get(&mut self, resource_id: u64) -> Option<ResourceAny> {
+    async fn get(&mut self, resource_id: u64) -> Option<(ResourceTypeId, ResourceAny)> {
         ResourceStore::get(&mut self.durable_ctx, resource_id).await
     }
 
-    async fn borrow(&self, resource_id: u64) -> Option<ResourceAny> {
+    async fn borrow(&self, resource_id: u64) -> Option<(ResourceTypeId, ResourceAny)> {
         self.durable_ctx.borrow(resource_id).await
     }
 }
 
 #[async_trait]
 impl FileSystemReading for DebugContext {
-    async fn list_directory(
+    async fn get_file_system_node(
         &self,
         path: &ComponentFilePath,
-    ) -> Result<ListDirectoryResult, WorkerExecutorError> {
-        self.durable_ctx.list_directory(path).await
+    ) -> Result<GetFileSystemNodeResult, WorkerExecutorError> {
+        self.durable_ctx.get_file_system_node(path).await
     }
 
     async fn read_file(
@@ -406,10 +382,6 @@ impl HostWasmRpc for DebugContext {
         self.durable_ctx.new(worker_id).await
     }
 
-    async fn ephemeral(&mut self, component_id: ComponentId) -> anyhow::Result<Resource<WasmRpc>> {
-        self.durable_ctx.ephemeral(component_id).await
-    }
-
     async fn invoke_and_await(
         &mut self,
         self_: Resource<WasmRpc>,
@@ -492,6 +464,22 @@ impl HostFutureInvokeResult for DebugContext {
     }
 }
 
+impl wasmtime_wasi::p2::bindings::cli::environment::Host for DebugContext {
+    fn get_environment(
+        &mut self,
+    ) -> impl Future<Output = anyhow::Result<Vec<(String, String)>>> + Send {
+        wasmtime_wasi::p2::bindings::cli::environment::Host::get_environment(&mut self.durable_ctx)
+    }
+
+    fn get_arguments(&mut self) -> impl Future<Output = anyhow::Result<Vec<String>>> + Send {
+        wasmtime_wasi::p2::bindings::cli::environment::Host::get_arguments(&mut self.durable_ctx)
+    }
+
+    fn initial_cwd(&mut self) -> impl Future<Output = anyhow::Result<Option<String>>> + Send {
+        wasmtime_wasi::p2::bindings::cli::environment::Host::initial_cwd(&mut self.durable_ctx)
+    }
+}
+
 #[async_trait]
 impl DynamicLinking<Self> for DebugContext {
     fn link(
@@ -499,7 +487,7 @@ impl DynamicLinking<Self> for DebugContext {
         engine: &Engine,
         linker: &mut Linker<Self>,
         component: &Component,
-        component_metadata: &ComponentMetadata,
+        component_metadata: &golem_service_base::model::Component,
     ) -> anyhow::Result<()> {
         self.durable_ctx
             .link(engine, linker, component, component_metadata)
@@ -525,18 +513,18 @@ impl InvocationContextManagement for DebugContext {
             .await
     }
 
-    async fn finish_span(
+    fn remove_span(
         &mut self,
         span_id: &invocation_context::SpanId,
     ) -> Result<(), WorkerExecutorError> {
-        self.durable_ctx.finish_span(span_id).await
+        self.durable_ctx.remove_span(span_id)
     }
 
-    fn remove_span(
+    async fn finish_span(
         &mut self,
         span_id: &invocation_context::SpanId,
     ) -> Result<(), WorkerExecutorError> {
-        self.durable_ctx.remove_span(span_id)
+        self.durable_ctx.finish_span(span_id).await
     }
 
     async fn set_span_attribute(
@@ -549,13 +537,26 @@ impl InvocationContextManagement for DebugContext {
             .set_span_attribute(span_id, key, value)
             .await
     }
+
+    fn clone_as_inherited_stack(&self, current_span_id: &SpanId) -> InvocationContextStack {
+        self.durable_ctx.clone_as_inherited_stack(current_span_id)
+    }
+}
+
+impl HasWasiConfigVars for DebugContext {
+    fn wasi_config_vars(&self) -> BTreeMap<String, String> {
+        self.durable_ctx.wasi_config_vars()
+    }
 }
 
 #[async_trait]
 impl WorkerCtx for DebugContext {
     type PublicState = PublicDurableWorkerState<Self>;
 
+    const LOG_EVENT_EMIT_BEHAVIOUR: LogEventEmitBehaviour = LogEventEmitBehaviour::Always;
+
     async fn create(
+        _account_id: AccountId,
         owned_worker_id: OwnedWorkerId,
         promise_service: Arc<dyn PromiseService>,
         worker_service: Arc<dyn WorkerService>,
@@ -580,6 +581,8 @@ impl WorkerCtx for DebugContext {
         plugins: Arc<dyn Plugins>,
         worker_fork: Arc<dyn WorkerForkService>,
         _resource_limits: Arc<dyn ResourceLimits>,
+        project_service: Arc<dyn ProjectService>,
+        agent_types_service: Arc<dyn AgentTypesService>,
     ) -> Result<Self, WorkerExecutorError> {
         let golem_ctx = DurableWorkerCtx::create(
             owned_worker_id,
@@ -603,6 +606,8 @@ impl WorkerCtx for DebugContext {
             file_loader,
             plugins,
             worker_fork,
+            project_service,
+            agent_types_service,
         )
         .await?;
         Ok(Self {
@@ -634,7 +639,7 @@ impl WorkerCtx for DebugContext {
         self.durable_ctx.owned_worker_id()
     }
 
-    fn component_metadata(&self) -> &ComponentMetadata {
+    fn component_metadata(&self) -> &golem_service_base::model::Component {
         self.durable_ctx.component_metadata()
     }
 
@@ -654,16 +659,11 @@ impl WorkerCtx for DebugContext {
         self.durable_ctx.worker_fork()
     }
 
-    async fn generate_unique_local_worker_id(
-        &mut self,
-        remote_worker_id: TargetWorkerId,
-    ) -> Result<WorkerId, WorkerExecutorError> {
-        self.durable_ctx
-            .generate_unique_local_worker_id(remote_worker_id)
-            .await
-    }
-
     fn component_service(&self) -> Arc<dyn ComponentService> {
         self.durable_ctx().component_service()
     }
+
+    fn created_by(&self) -> &AccountId {
+        self.durable_ctx.created_by()
+    }
 }
diff --git a/golem-debugging-service/src/debug_session.rs b/golem-debugging-service/src/debug_session.rs
index d10f7b6c..8c2dd479 100644
--- a/golem-debugging-service/src/debug_session.rs
+++ b/golem-debugging-service/src/debug_session.rs
@@ -22,11 +22,11 @@ use async_trait::async_trait;
 use bincode::Encode;
 use golem_common::model::auth::Namespace;
 use golem_common::model::oplog::{
-    DurableFunctionType, IndexedResourceKey, OplogEntry, OplogIndex, OplogPayload, WorkerError,
+    DurableFunctionType, OplogEntry, OplogIndex, OplogPayload, WorkerError,
 };
 use golem_common::model::public_oplog::{
-    CreateParameters, DescribeResourceParameters, ExportedFunctionCompletedParameters,
-    FailedUpdateParameters, GrowMemoryParameters, ImportedFunctionInvokedParameters, LogParameters,
+    CreateParameters, ExportedFunctionCompletedParameters, FailedUpdateParameters,
+    GrowMemoryParameters, ImportedFunctionInvokedParameters, LogParameters,
     PublicDurableFunctionType, PublicOplogEntry, ResourceParameters,
 };
 use golem_common::model::{
@@ -34,7 +34,7 @@ use golem_common::model::{
     WorkerMetadata,
 };
 use golem_wasm_ast::analysis::AnalysedType;
-use golem_wasm_rpc::protobuf::type_annotated_value::TypeAnnotatedValue;
+use golem_wasm_rpc::wasmtime::ResourceTypeId;
 use golem_wasm_rpc::{Value, ValueAndType};
 use golem_worker_executor::durable_host::http::serialized::{
     SerializableErrorCode, SerializableHttpRequest, SerializableResponse,
@@ -52,7 +52,7 @@ use serde::Serialize;
 use std::collections::{HashMap, HashSet};
 use std::fmt::Display;
 use std::ops::Deref;
-use std::sync::{Arc, Mutex, RwLock};
+use std::sync::{Arc, Mutex};
 use uuid::Uuid;
 
 // A shared debug session which will be internally used by the custom oplog service
@@ -150,9 +150,9 @@ impl DebugSessions for DebugSessionsDefault {
     }
 }
 
-#[derive(Debug, Clone)]
+#[derive(Clone)]
 pub struct DebugSessionData {
-    pub worker_metadata: Option<WorkerMetadata>,
+    pub worker_metadata: WorkerMetadata,
     pub target_oplog_index: Option<OplogIndex>,
     pub playback_overrides: PlaybackOverridesInternal,
     // The current status of the oplog index being replayed and possibly
@@ -173,10 +173,17 @@ impl PlaybackOverridesInternal {
     }
     pub fn from_playback_override(
         playback_overrides: Vec<PlaybackOverride>,
+        current_index: OplogIndex,
     ) -> Result<Self, String> {
         let mut overrides = HashMap::new();
         for override_data in playback_overrides {
             let oplog_index = override_data.index;
+            if oplog_index <= current_index {
+                return Err(
+                    "Cannot create overrides for oplog indices that are in the past".to_string(),
+                );
+            }
+
             let public_oplog_entry: PublicOplogEntry = override_data.oplog;
             let oplog_entry = get_oplog_entry_from_public_oplog_entry(public_oplog_entry)?;
             overrides.insert(oplog_index, oplog_entry);
@@ -227,24 +234,6 @@ impl ActiveSessionData {
     }
 }
 
-#[derive(Default)]
-pub struct ActiveSession {
-    pub active_session: Arc<RwLock<Option<ActiveSessionData>>>,
-}
-
-impl ActiveSession {
-    pub async fn set_active_session(&self, worker_id: WorkerId, cloud_namespace: Namespace) {
-        let mut active_session = self.active_session.write().unwrap();
-        *active_session = Some(ActiveSessionData::new(cloud_namespace, worker_id));
-    }
-
-    pub async fn get_active_session(&self) -> Option<ActiveSessionData> {
-        let active_session = &self.active_session.read().unwrap();
-        let active_session = active_session.as_ref();
-        active_session.cloned()
-    }
-}
-
 fn get_oplog_entry_from_public_oplog_entry(
     public_oplog_entry: PublicOplogEntry,
 ) -> Result<OplogEntry, String> {
@@ -270,7 +259,9 @@ fn get_oplog_entry_from_public_oplog_entry(
             component_version,
             args,
             env,
-            account_id,
+            project_id,
+            created_by,
+            wasi_config_vars,
             parent,
             component_size,
             initial_total_linear_memory_size,
@@ -281,7 +272,9 @@ fn get_oplog_entry_from_public_oplog_entry(
             component_version,
             args,
             env: env.into_iter().collect(),
-            account_id,
+            project_id,
+            created_by,
+            wasi_config_vars: wasi_config_vars.into(),
             parent,
             component_size,
             initial_total_linear_memory_size,
@@ -294,7 +287,7 @@ fn get_oplog_entry_from_public_oplog_entry(
             timestamp,
             function_name,
             response,
-            wrapped_function_type,
+            durable_function_type: wrapped_function_type,
             request,
         }) => {
             let response: OplogPayload = convert_response_value_and_type_to_oplog_payload(
@@ -320,7 +313,7 @@ fn get_oplog_entry_from_public_oplog_entry(
                 function_name,
                 request,
                 response,
-                wrapped_function_type: durable_function_type,
+                durable_function_type,
             })
         }
         PublicOplogEntry::ExportedFunctionInvoked(exported_function_invoked_parameters) => {
@@ -422,32 +415,26 @@ fn get_oplog_entry_from_public_oplog_entry(
         PublicOplogEntry::GrowMemory(GrowMemoryParameters { timestamp, delta }) => {
             Ok(OplogEntry::GrowMemory { timestamp, delta })
         }
-        PublicOplogEntry::CreateResource(ResourceParameters { timestamp, id }) => {
-            Ok(OplogEntry::CreateResource { timestamp, id })
-        }
-        PublicOplogEntry::DropResource(ResourceParameters { timestamp, id }) => {
-            Ok(OplogEntry::DropResource { timestamp, id })
-        }
-        PublicOplogEntry::DescribeResource(DescribeResourceParameters {
+        PublicOplogEntry::CreateResource(ResourceParameters {
             timestamp,
             id,
-            resource_name,
-            resource_params,
-        }) => {
-            let resource_params = resource_params
-                .iter()
-                .map(|value_and_type| value_and_type.to_string()) // This will call to_string of wasm wave
-                .collect::<Vec<_>>();
-
-            Ok(OplogEntry::DescribeResource {
-                timestamp,
-                id,
-                indexed_resource: IndexedResourceKey {
-                    resource_name,
-                    resource_params,
-                },
-            })
-        }
+            owner,
+            name,
+        }) => Ok(OplogEntry::CreateResource {
+            timestamp,
+            id,
+            resource_type_id: ResourceTypeId { owner, name },
+        }),
+        PublicOplogEntry::DropResource(ResourceParameters {
+            timestamp,
+            id,
+            owner,
+            name,
+        }) => Ok(OplogEntry::DropResource {
+            timestamp,
+            id,
+            resource_type_id: ResourceTypeId { owner, name },
+        }),
         PublicOplogEntry::Log(LogParameters {
             timestamp,
             level,
@@ -1050,7 +1037,7 @@ fn convert_response_value_and_type_to_oplog_payload(
 
 fn get_invoke_and_await_result(
     value_and_type: &ValueAndType,
-) -> Result<Result<TypeAnnotatedValue, SerializableError>, String> {
+) -> Result<Result<ValueAndType, SerializableError>, String> {
     match &value_and_type.value {
         Value::Result(Ok(Some(value))) => match &value_and_type.typ {
             AnalysedType::Result(type_result) => {
@@ -1062,9 +1049,7 @@ fn get_invoke_and_await_result(
                     .clone();
                 let value = value.deref().clone();
                 let value_and_type = ValueAndType::new(value, typ);
-                let type_annotated_value =
-                    TypeAnnotatedValue::try_from(value_and_type).map_err(|err| err.join(", "))?;
-                Ok(Ok(type_annotated_value))
+                Ok(Ok(value_and_type))
             }
 
             _ => Err("Failed to obtain type annotated value".to_string()),
diff --git a/golem-debugging-service/src/jrpc.rs b/golem-debugging-service/src/jrpc.rs
index 209824e9..b53db468 100644
--- a/golem-debugging-service/src/jrpc.rs
+++ b/golem-debugging-service/src/jrpc.rs
@@ -12,140 +12,407 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use crate::debug_session::ActiveSession;
 use crate::model::params::*;
 use crate::services::debug_service::{DebugService, DebugServiceError};
 use axum_jrpc::error::{JsonRpcError, JsonRpcErrorReason};
 use axum_jrpc::{Id, JsonRpcRequest, JsonRpcResponse};
-use golem_common::model::auth::AuthCtx;
+use futures::{SinkExt, StreamExt};
+use golem_common::model::auth::{AuthCtx, Namespace};
 use golem_common::model::OwnedWorkerId;
+use golem_worker_executor::services::worker_event::WorkerEventReceiver;
+use poem::web::websocket::{CloseCode, Message, WebSocketStream};
+use serde::Serialize;
 use serde_json::Value;
 use std::fmt::Display;
 use std::sync::Arc;
-use std::time::Duration;
+use tokio::select;
+use tokio::sync::mpsc::{self, Sender, UnboundedReceiver, UnboundedSender};
+use tokio::sync::oneshot;
+use tokio_stream::wrappers::errors::BroadcastStreamRecvError;
+use tokio_util::sync::{CancellationToken, DropGuard};
+use tracing::{debug, warn};
 
-pub async fn jrpc_handler(
+pub async fn run_jrpc_debug_websocket_session(
+    socket_stream: WebSocketStream,
     debug_service: Arc<dyn DebugService>,
-    json_rpc_request: JsonRpcRequest,
-    active_session: Arc<ActiveSession>,
     auth_ctx: AuthCtx,
-) -> JsonRpcResult {
-    let jrpc_id: Id = json_rpc_request.id;
-
-    match json_rpc_request.method.as_str() {
-        "current_oplog_index" => {
-            if let Some(active_session_data) = active_session.get_active_session().await {
-                let owned_worker_id = OwnedWorkerId::new(
-                    &active_session_data.cloud_namespace.account_id,
-                    &active_session_data.worker_id,
-                );
-
-                let result = debug_service.current_oplog_index(owned_worker_id).await;
-                to_json_rpc_result(&jrpc_id, result)
-            } else {
-                Err(inactive_session_error(&jrpc_id))
+) {
+    let (mut sink, mut stream) = socket_stream.split();
+    let (sender, mut receiver) = mpsc::channel(64);
+
+    // dedicated spawned future for sending outgoing messages to the client.
+    // The sink cannot be shared between threads and we need to emit notifications via side channels while driving the session.
+    let sender_handle = tokio::spawn(async move {
+        let mut closed = false;
+        while !closed {
+            let message = receiver.recv().await;
+            debug!("Sending message on jrpc debugging websocket: {message:?}");
+            match message {
+                Some(OutgoingJsonRpcMessage::Close) => {
+                    debug!("Closing connection");
+
+                    let _ = sink
+                        .send(Message::Close(Some((
+                            CloseCode::Normal,
+                            "Connection closed".to_string(),
+                        ))))
+                        .await;
+
+                    closed = true;
+                }
+                Some(OutgoingJsonRpcMessage::Response(response)) => {
+                    let result = sink
+                        .send(Message::Text(serde_json::to_string(&response).unwrap()))
+                        .await;
+
+                    if let Err(e) = result {
+                        warn!("Error sending response: {}", e);
+                    }
+                }
+                Some(OutgoingJsonRpcMessage::Notification(notification)) => {
+                    let result = sink
+                        .send(Message::Text(serde_json::to_string(&notification).unwrap()))
+                        .await;
+
+                    if let Err(e) = result {
+                        warn!("Error sending notification: {}", e);
+                    };
+                }
+                Some(OutgoingJsonRpcMessage::Error(error)) => {
+                    if error.should_terminate_session() {
+                        let result = sink
+                            .send(Message::Close(Some((CloseCode::Error, error.to_string()))))
+                            .await;
+
+                        if let Err(e) = result {
+                            debug!("Error sending close with error: {e}");
+                        }
+
+                        closed = true;
+                    } else {
+                        let result = sink
+                            .send(Message::Text(
+                                serde_json::to_string(&error.to_jrpc_response()).unwrap(),
+                            ))
+                            .await;
+
+                        if let Err(e) = result {
+                            warn!("Error sending error: {}", e);
+                        };
+                    }
+                }
+                None => {
+                    closed = true;
+                }
             }
         }
-        "connect" => {
-            let params: ConnectParams = parse_params(&jrpc_id, json_rpc_request.params)?;
+    });
 
-            let result = debug_service
-                .connect(&auth_ctx, params.worker_id, active_session)
-                .await;
+    let mut session = JrpcSession::new(debug_service.clone(), auth_ctx, sender.clone());
 
-            to_json_rpc_result(&jrpc_id, result)
-        }
-        "playback" => {
-            if let Some(active_session_data) = active_session.get_active_session().await {
-                let params: PlaybackParams = parse_params(&jrpc_id, json_rpc_request.params)?;
-
-                let owned_worker_id = OwnedWorkerId::new(
-                    &active_session_data.cloud_namespace.account_id,
-                    &active_session_data.worker_id,
-                );
-
-                let result = debug_service
-                    .playback(
-                        owned_worker_id,
-                        params.target_index,
-                        params.overrides,
-                        params.ensure_invocation_boundary.unwrap_or(true),
-                        params
-                            .time_out_in_seconds
-                            .map(Duration::from_secs)
-                            .unwrap_or(Duration::from_secs(5)),
-                    )
-                    .await;
+    // drive the session using the incoming websocket messages
+    while let Some(Ok(msg)) = stream.next().await {
+        match msg {
+            Message::Text(text) => {
+                let rpc_request: JsonRpcRequest = match serde_json::from_str(&text) {
+                    Ok(request) => request,
+                    Err(_) => {
+                        let response = JsonRpcResponse::error(
+                            Id::None(()),
+                            JsonRpcError::new(
+                                JsonRpcErrorReason::ParseError,
+                                "Invalid JSON-RPC".to_string(),
+                                axum_jrpc::Value::Null,
+                            ),
+                        );
+
+                        let _ = sender
+                            .send(OutgoingJsonRpcMessage::Response(response))
+                            .await;
+                        continue;
+                    }
+                };
 
-                to_json_rpc_result(&jrpc_id, result)
-            } else {
-                Err(inactive_session_error(&jrpc_id))
+                debug!("Received request on jrpc debugging websocket: {rpc_request:?}");
+
+                let response = session.handle_request(rpc_request).await;
+
+                match response {
+                    Ok(json_rpc_success) => {
+                        let _ = sender
+                            .send(OutgoingJsonRpcMessage::Response(json_rpc_success))
+                            .await;
+                    }
+                    Err(handler_error) => {
+                        let _ = sender
+                            .send(OutgoingJsonRpcMessage::Error(handler_error))
+                            .await;
+                    }
+                }
+            }
+            Message::Close(_) => {
+                // ack the close
+                let _ = sender.send(OutgoingJsonRpcMessage::Close).await;
             }
+            _ => {}
         }
-        "rewind" => {
-            if let Some(active_session_data) = active_session.get_active_session().await {
-                let params: RewindParams = parse_params(&jrpc_id, json_rpc_request.params)?;
-
-                let owned_worker_id = OwnedWorkerId::new(
-                    &active_session_data.cloud_namespace.account_id,
-                    &active_session_data.worker_id,
-                );
-
-                let result = debug_service
-                    .rewind(
-                        owned_worker_id,
-                        params.target_index,
-                        params.ensure_invocation_boundary.unwrap_or(true),
-                        params
-                            .time_out_in_seconds
-                            .map(Duration::from_secs)
-                            .unwrap_or(Duration::from_secs(5)),
-                    )
-                    .await;
-                to_json_rpc_result(&jrpc_id, result)
-            } else {
-                Err(inactive_session_error(&jrpc_id))
+    }
+
+    let _ = sender_handle.await;
+
+    // clean up after ourselves
+    session.terminate().await;
+}
+
+struct JrpcSessionData {
+    pub namespace: Namespace,
+    pub connected_worker: OwnedWorkerId,
+}
+
+struct JrpcSession {
+    debug_service: Arc<dyn DebugService>,
+    auth_ctx: AuthCtx,
+    active_session: Option<JrpcSessionData>,
+
+    // will be taken by a spawned future when succesfully connect to a worker for the first time.
+    // used to send notifications via a second channel
+    notifications_sidechannel: Sender<OutgoingJsonRpcMessage>,
+    worker_events_processor_dropguard: Option<DropGuard>,
+
+    // used to coordinate a final poll of notifications before returning to the calles
+    events_poll_sender: UnboundedSender<oneshot::Sender<()>>,
+    events_poll_receiver: Option<UnboundedReceiver<oneshot::Sender<()>>>,
+}
+
+impl JrpcSession {
+    fn new(
+        debug_service: Arc<dyn DebugService>,
+        auth_ctx: AuthCtx,
+        notifications_sidechannel: Sender<OutgoingJsonRpcMessage>,
+    ) -> Self {
+        let (events_poll_sender, events_poll_receiver) = mpsc::unbounded_channel();
+
+        Self {
+            debug_service,
+            auth_ctx,
+            active_session: None,
+            notifications_sidechannel,
+            worker_events_processor_dropguard: None,
+            events_poll_sender,
+            events_poll_receiver: Some(events_poll_receiver),
+        }
+    }
+
+    async fn terminate(self) {
+        if let Some(active_session) = self.active_session {
+            let result = self
+                .debug_service
+                .terminate_session(&active_session.connected_worker)
+                .await;
+            if let Err(e) = result {
+                warn!("Failed to terminate debugging session: {e}");
             }
         }
-        "fork" => {
-            if let Some(active_session_data) = active_session.get_active_session().await {
-                let owned_worker_id = OwnedWorkerId::new(
-                    &active_session_data.cloud_namespace.account_id,
-                    &active_session_data.worker_id,
-                );
-
-                let params: ForkParams = parse_params(&jrpc_id, json_rpc_request.params)?;
-                let result = debug_service
-                    .fork(
-                        owned_worker_id,
-                        params.target_worker_id,
-                        params.oplog_index_cut_off,
-                    )
+    }
+
+    async fn handle_request(
+        &mut self,
+        request: JsonRpcRequest,
+    ) -> Result<JsonRpcResponse, JrpcHandlerError> {
+        let jrpc_id: Id = request.id;
+
+        match request.method.as_str() {
+            "current_oplog_index" => {
+                if let Some(active_session_data) = &self.active_session {
+                    let owned_worker_id = active_session_data.connected_worker.clone();
+
+                    let result = self
+                        .debug_service
+                        .current_oplog_index(&owned_worker_id)
+                        .await;
+                    to_json_rpc_result(&jrpc_id, result)
+                } else {
+                    Err(inactive_session_error(&jrpc_id))
+                }
+            }
+            "connect" => {
+                if self.active_session.is_some() {
+                    Err(JrpcHandlerError::session_already_connected(
+                        jrpc_id.clone(),
+                        "Session is already connected to a worker".to_string(),
+                    ))?
+                }
+
+                let params: ConnectParams = parse_params(&jrpc_id, request.params)?;
+
+                let result = self
+                    .debug_service
+                    .connect(&self.auth_ctx, &params.worker_id)
                     .await;
-                to_json_rpc_result(&jrpc_id, result)
-            } else {
-                Err(inactive_session_error(&jrpc_id))
+
+                match result {
+                    Ok((result, connected_worker, namespace, worker_event_receiver)) => {
+                        self.active_session = Some(JrpcSessionData {
+                            connected_worker,
+                            namespace,
+                        });
+
+                        self.start_worker_event_processor(worker_event_receiver);
+
+                        self.ensure_pending_notifications_are_emitted().await;
+
+                        to_json_rpc_result(&jrpc_id, Ok(result))
+                    }
+                    Err(err) => to_json_rpc_result::<ConnectResult>(&jrpc_id, Err(err)),
+                }
+            }
+            "playback" => {
+                if let Some(active_session_data) = &self.active_session {
+                    let params: PlaybackParams = parse_params(&jrpc_id, request.params)?;
+
+                    let owned_worker_id = active_session_data.connected_worker.clone();
+
+                    let result = self
+                        .debug_service
+                        .playback(
+                            &owned_worker_id,
+                            &active_session_data.namespace.account_id,
+                            params.target_index,
+                            params.overrides,
+                            params.ensure_invocation_boundary.unwrap_or(true),
+                        )
+                        .await;
+
+                    self.ensure_pending_notifications_are_emitted().await;
+
+                    to_json_rpc_result(&jrpc_id, result)
+                } else {
+                    Err(inactive_session_error(&jrpc_id))
+                }
+            }
+            "rewind" => {
+                if let Some(active_session_data) = &self.active_session {
+                    let params: RewindParams = parse_params(&jrpc_id, request.params)?;
+
+                    let owned_worker_id = active_session_data.connected_worker.clone();
+
+                    let result = self
+                        .debug_service
+                        .rewind(
+                            &owned_worker_id,
+                            &active_session_data.namespace.account_id,
+                            params.target_index,
+                            params.ensure_invocation_boundary.unwrap_or(true),
+                        )
+                        .await;
+
+                    self.ensure_pending_notifications_are_emitted().await;
+
+                    to_json_rpc_result(&jrpc_id, result)
+                } else {
+                    Err(inactive_session_error(&jrpc_id))
+                }
+            }
+            "fork" => {
+                if let Some(active_session_data) = &self.active_session {
+                    let owned_worker_id = active_session_data.connected_worker.clone();
+
+                    let params: ForkParams = parse_params(&jrpc_id, request.params)?;
+                    let result = self
+                        .debug_service
+                        .fork(
+                            &active_session_data.namespace.account_id,
+                            &owned_worker_id,
+                            &params.target_worker_id,
+                            params.oplog_index_cut_off,
+                        )
+                        .await;
+                    to_json_rpc_result(&jrpc_id, result)
+                } else {
+                    Err(inactive_session_error(&jrpc_id))
+                }
             }
+
+            method => Err(method_not_found_error(&jrpc_id, method)),
         }
+    }
+
+    /// start forwarding notifications. May only be called once
+    fn start_worker_event_processor(&mut self, worker_event_receiver: WorkerEventReceiver) {
+        let notifications_sidechannel = self.notifications_sidechannel.clone();
+        let mut events_poll_receiver = self
+            .events_poll_receiver
+            .take()
+            .expect("events_poll_receiver was already taken");
+
+        let token = CancellationToken::new();
+        let cloned_token = token.clone();
+
+        let mut worker_event_stream = worker_event_receiver.to_stream();
+
+        // use a biased select to ensure the stream is empty before
+        tokio::spawn(async move {
+            loop {
+                select! {
+                    biased;
+                    _ = cloned_token.cancelled() => { break; }
+                    Some(event) = worker_event_stream.next() => {
+                        match event {
+                            Ok(event) => {
+                                if let Some(log_notifiation) = LogNotification::from_internal_worker_event(event) {
+                                    let params = serde_json::to_value(vec![log_notifiation]).expect("serializing message failed");
+
+                                    let notification = JsonRpcNotification { method: "emit-logs".to_string(), params };
+
+                                    let _ = notifications_sidechannel.send(OutgoingJsonRpcMessage::Notification(notification)).await;
+                                }
+                            }
+                            Err(BroadcastStreamRecvError::Lagged(number_of_missed_messages)) => {
+                                let value = LogsLaggedNotification { number_of_missed_messages };
+
+                                let params = serde_json::to_value(value).expect("serializing message failed");
+
+                                let notification = JsonRpcNotification { method: "notify-logs-lagged".to_string(), params };
+
+                                let _ = notifications_sidechannel.send(OutgoingJsonRpcMessage::Notification(notification)).await;
+                            },
+                        }
+                    }
+                    Some(sender) = events_poll_receiver.recv() => {
+                        sender.send(()).expect("Failed to send event poll response");
+                    }
+                }
+            }
+        });
+
+        // cancel spawned forwarding future when we are dropped
+        self.worker_events_processor_dropguard = Some(token.drop_guard());
+    }
 
-        method => Err(method_not_found_error(&jrpc_id, method)),
+    // Send a signal to the background worker that will only completed once the event stream contains no more messages.
+    // may only be called after start_worker_event_processor;
+    async fn ensure_pending_notifications_are_emitted(&self) {
+        let (sender, receiver) = oneshot::channel();
+        self.events_poll_sender.send(sender).unwrap();
+        receiver.await.unwrap();
     }
 }
 
-pub struct JrpcHandlerError {
-    pub jrpc_id: Id,
-    pub error_type: JrpcHandlerErrorType,
+#[derive(Debug)]
+struct JrpcHandlerError {
+    jrpc_id: Id,
+    error_type: JrpcHandlerErrorType,
 }
 
 impl JrpcHandlerError {
-    pub fn debug_service_error(jrpc_id: Id, error: DebugServiceError) -> Self {
+    fn debug_service_error(jrpc_id: Id, error: DebugServiceError) -> Self {
         JrpcHandlerError {
             jrpc_id,
             error_type: JrpcHandlerErrorType::DebugServiceError(error),
         }
     }
 
-    pub fn inactive_session(jrpc_id: Id) -> Self {
+    fn inactive_session(jrpc_id: Id) -> Self {
         JrpcHandlerError {
             jrpc_id,
             error_type: JrpcHandlerErrorType::InactiveSession {
@@ -154,14 +421,14 @@ impl JrpcHandlerError {
         }
     }
 
-    pub fn invalid_params(jrpc_id: Id, error: String) -> Self {
+    fn invalid_params(jrpc_id: Id, error: String) -> Self {
         JrpcHandlerError {
             jrpc_id,
             error_type: JrpcHandlerErrorType::InvalidParams { error },
         }
     }
 
-    pub fn method_not_found(jrpc_id: Id, method: &str) -> Self {
+    fn method_not_found(jrpc_id: Id, method: &str) -> Self {
         JrpcHandlerError {
             jrpc_id,
             error_type: JrpcHandlerErrorType::MethodNotFound {
@@ -169,17 +436,26 @@ impl JrpcHandlerError {
             },
         }
     }
+
+    fn session_already_connected(jrpc_id: Id, error: String) -> Self {
+        JrpcHandlerError {
+            jrpc_id,
+            error_type: JrpcHandlerErrorType::SessionAlreadyConnected { error },
+        }
+    }
 }
 
-pub enum JrpcHandlerErrorType {
+#[derive(Debug)]
+enum JrpcHandlerErrorType {
     DebugServiceError(DebugServiceError),
     InactiveSession { error: String },
     InvalidParams { error: String },
     MethodNotFound { method: String },
+    SessionAlreadyConnected { error: String },
 }
 
 impl JrpcHandlerError {
-    pub fn should_terminate_session(&self) -> bool {
+    fn should_terminate_session(&self) -> bool {
         matches!(
             self.error_type,
             JrpcHandlerErrorType::DebugServiceError(DebugServiceError::Conflict { .. })
@@ -187,12 +463,12 @@ impl JrpcHandlerError {
         )
     }
 
-    pub fn to_jrpc_response(&self) -> JsonRpcResponse {
+    fn to_jrpc_response(&self) -> JsonRpcResponse {
         match &self.error_type {
             JrpcHandlerErrorType::DebugServiceError(e) => JsonRpcResponse::error(
                 self.jrpc_id.clone(),
                 JsonRpcError::new(
-                    JsonRpcErrorReason::ApplicationError(-32000),
+                    JsonRpcErrorReason::ApplicationError(-1),
                     e.to_string(),
                     Value::Null,
                 ),
@@ -200,7 +476,7 @@ impl JrpcHandlerError {
             JrpcHandlerErrorType::InactiveSession { error } => JsonRpcResponse::error(
                 self.jrpc_id.clone(),
                 JsonRpcError::new(
-                    JsonRpcErrorReason::ApplicationError(-32003),
+                    JsonRpcErrorReason::ApplicationError(1000),
                     error.to_string(),
                     Value::Null,
                 ),
@@ -221,6 +497,14 @@ impl JrpcHandlerError {
                     Value::Null,
                 ),
             ),
+            JrpcHandlerErrorType::SessionAlreadyConnected { error } => JsonRpcResponse::error(
+                self.jrpc_id.clone(),
+                JsonRpcError::new(
+                    JsonRpcErrorReason::ApplicationError(1001),
+                    error.to_string(),
+                    Value::Null,
+                ),
+            ),
         }
     }
 }
@@ -235,6 +519,9 @@ impl Display for JrpcHandlerError {
                 write!(f, "InactiveSessionError: {error}")
             }
             JrpcHandlerErrorType::InvalidParams { error } => write!(f, "JsonRpcError: {error}"),
+            JrpcHandlerErrorType::SessionAlreadyConnected { error } => {
+                write!(f, "SessionAlreadyConnected: {error}")
+            }
             JrpcHandlerErrorType::MethodNotFound { method } => {
                 write!(f, "MethodNotFound: {method}")
             }
@@ -242,12 +529,10 @@ impl Display for JrpcHandlerError {
     }
 }
 
-pub type JsonRpcResult = Result<JsonRpcResponse, JrpcHandlerError>;
-
-pub fn to_json_rpc_result<T: serde::Serialize>(
+fn to_json_rpc_result<T: serde::Serialize>(
     jrpc_id: &Id,
     result: Result<T, DebugServiceError>,
-) -> JsonRpcResult {
+) -> Result<JsonRpcResponse, JrpcHandlerError> {
     result
         .map(|result| JsonRpcResponse::success(jrpc_id.clone(), result))
         .map_err(|e| JrpcHandlerError::debug_service_error(jrpc_id.clone(), e))
@@ -265,6 +550,41 @@ fn inactive_session_error(jrpc_id: &Id) -> JrpcHandlerError {
     JrpcHandlerError::inactive_session(jrpc_id.clone())
 }
 
-pub fn method_not_found_error(id: &Id, method: &str) -> JrpcHandlerError {
+fn method_not_found_error(id: &Id, method: &str) -> JrpcHandlerError {
     JrpcHandlerError::method_not_found(id.clone(), method)
 }
+
+#[derive(Clone, Debug)]
+struct JsonRpcNotification {
+    pub method: String,
+    pub params: Value,
+}
+
+impl Serialize for JsonRpcNotification {
+    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
+    where
+        S: serde::Serializer,
+    {
+        #[derive(Serialize)]
+        struct Helper<'a> {
+            jsonrpc: &'static str,
+            method: &'a str,
+            params: &'a Value,
+        }
+
+        Helper {
+            jsonrpc: "2.0",
+            method: &self.method,
+            params: &self.params,
+        }
+        .serialize(serializer)
+    }
+}
+
+#[derive(Debug)]
+enum OutgoingJsonRpcMessage {
+    Response(JsonRpcResponse),
+    Notification(JsonRpcNotification),
+    Error(JrpcHandlerError),
+    Close,
+}
diff --git a/golem-debugging-service/src/lib.rs b/golem-debugging-service/src/lib.rs
index 4d0be583..080abe5b 100644
--- a/golem-debugging-service/src/lib.rs
+++ b/golem-debugging-service/src/lib.rs
@@ -35,8 +35,9 @@ use async_trait::async_trait;
 use golem_service_base::clients::auth::AuthService as BaseAuthService;
 use golem_service_base::storage::blob::BlobStorage;
 use golem_worker_executor::durable_host::DurableWorkerCtx;
-use golem_worker_executor::preview2::{golem_api_1_x, golem_durability};
+use golem_worker_executor::preview2::{golem_agent, golem_api_1_x, golem_durability};
 use golem_worker_executor::services::active_workers::ActiveWorkers;
+use golem_worker_executor::services::agent_types::AgentTypesService;
 use golem_worker_executor::services::blob_store::BlobStoreService;
 use golem_worker_executor::services::component::ComponentService;
 use golem_worker_executor::services::events::Events;
@@ -46,6 +47,7 @@ use golem_worker_executor::services::key_value::KeyValueService;
 use golem_worker_executor::services::oplog::plugin::OplogProcessorPlugin;
 use golem_worker_executor::services::oplog::OplogService;
 use golem_worker_executor::services::plugins::{Plugins, PluginsObservations};
+use golem_worker_executor::services::projects::ProjectService;
 use golem_worker_executor::services::promise::PromiseService;
 use golem_worker_executor::services::rpc::{DirectWorkerInvocationRpc, RemoteInvocationRpc};
 use golem_worker_executor::services::scheduler::SchedulerService;
@@ -96,14 +98,15 @@ impl Bootstrap<DebugContext> for ServerBootstrap {
         golem_config: &GolemConfig,
         blob_storage: Arc<dyn BlobStorage>,
         plugins: Arc<dyn PluginsObservations>,
+        project_service: Arc<dyn ProjectService>,
     ) -> Arc<dyn ComponentService> {
         golem_worker_executor::services::component::configured(
             &golem_config.component_service,
-            &golem_config.project_service,
             &golem_config.component_cache,
             &golem_config.compiled_component_service,
             blob_storage,
             plugins,
+            project_service,
         )
     }
 
@@ -150,6 +153,8 @@ impl Bootstrap<DebugContext> for ServerBootstrap {
         file_loader: Arc<FileLoader>,
         plugins: Arc<dyn Plugins>,
         oplog_processor_plugin: Arc<dyn OplogProcessorPlugin>,
+        project_service: Arc<dyn ProjectService>,
+        agent_types_service: Arc<dyn AgentTypesService>,
     ) -> anyhow::Result<All<DebugContext>> {
         let remote_cloud_service_config = self.debug_config.cloud_service.clone();
 
@@ -201,6 +206,8 @@ impl Bootstrap<DebugContext> for ServerBootstrap {
             plugins.clone(),
             oplog_processor_plugin.clone(),
             resource_limits.clone(),
+            project_service.clone(),
+            agent_types_service.clone(),
             addition_deps.clone(),
         ));
 
@@ -233,11 +240,14 @@ impl Bootstrap<DebugContext> for ServerBootstrap {
             plugins.clone(),
             oplog_processor_plugin.clone(),
             resource_limits.clone(),
+            project_service.clone(),
+            agent_types_service.clone(),
             addition_deps.clone(),
         ));
 
         Ok(All::new(
             active_workers,
+            agent_types_service,
             engine,
             linker,
             runtime.clone(),
@@ -263,6 +273,7 @@ impl Bootstrap<DebugContext> for ServerBootstrap {
             plugins.clone(),
             oplog_processor_plugin.clone(),
             resource_limits,
+            project_service.clone(),
             addition_deps,
         ))
     }
@@ -276,7 +287,7 @@ impl Bootstrap<DebugContext> for ServerBootstrap {
         golem_config: GolemConfig,
         prometheus_registry: Registry,
         runtime: Handle,
-        join_set: &mut JoinSet<Result<(), anyhow::Error>>,
+        join_set: &mut JoinSet<Result<(), Error>>,
     ) -> anyhow::Result<RunDetails> {
         run_debug_worker_executor(
             self,
@@ -296,7 +307,7 @@ pub async fn run_debug_worker_executor<T: Bootstrap<DebugContext> + ?Sized>(
     cors_origin_regex: &str,
     prometheus_registry: Registry,
     runtime: Handle,
-    join_set: &mut JoinSet<Result<(), anyhow::Error>>,
+    join_set: &mut JoinSet<Result<(), Error>>,
 ) -> anyhow::Result<RunDetails> {
     debug!("Initializing debug worker executor");
 
@@ -347,6 +358,7 @@ pub fn create_debug_wasmtime_linker(engine: &Engine) -> anyhow::Result<Linker<De
     golem_api_1_x::oplog::add_to_linker_get_host(&mut linker, get_durable_ctx)?;
     golem_api_1_x::context::add_to_linker_get_host(&mut linker, get_durable_ctx)?;
     golem_durability::durability::add_to_linker_get_host(&mut linker, get_durable_ctx)?;
+    golem_agent::host::add_to_linker_get_host(&mut linker, get_durable_ctx)?;
     golem_wasm_rpc::golem_rpc_0_2_x::types::add_to_linker_get_host(&mut linker, get_durable_ctx)?;
     Ok(linker)
 }
@@ -356,8 +368,8 @@ async fn start_http_server(
     http_port: u16,
     cors_origin_regex: &str,
     prometheus_registry: &Registry,
-    join_set: &mut JoinSet<Result<(), anyhow::Error>>,
-) -> Result<u16, anyhow::Error> {
+    join_set: &mut JoinSet<Result<(), Error>>,
+) -> Result<u16, Error> {
     let open_api_service = api::make_open_api_service(services);
 
     let ui = open_api_service.swagger_ui();
diff --git a/golem-debugging-service/src/model/params.rs b/golem-debugging-service/src/model/params.rs
index ba9be7ff..bf49dbf2 100644
--- a/golem-debugging-service/src/model/params.rs
+++ b/golem-debugging-service/src/model/params.rs
@@ -14,7 +14,8 @@
 
 use golem_common::model::oplog::OplogIndex;
 use golem_common::model::public_oplog::PublicOplogEntry;
-use golem_common::model::WorkerId;
+use golem_common::model::{LogLevel, Timestamp, WorkerId};
+use golem_worker_executor::model::event::InternalWorkerEvent;
 use serde::{Deserialize, Serialize};
 
 #[derive(Serialize, Deserialize, Debug)]
@@ -27,7 +28,6 @@ pub struct PlaybackParams {
     pub target_index: OplogIndex,
     pub overrides: Option<Vec<PlaybackOverride>>,
     pub ensure_invocation_boundary: Option<bool>,
-    pub time_out_in_seconds: Option<u64>,
 }
 
 #[derive(Serialize, Deserialize, Debug, Clone)]
@@ -40,7 +40,6 @@ pub struct PlaybackOverride {
 pub struct RewindParams {
     pub target_index: OplogIndex,
     pub ensure_invocation_boundary: Option<bool>,
-    pub time_out_in_seconds: Option<u64>,
 }
 
 #[derive(Serialize, Deserialize, Debug)]
@@ -52,7 +51,6 @@ pub struct ForkParams {
 #[derive(Serialize, Deserialize, Debug)]
 pub struct ConnectResult {
     pub worker_id: WorkerId,
-    pub success: bool,
     pub message: String,
 }
 
@@ -60,15 +58,14 @@ pub struct ConnectResult {
 pub struct PlaybackResult {
     pub worker_id: WorkerId,
     pub current_index: OplogIndex,
-    pub success: bool,
     pub message: String,
+    pub incremental_playback: bool,
 }
 
 #[derive(Serialize, Deserialize, Debug)]
 pub struct RewindResult {
     pub worker_id: WorkerId,
     pub current_index: OplogIndex,
-    pub success: bool,
     pub message: String,
 }
 
@@ -76,6 +73,57 @@ pub struct RewindResult {
 pub struct ForkResult {
     pub source_worker_id: WorkerId,
     pub target_worker_id: WorkerId,
-    pub success: bool,
     pub message: String,
 }
+
+#[derive(Clone, Serialize, Deserialize)]
+#[serde(tag = "type")]
+pub enum LogNotification {
+    StdOut {
+        timestamp: Timestamp,
+        message: String,
+    },
+    StdErr {
+        timestamp: Timestamp,
+        message: String,
+    },
+    Log {
+        timestamp: Timestamp,
+        level: LogLevel,
+        context: String,
+        message: String,
+    },
+}
+
+impl LogNotification {
+    pub fn from_internal_worker_event(event: InternalWorkerEvent) -> Option<Self> {
+        match event {
+            InternalWorkerEvent::InvocationStart { .. } => None,
+            InternalWorkerEvent::InvocationFinished { .. } => None,
+            InternalWorkerEvent::StdOut { timestamp, bytes } => Some(Self::StdOut {
+                timestamp,
+                message: String::from_utf8_lossy(&bytes).to_string(),
+            }),
+            InternalWorkerEvent::StdErr { timestamp, bytes } => Some(Self::StdErr {
+                timestamp,
+                message: String::from_utf8_lossy(&bytes).to_string(),
+            }),
+            InternalWorkerEvent::Log {
+                timestamp,
+                level,
+                context,
+                message,
+            } => Some(Self::Log {
+                timestamp,
+                level,
+                context,
+                message,
+            }),
+        }
+    }
+}
+
+#[derive(Clone, Serialize, Deserialize)]
+pub struct LogsLaggedNotification {
+    pub number_of_missed_messages: u64,
+}
diff --git a/golem-debugging-service/src/oplog/debug_oplog.rs b/golem-debugging-service/src/oplog/debug_oplog.rs
index 2762f093..6a72a2e7 100644
--- a/golem-debugging-service/src/oplog/debug_oplog.rs
+++ b/golem-debugging-service/src/oplog/debug_oplog.rs
@@ -129,9 +129,8 @@ impl Oplog for DebugOplog {
         self.inner.length().await
     }
 
-    async fn upload_payload(&self, _data: &[u8]) -> Result<OplogPayload, String> {
-        // in a debugging session we don't need to upload anything
-        Err("Workers in debug cannot upload any new data to oplog".to_string())
+    async fn upload_payload(&self, data: &[u8]) -> Result<OplogPayload, String> {
+        Ok(OplogPayload::Inline(data.to_vec()))
     }
 
     async fn download_payload(&self, payload: &OplogPayload) -> Result<Bytes, String> {
diff --git a/golem-debugging-service/src/oplog/debug_oplog_service.rs b/golem-debugging-service/src/oplog/debug_oplog_service.rs
index e80234dd..abfc9653 100644
--- a/golem-debugging-service/src/oplog/debug_oplog_service.rs
+++ b/golem-debugging-service/src/oplog/debug_oplog_service.rs
@@ -16,8 +16,9 @@ use crate::debug_session::{DebugSessionId, DebugSessions};
 use crate::oplog::debug_oplog_constructor::CreateDebugOplogConstructor;
 use async_trait::async_trait;
 use bytes::Bytes;
+use golem_common::base_model::ProjectId;
 use golem_common::model::oplog::{OplogEntry, OplogIndex, OplogPayload};
-use golem_common::model::{AccountId, ComponentId, OwnedWorkerId, ScanCursor, WorkerMetadata};
+use golem_common::model::{ComponentId, OwnedWorkerId, ScanCursor, WorkerMetadata};
 use golem_service_base::error::worker_executor::WorkerExecutorError;
 use golem_worker_executor::model::ExecutionStatus;
 use golem_worker_executor::services::oplog::{OpenOplogs, Oplog, OplogService};
@@ -51,25 +52,12 @@ impl Debug for DebugOplogService {
 impl OplogService for DebugOplogService {
     async fn create(
         &self,
-        owned_worker_id: &OwnedWorkerId,
-        initial_entry: OplogEntry,
-        initial_worker_metadata: WorkerMetadata,
-        execution_status: Arc<RwLock<ExecutionStatus>>,
-    ) -> Arc<dyn Oplog + 'static> {
-        self.oplogs
-            .get_or_open(
-                &owned_worker_id.worker_id,
-                CreateDebugOplogConstructor::new(
-                    owned_worker_id.clone(),
-                    Some(initial_entry),
-                    OplogIndex::INITIAL,
-                    self.inner.clone(),
-                    self.debug_session.clone(),
-                    execution_status,
-                    initial_worker_metadata,
-                ),
-            )
-            .await
+        _owned_worker_id: &OwnedWorkerId,
+        _initial_entry: OplogEntry,
+        _initial_worker_metadata: WorkerMetadata,
+        _execution_status: Arc<RwLock<ExecutionStatus>>,
+    ) -> Arc<dyn Oplog> {
+        panic!("Cannot create a new oplog when debugging")
     }
 
     async fn open(
@@ -78,7 +66,7 @@ impl OplogService for DebugOplogService {
         last_oplog_index: OplogIndex,
         initial_worker_metadata: WorkerMetadata,
         execution_status: Arc<RwLock<ExecutionStatus>>,
-    ) -> Arc<dyn Oplog + 'static> {
+    ) -> Arc<dyn Oplog> {
         self.oplogs
             .get_or_open(
                 &owned_worker_id.worker_id,
@@ -135,13 +123,13 @@ impl OplogService for DebugOplogService {
 
     async fn scan_for_component(
         &self,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         component_id: &ComponentId,
         cursor: ScanCursor,
         count: u64,
     ) -> Result<(ScanCursor, Vec<OwnedWorkerId>), WorkerExecutorError> {
         self.inner
-            .scan_for_component(account_id, component_id, cursor, count)
+            .scan_for_component(project_id, component_id, cursor, count)
             .await
     }
 
diff --git a/golem-debugging-service/src/services/debug_service.rs b/golem-debugging-service/src/services/debug_service.rs
index 44f8db1e..974ba5aa 100644
--- a/golem-debugging-service/src/services/debug_service.rs
+++ b/golem-debugging-service/src/services/debug_service.rs
@@ -14,27 +14,30 @@
 
 use crate::auth::AuthService;
 use crate::debug_context::DebugContext;
-use crate::debug_session::{ActiveSession, PlaybackOverridesInternal};
+use crate::debug_session::PlaybackOverridesInternal;
 use crate::debug_session::{DebugSessionData, DebugSessionId, DebugSessions};
 use crate::model::params::*;
 use async_trait::async_trait;
 use axum_jrpc::error::{JsonRpcError, JsonRpcErrorReason};
 use gethostname::gethostname;
-use golem_common::model::auth::AuthCtx;
+use golem_common::base_model::ProjectId;
 use golem_common::model::auth::ProjectAction;
+use golem_common::model::auth::{AuthCtx, Namespace};
+use golem_common::model::invocation_context::InvocationContextStack;
 use golem_common::model::oplog::{OplogEntry, OplogIndex};
 use golem_common::model::{AccountId, OwnedWorkerId, WorkerId, WorkerMetadata};
 use golem_service_base::error::worker_executor::InterruptKind;
 use golem_worker_executor::services::oplog::Oplog;
+use golem_worker_executor::services::worker_event::WorkerEventReceiver;
 use golem_worker_executor::services::{
     All, HasConfig, HasExtraDeps, HasOplog, HasShardManagerService, HasShardService,
     HasWorkerForkService, HasWorkerService,
 };
 use golem_worker_executor::worker::Worker;
+use log::debug;
 use serde_json::Value;
 use std::fmt::Display;
 use std::sync::Arc;
-use std::time::Duration;
 use tracing::{error, info};
 
 #[async_trait]
@@ -42,40 +45,40 @@ pub trait DebugService: Send + Sync {
     async fn connect(
         &self,
         authentication_context: &AuthCtx,
-        source_worker_id: WorkerId,
-        active_session: Arc<ActiveSession>,
-    ) -> Result<ConnectResult, DebugServiceError>;
+        source_worker_id: &WorkerId,
+    ) -> Result<(ConnectResult, OwnedWorkerId, Namespace, WorkerEventReceiver), DebugServiceError>;
 
     async fn playback(
         &self,
-        owned_worker_id: OwnedWorkerId,
+        owned_worker_id: &OwnedWorkerId,
+        account_id: &AccountId,
         target_index: OplogIndex,
         overrides: Option<Vec<PlaybackOverride>>,
         ensure_invocation_boundary: bool,
-        wait_time: Duration,
     ) -> Result<PlaybackResult, DebugServiceError>;
 
     async fn rewind(
         &self,
-        owned_worker_id: OwnedWorkerId,
+        owned_worker_id: &OwnedWorkerId,
+        account_id: &AccountId,
         target_index: OplogIndex,
         ensure_invocation_boundary: bool,
-        timeout: Duration,
     ) -> Result<RewindResult, DebugServiceError>;
 
     async fn fork(
         &self,
-        source_owned_worker_id: OwnedWorkerId,
-        target_worker_id: WorkerId,
+        account_id: &AccountId,
+        source_owned_worker_id: &OwnedWorkerId,
+        target_worker_id: &WorkerId,
         oplog_index_cut_off: OplogIndex,
     ) -> Result<ForkResult, DebugServiceError>;
 
     async fn current_oplog_index(
         &self,
-        worker_id: OwnedWorkerId,
+        worker_id: &OwnedWorkerId,
     ) -> Result<OplogIndex, DebugServiceError>;
 
-    async fn terminate_session(&self, worker_id: OwnedWorkerId) -> Result<(), DebugServiceError>;
+    async fn terminate_session(&self, worker_id: &OwnedWorkerId) -> Result<(), DebugServiceError>;
 }
 
 #[derive(Clone, Debug)]
@@ -164,8 +167,8 @@ impl DebugServiceError {
 }
 
 pub struct DebugServiceDefault {
-    worker_auth_service: Arc<dyn AuthService + Sync + Send>,
-    debug_session: Arc<dyn DebugSessions + Sync + Send>,
+    worker_auth_service: Arc<dyn AuthService>,
+    debug_session: Arc<dyn DebugSessions>,
     all: All<DebugContext>,
 }
 
@@ -187,9 +190,10 @@ impl DebugServiceDefault {
     async fn connect_worker(
         &self,
         worker_id: WorkerId,
-        account_id: AccountId,
-    ) -> Result<WorkerMetadata, DebugServiceError> {
-        let owned_worker_id = OwnedWorkerId::new(&account_id, &worker_id);
+        account_id: &AccountId,
+        project_id: &ProjectId,
+    ) -> Result<(WorkerMetadata, WorkerEventReceiver), DebugServiceError> {
+        let owned_worker_id = OwnedWorkerId::new(project_id, &worker_id);
 
         // This get will only look at the oplogs to see if a worker presumably exists in the real executor.
         // This is only used to get the existing metadata that was/is running in the real executor
@@ -219,17 +223,21 @@ impl DebugServiceDefault {
         if let Some(existing_metadata) = existing_metadata {
             let worker_args = existing_metadata.args;
             let worker_env = existing_metadata.env;
+            let worker_wasi_config_vars = existing_metadata.wasi_config_vars;
             let component_version = existing_metadata.last_known_status.component_version;
 
             let parent = existing_metadata.parent;
 
             let worker = Worker::get_or_create_suspended(
                 &self.all,
+                account_id,
                 &owned_worker_id,
                 Some(worker_args),
                 Some(worker_env),
+                Some(worker_wasi_config_vars),
                 Some(component_version),
                 parent,
+                &InvocationContextStack::fresh(),
             )
             .await
             .map_err(|e| DebugServiceError::internal(e.to_string(), Some(worker_id.clone())))?;
@@ -238,7 +246,9 @@ impl DebugServiceDefault {
                 .get_metadata()
                 .map_err(|e| DebugServiceError::internal(e.to_string(), Some(worker_id.clone())))?;
 
-            Ok(metadata)
+            let receiver = worker.event_service().receiver();
+
+            Ok((metadata, receiver))
         } else {
             Err(DebugServiceError::internal(
                 "Worker doesn't exist in live/real worker executor for it to connect to"
@@ -248,227 +258,12 @@ impl DebugServiceDefault {
         }
     }
 
-    async fn rewind(
-        &self,
-        owned_worker_id: &OwnedWorkerId,
-        target_index: &OplogIndex,
-        ensure_invocation_boundary: bool,
-        wait_time: Duration,
-    ) -> Result<RewindResult, DebugServiceError> {
-        let debug_session_id = DebugSessionId::new(owned_worker_id.clone());
-
-        let debug_session_data =
-            self.debug_session
-                .get(&debug_session_id)
-                .await
-                .ok_or(DebugServiceError::internal(
-                    "No debug session found. Rewind can be called ".to_string(),
-                    Some(owned_worker_id.worker_id.clone()),
-                ))?;
-
-        if let Some(current_oplog_index) = debug_session_data.target_oplog_index {
-            let worker = Worker::get_or_create_suspended(
-                &self.all,
-                owned_worker_id,
-                debug_session_data
-                    .worker_metadata
-                    .as_ref()
-                    .map(|m| m.args.clone()),
-                debug_session_data
-                    .worker_metadata
-                    .as_ref()
-                    .map(|m| m.env.clone()),
-                debug_session_data
-                    .worker_metadata
-                    .as_ref()
-                    .map(|m| m.last_known_status.component_version),
-                debug_session_data
-                    .worker_metadata
-                    .as_ref()
-                    .and_then(|m| m.parent.clone()),
-            )
-            .await
-            .map_err(|e| {
-                DebugServiceError::internal(e.to_string(), Some(owned_worker_id.worker_id.clone()))
-            })?;
-
-            let new_target_index = if ensure_invocation_boundary {
-                Self::get_target_oplog_index_at_invocation_boundary(
-                    worker.oplog(),
-                    *target_index,
-                    current_oplog_index,
-                )
-                .await
-                .map_err(|e| {
-                    DebugServiceError::internal(e, Some(owned_worker_id.worker_id.clone()))
-                })?
-            } else {
-                *target_index
-            };
-
-            if new_target_index > current_oplog_index {
-                return Err(DebugServiceError::validation_failed(
-                    vec![
-                        format!(
-                            "Target oplog index {} (corresponding to an invocation boundary) for rewind is greater than the existing target oplog index {}",
-                            target_index,
-                            current_oplog_index
-                        )],
-                        Some(owned_worker_id.worker_id.clone()))
-                 );
-            };
-
-            self.debug_session
-                .update(debug_session_id.clone(), new_target_index, None)
-                .await;
-
-            self.debug_session
-                .update_oplog_index(debug_session_id.clone(), OplogIndex::NONE)
-                .await;
-
-            // we restart regardless of the current status of the worker such that it restarts
-            worker.set_interrupting(InterruptKind::Restart).await;
-
-            tokio::time::sleep(wait_time).await;
-
-            let last_index = self
-                .debug_session
-                .get(&debug_session_id)
-                .await
-                .map(|d| d.current_oplog_index)
-                .unwrap_or(OplogIndex::NONE);
-
-            Ok(RewindResult {
-                worker_id: owned_worker_id.worker_id.clone(),
-                current_index: last_index,
-                success: true,
-                message: format!("Rewinding the worker to index {target_index}"),
-            })
-        } else {
-            // If this is the first step in a debugging session, then rewind is more or less
-            // playback to that index
-            self.playback(
-                owned_worker_id.clone(),
-                *target_index,
-                None,
-                ensure_invocation_boundary,
-                wait_time,
-            )
-            .await
-            .map(|result| RewindResult {
-                worker_id: owned_worker_id.worker_id.clone(),
-                current_index: result.current_index,
-                success: true,
-                message: format!("Rewinding the worker to index {target_index}"),
-            })
-        }
-    }
-
-    async fn resume_replay_with_target_index(
-        &self,
-        worker_id: &WorkerId,
-        account_id: &AccountId,
-        existing_target_oplog_index: Option<OplogIndex>,
-        target_index: OplogIndex,
-        playback_overrides: Option<Vec<PlaybackOverride>>,
-        ensure_invocation_boundary: bool,
-        timeout: Duration,
-    ) -> Result<OplogIndex, DebugServiceError> {
-        let owned_worker_id = OwnedWorkerId::new(account_id, worker_id);
-
-        let debug_session_id = DebugSessionId::new(owned_worker_id.clone());
-
-        let session_data =
-            self.debug_session
-                .get(&debug_session_id)
-                .await
-                .ok_or(DebugServiceError::internal(
-                    "No debug session found".to_string(),
-                    Some(worker_id.clone()),
-                ))?;
-
-        if let Some(existing_target_index) = existing_target_oplog_index {
-            if target_index < existing_target_index {
-                return Err(DebugServiceError::internal(
-                    format!(
-                        "Target oplog index {target_index} for playback is less than the existing target oplog index {existing_target_index}. Use rewind instead"
-                    ),
-                    Some(debug_session_id.worker_id()),
-                ));
-            }
-        }
-
-        if let Some(worker_metadata) = session_data.worker_metadata {
-            // At this point, the worker do exist after the connect
-            // however, the debug session is updated with a different target index
-            // allowing replaying to (potentially) stop at this index
-            let worker = Worker::get_or_create_suspended(
-                &self.all,
-                &OwnedWorkerId::new(account_id, worker_id),
-                Some(worker_metadata.args.clone()),
-                Some(worker_metadata.env.clone()),
-                Some(worker_metadata.last_known_status.component_version),
-                worker_metadata.parent.clone(),
-            )
-            .await
-            .map_err(|e| DebugServiceError::internal(e.to_string(), Some(worker_id.clone())))?;
-
-            // We select a new target index based on the given target index
-            // such that it is always in an invocation boundary
-            let new_target_index = if ensure_invocation_boundary {
-                Self::target_index_at_invocation_boundary(worker_id, &worker, target_index).await?
-            } else {
-                target_index
-            };
-
-            let mut playback_overrides_validated = None;
-
-            if let Some(overrides) = playback_overrides {
-                playback_overrides_validated =
-                    Some(Self::validate_playback_overrides(worker_id.clone(), overrides).await?);
-            }
-
-            // We update the session with the new target index
-            // before starting the worker
-            self.debug_session
-                .update(
-                    debug_session_id.clone(),
-                    new_target_index,
-                    playback_overrides_validated,
-                )
-                .await;
-
-            if existing_target_oplog_index.is_some() {
-                worker.stop().await;
-            }
-
-            Worker::start_if_needed(worker.clone())
-                .await
-                .map_err(|e| DebugServiceError::internal(e.to_string(), Some(worker_id.clone())))?;
-
-            tokio::time::sleep(timeout).await;
-
-            let last_index = self
-                .debug_session
-                .get(&debug_session_id)
-                .await
-                .map(|d| d.current_oplog_index)
-                .unwrap_or(OplogIndex::INITIAL);
-
-            Ok(last_index)
-        } else {
-            Err(DebugServiceError::internal(
-                "No initial metadata found".to_string(),
-                Some(worker_id.clone()),
-            ))
-        }
-    }
-
     pub async fn validate_playback_overrides(
         worker_id: WorkerId,
+        current_index: OplogIndex,
         overrides: Vec<PlaybackOverride>,
     ) -> Result<PlaybackOverridesInternal, DebugServiceError> {
-        PlaybackOverridesInternal::from_playback_override(overrides).map_err(|err| {
+        PlaybackOverridesInternal::from_playback_override(overrides, current_index).map_err(|err| {
             DebugServiceError::ValidationFailed {
                 worker_id: Some(worker_id.clone()),
                 errors: vec![err],
@@ -482,7 +277,7 @@ impl DebugServiceDefault {
         target_oplog_index: OplogIndex,
     ) -> Result<OplogIndex, DebugServiceError> {
         // New target index to be calculated here
-        let oplog: Arc<dyn Oplog + Send + Sync> = worker.oplog();
+        let oplog: Arc<dyn Oplog> = worker.oplog();
 
         let original_current_oplog_index = oplog.current_oplog_index().await;
 
@@ -496,7 +291,7 @@ impl DebugServiceDefault {
     }
 
     pub async fn get_target_oplog_index_at_invocation_boundary(
-        oplog: Arc<dyn Oplog + Send + Sync>,
+        oplog: Arc<dyn Oplog>,
         target_oplog_index: OplogIndex,
         original_last_oplog_index: OplogIndex,
     ) -> Result<OplogIndex, String> {
@@ -531,9 +326,9 @@ impl DebugService for DebugServiceDefault {
     async fn connect(
         &self,
         auth_ctx: &AuthCtx,
-        worker_id: WorkerId,
-        active_session: Arc<ActiveSession>,
-    ) -> Result<ConnectResult, DebugServiceError> {
+        worker_id: &WorkerId,
+    ) -> Result<(ConnectResult, OwnedWorkerId, Namespace, WorkerEventReceiver), DebugServiceError>
+    {
         let namespace = self
             .worker_auth_service
             .is_authorized_by_component(
@@ -544,7 +339,7 @@ impl DebugService for DebugServiceDefault {
             .await
             .map_err(|e| DebugServiceError::unauthorized(format!("Unauthorized: {e}")))?;
 
-        let owned_worker_id = OwnedWorkerId::new(&namespace.account_id, &worker_id);
+        let owned_worker_id = OwnedWorkerId::new(&namespace.project_id, worker_id);
 
         let debug_session_id = DebugSessionId::new(owned_worker_id.clone());
 
@@ -555,21 +350,20 @@ impl DebugService for DebugServiceDefault {
             ));
         }
 
-        // Ensuring active session is set with the fundamental details of worker_id that is going to be debugged
-        active_session
-            .set_active_session(owned_worker_id.worker_id.clone(), namespace.clone())
-            .await;
-
         // This simply migrates the worker to the debug mode, but it doesn't start the worker
-        let metadata = self
-            .connect_worker(worker_id.clone(), namespace.account_id.clone())
+        let (worker_metadata, worker_event_receiver) = self
+            .connect_worker(
+                worker_id.clone(),
+                &namespace.account_id,
+                &namespace.project_id,
+            )
             .await?;
 
         self.debug_session
             .insert(
-                DebugSessionId::new(owned_worker_id),
+                debug_session_id,
                 DebugSessionData {
-                    worker_metadata: Some(metadata),
+                    worker_metadata,
                     target_oplog_index: None,
                     playback_overrides: PlaybackOverridesInternal::empty(),
                     current_oplog_index: OplogIndex::NONE,
@@ -577,82 +371,262 @@ impl DebugService for DebugServiceDefault {
             )
             .await;
 
-        Ok(ConnectResult {
+        let connect_result = ConnectResult {
             worker_id: worker_id.clone(),
-            success: true,
             message: format!("Worker {worker_id} connected to namespace {namespace}"),
-        })
+        };
+
+        Ok((
+            connect_result,
+            owned_worker_id,
+            namespace,
+            worker_event_receiver,
+        ))
     }
 
     async fn playback(
         &self,
-        owned_worker_id: OwnedWorkerId,
+        owned_worker_id: &OwnedWorkerId,
+        account_id: &AccountId,
         target_index: OplogIndex,
-        overrides: Option<Vec<PlaybackOverride>>,
+        playback_overrides: Option<Vec<PlaybackOverride>>,
         ensure_invocation_boundary: bool,
-        timeout: Duration,
     ) -> Result<PlaybackResult, DebugServiceError> {
+        if !target_index.is_defined() {
+            return Err(DebugServiceError::ValidationFailed {
+                worker_id: Some(owned_worker_id.worker_id.clone()),
+                errors: vec![format!(
+                    "Trying to rewind to an invalid oplog index {target_index}"
+                )],
+            });
+        }
+
         let debug_session_id = DebugSessionId::new(owned_worker_id.clone());
+        let worker_id = owned_worker_id.worker_id.clone();
 
-        let existing_session_data =
+        let session_data =
             self.debug_session
                 .get(&debug_session_id)
                 .await
                 .ok_or(DebugServiceError::internal(
                     "No debug session found".to_string(),
-                    Some(owned_worker_id.worker_id.clone()),
+                    Some(worker_id.clone()),
                 ))?;
 
-        let existing_target_index = existing_session_data.target_oplog_index;
+        let current_oplog_index = session_data.current_oplog_index;
+
+        debug!("Playback from current oplog index {current_oplog_index}");
+
+        // At this point, the worker do exist after the connect
+        // however, the debug session is updated with a different target index
+        // allowing replaying to (potentially) stop at this index
+        let worker = Worker::get_or_create_suspended(
+            &self.all,
+            account_id,
+            owned_worker_id,
+            Some(session_data.worker_metadata.args.clone()),
+            Some(session_data.worker_metadata.env.clone()),
+            Some(session_data.worker_metadata.wasi_config_vars.clone()),
+            Some(
+                session_data
+                    .worker_metadata
+                    .last_known_status
+                    .component_version,
+            ),
+            session_data.worker_metadata.parent.clone(),
+            &InvocationContextStack::fresh(),
+        )
+        .await
+        .map_err(|e| DebugServiceError::internal(e.to_string(), Some(worker_id.clone())))?;
 
-        let stopped_at_index = self
-            .resume_replay_with_target_index(
-                &owned_worker_id.worker_id,
-                &owned_worker_id.account_id,
-                existing_target_index,
-                target_index,
-                overrides,
-                ensure_invocation_boundary,
-                timeout,
+        // We select a new target index based on the given target index
+        // such that it is always in an invocation boundary
+        let new_target_index = if ensure_invocation_boundary {
+            Self::target_index_at_invocation_boundary(&worker_id, &worker, target_index).await?
+        } else {
+            target_index
+        };
+
+        if new_target_index < current_oplog_index {
+            return Err(DebugServiceError::internal(
+                format!(
+                    "Target oplog index {target_index} for playback is less than the existing target oplog index {current_oplog_index}. Use rewind instead"
+                ),
+                Some(debug_session_id.worker_id()),
+            ));
+        }
+
+        let playback_overrides_validated = if let Some(overrides) = playback_overrides {
+            Some(
+                Self::validate_playback_overrides(
+                    worker_id.clone(),
+                    current_oplog_index,
+                    overrides,
+                )
+                .await?,
             )
-            .await?;
+        } else {
+            None
+        };
+
+        // We update the session with the new target index
+        // before starting the worker
+        self.debug_session
+            .update(
+                debug_session_id.clone(),
+                new_target_index,
+                playback_overrides_validated,
+            )
+            .await;
+
+        // this will fail if the worker is not currently running and do nothing.
+        // If this succeeded it means we continued from the previous oplog and only some of the log events are reemitted.
+        let incremental_playback = worker.resume_replay().await.is_ok();
+
+        // the worker was not running, we need to start it so it starts replaying
+        if !incremental_playback {
+            Worker::start_if_needed(worker.clone()).await.map_err(|e| {
+                DebugServiceError::internal(
+                    format!("Failed to start worker for resumption: {e}"),
+                    Some(worker_id.clone()),
+                )
+            })?;
+        }
+
+        // This might fail if we are replaying beyond the oplog index and trapping due to entering live mode, ignore.
+        let _ = worker.await_ready_to_process_commands().await;
+
+        let stopped_at_index = self
+            .debug_session
+            .get(&debug_session_id)
+            .await
+            .map(|d| d.current_oplog_index)
+            .unwrap_or(OplogIndex::INITIAL);
 
         Ok(PlaybackResult {
             worker_id: owned_worker_id.worker_id.clone(),
             current_index: stopped_at_index,
-            success: true,
+            incremental_playback,
             message: format!(
                 "Playback worker {} stopped at index {}",
-                owned_worker_id.worker_id, target_index
+                owned_worker_id.worker_id, stopped_at_index
             ),
         })
     }
 
     async fn rewind(
         &self,
-        owned_worker_id: OwnedWorkerId,
-        target_oplog_index: OplogIndex,
+        owned_worker_id: &OwnedWorkerId,
+        account_id: &AccountId,
+        target_index: OplogIndex,
         ensure_invocation_boundary: bool,
-        timeout: Duration,
     ) -> Result<RewindResult, DebugServiceError> {
+        if !target_index.is_defined() {
+            return Err(DebugServiceError::ValidationFailed {
+                worker_id: Some(owned_worker_id.worker_id.clone()),
+                errors: vec![format!(
+                    "Trying to rewind to an invalid oplog index {target_index}"
+                )],
+            });
+        }
+
         info!(
             "Rewinding worker {} to index {}",
-            owned_worker_id.worker_id, target_oplog_index
+            owned_worker_id.worker_id, target_index
         );
 
-        self.rewind(
-            &owned_worker_id,
-            &target_oplog_index,
-            ensure_invocation_boundary,
-            timeout,
+        let debug_session_id = DebugSessionId::new(owned_worker_id.clone());
+
+        let debug_session_data =
+            self.debug_session
+                .get(&debug_session_id)
+                .await
+                .ok_or(DebugServiceError::internal(
+                    "No debug session found. Rewind cannot be called ".to_string(),
+                    Some(owned_worker_id.worker_id.clone()),
+                ))?;
+
+        let current_oplog_index = debug_session_data.current_oplog_index;
+
+        let worker = Worker::get_or_create_suspended(
+            &self.all,
+            account_id,
+            owned_worker_id,
+            Some(debug_session_data.worker_metadata.args.clone()),
+            Some(debug_session_data.worker_metadata.env.clone()),
+            Some(debug_session_data.worker_metadata.wasi_config_vars.clone()),
+            Some(
+                debug_session_data
+                    .worker_metadata
+                    .last_known_status
+                    .component_version,
+            ),
+            debug_session_data.worker_metadata.parent.clone(),
+            &InvocationContextStack::fresh(),
         )
         .await
+        .map_err(|e| {
+            DebugServiceError::internal(e.to_string(), Some(owned_worker_id.worker_id.clone()))
+        })?;
+
+        let new_target_index = if ensure_invocation_boundary {
+            Self::get_target_oplog_index_at_invocation_boundary(
+                worker.oplog(),
+                target_index,
+                current_oplog_index,
+            )
+            .await
+            .map_err(|e| DebugServiceError::internal(e, Some(owned_worker_id.worker_id.clone())))?
+        } else {
+            target_index
+        };
+
+        if new_target_index >= current_oplog_index {
+            return Err(DebugServiceError::validation_failed(
+                vec![
+                    format!(
+                        "Target oplog index {} (corresponding to an invocation boundary) for rewind is greater than the existing target oplog index {}",
+                        target_index,
+                        current_oplog_index
+                    )],
+                    Some(owned_worker_id.worker_id.clone()))
+                );
+        };
+
+        self.debug_session
+            .update(debug_session_id.clone(), new_target_index, None)
+            .await;
+
+        self.debug_session
+            .update_oplog_index(debug_session_id.clone(), OplogIndex::NONE)
+            .await;
+
+        // we restart regardless of the current status of the worker such that it restarts
+        if let Some(mut receiver) = worker.set_interrupting(InterruptKind::Restart).await {
+            let _ = receiver.recv().await;
+        };
+
+        let _ = worker.await_ready_to_process_commands().await;
+
+        let stopped_at_index = self
+            .debug_session
+            .get(&debug_session_id)
+            .await
+            .map(|d| d.current_oplog_index)
+            .unwrap_or(OplogIndex::NONE);
+
+        Ok(RewindResult {
+            worker_id: owned_worker_id.worker_id.clone(),
+            current_index: stopped_at_index,
+            message: format!("Rewinding the worker to index {target_index}"),
+        })
     }
 
     async fn fork(
         &self,
-        source_worker_id: OwnedWorkerId,
-        target_worker_id: WorkerId,
+        account_id: &AccountId,
+        source_worker_id: &OwnedWorkerId,
+        target_worker_id: &WorkerId,
         oplog_index_cut_off: OplogIndex,
     ) -> Result<ForkResult, DebugServiceError> {
         info!(
@@ -665,7 +639,12 @@ impl DebugService for DebugServiceDefault {
         // debugging executor
         self.all
             .worker_fork_service()
-            .fork(&source_worker_id, &target_worker_id, oplog_index_cut_off)
+            .fork(
+                account_id,
+                source_worker_id,
+                target_worker_id,
+                oplog_index_cut_off,
+            )
             .await
             .map_err(|e| {
                 DebugServiceError::internal(e.to_string(), Some(source_worker_id.worker_id.clone()))
@@ -674,14 +653,13 @@ impl DebugService for DebugServiceDefault {
         Ok(ForkResult {
             source_worker_id: source_worker_id.worker_id.clone(),
             target_worker_id: target_worker_id.clone(),
-            success: true,
             message: format!("Forked worker {source_worker_id} to new worker {target_worker_id}"),
         })
     }
 
     async fn current_oplog_index(
         &self,
-        worker_id: OwnedWorkerId,
+        worker_id: &OwnedWorkerId,
     ) -> Result<OplogIndex, DebugServiceError> {
         let debug_session_id = DebugSessionId::new(worker_id.clone());
 
@@ -695,14 +673,14 @@ impl DebugService for DebugServiceDefault {
             Some(index) => Ok(index),
             None => Err(DebugServiceError::internal(
                 "No debug session found".to_string(),
-                Some(worker_id.worker_id),
+                Some(worker_id.worker_id()),
             )),
         }
     }
 
     async fn terminate_session(
         &self,
-        owned_worker_id: OwnedWorkerId,
+        owned_worker_id: &OwnedWorkerId,
     ) -> Result<(), DebugServiceError> {
         let debug_session_id = DebugSessionId::new(owned_worker_id.clone());
 
@@ -711,7 +689,7 @@ impl DebugService for DebugServiceDefault {
             .await
             .ok_or(DebugServiceError::internal(
                 "No debug session found".to_string(),
-                Some(owned_worker_id.worker_id),
+                Some(owned_worker_id.worker_id()),
             ))?;
 
         Ok(())
@@ -780,21 +758,6 @@ mod tests {
 
     #[async_trait]
     impl Oplog for TestOplog {
-        async fn read(&self, oplog_index: OplogIndex) -> OplogEntry {
-            if oplog_index == OplogIndex::from_u64(self.invocation_completion_index) {
-                OplogEntry::ExportedFunctionCompleted {
-                    timestamp: Timestamp::now_utc(),
-                    response: OplogPayload::Inline(Bytes::new().into()),
-                    consumed_fuel: 0,
-                }
-            } else {
-                // Any other oplog entry other than export function completed
-                OplogEntry::NoOp {
-                    timestamp: Timestamp::now_utc(),
-                }
-            }
-        }
-
         async fn add(&self, _entry: OplogEntry) {
             unimplemented!()
         }
@@ -815,6 +778,21 @@ mod tests {
             unimplemented!()
         }
 
+        async fn read(&self, oplog_index: OplogIndex) -> OplogEntry {
+            if oplog_index == OplogIndex::from_u64(self.invocation_completion_index) {
+                OplogEntry::ExportedFunctionCompleted {
+                    timestamp: Timestamp::now_utc(),
+                    response: OplogPayload::Inline(Bytes::new().into()),
+                    consumed_fuel: 0,
+                }
+            } else {
+                // Any other oplog entry other than export function completed
+                OplogEntry::NoOp {
+                    timestamp: Timestamp::now_utc(),
+                }
+            }
+        }
+
         async fn length(&self) -> u64 {
             unimplemented!()
         }
diff --git a/golem-debugging-service/tests/debug_mode/debug_bootstrap.rs b/golem-debugging-service/tests/debug_mode/debug_bootstrap.rs
index 581a660c..ff4714e9 100644
--- a/golem-debugging-service/tests/debug_mode/debug_bootstrap.rs
+++ b/golem-debugging-service/tests/debug_mode/debug_bootstrap.rs
@@ -12,6 +12,7 @@ use golem_debugging_service::{create_debug_wasmtime_linker, run_debug_worker_exe
 use golem_service_base::storage::blob::BlobStorage;
 use golem_test_framework::components::worker_executor::provided::ProvidedWorkerExecutor;
 use golem_worker_executor::services::active_workers::ActiveWorkers;
+use golem_worker_executor::services::agent_types::AgentTypesService;
 use golem_worker_executor::services::blob_store::BlobStoreService;
 use golem_worker_executor::services::component::ComponentService;
 use golem_worker_executor::services::events::Events;
@@ -23,6 +24,7 @@ use golem_worker_executor::services::key_value::KeyValueService;
 use golem_worker_executor::services::oplog::plugin::OplogProcessorPlugin;
 use golem_worker_executor::services::oplog::OplogService;
 use golem_worker_executor::services::plugins::{Plugins, PluginsObservations};
+use golem_worker_executor::services::projects::ProjectService;
 use golem_worker_executor::services::promise::PromiseService;
 use golem_worker_executor::services::rdbms;
 use golem_worker_executor::services::resource_limits;
@@ -83,14 +85,15 @@ impl Bootstrap<DebugContext> for TestDebuggingServerBootStrap {
         golem_config: &GolemConfig,
         blob_storage: Arc<dyn BlobStorage>,
         plugin_observations: Arc<dyn PluginsObservations>,
+        project_service: Arc<dyn ProjectService>,
     ) -> Arc<dyn ComponentService> {
         golem_worker_executor::services::component::configured(
             &get_component_service_config(),
-            &golem_config.project_service,
             &get_component_cache_config(),
             &golem_config.compiled_component_service,
             blob_storage,
             plugin_observations,
+            project_service,
         )
     }
 
@@ -128,6 +131,8 @@ impl Bootstrap<DebugContext> for TestDebuggingServerBootStrap {
         file_loader: Arc<FileLoader>,
         plugins: Arc<dyn Plugins>,
         oplog_processor_plugin: Arc<dyn OplogProcessorPlugin>,
+        project_service: Arc<dyn ProjectService>,
+        agent_types_service: Arc<dyn AgentTypesService>,
     ) -> anyhow::Result<All<DebugContext>> {
         let auth_service: Arc<dyn AuthService> = Arc::new(TestAuthService);
 
@@ -140,6 +145,9 @@ impl Bootstrap<DebugContext> for TestDebuggingServerBootStrap {
                 self.regular_worker_executor_context.grpc_port(),
                 true,
             )),
+            project_resolver: self
+                .regular_worker_executor_context
+                .create_project_resolver(),
         });
 
         let debug_sessions: Arc<dyn DebugSessions> = Arc::new(DebugSessionsDefault::default());
@@ -183,6 +191,8 @@ impl Bootstrap<DebugContext> for TestDebuggingServerBootStrap {
             plugins.clone(),
             oplog_processor_plugin.clone(),
             resource_limits.clone(),
+            project_service.clone(),
+            agent_types_service.clone(),
             addition_deps.clone(),
         ));
 
@@ -215,11 +225,14 @@ impl Bootstrap<DebugContext> for TestDebuggingServerBootStrap {
             plugins.clone(),
             oplog_processor_plugin.clone(),
             resource_limits.clone(),
+            project_service.clone(),
+            agent_types_service.clone(),
             addition_deps.clone(),
         ));
 
         Ok(All::new(
             active_workers,
+            agent_types_service,
             engine,
             linker,
             runtime.clone(),
@@ -245,6 +258,7 @@ impl Bootstrap<DebugContext> for TestDebuggingServerBootStrap {
             plugins.clone(),
             oplog_processor_plugin.clone(),
             resource_limits,
+            project_service,
             addition_deps,
         ))
     }
diff --git a/golem-debugging-service/tests/debug_mode/debug_worker_executor.rs b/golem-debugging-service/tests/debug_mode/debug_worker_executor.rs
index a28a7b4a..eab52e6f 100644
--- a/golem-debugging-service/tests/debug_mode/debug_worker_executor.rs
+++ b/golem-debugging-service/tests/debug_mode/debug_worker_executor.rs
@@ -1,10 +1,12 @@
 use anyhow::Context;
+use axum_jrpc::error::JsonRpcError;
 use axum_jrpc::{Id, JsonRpcAnswer, JsonRpcRequest, JsonRpcResponse};
-use futures_util::stream::{SplitSink, SplitStream};
-use futures_util::{SinkExt, StreamExt};
+use futures::stream::{SplitSink, SplitStream};
+use futures::{SinkExt, StreamExt};
 use golem_common::model::auth::TokenSecret;
 use serde::de::DeserializeOwned;
-use serde::Serialize;
+use serde::{Deserialize, Serialize};
+use serde_json::Value;
 use tokio::net::TcpStream;
 use tokio_tungstenite::tungstenite::client::IntoClientRequest;
 use tokio_tungstenite::tungstenite::protocol::frame::Utf8Payload;
@@ -20,6 +22,17 @@ pub type DebugRead = SplitStream<DebugServiceClient>;
 pub struct DebugWorkerExecutorClient {
     write_msg: DebugWrite,
     read_msg: DebugRead,
+    read_messages: Vec<UntypedJrpcMessage>,
+}
+
+#[derive(Debug, Clone, PartialEq, Deserialize, Serialize)]
+pub struct UntypedJrpcMessage {
+    pub jsonrpc: String,
+    pub method: Option<String>,
+    pub id: Option<String>,
+    pub params: Option<Value>,
+    pub error: Option<JsonRpcError>,
+    pub result: Option<Value>,
 }
 
 impl DebugWorkerExecutorClient {
@@ -47,28 +60,36 @@ impl DebugWorkerExecutorClient {
         Ok(id)
     }
 
-    pub async fn read_jrpc_msg<T: DeserializeOwned>(&mut self, id: Id) -> anyhow::Result<T> {
+    pub async fn read_jrpc_response<T: DeserializeOwned>(&mut self, id: Id) -> anyhow::Result<T> {
         let time = std::time::Instant::now();
         loop {
             if let Some(msg) = self.read_msg.next().await {
                 match msg {
                     Ok(Message::Text(text)) => {
-                        let response: JsonRpcResponse = serde_json::from_str(text.as_str())
-                            .map_err(|e| anyhow::anyhow!("Failed to parse response: {}", e))?;
-
-                        if response.id == id {
-                            match response.result {
-                                JsonRpcAnswer::Result(result) => {
-                                    let result: T =
-                                        serde_json::from_value(result).map_err(|e| {
-                                            anyhow::anyhow!("Failed to parse response: {}", e)
-                                        })?;
-                                    break Ok(result); // Break out of the loop with a Result
-                                }
-                                JsonRpcAnswer::Error(_) => {
-                                    break Err(anyhow::anyhow!("Error response"))
+                        {
+                            let message =
+                                serde_json::from_str::<UntypedJrpcMessage>(text.as_str())?;
+                            self.read_messages.push(message);
+                        }
+
+                        let maybe_response = serde_json::from_str::<JsonRpcResponse>(text.as_str());
+
+                        match maybe_response {
+                            Ok(response) if response.id == id => {
+                                match response.result {
+                                    JsonRpcAnswer::Result(result) => {
+                                        let result: T =
+                                            serde_json::from_value(result).map_err(|e| {
+                                                anyhow::anyhow!("Failed to parse response: {}", e)
+                                            })?;
+                                        break Ok(result); // Break out of the loop with a Result
+                                    }
+                                    JsonRpcAnswer::Error(_) => {
+                                        break Err(anyhow::anyhow!("Error response"))
+                                    }
                                 }
                             }
+                            _ => {}
                         }
                     }
                     _ => {
@@ -83,6 +104,17 @@ impl DebugWorkerExecutorClient {
         }
     }
 
+    pub async fn drain_connection(&mut self) -> anyhow::Result<()> {
+        while let Some(msg) = self.read_msg.next().await {
+            if let Message::Text(text) = msg? {
+                let message = serde_json::from_str::<UntypedJrpcMessage>(text.as_str())?;
+                self.read_messages.push(message);
+            }
+        }
+
+        Ok(())
+    }
+
     pub async fn connect(port: u16, token: TokenSecret) -> Result<Self, anyhow::Error> {
         let server_url = format!("ws://127.0.0.1:{port}/v1/debugger");
 
@@ -107,6 +139,19 @@ impl DebugWorkerExecutorClient {
         Ok(DebugWorkerExecutorClient {
             write_msg: write,
             read_msg: read,
+            read_messages: Vec::new(),
         })
     }
+
+    pub async fn close(&mut self) -> anyhow::Result<()> {
+        self.write_msg.send(Message::Close(None)).await?;
+
+        self.drain_connection().await?;
+
+        Ok(())
+    }
+
+    pub fn all_read_messages(&self) -> Vec<UntypedJrpcMessage> {
+        self.read_messages.clone()
+    }
 }
diff --git a/golem-debugging-service/tests/debug_mode/dsl.rs b/golem-debugging-service/tests/debug_mode/dsl.rs
index 7d9fcc90..4bea9e49 100644
--- a/golem-debugging-service/tests/debug_mode/dsl.rs
+++ b/golem-debugging-service/tests/debug_mode/dsl.rs
@@ -15,14 +15,9 @@ pub trait TestDslDebugMode {
         &mut self,
         target_index: OplogIndex,
         overrides: Option<Vec<PlaybackOverride>>,
-        wait_time_in_seconds: u64,
     ) -> anyhow::Result<PlaybackResult>;
 
-    async fn rewind(
-        &mut self,
-        target_index: OplogIndex,
-        wait_time_in_seconds: u64,
-    ) -> anyhow::Result<RewindResult>;
+    async fn rewind(&mut self, target_index: OplogIndex) -> anyhow::Result<RewindResult>;
 
     async fn fork(
         &mut self,
@@ -45,14 +40,13 @@ impl TestDslDebugMode for DebugWorkerExecutorClient {
             )
             .await?;
 
-        self.read_jrpc_msg(id).await
+        self.read_jrpc_response(id).await
     }
 
     async fn playback(
         &mut self,
         target_index: OplogIndex,
         overrides: Option<Vec<PlaybackOverride>>,
-        wait_time_in_seconds: u64,
     ) -> anyhow::Result<PlaybackResult> {
         let id = self
             .send_jrpc_msg(
@@ -61,31 +55,25 @@ impl TestDslDebugMode for DebugWorkerExecutorClient {
                     target_index,
                     overrides,
                     ensure_invocation_boundary: None,
-                    time_out_in_seconds: Some(wait_time_in_seconds),
                 },
             )
             .await?;
 
-        self.read_jrpc_msg(id).await
+        self.read_jrpc_response(id).await
     }
 
-    async fn rewind(
-        &mut self,
-        target_index: OplogIndex,
-        wait_time_in_seconds: u64,
-    ) -> anyhow::Result<RewindResult> {
+    async fn rewind(&mut self, target_index: OplogIndex) -> anyhow::Result<RewindResult> {
         let id = self
             .send_jrpc_msg(
                 "rewind",
                 RewindParams {
                     target_index,
                     ensure_invocation_boundary: None,
-                    time_out_in_seconds: Some(wait_time_in_seconds),
                 },
             )
             .await?;
 
-        self.read_jrpc_msg(id).await
+        self.read_jrpc_response(id).await
     }
 
     async fn fork(
@@ -103,13 +91,13 @@ impl TestDslDebugMode for DebugWorkerExecutorClient {
             )
             .await?;
 
-        self.read_jrpc_msg(id).await
+        self.read_jrpc_response(id).await
     }
 
     async fn current_index(&mut self) -> anyhow::Result<OplogIndex> {
         let id = self.send_jrpc_msg("current_oplog_index", ()).await?;
 
-        let result = self.read_jrpc_msg(id).await?;
+        let result = self.read_jrpc_response(id).await?;
 
         Ok(result)
     }
diff --git a/golem-debugging-service/tests/debug_mode/mod.rs b/golem-debugging-service/tests/debug_mode/mod.rs
index 7e388313..f74a0ab3 100644
--- a/golem-debugging-service/tests/debug_mode/mod.rs
+++ b/golem-debugging-service/tests/debug_mode/mod.rs
@@ -28,11 +28,24 @@ pub async fn start_debug_worker_executor(
     redis_monitor.assert_valid();
     let prometheus = golem_worker_executor::metrics::register_all();
 
+    let admin_account_id = regular_worker_dependencies.cloud_service.admin_account_id();
+    let admin_default_project_id = regular_worker_dependencies
+        .cloud_service
+        .get_default_project(&regular_worker_dependencies.cloud_service.admin_token())
+        .await?;
+    let admin_default_project_name = regular_worker_dependencies
+        .cloud_service
+        .get_project_name(&admin_default_project_id)
+        .await?;
+
     let config = get_golem_config(
         redis.public_port(),
         debug_context.redis_prefix(),
         debug_context.grpc_port(),
         debug_context.http_port(),
+        admin_account_id,
+        admin_default_project_id,
+        admin_default_project_name,
     );
 
     let handle = Handle::current();
diff --git a/golem-debugging-service/tests/debug_tests.rs b/golem-debugging-service/tests/debug_tests.rs
index 23b66b4e..435777f2 100644
--- a/golem-debugging-service/tests/debug_tests.rs
+++ b/golem-debugging-service/tests/debug_tests.rs
@@ -1,4 +1,4 @@
-use crate::debug_mode::debug_worker_executor::DebugWorkerExecutorClient;
+use crate::debug_mode::debug_worker_executor::{DebugWorkerExecutorClient, UntypedJrpcMessage};
 use crate::regular_mode::regular_worker_executor::TestRegularWorkerExecutor;
 use crate::*;
 use golem_common::model::oplog::OplogIndex;
@@ -9,7 +9,7 @@ use golem_service_base::model::PublicOplogEntryWithIndex;
 use golem_test_framework::dsl::TestDsl;
 use golem_wasm_ast::analysis::analysed_type::{record, str, variant};
 use golem_wasm_ast::analysis::{NameOptionTypePair, NameTypePair};
-use golem_wasm_rpc::{IntoValueAndType, Value, ValueAndType};
+use golem_wasm_rpc::{IntoValueAndType, Record, Value, ValueAndType};
 use test_r::{inherit_test_dep, test};
 
 inherit_test_dep!(RegularWorkerExecutorTestDependencies);
@@ -24,8 +24,12 @@ async fn test_connect_non_invoked_worker(
     deps: &RegularWorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
-    let context = RegularExecutorTestContext::new(last_unique_id);
-    let regular_worker_executor = start_regular_executor(deps, &context).await.into_admin();
+    let context =
+        RegularExecutorTestContext::new(last_unique_id, &deps.admin().await.default_project_id);
+    let regular_worker_executor = start_regular_executor(deps, &context)
+        .await
+        .into_admin()
+        .await;
 
     let debug_context = DebugExecutorTestContext::from(&context);
 
@@ -59,8 +63,12 @@ async fn test_connect_invoked_worker(
     deps: &RegularWorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
-    let context = RegularExecutorTestContext::new(last_unique_id);
-    let regular_worker_executor = start_regular_executor(deps, &context).await.into_admin();
+    let context =
+        RegularExecutorTestContext::new(last_unique_id, &deps.admin().await.default_project_id);
+    let regular_worker_executor = start_regular_executor(deps, &context)
+        .await
+        .into_admin()
+        .await;
 
     let debug_context = DebugExecutorTestContext::from(&context);
     let mut debug_executor = start_debug_executor(deps, &debug_context).await;
@@ -78,7 +86,7 @@ async fn test_connect_invoked_worker(
 
     let _ = regular_worker_executor
         .invoke_and_await(
-            worker_id.clone(),
+            &worker_id,
             "golem:it/api.{initialize-cart}",
             vec!["test-user-1".into_value_and_type()],
         )
@@ -86,14 +94,14 @@ async fn test_connect_invoked_worker(
 
     let _ = regular_worker_executor
         .invoke_and_await(
-            worker_id.clone(),
+            &worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1000".into_value_and_type()),
                 ("name", "Golem T-Shirt M".into_value_and_type()),
                 ("price", 100.0f32.into_value_and_type()),
                 ("quantity", 5u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -115,8 +123,12 @@ async fn test_connect_and_playback(
     deps: &RegularWorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
-    let context = RegularExecutorTestContext::new(last_unique_id);
-    let regular_worker_executor = start_regular_executor(deps, &context).await.into_admin();
+    let context =
+        RegularExecutorTestContext::new(last_unique_id, &deps.admin().await.default_project_id);
+    let regular_worker_executor = start_regular_executor(deps, &context)
+        .await
+        .into_admin()
+        .await;
 
     let debug_context = DebugExecutorTestContext::from(&context);
     let mut debug_executor = start_debug_executor(deps, &debug_context).await;
@@ -146,7 +158,7 @@ async fn test_connect_and_playback(
     let first_invocation_boundary = nth_invocation_boundary(&oplogs, 1);
 
     let playback_result = debug_executor
-        .playback(first_invocation_boundary, None, 3)
+        .playback(first_invocation_boundary, None)
         .await
         .expect("Failed to playback the worker in debug mode");
 
@@ -157,6 +169,160 @@ async fn test_connect_and_playback(
     assert_eq!(playback_result.current_index, first_invocation_boundary);
 }
 
+#[test]
+#[tracing::instrument]
+async fn test_connect_and_playback_raw(
+    last_unique_id: &LastUniqueId,
+    deps: &RegularWorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
+    let context =
+        RegularExecutorTestContext::new(last_unique_id, &deps.admin().await.default_project_id);
+
+    let regular_worker_executor = start_regular_executor(deps, &context)
+        .await
+        .into_admin()
+        .await;
+
+    let debug_context = DebugExecutorTestContext::from(&context);
+    let mut debug_executor = start_debug_executor(deps, &debug_context).await;
+
+    let component = regular_worker_executor
+        .component("shopping-cart")
+        .store()
+        .await;
+
+    let worker_id = regular_worker_executor
+        .start_worker(&component, "shopping-cart")
+        .await
+        .unwrap();
+
+    run_shopping_cart_initialize_and_add(&regular_worker_executor, &worker_id).await;
+
+    regular_worker_executor
+        .invoke_and_await(
+            &worker_id,
+            "golem:it/api.{add-item}",
+            vec![Record(vec![
+                ("product-id", "G1001".into_value_and_type()),
+                ("name", "Golem T-Shirt L".into_value_and_type()),
+                ("price", 120.0f32.into_value_and_type()),
+                ("quantity", 5u32.into_value_and_type()),
+            ])
+            .into_value_and_type()],
+        )
+        .await
+        .unwrap()
+        .expect("Failed to invoke and await");
+
+    regular_worker_executor
+        .invoke_and_await(&worker_id, "golem:it/api.{checkout}", vec![])
+        .await
+        .unwrap()
+        .expect("Failed to invoke and await");
+
+    let oplogs = regular_worker_executor
+        .get_oplog(&worker_id, OplogIndex::INITIAL)
+        .await
+        .unwrap();
+
+    debug_executor
+        .connect(&worker_id)
+        .await
+        .expect("Failed to connect to the worker in debug mode");
+
+    let first_invocation_boundary = nth_invocation_boundary(&oplogs, 1);
+    let fourth_invocation_boundary = nth_invocation_boundary(&oplogs, 4);
+
+    let playback_result_1 = debug_executor
+        .playback(fourth_invocation_boundary, None)
+        .await
+        .expect("Failed to playback the worker in debug mode");
+
+    assert!(!playback_result_1.incremental_playback);
+
+    debug_executor
+        .rewind(first_invocation_boundary)
+        .await
+        .expect("Failed to rewind the worker in debug mode");
+
+    let playback_result_2 = debug_executor
+        .playback(fourth_invocation_boundary, None)
+        .await
+        .expect("Failed to playback the worker in debug mode");
+
+    assert!(playback_result_2.incremental_playback);
+
+    let all_messages = debug_executor.all_read_messages();
+
+    assert!(matches!(
+        &all_messages[..],
+        [
+            UntypedJrpcMessage {
+                result: Some(_),
+                ..
+            },
+            UntypedJrpcMessage {
+                method: Some(_),
+                ..
+            },
+            UntypedJrpcMessage {
+                method: Some(_),
+                ..
+            },
+            UntypedJrpcMessage {
+                method: Some(_),
+                ..
+            },
+            UntypedJrpcMessage {
+                method: Some(_),
+                ..
+            },
+            UntypedJrpcMessage {
+                result: Some(_),
+                ..
+            },
+            UntypedJrpcMessage {
+                method: Some(_),
+                ..
+            },
+            UntypedJrpcMessage {
+                result: Some(_),
+                ..
+            },
+            UntypedJrpcMessage {
+                method: Some(_),
+                ..
+            },
+            UntypedJrpcMessage {
+                method: Some(_),
+                ..
+            },
+            UntypedJrpcMessage {
+                method: Some(_),
+                ..
+            },
+            UntypedJrpcMessage {
+                result: Some(_),
+                ..
+            },
+        ]
+    ));
+
+    for id in [1, 2, 3, 4, 6, 8, 9, 10] {
+        assert_eq!(all_messages[id].method, Some("emit-logs".to_string()))
+    }
+
+    assert_eq!(
+        all_messages[1].params.clone().unwrap().as_array().unwrap()[0]
+            .as_object()
+            .unwrap()
+            .get("message")
+            .unwrap(),
+        &serde_json::json!("Initializing cart for user test-user-1\n")
+    )
+}
+
 #[test]
 #[tracing::instrument]
 async fn test_connect_and_playback_to_middle_of_invocation(
@@ -164,8 +330,12 @@ async fn test_connect_and_playback_to_middle_of_invocation(
     deps: &RegularWorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
-    let context = RegularExecutorTestContext::new(last_unique_id);
-    let regular_worker_executor = start_regular_executor(deps, &context).await.into_admin();
+    let context =
+        RegularExecutorTestContext::new(last_unique_id, &deps.admin().await.default_project_id);
+    let regular_worker_executor = start_regular_executor(deps, &context)
+        .await
+        .into_admin()
+        .await;
 
     let debug_context = DebugExecutorTestContext::from(&context);
     let mut debug_executor = start_debug_executor(deps, &debug_context).await;
@@ -197,7 +367,7 @@ async fn test_connect_and_playback_to_middle_of_invocation(
     let index_in_middle = previous_index(first_invocation_boundary);
 
     let playback_result = debug_executor
-        .playback(index_in_middle, None, 3)
+        .playback(index_in_middle, None)
         .await
         .expect("Failed to playback the worker in debug mode");
 
@@ -216,8 +386,12 @@ async fn test_playback_from_breakpoint(
     deps: &RegularWorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
-    let context = RegularExecutorTestContext::new(last_unique_id);
-    let regular_worker_executor = start_regular_executor(deps, &context).await.into_admin();
+    let context =
+        RegularExecutorTestContext::new(last_unique_id, &deps.admin().await.default_project_id);
+    let regular_worker_executor = start_regular_executor(deps, &context)
+        .await
+        .into_admin()
+        .await;
 
     let debug_context = DebugExecutorTestContext::from(&context);
     let mut debug_executor = start_debug_executor(deps, &debug_context).await;
@@ -250,7 +424,7 @@ async fn test_playback_from_breakpoint(
         .expect("Failed to connect to the worker in debug mode");
 
     let playback_result1 = debug_executor
-        .playback(initialize_boundary, None, 3)
+        .playback(initialize_boundary, None)
         .await
         .expect("Failed to playback the worker in debug mode");
 
@@ -266,7 +440,7 @@ async fn test_playback_from_breakpoint(
     assert_eq!(current_index, initialize_boundary);
 
     let playback_result2 = debug_executor
-        .playback(add_item_boundary, None, 3)
+        .playback(add_item_boundary, None)
         .await
         .expect("Failed to playback the worker in debug mode");
 
@@ -280,7 +454,9 @@ async fn test_playback_from_breakpoint(
     assert_eq!(connect_result.worker_id, worker_id);
     assert_eq!(playback_result1.worker_id, worker_id);
     assert_eq!(playback_result1.current_index, initialize_boundary);
+    assert!(!playback_result1.incremental_playback);
     assert_eq!(playback_result2.worker_id, worker_id);
+    assert!(playback_result2.incremental_playback);
 }
 
 #[test]
@@ -290,8 +466,12 @@ async fn test_playback_and_rewind(
     deps: &RegularWorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
-    let context = RegularExecutorTestContext::new(last_unique_id);
-    let regular_worker_executor = start_regular_executor(deps, &context).await.into_admin();
+    let context =
+        RegularExecutorTestContext::new(last_unique_id, &deps.admin().await.default_project_id);
+    let regular_worker_executor = start_regular_executor(deps, &context)
+        .await
+        .into_admin()
+        .await;
 
     let debug_context = DebugExecutorTestContext::from(&context);
     let mut debug_executor = start_debug_executor(deps, &debug_context).await;
@@ -324,12 +504,12 @@ async fn test_playback_and_rewind(
         .expect("Failed to connect to the worker in debug mode");
 
     let playback_result = debug_executor
-        .playback(second_boundary, None, 3)
+        .playback(second_boundary, None)
         .await
         .expect("Failed to playback the worker in debug mode");
 
     let rewind_result = debug_executor
-        .rewind(first_boundary, 3)
+        .rewind(first_boundary)
         .await
         .expect("Failed to playback the worker in debug mode");
 
@@ -349,8 +529,12 @@ async fn test_playback_and_fork(
     deps: &RegularWorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
-    let context = RegularExecutorTestContext::new(last_unique_id);
-    let regular_worker_executor = start_regular_executor(deps, &context).await.into_admin();
+    let context =
+        RegularExecutorTestContext::new(last_unique_id, &deps.admin().await.default_project_id);
+    let regular_worker_executor = start_regular_executor(deps, &context)
+        .await
+        .into_admin()
+        .await;
 
     let debug_context = DebugExecutorTestContext::from(&context);
     let mut debug_executor = start_debug_executor(deps, &debug_context).await;
@@ -381,7 +565,7 @@ async fn test_playback_and_fork(
         .expect("Failed to connect to the worker in debug mode");
 
     let playback_result = debug_executor
-        .playback(first_boundary, None, 3)
+        .playback(first_boundary, None)
         .await
         .expect("Failed to playback the worker in debug mode");
 
@@ -407,14 +591,14 @@ async fn test_playback_and_fork(
     // invoke the forked worker with second invocation
     let _ = regular_worker_executor
         .invoke_and_await(
-            target_worker_id.clone(),
+            &target_worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1000".into_value_and_type()),
                 ("name", "Golem T-Shirt M".into_value_and_type()),
                 ("price", 100.0f32.into_value_and_type()),
                 ("quantity", 5u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -441,8 +625,12 @@ async fn test_playback_with_overrides(
     deps: &RegularWorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
-    let context = RegularExecutorTestContext::new(last_unique_id);
-    let regular_worker_executor = start_regular_executor(deps, &context).await.into_admin();
+    let context =
+        RegularExecutorTestContext::new(last_unique_id, &deps.admin().await.default_project_id);
+    let regular_worker_executor = start_regular_executor(deps, &context)
+        .await
+        .into_admin()
+        .await;
 
     let debug_context = DebugExecutorTestContext::from(&context);
     let mut debug_executor = start_debug_executor(deps, &debug_context).await;
@@ -486,7 +674,6 @@ async fn test_playback_with_overrides(
         .playback(
             shopping_cart_execution_result.last_add_item_boundary,
             Some(vec![oplog_overrides]),
-            3,
         )
         .await
         .expect("Failed to playback the worker in debug mode");
@@ -614,7 +801,7 @@ async fn run_shopping_cart_initialize_and_add(
 ) {
     regular_worker_executor
         .invoke_and_await(
-            worker_id.clone(),
+            worker_id,
             "golem:it/api.{initialize-cart}",
             vec!["test-user-1".into_value_and_type()],
         )
@@ -624,14 +811,14 @@ async fn run_shopping_cart_initialize_and_add(
 
     regular_worker_executor
         .invoke_and_await(
-            worker_id.clone(),
+            worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1000".into_value_and_type()),
                 ("name", "Golem T-Shirt M".into_value_and_type()),
                 ("price", 100.0f32.into_value_and_type()),
                 ("quantity", 5u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await
@@ -648,21 +835,21 @@ async fn run_shopping_cart_workflow(
 
     // Checkout
     let _ = regular_worker_executor
-        .invoke_and_await(worker_id.clone(), "golem:it/api.{checkout}", vec![])
+        .invoke_and_await(worker_id, "golem:it/api.{checkout}", vec![])
         .await
         .expect("Failed to invoke and await");
 
     // Add Item again
     let _ = regular_worker_executor
         .invoke_and_await(
-            worker_id.clone(),
+            worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1000".into_value_and_type()),
                 ("name", "Golem T-Shirt M".into_value_and_type()),
                 ("price", 100.0f32.into_value_and_type()),
                 ("quantity", 5u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
diff --git a/golem-debugging-service/tests/lib.rs b/golem-debugging-service/tests/lib.rs
index 8c51f575..a36fb02d 100644
--- a/golem-debugging-service/tests/lib.rs
+++ b/golem-debugging-service/tests/lib.rs
@@ -1,4 +1,12 @@
+pub mod debug_mode;
+pub mod debug_tests;
+pub mod regular_mode;
+pub mod services;
+
 use async_trait::async_trait;
+pub use debug_mode::context::DebugExecutorTestContext;
+pub use debug_mode::dsl::TestDslDebugMode;
+pub use debug_mode::start_debug_worker_executor;
 use golem_common::config::RedisConfig;
 use golem_common::model::{AccountId, ProjectId, RetryConfig};
 use golem_common::tracing::{init_tracing_with_default_debug_env_filter, TracingConfig};
@@ -31,7 +39,8 @@ use golem_worker_executor::services::golem_config::{
     ProjectServiceDisabledConfig, ShardManagerServiceConfig, ShardManagerServiceSingleShardConfig,
     WorkerServiceGrpcConfig,
 };
-use std::env::var;
+pub use regular_mode::context::RegularExecutorTestContext;
+pub use regular_mode::start_regular_worker_executor;
 use std::fmt::{Debug, Formatter};
 use std::path::{Path, PathBuf};
 use std::sync::atomic::AtomicU16;
@@ -42,19 +51,6 @@ use test_r::test_dep;
 use tracing::Level;
 use uuid::Uuid;
 
-pub mod debug_mode;
-pub mod debug_tests;
-pub mod regular_mode;
-pub mod services;
-
-pub use debug_mode::context::DebugExecutorTestContext;
-pub use debug_mode::dsl::TestDslDebugMode;
-pub use debug_mode::start_debug_worker_executor;
-use golem_test_framework::components::redis::docker::DockerRedis;
-use golem_test_framework::components::redis_monitor::docker::DockerRedisMonitor;
-pub use regular_mode::context::RegularExecutorTestContext;
-pub use regular_mode::start_regular_worker_executor;
-
 test_r::enable!();
 
 #[derive(Debug)]
@@ -92,6 +88,9 @@ pub fn get_golem_config(
     redis_prefix: String,
     grpc_port: u16,
     http_port: u16,
+    account_id: AccountId,
+    default_project_id: ProjectId,
+    default_project_name: String,
 ) -> GolemConfig {
     GolemConfig {
         key_value_storage: KeyValueStorageConfig::Redis(RedisConfig {
@@ -119,7 +118,11 @@ pub fn get_golem_config(
             connect_timeout: Duration::from_secs(120),
         },
         memory: MemoryConfig::default(),
-        project_service: ProjectServiceConfig::Disabled(ProjectServiceDisabledConfig {}),
+        project_service: ProjectServiceConfig::Disabled(ProjectServiceDisabledConfig {
+            account_id,
+            project_id: default_project_id,
+            project_name: default_project_name,
+        }),
         ..Default::default()
     }
 }
@@ -229,33 +232,17 @@ impl Debug for RegularWorkerExecutorTestDependencies {
 
 impl RegularWorkerExecutorTestDependencies {
     pub async fn new() -> Self {
-        let docker_active = var("GOLEM_DOCKER_SERVICES")
-            .map(|v| v == "true")
-            .unwrap_or(false);
-
-        let redis: Arc<dyn Redis + Send + Sync + 'static> = if !docker_active {
-            Arc::new(SpawnedRedis::new(
-                6379,
-                "".to_string(),
-                Level::INFO,
-                Level::ERROR,
-            ))
-        } else {
-            Arc::new(DockerRedis::new("test_network", "".to_string()).await)
-        };
-        let redis_monitor: Arc<dyn RedisMonitor + Send + Sync + 'static> = if !docker_active {
-            Arc::new(SpawnedRedisMonitor::new(
-                redis.clone(),
-                Level::DEBUG,
-                Level::ERROR,
-            ))
-        } else {
-            Arc::new(DockerRedisMonitor::new(
-                redis.clone(),
-                Level::DEBUG,
-                Level::ERROR,
-            ))
-        };
+        let redis: Arc<dyn Redis> = Arc::new(SpawnedRedis::new(
+            6379,
+            "".to_string(),
+            Level::INFO,
+            Level::ERROR,
+        ));
+        let redis_monitor: Arc<dyn RedisMonitor> = Arc::new(SpawnedRedisMonitor::new(
+            redis.clone(),
+            Level::DEBUG,
+            Level::ERROR,
+        ));
 
         let blob_storage = Arc::new(
             FileSystemBlobStorage::new(Path::new("data/blobs"))
@@ -270,6 +257,7 @@ impl RegularWorkerExecutorTestDependencies {
             Path::new("../golem-debugging-service/test-components").to_path_buf();
         let account_id = AccountId::generate();
         let project_id = ProjectId::new_v4();
+        let project_name = "default".to_string();
         let token = Uuid::new_v4();
         let component_service: Arc<dyn ComponentService> = Arc::new(
             FileSystemComponentService::new(
@@ -282,7 +270,10 @@ impl RegularWorkerExecutorTestDependencies {
         );
 
         let cloud_service = Arc::new(AdminOnlyStubCloudService::new(
-            account_id, token, project_id,
+            account_id,
+            token,
+            project_id,
+            project_name,
         ));
 
         Self {
@@ -396,6 +387,6 @@ impl TestDependencies for RegularWorkerExecutorTestDependencies {
     }
 
     fn cloud_service(&self) -> Arc<dyn CloudService> {
-        panic!("Not supported")
+        self.cloud_service.clone()
     }
 }
diff --git a/golem-debugging-service/tests/regular_mode/mod.rs b/golem-debugging-service/tests/regular_mode/mod.rs
index 57434c68..32ff71f6 100644
--- a/golem-debugging-service/tests/regular_mode/mod.rs
+++ b/golem-debugging-service/tests/regular_mode/mod.rs
@@ -26,12 +26,25 @@ pub async fn start_regular_worker_executor(
     redis.assert_valid();
     redis_monitor.assert_valid();
 
+    let admin_account_id = deps.cloud_service.admin_account_id();
+    let admin_default_project_id = deps
+        .cloud_service
+        .get_default_project(&deps.cloud_service.admin_token())
+        .await?;
+    let admin_default_project_name = deps
+        .cloud_service
+        .get_project_name(&admin_default_project_id)
+        .await?;
+
     let prometheus = golem_worker_executor::metrics::register_all();
     let config = get_golem_config(
         redis.public_port(),
         context.redis_prefix(),
         context.grpc_port(),
         context.http_port(),
+        admin_account_id,
+        admin_default_project_id,
+        admin_default_project_name,
     );
     let handle = Handle::current();
 
diff --git a/golem-debugging-service/tests/regular_mode/worker_ctx.rs b/golem-debugging-service/tests/regular_mode/worker_ctx.rs
index f9f47d89..1b25f6f0 100644
--- a/golem-debugging-service/tests/regular_mode/worker_ctx.rs
+++ b/golem-debugging-service/tests/regular_mode/worker_ctx.rs
@@ -4,34 +4,34 @@ use golem_common::model::invocation_context::{
     self, AttributeValue, InvocationContextStack, SpanId,
 };
 use golem_common::model::oplog::UpdateDescription;
-use golem_common::model::oplog::WorkerResourceId;
 use golem_common::model::{
-    AccountId, ComponentFilePath, ComponentVersion, IdempotencyKey, OwnedWorkerId,
-    PluginInstallationId, TargetWorkerId, WorkerId, WorkerMetadata, WorkerStatus,
+    AccountId, ComponentFilePath, ComponentVersion, GetFileSystemNodeResult, IdempotencyKey,
+    OwnedWorkerId, PluginInstallationId, ProjectId, WorkerId, WorkerMetadata, WorkerStatus,
     WorkerStatusRecord,
 };
 use golem_service_base::error::worker_executor::{InterruptKind, WorkerExecutorError};
 use golem_wasm_rpc::golem_rpc_0_2_x::types::{
     CancellationToken, Datetime, FutureInvokeResult, HostFutureInvokeResult, Pollable, WasmRpc,
 };
-use golem_wasm_rpc::wasmtime::ResourceStore;
+use golem_wasm_rpc::wasmtime::{ResourceStore, ResourceTypeId};
 use golem_wasm_rpc::{HostWasmRpc, RpcError, Uri, WitValue};
 use golem_wasm_rpc::{Value, ValueAndType};
 use golem_worker_executor::durable_host::{
     DurableWorkerCtx, DurableWorkerCtxView, PublicDurableWorkerState,
 };
 use golem_worker_executor::model::{
-    CurrentResourceLimits, ExecutionStatus, LastError, ListDirectoryResult, ReadFileResult,
-    TrapType, WorkerConfig,
+    CurrentResourceLimits, ExecutionStatus, LastError, ReadFileResult, TrapType, WorkerConfig,
 };
 use golem_worker_executor::services::active_workers::ActiveWorkers;
+use golem_worker_executor::services::agent_types::AgentTypesService;
 use golem_worker_executor::services::blob_store::BlobStoreService;
-use golem_worker_executor::services::component::{ComponentMetadata, ComponentService};
+use golem_worker_executor::services::component::ComponentService;
 use golem_worker_executor::services::file_loader::FileLoader;
 use golem_worker_executor::services::golem_config::GolemConfig;
 use golem_worker_executor::services::key_value::KeyValueService;
 use golem_worker_executor::services::oplog::{Oplog, OplogService};
 use golem_worker_executor::services::plugins::Plugins;
+use golem_worker_executor::services::projects::ProjectService;
 use golem_worker_executor::services::promise::PromiseService;
 use golem_worker_executor::services::rdbms::RdbmsService;
 use golem_worker_executor::services::resource_limits::ResourceLimits;
@@ -45,11 +45,12 @@ use golem_worker_executor::services::worker_proxy::WorkerProxy;
 use golem_worker_executor::services::{HasAll, HasConfig, HasOplogService};
 use golem_worker_executor::worker::{RetryDecision, Worker};
 use golem_worker_executor::workerctx::{
-    DynamicLinking, ExternalOperations, FileSystemReading, FuelManagement, IndexedResourceStore,
-    InvocationContextManagement, InvocationHooks, InvocationManagement, StatusManagement,
-    UpdateManagement, WorkerCtx,
+    DynamicLinking, ExternalOperations, FileSystemReading, FuelManagement, HasWasiConfigVars,
+    InvocationContextManagement, InvocationHooks, InvocationManagement, LogEventEmitBehaviour,
+    StatusManagement, UpdateManagement, WorkerCtx,
 };
-use std::collections::HashSet;
+use std::collections::{BTreeMap, HashSet};
+use std::future::Future;
 use std::sync::{Arc, RwLock, Weak};
 use tracing::debug;
 use wasmtime::component::{Component, Instance, Linker, Resource, ResourceAny};
@@ -65,7 +66,10 @@ pub struct TestWorkerCtx {
 impl WorkerCtx for TestWorkerCtx {
     type PublicState = PublicDurableWorkerState<TestWorkerCtx>;
 
+    const LOG_EVENT_EMIT_BEHAVIOUR: LogEventEmitBehaviour = LogEventEmitBehaviour::LiveOnly;
+
     async fn create(
+        _account_id: AccountId,
         owned_worker_id: OwnedWorkerId,
         promise_service: Arc<dyn PromiseService>,
         worker_service: Arc<dyn WorkerService>,
@@ -90,6 +94,8 @@ impl WorkerCtx for TestWorkerCtx {
         plugins: Arc<dyn Plugins>,
         worker_fork: Arc<dyn WorkerForkService>,
         _resource_limits: Arc<dyn ResourceLimits>,
+        project_service: Arc<dyn ProjectService>,
+        agent_types_service: Arc<dyn AgentTypesService>,
     ) -> Result<Self, WorkerExecutorError> {
         let durable_ctx = DurableWorkerCtx::create(
             owned_worker_id,
@@ -113,6 +119,8 @@ impl WorkerCtx for TestWorkerCtx {
             file_loader,
             plugins,
             worker_fork,
+            project_service,
+            agent_types_service,
         )
         .await?;
         Ok(Self { durable_ctx })
@@ -142,7 +150,11 @@ impl WorkerCtx for TestWorkerCtx {
         self.durable_ctx.owned_worker_id()
     }
 
-    fn component_metadata(&self) -> &ComponentMetadata {
+    fn created_by(&self) -> &AccountId {
+        self.durable_ctx.created_by()
+    }
+
+    fn component_metadata(&self) -> &golem_service_base::model::Component {
         self.durable_ctx.component_metadata()
     }
 
@@ -165,15 +177,6 @@ impl WorkerCtx for TestWorkerCtx {
     fn worker_fork(&self) -> Arc<dyn WorkerForkService> {
         self.durable_ctx.worker_fork()
     }
-
-    async fn generate_unique_local_worker_id(
-        &mut self,
-        remote_worker_id: TargetWorkerId,
-    ) -> Result<WorkerId, WorkerExecutorError> {
-        self.durable_ctx
-            .generate_unique_local_worker_id(remote_worker_id)
-            .await
-    }
 }
 
 #[async_trait]
@@ -218,11 +221,11 @@ impl ResourceLimiterAsync for TestWorkerCtx {
 
 #[async_trait]
 impl FileSystemReading for TestWorkerCtx {
-    async fn list_directory(
+    async fn get_file_system_node(
         &self,
         path: &ComponentFilePath,
-    ) -> Result<ListDirectoryResult, WorkerExecutorError> {
-        self.durable_ctx.list_directory(path).await
+    ) -> Result<GetFileSystemNodeResult, WorkerExecutorError> {
+        self.durable_ctx.get_file_system_node(path).await
     }
 
     async fn read_file(
@@ -241,13 +244,6 @@ impl HostWasmRpc for TestWorkerCtx {
         self.durable_ctx.new(worker_id).await
     }
 
-    async fn ephemeral(
-        &mut self,
-        component_id: golem_wasm_rpc::ComponentId,
-    ) -> anyhow::Result<Resource<WasmRpc>> {
-        self.durable_ctx.ephemeral(component_id).await
-    }
-
     async fn invoke_and_await(
         &mut self,
         self_: Resource<WasmRpc>,
@@ -337,7 +333,7 @@ impl DynamicLinking<TestWorkerCtx> for TestWorkerCtx {
         engine: &Engine,
         linker: &mut Linker<TestWorkerCtx>,
         component: &Component,
-        component_metadata: &ComponentMetadata,
+        component_metadata: &golem_service_base::model::Component,
     ) -> anyhow::Result<()> {
         self.durable_ctx
             .link(engine, linker, component, component_metadata)
@@ -371,34 +367,6 @@ impl FuelManagement for TestWorkerCtx {
     }
 }
 
-#[async_trait]
-impl IndexedResourceStore for TestWorkerCtx {
-    fn get_indexed_resource(
-        &self,
-        resource_name: &str,
-        resource_params: &[String],
-    ) -> Option<WorkerResourceId> {
-        self.durable_ctx
-            .get_indexed_resource(resource_name, resource_params)
-    }
-
-    async fn store_indexed_resource(
-        &mut self,
-        resource_name: &str,
-        resource_params: &[String],
-        resource: WorkerResourceId,
-    ) {
-        self.durable_ctx
-            .store_indexed_resource(resource_name, resource_params, resource)
-            .await
-    }
-
-    fn drop_indexed_resource(&mut self, resource_name: &str, resource_params: &[String]) {
-        self.durable_ctx
-            .drop_indexed_resource(resource_name, resource_params)
-    }
-}
-
 #[async_trait]
 impl ExternalOperations<TestWorkerCtx> for TestWorkerCtx {
     type ExtraDeps = ();
@@ -432,8 +400,10 @@ impl ExternalOperations<TestWorkerCtx> for TestWorkerCtx {
     async fn resume_replay(
         store: &mut (impl AsContextMut<Data = TestWorkerCtx> + Send),
         instance: &Instance,
+        refresh_replay_target: bool,
     ) -> Result<RetryDecision, WorkerExecutorError> {
-        DurableWorkerCtx::<TestWorkerCtx>::resume_replay(store, instance).await
+        DurableWorkerCtx::<TestWorkerCtx>::resume_replay(store, instance, refresh_replay_target)
+            .await
     }
 
     async fn prepare_instance(
@@ -446,12 +416,12 @@ impl ExternalOperations<TestWorkerCtx> for TestWorkerCtx {
 
     async fn record_last_known_limits<T: HasAll<TestWorkerCtx> + Send + Sync>(
         this: &T,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         last_known_limits: &CurrentResourceLimits,
     ) -> Result<(), WorkerExecutorError> {
         DurableWorkerCtx::<TestWorkerCtx>::record_last_known_limits(
             this,
-            account_id,
+            project_id,
             last_known_limits,
         )
         .await
@@ -472,12 +442,14 @@ impl ExternalOperations<TestWorkerCtx> for TestWorkerCtx {
 
     async fn on_worker_update_failed_to_start<T: HasAll<TestWorkerCtx> + Send + Sync>(
         this: &T,
+        account_id: &AccountId,
         owned_worker_id: &OwnedWorkerId,
         target_version: ComponentVersion,
         details: Option<String>,
     ) -> Result<(), WorkerExecutorError> {
         DurableWorkerCtx::<TestWorkerCtx>::on_worker_update_failed_to_start(
             this,
+            account_id,
             owned_worker_id,
             target_version,
             details,
@@ -582,15 +554,15 @@ impl ResourceStore for TestWorkerCtx {
         self.durable_ctx.self_uri()
     }
 
-    async fn add(&mut self, resource: ResourceAny) -> u64 {
-        self.durable_ctx.add(resource).await
+    async fn add(&mut self, resource: ResourceAny, name: ResourceTypeId) -> u64 {
+        self.durable_ctx.add(resource, name).await
     }
 
-    async fn get(&mut self, resource_id: u64) -> Option<ResourceAny> {
+    async fn get(&mut self, resource_id: u64) -> Option<(ResourceTypeId, ResourceAny)> {
         ResourceStore::get(&mut self.durable_ctx, resource_id).await
     }
 
-    async fn borrow(&self, resource_id: u64) -> Option<ResourceAny> {
+    async fn borrow(&self, resource_id: u64) -> Option<(ResourceTypeId, ResourceAny)> {
         self.durable_ctx.borrow(resource_id).await
     }
 }
@@ -664,4 +636,30 @@ impl InvocationContextManagement for TestWorkerCtx {
             .set_span_attribute(span_id, key, value)
             .await
     }
+
+    fn clone_as_inherited_stack(&self, current_span_id: &SpanId) -> InvocationContextStack {
+        self.durable_ctx.clone_as_inherited_stack(current_span_id)
+    }
+}
+
+impl HasWasiConfigVars for TestWorkerCtx {
+    fn wasi_config_vars(&self) -> BTreeMap<String, String> {
+        self.durable_ctx.wasi_config_vars()
+    }
+}
+
+impl wasmtime_wasi::p2::bindings::cli::environment::Host for TestWorkerCtx {
+    fn get_environment(
+        &mut self,
+    ) -> impl Future<Output = anyhow::Result<Vec<(String, String)>>> + Send {
+        wasmtime_wasi::p2::bindings::cli::environment::Host::get_environment(&mut self.durable_ctx)
+    }
+
+    fn get_arguments(&mut self) -> impl Future<Output = anyhow::Result<Vec<String>>> + Send {
+        wasmtime_wasi::p2::bindings::cli::environment::Host::get_arguments(&mut self.durable_ctx)
+    }
+
+    fn initial_cwd(&mut self) -> impl Future<Output = anyhow::Result<Option<String>>> + Send {
+        wasmtime_wasi::p2::bindings::cli::environment::Host::initial_cwd(&mut self.durable_ctx)
+    }
 }
diff --git a/golem-debugging-service/tests/services/worker_proxy.rs b/golem-debugging-service/tests/services/worker_proxy.rs
index 66cad671..1c1809b3 100644
--- a/golem-debugging-service/tests/services/worker_proxy.rs
+++ b/golem-debugging-service/tests/services/worker_proxy.rs
@@ -7,13 +7,13 @@ use golem_api_grpc::proto::golem::workerexecutor::v1::{
 };
 use golem_common::base_model::OplogIndex;
 use golem_common::model::invocation_context::InvocationContextStack;
-use golem_common::model::{ComponentVersion, IdempotencyKey, OwnedWorkerId, WorkerId};
+use golem_common::model::{ComponentVersion, IdempotencyKey, OwnedWorkerId, ProjectId, WorkerId};
 use golem_service_base::error::worker_executor::WorkerExecutorError;
 use golem_service_base::model::RevertWorkerTarget;
 use golem_test_framework::components::worker_executor::WorkerExecutor;
 use golem_wasm_rpc::{ValueAndType, WitValue};
 use golem_worker_executor::services::worker_proxy::{WorkerProxy, WorkerProxyError};
-use std::collections::HashMap;
+use std::collections::{BTreeMap, HashMap};
 use std::sync::Arc;
 
 // Worker Proxy will be internally used by fork functionality,
@@ -24,6 +24,7 @@ use std::sync::Arc;
 // however place it in the real executor
 pub struct TestWorkerProxy {
     pub worker_executor: Arc<dyn WorkerExecutor + Send + Sync + 'static>,
+    pub project_resolver: Arc<dyn GetWorkerProject>,
 }
 
 impl TestWorkerProxy {
@@ -42,6 +43,20 @@ impl TestWorkerProxy {
 
 #[async_trait]
 impl WorkerProxy for TestWorkerProxy {
+    async fn start(
+        &self,
+        _owned_worker_id: &OwnedWorkerId,
+        _caller_args: Vec<String>,
+        _caller_env: HashMap<String, String>,
+        _caller_wasi_config_vars: BTreeMap<String, String>,
+    ) -> Result<(), WorkerProxyError> {
+        Err(WorkerProxyError::InternalError(
+            WorkerExecutorError::unknown(
+                "Not implemented in tests as debug service is not expected to call start through proxy",
+            )
+        ))
+    }
+
     async fn invoke_and_await(
         &self,
         _owned_worker_id: &OwnedWorkerId,
@@ -51,6 +66,7 @@ impl WorkerProxy for TestWorkerProxy {
         _caller_worker_id: WorkerId,
         _caller_args: Vec<String>,
         _caller_env: HashMap<String, String>,
+        _caller_wasi_config_vars: BTreeMap<String, String>,
         _invocation_context_stack: InvocationContextStack,
     ) -> Result<Option<ValueAndType>, WorkerProxyError> {
         Err(WorkerProxyError::InternalError(
@@ -69,6 +85,7 @@ impl WorkerProxy for TestWorkerProxy {
         _caller_worker_id: WorkerId,
         _caller_args: Vec<String>,
         _caller_env: HashMap<String, String>,
+        _caller_wasi_config_vars: BTreeMap<String, String>,
         _invocation_context_stack: InvocationContextStack,
     ) -> Result<(), WorkerProxyError> {
         Err(WorkerProxyError::InternalError(
@@ -93,6 +110,7 @@ impl WorkerProxy for TestWorkerProxy {
 
     async fn resume(&self, worker_id: &WorkerId, force: bool) -> Result<(), WorkerProxyError> {
         let mut retry_count = Self::RETRY_COUNT;
+        let project_id = self.project_resolver.get_worker_project(worker_id).await?;
         let worker_id: golem_api_grpc::proto::golem::worker::WorkerId = worker_id.clone().into();
 
         let result = loop {
@@ -106,6 +124,7 @@ impl WorkerProxy for TestWorkerProxy {
                     account_id: Some(AccountId {
                         name: "test-account".to_string(),
                     }),
+                    project_id: Some(project_id.clone().into()),
                     force: Some(force),
                 })
                 .await;
@@ -137,6 +156,10 @@ impl WorkerProxy for TestWorkerProxy {
         target_worker_id: &WorkerId,
         oplog_index_cutoff: &OplogIndex,
     ) -> Result<(), WorkerProxyError> {
+        let project_id = self
+            .project_resolver
+            .get_worker_project(source_worker_id)
+            .await?;
         let result = self
             .worker_executor
             .client()
@@ -146,6 +169,7 @@ impl WorkerProxy for TestWorkerProxy {
                 account_id: Some(AccountId {
                     name: "test-account".to_string(),
                 }),
+                project_id: Some(project_id.into()),
                 source_worker_id: Some(source_worker_id.clone().into()),
                 target_worker_id: Some(target_worker_id.clone().into()),
                 oplog_index_cutoff: (*oplog_index_cutoff).into(),
@@ -167,19 +191,21 @@ impl WorkerProxy for TestWorkerProxy {
 
     async fn revert(
         &self,
-        worker_id: WorkerId,
+        worker_id: &WorkerId,
         target: RevertWorkerTarget,
     ) -> Result<(), WorkerProxyError> {
+        let project_id = self.project_resolver.get_worker_project(worker_id).await?;
         let result = self
             .worker_executor
             .client()
             .await
             .map_err(|e| WorkerProxyError::InternalError(WorkerExecutorError::from(e)))?
             .revert_worker(RevertWorkerRequest {
-                worker_id: Some(worker_id.into()),
+                worker_id: Some(worker_id.clone().into()),
                 account_id: Some(AccountId {
                     name: "test-account".to_string(),
                 }),
+                project_id: Some(project_id.into()),
                 target: Some(target.into()),
             })
             .await?
@@ -197,3 +223,9 @@ impl WorkerProxy for TestWorkerProxy {
         }
     }
 }
+
+#[async_trait]
+pub trait GetWorkerProject: Send + Sync {
+    async fn get_worker_project(&self, worker_id: &WorkerId)
+        -> Result<ProjectId, WorkerProxyError>;
+}
diff --git a/golem-rib-repl/src/repl_printer.rs b/golem-rib-repl/src/repl_printer.rs
index b1d60a53..2e67014f 100644
--- a/golem-rib-repl/src/repl_printer.rs
+++ b/golem-rib-repl/src/repl_printer.rs
@@ -89,35 +89,11 @@ pub trait ReplPrinter {
                 println!("{}", "()".yellow());
             }
 
-            RibResult::Val(value_and_type) => match &value_and_type.value {
-                Value::Handle { uri, resource_id } => {
-                    println!("{} {}", "[warn]".magenta(), "the syntax below to show the resource-handle value is only used for display purposes".to_string().white());
-
-                    println!();
-
-                    let resource = Value::Record(vec![
-                        Value::String(uri.to_string()),
-                        Value::U64(*resource_id),
-                    ]);
-
-                    let analysed_type = record(vec![
-                        NameTypePair {
-                            name: "uri".to_string(),
-                            typ: str(),
-                        },
-                        NameTypePair {
-                            name: "resource-id".to_string(),
-                            typ: u64(),
-                        },
-                    ]);
-
-                    let result = ValueAndType::new(resource, analysed_type);
-
-                    println!("{}", result.to_string().yellow());
-                }
-
-                _ => println!("{}", result.to_string().yellow()),
-            },
+            RibResult::Val(value_and_type) => {
+                let value_str = display_for_value_and_type(value_and_type);
+                let formatted = try_formatting(&value_str, 2);
+                println!("{}", formatted.yellow());
+            }
         }
     }
 
@@ -128,7 +104,7 @@ pub trait ReplPrinter {
     fn print_wasm_value_type(&self, analysed_type: &AnalysedType) {
         match analysed_type {
             AnalysedType::Handle(type_handle) => {
-                let text = display_for_resource_handle(type_handle);
+                let text = display_for_resource_handle_type(type_handle);
                 println!("{} {}", "[warn]".magenta(), "the syntax below to show the resource-handle type is only used for display purposes".to_string().white());
 
                 println!();
@@ -446,7 +422,7 @@ fn print_bootstrap_error(error: &ReplBootstrapError) {
 }
 
 // Only used for displaying since Wasm Wave is yet to support resource handle types
-fn display_for_resource_handle(type_handle: &TypeHandle) -> String {
+fn display_for_resource_handle_type(type_handle: &TypeHandle) -> String {
     let resource_id = &type_handle.resource_id.0;
     let uri = &type_handle.mode;
 
@@ -490,3 +466,280 @@ impl Display for Indent {
         Ok(())
     }
 }
+
+// To intercept any presence of resource handle and therefore inspecting each element
+// instead of value_and_type.to_string()
+fn display_for_value_and_type(value_and_type: &ValueAndType) -> String {
+    match &value_and_type.value {
+        Value::Bool(_) => value_and_type.to_string(),
+        Value::U8(_) => value_and_type.to_string(),
+        Value::U16(_) => value_and_type.to_string(),
+        Value::U32(_) => value_and_type.to_string(),
+        Value::U64(_) => value_and_type.to_string(),
+        Value::S8(_) => value_and_type.to_string(),
+        Value::S16(_) => value_and_type.to_string(),
+        Value::S32(_) => value_and_type.to_string(),
+        Value::S64(_) => value_and_type.to_string(),
+        Value::F32(_) => value_and_type.to_string(),
+        Value::F64(_) => value_and_type.to_string(),
+        Value::Char(_) => value_and_type.to_string(),
+        Value::String(_) => value_and_type.to_string(),
+        Value::List(values) => {
+            let inner_type = match &value_and_type.typ {
+                AnalysedType::List(inner_type) => inner_type.inner.as_ref(),
+                _ => panic!("Expected a list type"),
+            };
+
+            let mut string = "[".to_string();
+            for (i, value) in values.iter().enumerate() {
+                if i > 0 {
+                    string.push_str(", ");
+                }
+                let inner_value_and_type = ValueAndType::new(value.clone(), inner_type.clone());
+                let inner_value_and_type = display_for_value_and_type(&inner_value_and_type);
+                string.push_str(&inner_value_and_type.to_string());
+            }
+
+            string.push(']');
+
+            string
+        }
+        Value::Tuple(tuple) => {
+            let inner_types = match &value_and_type.typ {
+                AnalysedType::Tuple(inner_types) => inner_types.items.clone(),
+                _ => panic!("Expected a tuple type"),
+            };
+
+            let mut string = "(".to_string();
+            for (i, value) in tuple.iter().enumerate() {
+                if i > 0 {
+                    string.push_str(", ");
+                }
+                let inner_value_and_type = ValueAndType::new(value.clone(), inner_types[i].clone());
+                let inner_value_and_type = display_for_value_and_type(&inner_value_and_type);
+                string.push_str(&inner_value_and_type);
+            }
+            string.push(')');
+
+            string
+        }
+        Value::Record(values) => {
+            let inner_types = match &value_and_type.typ {
+                AnalysedType::Record(inner_types) => inner_types.fields.clone(),
+                _ => panic!("Expected a record type"),
+            };
+
+            let mut string = "{".to_string();
+            for (i, value) in values.iter().enumerate() {
+                if i > 0 {
+                    string.push_str(", ");
+                }
+                let inner_value_and_type =
+                    ValueAndType::new(value.clone(), inner_types[i].typ.clone());
+                let inner_value_and_type = display_for_value_and_type(&inner_value_and_type);
+                string.push_str(&format!(
+                    "{}: {}",
+                    inner_types[i].name, inner_value_and_type
+                ));
+            }
+            string.push('}');
+
+            string
+        }
+        Value::Variant {
+            case_idx,
+            case_value,
+        } => {
+            let variant_type = match &value_and_type.typ {
+                AnalysedType::Variant(variant_type) => variant_type,
+                _ => panic!("Expected a variant type"),
+            };
+
+            let case_name = variant_type
+                .cases
+                .get(*case_idx as usize)
+                .map_or("unknown", |c| &c.name);
+
+            match case_value {
+                Some(value) => {
+                    let inner_value_and_type = ValueAndType::new(
+                        value.as_ref().clone(),
+                        variant_type.cases[*case_idx as usize].clone().typ.unwrap(),
+                    );
+
+                    let inner_value_and_type = display_for_value_and_type(&inner_value_and_type);
+                    format!("{case_name}({inner_value_and_type})")
+                }
+
+                None => {
+                    // If the case has no value, just return the case name
+                    case_name.to_string()
+                }
+            }
+        }
+        Value::Enum(case_index) => {
+            let enum_type = match &value_and_type.typ {
+                AnalysedType::Enum(enum_type) => enum_type,
+                _ => panic!("Expected an enum type"),
+            };
+
+            let case_name = enum_type
+                .cases
+                .get(*case_index as usize)
+                .unwrap_or_else(|| {
+                    panic!("Enum case index out of bounds: {case_index}");
+                });
+            case_name.to_string()
+        }
+        Value::Flags(bool_list) => {
+            let flags_type = match &value_and_type.typ {
+                AnalysedType::Flags(flags_type) => flags_type,
+                _ => panic!("Expected a flags type"),
+            };
+
+            let mut string = "{".to_string();
+            for (i, value) in bool_list.iter().enumerate() {
+                if i > 0 {
+                    string.push_str(", ");
+                }
+                let flag_name = flags_type.names.get(i).unwrap_or_else(|| {
+                    panic!("Flags index out of bounds: {i}");
+                });
+
+                if *value {
+                    string.push_str(flag_name);
+                }
+            }
+            string.push('}');
+
+            string
+        }
+        Value::Option(option) => {
+            let inner_type = match &value_and_type.typ {
+                AnalysedType::Option(inner_type) => inner_type.inner.as_ref(),
+                _ => panic!("Expected an option type"),
+            };
+
+            match option {
+                Some(value) => {
+                    let inner_value_and_type =
+                        ValueAndType::new(value.as_ref().clone(), inner_type.clone());
+                    let inner_value_and_type = display_for_value_and_type(&inner_value_and_type);
+                    format!("some({inner_value_and_type})")
+                }
+                None => "none".to_string(),
+            }
+        }
+        Value::Result(result) => {
+            let x: &Result<Option<Box<Value>>, Option<Box<Value>>> = result;
+
+            let ok_inner_type: Option<&Box<AnalysedType>> = match &value_and_type.typ {
+                AnalysedType::Result(inner_type) => inner_type.ok.as_ref(),
+                _ => panic!("Expected a result type"),
+            };
+
+            let err_inner_type: Option<&Box<AnalysedType>> = match &value_and_type.typ {
+                AnalysedType::Result(inner_type) => inner_type.err.as_ref(),
+                _ => panic!("Expected a result type"),
+            };
+
+            match x {
+                Ok(Some(value)) => {
+                    let inner_value_and_type = ValueAndType::new(
+                        value.as_ref().clone(),
+                        ok_inner_type.unwrap().as_ref().clone(),
+                    );
+                    let inner_value_and_type = display_for_value_and_type(&inner_value_and_type);
+                    format!("ok({inner_value_and_type})")
+                }
+                Ok(None) => "ok".to_string(),
+                Err(Some(value)) => {
+                    let inner_value_and_type = ValueAndType::new(
+                        value.as_ref().clone(),
+                        err_inner_type.unwrap().as_ref().clone(),
+                    );
+                    let inner_value_and_type = display_for_value_and_type(&inner_value_and_type);
+                    format!("err({inner_value_and_type})")
+                }
+                Err(None) => "err".to_string(),
+            }
+        }
+        Value::Handle { uri, resource_id } => display_for_resource_handle(uri, resource_id),
+    }
+}
+
+fn display_for_resource_handle(uri: &str, resource_id: &u64) -> String {
+    let resource = Value::Record(vec![
+        Value::String(uri.to_string()),
+        Value::U64(*resource_id),
+    ]);
+
+    let analysed_type = record(vec![
+        NameTypePair {
+            name: "uri".to_string(),
+            typ: str(),
+        },
+        NameTypePair {
+            name: "resource-id".to_string(),
+            typ: u64(),
+        },
+    ]);
+
+    let result = ValueAndType::new(resource, analysed_type);
+
+    result.to_string()
+}
+
+fn try_formatting(input: &str, _indent: usize) -> String {
+    let mut result = String::new();
+    let mut depth = 0;
+    let chars: Vec<char> = input.chars().collect();
+    let mut i = 0;
+
+    while i < chars.len() {
+        match chars[i] {
+            '{' | '[' => {
+                // Check for empty object or array
+                let mut j = i + 1;
+                while j < chars.len() && chars[j].is_whitespace() {
+                    j += 1;
+                }
+                if j < chars.len() && (chars[j] == '}' || chars[j] == ']') {
+                    result.push(chars[i]);
+                    result.push(chars[j]);
+                    i = j + 1;
+                    continue;
+                }
+
+                depth += 1;
+                result.push(chars[i]);
+                result.push('\n');
+                result.push_str(&"  ".repeat(depth));
+                i += 1;
+            }
+            '}' | ']' => {
+                depth = depth.saturating_sub(1);
+                result.push('\n');
+                result.push_str(&"  ".repeat(depth));
+                result.push(chars[i]);
+                i += 1;
+            }
+            ',' => {
+                result.push(chars[i]);
+                result.push('\n');
+                result.push_str(&"  ".repeat(depth));
+                i += 1;
+                // Skip whitespace after comma
+                while i < chars.len() && chars[i].is_whitespace() && chars[i] != '\n' {
+                    i += 1;
+                }
+            }
+            _ => {
+                result.push(chars[i]);
+                i += 1;
+            }
+        }
+    }
+
+    result
+}
diff --git a/golem-rib/regression_tests/lib.rs b/golem-rib/regression_tests/lib.rs
index b5dda71b..c0ce8ac5 100644
--- a/golem-rib/regression_tests/lib.rs
+++ b/golem-rib/regression_tests/lib.rs
@@ -2,10 +2,10 @@ test_r::enable!();
 
 use test_r::test;
 
-use golem_wasm_ast::analysis::{
-    AnalysedType, NameTypePair, TypeBool, TypeF32, TypeF64, TypeRecord, TypeS16, TypeS32, TypeStr,
-    TypeU64, TypeU8,
+use golem_wasm_ast::analysis::analysed_type::{
+    bool, f32, f64, field, record, s16, s32, str, u64, u8,
 };
+use golem_wasm_ast::analysis::AnalysedType;
 use golem_wasm_rpc::ValueAndType;
 use rib::{
     EvaluatedFnArgs, EvaluatedFqFn, EvaluatedWorkerName, Expr, Interpreter, RibCompiler,
@@ -570,214 +570,59 @@ fn expected_value_and_type() -> ValueAndType {
 }
 
 fn expected_analysed_type() -> AnalysedType {
-    AnalysedType::Record(TypeRecord {
-        fields: vec![
-            NameTypePair {
-                name: "a".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "aa".to_string(),
-                typ: AnalysedType::U64(TypeU64),
-            },
-            NameTypePair {
-                name: "ab".to_string(),
-                typ: AnalysedType::S32(TypeS32),
-            },
-            NameTypePair {
-                name: "ac".to_string(),
-                typ: AnalysedType::F32(TypeF32),
-            },
-            NameTypePair {
-                name: "ad".to_string(),
-                typ: AnalysedType::F64(TypeF64),
-            },
-            NameTypePair {
-                name: "ae".to_string(),
-                typ: AnalysedType::Bool(TypeBool),
-            },
-            NameTypePair {
-                name: "af".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "ag".to_string(),
-                typ: AnalysedType::S16(TypeS16),
-            },
-            NameTypePair {
-                name: "ah".to_string(),
-                typ: AnalysedType::U8(TypeU8),
-            },
-            NameTypePair {
-                name: "ai".to_string(),
-                typ: AnalysedType::Bool(TypeBool),
-            },
-            NameTypePair {
-                name: "aj".to_string(),
-                typ: AnalysedType::F64(TypeF64),
-            },
-            NameTypePair {
-                name: "ak".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "b".to_string(),
-                typ: AnalysedType::U64(TypeU64),
-            },
-            NameTypePair {
-                name: "bb".to_string(),
-                typ: AnalysedType::U64(TypeU64),
-            },
-            NameTypePair {
-                name: "c".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "cc".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "d".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "dd".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "e".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "ee".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "f".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "ff".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "g".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "gg".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "h".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "hh".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "i".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "j".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "k".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "l".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "m".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "n".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "o".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "p".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "q".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "qq".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "r".to_string(),
-                typ: AnalysedType::U64(TypeU64),
-            },
-            NameTypePair {
-                name: "rr".to_string(),
-                typ: AnalysedType::U64(TypeU64),
-            },
-            NameTypePair {
-                name: "s".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "ss".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "t".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "tt".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "u".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "uu".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "v".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "vv".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "w".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "ww".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "x".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "y".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-            NameTypePair {
-                name: "z".to_string(),
-                typ: AnalysedType::Str(TypeStr),
-            },
-        ],
-    })
+    record(vec![
+        field("a", str()),
+        field("aa", u64()),
+        field("ab", s32()),
+        field("ac", f32()),
+        field("ad", f64()),
+        field("ae", bool()),
+        field("af", str()),
+        field("ag", s16()),
+        field("ah", u8()),
+        field("ai", bool()),
+        field("aj", f64()),
+        field("ak", str()),
+        field("b", u64()),
+        field("bb", u64()),
+        field("c", str()),
+        field("cc", str()),
+        field("d", str()),
+        field("dd", str()),
+        field("e", str()),
+        field("ee", str()),
+        field("f", str()),
+        field("ff", str()),
+        field("g", str()),
+        field("gg", str()),
+        field("h", str()),
+        field("hh", str()),
+        field("i", str()),
+        field("j", str()),
+        field("k", str()),
+        field("l", str()),
+        field("m", str()),
+        field("n", str()),
+        field("o", str()),
+        field("p", str()),
+        field("q", str()),
+        field("qq", str()),
+        field("r", u64()),
+        field("rr", u64()),
+        field("s", str()),
+        field("ss", str()),
+        field("t", str()),
+        field("tt", str()),
+        field("u", str()),
+        field("uu", str()),
+        field("v", str()),
+        field("vv", str()),
+        field("w", str()),
+        field("ww", str()),
+        field("x", str()),
+        field("y", str()),
+        field("z", str()),
+    ])
 }
 
 mod component_metadata {
@@ -1311,269 +1156,198 @@ mod function_metadata {
 }
 
 mod data_types {
-    use crate::test_utils;
+    use golem_wasm_ast::analysis::analysed_type::{
+        bool, case, chr, f32, f64, field, flags, list, option, r#enum, record, result, s16, s32,
+        s64, s8, str, tuple, u16, u32, u64, u8, unit_case, variant,
+    };
     use golem_wasm_ast::analysis::*;
 
     // Result
     pub(crate) fn result_of_str_type() -> AnalysedType {
-        AnalysedType::Result(TypeResult {
-            ok: Some(Box::new(AnalysedType::Str(TypeStr))),
-            err: Some(Box::new(AnalysedType::Str(TypeStr))),
-        })
+        result(str(), str())
     }
 
     pub(crate) fn result_of_number_type() -> AnalysedType {
-        AnalysedType::Result(TypeResult {
-            ok: Some(Box::new(AnalysedType::U64(TypeU64))),
-            err: Some(Box::new(AnalysedType::U64(TypeU64))),
-        })
+        result(u64(), u64())
     }
 
     pub(crate) fn result_of_option_type() -> AnalysedType {
-        AnalysedType::Result(TypeResult {
-            ok: Some(Box::new(option_of_str_type())),
-            err: Some(Box::new(option_of_str_type())),
-        })
+        result(option_of_str_type(), option_of_str_type())
     }
 
     pub(crate) fn result_of_variant_type() -> AnalysedType {
-        AnalysedType::Result(TypeResult {
-            ok: Some(Box::new(variant_type())),
-            err: Some(Box::new(variant_type())),
-        })
+        result(variant_type(), variant_type())
     }
 
     pub(crate) fn result_of_enum_type() -> AnalysedType {
-        AnalysedType::Result(TypeResult {
-            ok: Some(Box::new(enum_type())),
-            err: Some(Box::new(enum_type())),
-        })
+        result(enum_type(), enum_type())
     }
 
     pub(crate) fn result_of_tuple_type() -> AnalysedType {
-        AnalysedType::Result(TypeResult {
-            ok: Some(Box::new(tuple_type())),
-            err: Some(Box::new(tuple_type())),
-        })
+        result(tuple_type(), tuple_type())
     }
 
     pub(crate) fn result_of_flag_type() -> AnalysedType {
-        AnalysedType::Result(TypeResult {
-            ok: Some(Box::new(flag_type())),
-            err: Some(Box::new(flag_type())),
-        })
+        result(flag_type(), flag_type())
     }
 
     pub(crate) fn result_of_record_type() -> AnalysedType {
-        AnalysedType::Result(TypeResult {
-            ok: Some(Box::new(record_type())),
-            err: Some(Box::new(record_type())),
-        })
+        result(record_type(), record_type())
     }
 
     pub(crate) fn result_of_list_type() -> AnalysedType {
-        AnalysedType::Result(TypeResult {
-            ok: Some(Box::new(list_of_str_type())),
-            err: Some(Box::new(list_of_str_type())),
-        })
+        result(list_of_str_type(), list_of_str_type())
     }
 
     // List
     pub(crate) fn list_of_number_type_type() -> AnalysedType {
-        AnalysedType::List(TypeList {
-            inner: Box::new(AnalysedType::U64(TypeU64)),
-        })
+        list(u64())
     }
 
     pub(crate) fn list_of_str_type() -> AnalysedType {
-        AnalysedType::List(TypeList {
-            inner: Box::new(AnalysedType::Str(TypeStr)),
-        })
+        list(str())
     }
 
     pub(crate) fn list_of_option_type() -> AnalysedType {
-        AnalysedType::List(TypeList {
-            inner: Box::new(AnalysedType::Option(TypeOption {
-                inner: Box::new(AnalysedType::Str(TypeStr)),
-            })),
-        })
+        list(option(str()))
     }
 
     pub(crate) fn list_of_list_type() -> AnalysedType {
-        AnalysedType::List(TypeList {
-            inner: Box::new(AnalysedType::List(TypeList {
-                inner: Box::new(AnalysedType::Str(TypeStr)),
-            })),
-        })
+        list(list(str()))
     }
 
     pub(crate) fn list_of_variant_type() -> AnalysedType {
-        AnalysedType::List(TypeList {
-            inner: Box::new(variant_type()),
-        })
+        list(variant_type())
     }
 
     pub(crate) fn list_of_enum_type() -> AnalysedType {
-        AnalysedType::List(TypeList {
-            inner: Box::new(enum_type()),
-        })
+        list(enum_type())
     }
 
     pub(crate) fn list_of_tuple() -> AnalysedType {
-        AnalysedType::List(TypeList {
-            inner: Box::new(tuple_type()),
-        })
+        list(tuple_type())
     }
 
     pub(crate) fn list_of_record_type() -> AnalysedType {
-        AnalysedType::List(TypeList {
-            inner: Box::new(record_type()),
-        })
+        list(record_type())
     }
 
     pub(crate) fn option_of_number_type() -> AnalysedType {
-        AnalysedType::Option(TypeOption {
-            inner: Box::new(AnalysedType::U64(TypeU64)),
-        })
+        option(u64())
     }
 
     // Option
     pub(crate) fn option_of_str_type() -> AnalysedType {
-        AnalysedType::Option(TypeOption {
-            inner: Box::new(AnalysedType::Str(TypeStr)),
-        })
+        option(str())
     }
 
     pub(crate) fn option_of_option_type() -> AnalysedType {
-        AnalysedType::Option(TypeOption {
-            inner: Box::new(AnalysedType::Option(TypeOption {
-                inner: Box::new(AnalysedType::Str(TypeStr)),
-            })),
-        })
+        option(option(str()))
     }
 
     pub(crate) fn option_of_variant_type() -> AnalysedType {
-        AnalysedType::Option(TypeOption {
-            inner: Box::new(variant_type()),
-        })
+        option(variant_type())
     }
 
     pub(crate) fn option_of_enum_type() -> AnalysedType {
-        AnalysedType::Option(TypeOption {
-            inner: Box::new(enum_type()),
-        })
+        option(enum_type())
     }
 
     pub(crate) fn option_of_tuple() -> AnalysedType {
-        AnalysedType::Option(TypeOption {
-            inner: Box::new(tuple_type()),
-        })
+        option(tuple_type())
     }
 
     pub(crate) fn option_of_record_type() -> AnalysedType {
-        AnalysedType::Option(TypeOption {
-            inner: Box::new(record_type()),
-        })
+        option(record_type())
     }
 
     pub(crate) fn option_of_list() -> AnalysedType {
-        AnalysedType::Option(TypeOption {
-            inner: Box::new(AnalysedType::List(TypeList {
-                inner: Box::new(AnalysedType::Str(TypeStr)),
-            })),
-        })
+        option(list(str()))
     }
 
     // Record
     pub(crate) fn record_type() -> AnalysedType {
-        test_utils::analysed_type_record(vec![
-            (
+        record(vec![
+            field(
                 "string-headers",
-                test_utils::analysed_type_record(vec![(
-                    "authorization-string",
-                    AnalysedType::Str(TypeStr),
-                )]),
+                record(vec![field("authorization-string", str())]),
             ),
-            (
+            field(
                 "data-body",
-                test_utils::analysed_type_record(vec![
-                    ("str", AnalysedType::Str(TypeStr)),
-                    ("list-of-str", list_of_str_type()),
-                    ("list-of-option", list_of_option_type()),
-                    ("list-of-list", list_of_list_type()),
-                    ("list-of-variant", list_of_variant_type()),
-                    ("list-of-enum", list_of_enum_type()),
-                    ("list-of-tuple", list_of_tuple()),
-                    (
+                record(vec![
+                    field("str", str()),
+                    field("list-of-str", list_of_str_type()),
+                    field("list-of-option", list_of_option_type()),
+                    field("list-of-list", list_of_list_type()),
+                    field("list-of-variant", list_of_variant_type()),
+                    field("list-of-enum", list_of_enum_type()),
+                    field("list-of-tuple", list_of_tuple()),
+                    field(
                         "list-of-record",
-                        AnalysedType::List(TypeList {
-                            inner: Box::new(test_utils::analysed_type_record(vec![
-                                ("field-string-one", AnalysedType::Str(TypeStr)),
-                                ("field-string-two", AnalysedType::Str(TypeStr)),
-                            ])),
-                        }),
+                        list(record(vec![
+                            field("field-string-one", str()),
+                            field("field-string-two", str()),
+                        ])),
                     ),
-                    ("option-of-str", option_of_str_type()),
-                    ("option-of-option", option_of_option_type()),
-                    ("option-of-variant", option_of_variant_type()),
-                    ("option-of-enum", option_of_enum_type()),
-                    ("option-of-tuple", option_of_tuple()),
-                    (
+                    field("option-of-str", option_of_str_type()),
+                    field("option-of-option", option_of_option_type()),
+                    field("option-of-variant", option_of_variant_type()),
+                    field("option-of-enum", option_of_enum_type()),
+                    field("option-of-tuple", option_of_tuple()),
+                    field(
                         "option-of-record",
-                        AnalysedType::Option(TypeOption {
-                            inner: Box::new(test_utils::analysed_type_record(vec![
-                                ("field-string-one", AnalysedType::Str(TypeStr)),
-                                ("field-string-two", AnalysedType::Str(TypeStr)),
-                            ])),
-                        }),
+                        option(record(vec![
+                            field("field-string-one", str()),
+                            field("field-string-two", str()),
+                        ])),
                     ),
-                    ("option-of-list", option_of_list()),
-                    (
+                    field("option-of-list", option_of_list()),
+                    field(
                         "nested-record",
-                        test_utils::analysed_type_record(vec![
-                            ("field-string-one", AnalysedType::Str(TypeStr)),
-                            ("field-string-two", AnalysedType::Str(TypeStr)),
+                        record(vec![
+                            field("field-string-one", str()),
+                            field("field-string-two", str()),
                         ]),
                     ),
-                    ("variant-data-a", variant_type()),
-                    ("variant-data-b", variant_type()),
-                    ("variant-data-c", variant_type()),
-                    ("variant-data-d", variant_type()),
-                    ("variant-data-e", variant_type()),
-                    ("variant-data-f", variant_type()),
-                    ("enum-data-a", enum_type()),
-                    ("enum-data-b", enum_type()),
-                    ("enum-data-c", enum_type()),
-                    ("flags-data-a", flag_type()),
-                    ("flags-data-b", flag_type()),
-                    ("flags-data-c", flag_type()),
-                    ("result-data-a", result_of_str_type()),
-                    ("result-data-b", result_of_number_type()),
-                    ("result-data-c", result_of_enum_type()),
-                    ("result-data-d", result_of_variant_type()),
-                    ("result-data-e", result_of_tuple_type()),
-                    ("result-data-f", result_of_option_type()),
-                    ("result-data-g", result_of_str_type()),
-                    ("result-data-h", result_of_number_type()),
-                    ("result-data-i", result_of_enum_type()),
-                    ("result-data-j", result_of_variant_type()),
-                    ("result-data-k", result_of_tuple_type()),
-                    ("result-data-l", result_of_option_type()),
-                    ("result-data-m", result_of_flag_type()),
-                    ("result-data-n", result_of_flag_type()),
-                    ("tuple-data", tuple_type()),
-                    ("character-data", AnalysedType::Chr(TypeChr)),
-                    ("f64-data", AnalysedType::F64(TypeF64)),
-                    ("f32-data", AnalysedType::F32(TypeF32)),
-                    ("u64-data", AnalysedType::U64(TypeU64)),
-                    ("s64-data", AnalysedType::S64(TypeS64)),
-                    ("u32-data", AnalysedType::U32(TypeU32)),
-                    ("s32-data", AnalysedType::S32(TypeS32)),
-                    ("u16-data", AnalysedType::U16(TypeU16)),
-                    ("s16-data", AnalysedType::S16(TypeS16)),
-                    ("u8-data", AnalysedType::U8(TypeU8)),
-                    ("s8-data", AnalysedType::S8(TypeS8)),
-                    ("boolean-data", AnalysedType::Bool(TypeBool)),
+                    field("variant-data-a", variant_type()),
+                    field("variant-data-b", variant_type()),
+                    field("variant-data-c", variant_type()),
+                    field("variant-data-d", variant_type()),
+                    field("variant-data-e", variant_type()),
+                    field("variant-data-f", variant_type()),
+                    field("enum-data-a", enum_type()),
+                    field("enum-data-b", enum_type()),
+                    field("enum-data-c", enum_type()),
+                    field("flags-data-a", flag_type()),
+                    field("flags-data-b", flag_type()),
+                    field("flags-data-c", flag_type()),
+                    field("result-data-a", result_of_str_type()),
+                    field("result-data-b", result_of_number_type()),
+                    field("result-data-c", result_of_enum_type()),
+                    field("result-data-d", result_of_variant_type()),
+                    field("result-data-e", result_of_tuple_type()),
+                    field("result-data-f", result_of_option_type()),
+                    field("result-data-g", result_of_str_type()),
+                    field("result-data-h", result_of_number_type()),
+                    field("result-data-i", result_of_enum_type()),
+                    field("result-data-j", result_of_variant_type()),
+                    field("result-data-k", result_of_tuple_type()),
+                    field("result-data-l", result_of_option_type()),
+                    field("result-data-m", result_of_flag_type()),
+                    field("result-data-n", result_of_flag_type()),
+                    field("tuple-data", tuple_type()),
+                    field("character-data", chr()),
+                    field("f64-data", f64()),
+                    field("f32-data", f32()),
+                    field("u64-data", u64()),
+                    field("s64-data", s64()),
+                    field("u32-data", u32()),
+                    field("s32-data", s32()),
+                    field("u16-data", u16()),
+                    field("s16-data", s16()),
+                    field("u8-data", u8()),
+                    field("s8-data", s8()),
+                    field("boolean-data", bool()),
                 ]),
             ),
         ])
@@ -1581,169 +1355,62 @@ mod data_types {
 
     // Tuple
     pub(crate) fn tuple_type() -> AnalysedType {
-        AnalysedType::Tuple(TypeTuple {
-            items: vec![
-                AnalysedType::Str(TypeStr),
-                AnalysedType::U64(TypeU64),
-                AnalysedType::S32(TypeS32),
-                AnalysedType::F32(TypeF32),
-                AnalysedType::F64(TypeF64),
-                AnalysedType::Bool(TypeBool),
-                AnalysedType::Chr(TypeChr),
-                AnalysedType::Option(TypeOption {
-                    inner: Box::new(AnalysedType::S16(TypeS16)),
-                }),
-                AnalysedType::Result(TypeResult {
-                    ok: Some(Box::new(AnalysedType::U8(TypeU8))),
-                    err: Some(Box::new(AnalysedType::S8(TypeS8))),
-                }),
-                AnalysedType::List(TypeList {
-                    inner: Box::new(AnalysedType::Bool(TypeBool)),
-                }),
-                AnalysedType::Variant(TypeVariant {
-                    cases: vec![
-                        NameOptionTypePair {
-                            name: "case-hello".to_string(),
-                            typ: Some(AnalysedType::F64(TypeF64)),
-                        },
-                        NameOptionTypePair {
-                            name: "case-none".to_string(),
-                            typ: None,
-                        },
-                    ],
-                }),
-                AnalysedType::Record(TypeRecord {
-                    // Option<Record>
-                    fields: vec![
-                        NameTypePair {
-                            name: "field-one".to_string(),
-                            typ: AnalysedType::Bool(TypeBool),
-                        },
-                        NameTypePair {
-                            name: "field-two".to_string(),
-                            typ: AnalysedType::Str(TypeStr),
-                        },
-                    ],
-                }),
-            ],
-        })
+        tuple(vec![
+            str(),
+            u64(),
+            s32(),
+            f32(),
+            f64(),
+            bool(),
+            chr(),
+            option(s16()),
+            result(u8(), s8()),
+            list(bool()),
+            variant(vec![case("case-hello", f64()), unit_case("case-none")]),
+            record(vec![field("field-one", bool()), field("field-two", str())]),
+        ])
     }
 
     // Enum
     pub(crate) fn enum_type() -> AnalysedType {
-        AnalysedType::Enum(TypeEnum {
-            cases: vec![
-                "enum-a".to_string(),
-                "enum-b".to_string(),
-                "enum-c".to_string(),
-            ],
-        })
+        r#enum(&["enum-a", "enum-b", "enum-c"])
     }
 
     // Str
     pub(crate) fn str_type() -> AnalysedType {
-        AnalysedType::Str(TypeStr)
+        str()
     }
 
     // Number
     pub(crate) fn number_type() -> AnalysedType {
-        AnalysedType::U64(TypeU64)
+        u64()
     }
 
     // Flag
     pub(crate) fn flag_type() -> AnalysedType {
-        AnalysedType::Flags(TypeFlags {
-            names: vec![
-                "featurex".to_string(),
-                "featurey".to_string(),
-                "featurez".to_string(),
-            ],
-        })
+        flags(&["featurex", "featurey", "featurez"])
     }
 
     // Variant
     pub(crate) fn variant_type() -> AnalysedType {
-        AnalysedType::Variant(TypeVariant {
-            cases: vec![
-                NameOptionTypePair {
-                    name: "case-none".to_string(),
-                    typ: None,
-                },
-                NameOptionTypePair {
-                    name: "case-str".to_string(),
-                    typ: Some(AnalysedType::Str(TypeStr)), // Variant case for String
-                },
-                NameOptionTypePair {
-                    name: "case-u64".to_string(),
-                    typ: Some(AnalysedType::U64(TypeU64)), // Variant case for u64
-                },
-                NameOptionTypePair {
-                    name: "case-s32".to_string(),
-                    typ: Some(AnalysedType::S32(TypeS32)), // Variant case for i32
-                },
-                NameOptionTypePair {
-                    name: "case-f32".to_string(),
-                    typ: Some(AnalysedType::F32(TypeF32)), // Variant case for f32
-                },
-                NameOptionTypePair {
-                    name: "case-f64".to_string(),
-                    typ: Some(AnalysedType::F64(TypeF64)), // Variant case for f64
-                },
-                NameOptionTypePair {
-                    name: "case-bool".to_string(),
-                    typ: Some(AnalysedType::Bool(TypeBool)), // Variant case for bool
-                },
-                NameOptionTypePair {
-                    name: "case-chr".to_string(),
-                    typ: Some(AnalysedType::Chr(TypeChr)), // Variant case for char
-                },
-                NameOptionTypePair {
-                    name: "case-list".to_string(),
-                    typ: Some(AnalysedType::List(TypeList {
-                        // Variant case for List
-                        inner: Box::new(AnalysedType::S16(TypeS16)),
-                    })),
-                },
-                NameOptionTypePair {
-                    name: "case-option".to_string(),
-                    typ: Some(AnalysedType::Option(TypeOption {
-                        // Variant case for Option
-                        inner: Box::new(AnalysedType::U16(TypeU16)),
-                    })),
-                },
-                NameOptionTypePair {
-                    name: "case-result".to_string(),
-                    typ: Some(AnalysedType::Result(TypeResult {
-                        // Variant case for Result
-                        ok: Some(Box::new(AnalysedType::U8(TypeU8))),
-                        err: Some(Box::new(AnalysedType::S8(TypeS8))),
-                    })),
-                },
-                NameOptionTypePair {
-                    name: "case-record".to_string(),
-                    typ: Some(AnalysedType::Record(TypeRecord {
-                        // Variant case for Record
-                        fields: vec![
-                            NameTypePair {
-                                name: "field1".to_string(),
-                                typ: AnalysedType::Str(TypeStr),
-                            },
-                            NameTypePair {
-                                name: "field2".to_string(),
-                                typ: AnalysedType::Bool(TypeBool),
-                            },
-                        ],
-                    })),
-                },
-                NameOptionTypePair {
-                    name: "case-tuple".to_string(),
-                    typ: Some(AnalysedType::Tuple(TypeTuple {
-                        // Variant case for Tuple
-                        items: vec![AnalysedType::F32(TypeF32), AnalysedType::U32(TypeU32)],
-                    })),
-                },
-            ],
-        })
+        variant(vec![
+            unit_case("case-none"),
+            case("case-str", str()),
+            case("case-u64", u64()),
+            case("case-s32", s32()),
+            case("case-f32", f32()),
+            case("case-f64", f64()),
+            case("case-bool", bool()),
+            case("case-chr", chr()),
+            case("case-list", list(s16())),
+            case("case-option", option(u16())),
+            case("case-result", result(u8(), s8())),
+            case(
+                "case-record",
+                record(vec![field("field1", str()), field("field2", bool())]),
+            ),
+            case("case-tuple", tuple(vec![f32(), u32()])),
+        ])
     }
 }
 
@@ -2049,7 +1716,8 @@ mod mock_interpreter {
     };
     use async_trait::async_trait;
 
-    use golem_wasm_ast::analysis::{AnalysedType, TypeStr};
+    use golem_wasm_ast::analysis::analysed_type::{field, record, str};
+    use golem_wasm_ast::analysis::AnalysedType;
     use golem_wasm_rpc::ValueAndType;
     use rib::{ComponentDependencyKey, DefaultWorkerNameGenerator, InstructionId};
     use std::collections::HashMap;
@@ -2208,19 +1876,10 @@ mod mock_interpreter {
                 .map(|(name, result)| (FunctionName(name.to_string()), result))
                 .collect();
 
-        let record_input_type = test_utils::analysed_type_record(vec![
-            (
-                "headers",
-                test_utils::analysed_type_record(vec![("name", AnalysedType::Str(TypeStr))]),
-            ),
-            (
-                "body",
-                test_utils::analysed_type_record(vec![("name", AnalysedType::Str(TypeStr))]),
-            ),
-            (
-                "path",
-                test_utils::analysed_type_record(vec![("name", AnalysedType::Str(TypeStr))]),
-            ),
+        let record_input_type = record(vec![
+            field("headers", record(vec![field("name", str())])),
+            field("body", record(vec![field("name", str())])),
+            field("path", record(vec![field("name", str())])),
         ]);
 
         let record_input_value = test_utils::get_value_and_type(
@@ -2262,7 +1921,7 @@ mod mock_interpreter {
             &self,
             _component_info: ComponentDependencyKey,
             _instruction_id: &InstructionId,
-            _worker_name: Option<EvaluatedWorkerName>,
+            _worker_name: EvaluatedWorkerName,
             function_name: EvaluatedFqFn,
             _args: EvaluatedFnArgs,
             _return_type: Option<AnalysedType>,
@@ -2284,18 +1943,6 @@ mod test_utils {
     use golem_wasm_ast::analysis::*;
     use golem_wasm_rpc::ValueAndType;
 
-    pub(crate) fn analysed_type_record(fields: Vec<(&str, AnalysedType)>) -> AnalysedType {
-        AnalysedType::Record(TypeRecord {
-            fields: fields
-                .into_iter()
-                .map(|(name, typ)| NameTypePair {
-                    name: name.to_string(),
-                    typ,
-                })
-                .collect(),
-        })
-    }
-
     pub(crate) fn get_value_and_type(
         analysed_type: &AnalysedType,
         wasm_wave_str: &str,
diff --git a/golem-rib/src/compiler/byte_code.rs b/golem-rib/src/compiler/byte_code.rs
index 7de1d601..72729023 100644
--- a/golem-rib/src/compiler/byte_code.rs
+++ b/golem-rib/src/compiler/byte_code.rs
@@ -469,9 +469,9 @@ mod internal {
 
                         let instance_variable = match module.as_ref() {
                             InstanceIdentifier::WitResource { variable_id, .. } => {
-                                let variable_id = variable_id.clone().ok_or({
-                                    RibByteCodeGenerationError::UnresolvedResourceVariable
-                                })?;
+                                let variable_id = variable_id.clone().unwrap_or_else(|| {
+                                    VariableId::global("___STATIC_WIT_RESOURCE".to_string())
+                                });
                                 InstanceVariable::WitResource(variable_id)
                             }
                             InstanceIdentifier::WitWorker { variable_id, .. } => {
@@ -544,70 +544,6 @@ mod internal {
                                     method: method.clone(),
                                 },
                             )),
-                            DynamicParsedFunctionReference::IndexedResourceConstructor {
-                                resource,
-                                resource_params,
-                            } => {
-                                for param in resource_params {
-                                    stack.push(ExprState::from_expr(param));
-                                }
-                                instructions.push(RibIR::CreateFunctionName(
-                                    site,
-                                    FunctionReferenceType::IndexedResourceConstructor {
-                                        resource: resource.clone(),
-                                        arg_size: resource_params.len(),
-                                    },
-                                ))
-                            }
-                            DynamicParsedFunctionReference::IndexedResourceMethod {
-                                resource,
-                                resource_params,
-                                method,
-                            } => {
-                                for param in resource_params {
-                                    stack.push(ExprState::from_expr(param));
-                                }
-                                instructions.push(RibIR::CreateFunctionName(
-                                    site,
-                                    FunctionReferenceType::IndexedResourceMethod {
-                                        resource: resource.clone(),
-                                        arg_size: resource_params.len(),
-                                        method: method.clone(),
-                                    },
-                                ))
-                            }
-                            DynamicParsedFunctionReference::IndexedResourceStaticMethod {
-                                resource,
-                                resource_params,
-                                method,
-                            } => {
-                                for param in resource_params {
-                                    stack.push(ExprState::from_expr(param));
-                                }
-                                instructions.push(RibIR::CreateFunctionName(
-                                    site,
-                                    FunctionReferenceType::IndexedResourceStaticMethod {
-                                        resource: resource.clone(),
-                                        arg_size: resource_params.len(),
-                                        method: method.clone(),
-                                    },
-                                ))
-                            }
-                            DynamicParsedFunctionReference::IndexedResourceDrop {
-                                resource,
-                                resource_params,
-                            } => {
-                                for param in resource_params {
-                                    stack.push(ExprState::from_expr(param));
-                                }
-                                instructions.push(RibIR::CreateFunctionName(
-                                    site,
-                                    FunctionReferenceType::IndexedResourceDrop {
-                                        resource: resource.clone(),
-                                        arg_size: resource_params.len(),
-                                    },
-                                ))
-                            }
                         }
                     }
 
@@ -726,6 +662,8 @@ mod internal {
                         value: Value::Flags(bitmap),
                         typ: AnalysedType::Flags(TypeFlags {
                             names: all_flags.iter().map(|n| n.to_string()).collect(),
+                            owner: None,
+                            name: None,
                         }),
                     }));
                 }
@@ -1017,8 +955,8 @@ mod compiler_tests {
 
     use super::*;
     use crate::{ArmPattern, InferredType, MatchArm, RibCompiler, VariableId};
-    use golem_wasm_ast::analysis::analysed_type::{list, s32, str};
-    use golem_wasm_ast::analysis::{AnalysedType, NameTypePair, TypeRecord, TypeStr};
+    use golem_wasm_ast::analysis::analysed_type;
+    use golem_wasm_ast::analysis::analysed_type::{field, list, record, s32, str};
     use golem_wasm_rpc::{IntoValueAndType, Value, ValueAndType};
 
     #[test]
@@ -1267,18 +1205,10 @@ mod compiler_tests {
         let instruction_set = vec![
             RibIR::PushLit(bar_value),
             RibIR::PushLit(foo_value),
-            RibIR::CreateAndPushRecord(AnalysedType::Record(TypeRecord {
-                fields: vec![
-                    NameTypePair {
-                        name: "foo_key".to_string(),
-                        typ: AnalysedType::Str(TypeStr),
-                    },
-                    NameTypePair {
-                        name: "bar_key".to_string(),
-                        typ: AnalysedType::Str(TypeStr),
-                    },
-                ],
-            })),
+            RibIR::CreateAndPushRecord(record(vec![
+                field("foo_key", str()),
+                field("bar_key", str()),
+            ])),
             RibIR::UpdateRecord("foo_key".to_string()),
             RibIR::UpdateRecord("bar_key".to_string()),
         ];
@@ -1419,18 +1349,10 @@ mod compiler_tests {
         let instruction_set = vec![
             RibIR::PushLit(bar_value),
             RibIR::PushLit(foo_value),
-            RibIR::CreateAndPushRecord(AnalysedType::Record(TypeRecord {
-                fields: vec![
-                    NameTypePair {
-                        name: "bar_key".to_string(),
-                        typ: AnalysedType::Str(TypeStr),
-                    },
-                    NameTypePair {
-                        name: "foo_key".to_string(),
-                        typ: AnalysedType::Str(TypeStr),
-                    },
-                ],
-            })),
+            RibIR::CreateAndPushRecord(analysed_type::record(vec![
+                field("bar_key", str()),
+                field("foo_key", str()),
+            ])),
             RibIR::UpdateRecord("foo_key".to_string()), // next pop is foo_value
             RibIR::UpdateRecord("bar_key".to_string()), // last pop is bar_value
             RibIR::SelectField("bar_key".to_string()),
@@ -1539,7 +1461,7 @@ mod compiler_tests {
 
         use crate::compiler::byte_code::compiler_tests::internal;
         use crate::{Expr, RibCompiler, RibCompilerConfig};
-        use golem_wasm_ast::analysis::{AnalysedType, TypeStr};
+        use golem_wasm_ast::analysis::analysed_type::str;
 
         #[test]
         fn test_unknown_function() {
@@ -1556,36 +1478,9 @@ mod compiler_tests {
             assert_eq!(compiler_error, "error in the following rib found at line 2, column 16\n`foo(request)`\ncause: invalid function call `foo`\nunknown function\n");
         }
 
-        #[test]
-        fn test_unknown_resource_method() {
-            let metadata = internal::metadata_with_resource_methods();
-            let expr = r#"
-               let user_id = "user";
-               golem:it/api.{cart(user_id).add-item}("apple");
-               golem:it/api.{cart(user_id).foo}("apple");
-                "success"
-            "#;
-
-            let expr = Expr::from_text(expr).unwrap();
-
-            let compiler_config = RibCompilerConfig::new(metadata, vec![]);
-
-            let compiler = RibCompiler::new(compiler_config);
-
-            let compiler_error = compiler.compile(expr).unwrap_err().to_string();
-            assert_eq!(
-                compiler_error,
-                "error in the following rib found at line 4, column 16\n`foo(\"apple\")`\ncause: invalid function call `foo`\nunknown function\n"
-            );
-        }
-
         #[test]
         fn test_invalid_arg_size_function() {
-            let metadata = internal::get_component_metadata(
-                "foo",
-                vec![AnalysedType::Str(TypeStr)],
-                AnalysedType::Str(TypeStr),
-            );
+            let metadata = internal::get_component_metadata("foo", vec![str()], str());
 
             let expr = r#"
                let user_id = "user";
@@ -1606,35 +1501,9 @@ mod compiler_tests {
             );
         }
 
-        #[test]
-        fn test_invalid_arg_size_resource_method() {
-            let metadata = internal::metadata_with_resource_methods();
-            let expr = r#"
-               let user_id = "user";
-               golem:it/api.{cart(user_id).add-item}("apple", "samsung");
-                "success"
-            "#;
-
-            let expr = Expr::from_text(expr).unwrap();
-
-            let compiler_config = RibCompilerConfig::new(metadata, vec![]);
-
-            let compiler = RibCompiler::new(compiler_config);
-
-            let compiler_error = compiler.compile(expr).unwrap_err().to_string();
-            assert_eq!(
-                compiler_error,
-                "error in the following rib found at line 3, column 16\n`add-item(\"apple\", \"samsung\")`\ncause: invalid argument size for function `add-item`. expected 1 arguments, found 2\n"
-            );
-        }
-
         #[test]
         fn test_invalid_arg_types_function() {
-            let metadata = internal::get_component_metadata(
-                "foo",
-                vec![AnalysedType::Str(TypeStr)],
-                AnalysedType::Str(TypeStr),
-            );
+            let metadata = internal::get_component_metadata("foo", vec![str()], str());
 
             let expr = r#"
                let result = foo(1u64);
@@ -1654,28 +1523,6 @@ mod compiler_tests {
             );
         }
 
-        #[test]
-        fn test_invalid_arg_types_resource_method() {
-            let metadata = internal::metadata_with_resource_methods();
-            let expr = r#"
-               let user_id = "user";
-               golem:it/api.{cart(user_id).add-item}("apple");
-                "success"
-            "#;
-
-            let expr = Expr::from_text(expr).unwrap();
-
-            let compiler_config = RibCompilerConfig::new(metadata, vec![]);
-
-            let compiler = RibCompiler::new(compiler_config);
-
-            let compiler_error = compiler.compile(expr).unwrap_err().to_string();
-            assert_eq!(
-                compiler_error,
-                "error in the following rib found at line 3, column 54\n`\"apple\"`\ncause: type mismatch. expected record { name: string }, found string\ninvalid argument to the function `add-item`\n"
-            );
-        }
-
         #[test]
         fn test_invalid_arg_types_variants() {
             let metadata = internal::metadata_with_variants();
@@ -1706,16 +1553,16 @@ mod compiler_tests {
 
         use crate::compiler::byte_code::compiler_tests::internal;
         use crate::{Expr, RibCompiler, RibCompilerConfig};
-        use golem_wasm_ast::analysis::{
-            AnalysedType, NameOptionTypePair, NameTypePair, TypeEnum, TypeList, TypeOption,
-            TypeRecord, TypeResult, TypeStr, TypeTuple, TypeU32, TypeU64, TypeVariant,
+        use golem_wasm_ast::analysis::analysed_type::{
+            case, field, list, option, r#enum, record, result, str, tuple, u32, u64, unit_case,
+            variant,
         };
 
         #[test]
         async fn test_str_global_input() {
-            let request_value_type = AnalysedType::Str(TypeStr);
+            let request_value_type = str();
 
-            let output_analysed_type = AnalysedType::Str(TypeStr);
+            let output_analysed_type = str();
 
             let analysed_exports = internal::get_component_metadata(
                 "my-worker-function",
@@ -1744,9 +1591,9 @@ mod compiler_tests {
 
         #[test]
         async fn test_number_global_input() {
-            let request_value_type = AnalysedType::U32(TypeU32);
+            let request_value_type = u32();
 
-            let output_analysed_type = AnalysedType::Str(TypeStr);
+            let output_analysed_type = str();
 
             let analysed_exports = internal::get_component_metadata(
                 "my-worker-function",
@@ -1775,24 +1622,13 @@ mod compiler_tests {
 
         #[test]
         async fn test_variant_type_info() {
-            let request_value_type = AnalysedType::Variant(TypeVariant {
-                cases: vec![
-                    NameOptionTypePair {
-                        name: "register-user".to_string(),
-                        typ: Some(AnalysedType::U64(TypeU64)),
-                    },
-                    NameOptionTypePair {
-                        name: "process-user".to_string(),
-                        typ: Some(AnalysedType::Str(TypeStr)),
-                    },
-                    NameOptionTypePair {
-                        name: "validate".to_string(),
-                        typ: None,
-                    },
-                ],
-            });
+            let request_value_type = variant(vec![
+                case("register-user", u64()),
+                case("process-user", str()),
+                unit_case("validate"),
+            ]);
 
-            let output_analysed_type = AnalysedType::Str(TypeStr);
+            let output_analysed_type = str();
 
             let analysed_exports = internal::get_component_metadata(
                 "my-worker-function",
@@ -1826,12 +1662,9 @@ mod compiler_tests {
 
         #[test]
         async fn test_result_type_info() {
-            let request_value_type = AnalysedType::Result(TypeResult {
-                ok: Some(Box::new(AnalysedType::U64(TypeU64))),
-                err: Some(Box::new(AnalysedType::Str(TypeStr))),
-            });
+            let request_value_type = result(u64(), str());
 
-            let output_analysed_type = AnalysedType::Str(TypeStr);
+            let output_analysed_type = str();
 
             let analysed_exports = internal::get_component_metadata(
                 "my-worker-function",
@@ -1865,11 +1698,9 @@ mod compiler_tests {
 
         #[test]
         async fn test_option_type_info() {
-            let request_value_type = AnalysedType::Option(TypeOption {
-                inner: Box::new(AnalysedType::Str(TypeStr)),
-            });
+            let request_value_type = option(str());
 
-            let output_analysed_type = AnalysedType::Str(TypeStr);
+            let output_analysed_type = str();
 
             let analysed_exports = internal::get_component_metadata(
                 "my-worker-function",
@@ -1903,11 +1734,8 @@ mod compiler_tests {
 
         #[test]
         async fn test_enum_type_info() {
-            let request_value_type = AnalysedType::Enum(TypeEnum {
-                cases: vec!["prod".to_string(), "dev".to_string(), "test".to_string()],
-            });
-
-            let output_analysed_type = AnalysedType::Str(TypeStr);
+            let request_value_type = r#enum(&["prod", "dev", "test"]);
+            let output_analysed_type = str();
 
             let analysed_exports = internal::get_component_metadata(
                 "my-worker-function",
@@ -1942,19 +1770,10 @@ mod compiler_tests {
 
         #[test]
         async fn test_record_global_input() {
-            let request_value_type = AnalysedType::Record(TypeRecord {
-                fields: vec![NameTypePair {
-                    name: "path".to_string(),
-                    typ: AnalysedType::Record(TypeRecord {
-                        fields: vec![NameTypePair {
-                            name: "user".to_string(),
-                            typ: AnalysedType::Str(TypeStr),
-                        }],
-                    }),
-                }],
-            });
+            let request_value_type =
+                record(vec![field("path", record(vec![field("user", str())]))]);
 
-            let output_analysed_type = AnalysedType::Str(TypeStr);
+            let output_analysed_type = str();
 
             let analysed_exports = internal::get_component_metadata(
                 "my-worker-function",
@@ -1992,20 +1811,9 @@ mod compiler_tests {
 
         #[test]
         async fn test_tuple_global_input() {
-            let request_value_type = AnalysedType::Tuple(TypeTuple {
-                items: vec![
-                    AnalysedType::Str(TypeStr),
-                    AnalysedType::U32(TypeU32),
-                    AnalysedType::Record(TypeRecord {
-                        fields: vec![NameTypePair {
-                            name: "user".to_string(),
-                            typ: AnalysedType::Str(TypeStr),
-                        }],
-                    }),
-                ],
-            });
+            let request_value_type = tuple(vec![str(), u32(), record(vec![field("user", str())])]);
 
-            let output_analysed_type = AnalysedType::Str(TypeStr);
+            let output_analysed_type = str();
 
             let analysed_exports = internal::get_component_metadata(
                 "my-worker-function",
@@ -2038,11 +1846,9 @@ mod compiler_tests {
 
         #[test]
         async fn test_list_global_input() {
-            let request_value_type = AnalysedType::List(TypeList {
-                inner: Box::new(AnalysedType::Str(TypeStr)),
-            });
+            let request_value_type = list(str());
 
-            let output_analysed_type = AnalysedType::Str(TypeStr);
+            let output_analysed_type = str();
 
             let analysed_exports = internal::get_component_metadata(
                 "my-worker-function",
@@ -2076,6 +1882,7 @@ mod compiler_tests {
 
     mod internal {
         use crate::{ComponentDependency, ComponentDependencyKey, RibInputTypeInfo};
+        use golem_wasm_ast::analysis::analysed_type::{case, str, u64, unit_case, variant};
         use golem_wasm_ast::analysis::*;
         use std::collections::HashMap;
         use uuid::Uuid;
@@ -2087,27 +1894,18 @@ mod compiler_tests {
                     name: "foo".to_string(),
                     parameters: vec![AnalysedFunctionParameter {
                         name: "param1".to_string(),
-                        typ: AnalysedType::Variant(TypeVariant {
-                            cases: vec![
-                                NameOptionTypePair {
-                                    name: "register-user".to_string(),
-                                    typ: Some(AnalysedType::U64(TypeU64)),
-                                },
-                                NameOptionTypePair {
-                                    name: "process-user".to_string(),
-                                    typ: Some(AnalysedType::Str(TypeStr)),
-                                },
-                                NameOptionTypePair {
-                                    name: "validate".to_string(),
-                                    typ: None,
-                                },
-                            ],
-                        }),
+                        typ: variant(vec![
+                            case("register-user", u64()),
+                            case("process-user", str()),
+                            unit_case("validate"),
+                        ]),
                     }],
                     result: Some(AnalysedFunctionResult {
                         typ: AnalysedType::Handle(TypeHandle {
                             resource_id: AnalysedResourceId(0),
                             mode: AnalysedResourceMode::Owned,
+                            name: None,
+                            owner: None,
                         }),
                     }),
                 }],
@@ -2126,60 +1924,6 @@ mod compiler_tests {
             }]
         }
 
-        pub(crate) fn metadata_with_resource_methods() -> Vec<ComponentDependency> {
-            let instance = AnalysedExport::Instance(AnalysedInstance {
-                name: "golem:it/api".to_string(),
-                functions: vec![
-                    AnalysedFunction {
-                        name: "[constructor]cart".to_string(),
-                        parameters: vec![AnalysedFunctionParameter {
-                            name: "param1".to_string(),
-                            typ: AnalysedType::Str(TypeStr),
-                        }],
-                        result: Some(AnalysedFunctionResult {
-                            typ: AnalysedType::Handle(TypeHandle {
-                                resource_id: AnalysedResourceId(0),
-                                mode: AnalysedResourceMode::Owned,
-                            }),
-                        }),
-                    },
-                    AnalysedFunction {
-                        name: "[method]cart.add-item".to_string(),
-                        parameters: vec![
-                            AnalysedFunctionParameter {
-                                name: "self".to_string(),
-                                typ: AnalysedType::Handle(TypeHandle {
-                                    resource_id: AnalysedResourceId(0),
-                                    mode: AnalysedResourceMode::Borrowed,
-                                }),
-                            },
-                            AnalysedFunctionParameter {
-                                name: "item".to_string(),
-                                typ: AnalysedType::Record(TypeRecord {
-                                    fields: vec![NameTypePair {
-                                        name: "name".to_string(),
-                                        typ: AnalysedType::Str(TypeStr),
-                                    }],
-                                }),
-                            },
-                        ],
-                        result: None,
-                    },
-                ],
-            });
-
-            let component_info = ComponentDependencyKey {
-                component_name: "foo".to_string(),
-                component_id: Uuid::new_v4(),
-                root_package_name: None,
-                root_package_version: None,
-            };
-
-            vec![ComponentDependency {
-                component_dependency_key: component_info,
-                component_exports: vec![instance],
-            }]
-        }
         pub(crate) fn get_component_metadata(
             function_name: &str,
             input_types: Vec<AnalysedType>,
diff --git a/golem-rib/src/compiler/worker_functions_in_rib.rs b/golem-rib/src/compiler/worker_functions_in_rib.rs
index 6433c131..317e2d91 100644
--- a/golem-rib/src/compiler/worker_functions_in_rib.rs
+++ b/golem-rib/src/compiler/worker_functions_in_rib.rs
@@ -37,7 +37,7 @@ impl WorkerFunctionsInRib {
         let mut function_calls = vec![];
 
         for key in worker_invoke_registry_keys {
-            let function_type = component_dependency
+            let (_, function_type) = component_dependency
                 .get_function_type(&None, &key)
                 .map_err(|e| RibCompilationError::RibStaticAnalysisError(e.to_string()))?;
 
diff --git a/golem-rib/src/expr.rs b/golem-rib/src/expr.rs
index 5b5b5e57..d4611034 100644
--- a/golem-rib/src/expr.rs
+++ b/golem-rib/src/expr.rs
@@ -1146,10 +1146,12 @@ impl Expr {
         // worker function invocations as this forms the foundation for the rest of the
         // compilation. This is compiler doing its best to infer all the calls such
         // as worker invokes or instance calls etc.
-        self.resolve_method_calls()?;
         type_inference::type_inference_fix_point(Self::resolve_method_calls, self)?;
         self.infer_function_call_types(component_dependency)?;
-        type_inference::type_inference_fix_point(Self::inference_scan, self)?;
+        type_inference::type_inference_fix_point(
+            |x| Self::inference_scan(x, component_dependency),
+            self,
+        )?;
         self.check_types(component_dependency)?;
         self.unify_types()?;
         Ok(())
@@ -1195,12 +1197,16 @@ impl Expr {
     // An inference is a single cycle of to-and-fro scanning of Rib expression, that it takes part in fix point of inference.
     // Not all phases of compilation will be part of this scan.
     // Example: function call argument inference based on the worker function hardly needs to be part of the scan.
-    pub fn inference_scan(&mut self) -> Result<(), RibTypeErrorInternal> {
+    pub fn inference_scan(
+        &mut self,
+        component_dependencies: &ComponentDependencies,
+    ) -> Result<(), RibTypeErrorInternal> {
         self.infer_all_identifiers();
         self.push_types_down()?;
         self.infer_all_identifiers();
-        self.pull_types_up()?;
+        self.pull_types_up(component_dependencies)?;
         self.infer_global_inputs();
+        self.infer_function_call_types(component_dependencies)?;
         Ok(())
     }
 
@@ -1257,8 +1263,11 @@ impl Expr {
         type_inference::infer_all_identifiers(self)
     }
 
-    pub fn pull_types_up(&mut self) -> Result<(), RibTypeErrorInternal> {
-        type_inference::type_pull_up(self)
+    pub fn pull_types_up(
+        &mut self,
+        component_dependencies: &ComponentDependencies,
+    ) -> Result<(), RibTypeErrorInternal> {
+        type_inference::type_pull_up(self, component_dependencies)
     }
 
     pub fn infer_global_inputs(&mut self) {
diff --git a/golem-rib/src/function_name.rs b/golem-rib/src/function_name.rs
index 98cdfc88..895d6e14 100644
--- a/golem-rib/src/function_name.rs
+++ b/golem-rib/src/function_name.rs
@@ -12,11 +12,9 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use crate::Expr;
 use bincode::{BorrowDecode, Decode, Encode};
 use combine::stream::position::Stream;
 use combine::{eof, EasyParser, Parser};
-use golem_wasm_rpc::{parse_value_and_type, ValueAndType};
 use semver::{BuildMetadata, Prerelease};
 use serde::{Deserialize, Serialize};
 use std::borrow::Cow;
@@ -25,6 +23,14 @@ use std::fmt::Display;
 #[derive(PartialEq, Hash, Eq, Clone, Ord, PartialOrd)]
 pub struct SemVer(pub semver::Version);
 
+impl SemVer {
+    pub fn parse(version: &str) -> Result<Self, String> {
+        semver::Version::parse(version)
+            .map(SemVer)
+            .map_err(|e| format!("Invalid semver string: {e}"))
+    }
+}
+
 impl std::fmt::Debug for SemVer {
     fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
         write!(f, "{}", self.0)
@@ -132,45 +138,35 @@ impl ParsedFunctionSite {
             } => Some(format!("{namespace}:{package}/{interface}@{}", version.0)),
         }
     }
+
+    pub fn unversioned(&self) -> ParsedFunctionSite {
+        match self {
+            ParsedFunctionSite::Global => ParsedFunctionSite::Global,
+            ParsedFunctionSite::Interface { name } => {
+                ParsedFunctionSite::Interface { name: name.clone() }
+            }
+            ParsedFunctionSite::PackagedInterface {
+                namespace,
+                package,
+                interface,
+                version: _,
+            } => ParsedFunctionSite::PackagedInterface {
+                namespace: namespace.clone(),
+                package: package.clone(),
+                interface: interface.clone(),
+                version: None,
+            },
+        }
+    }
 }
 
 #[derive(Debug, Hash, PartialEq, Eq, Clone, Ord, PartialOrd)]
 pub enum DynamicParsedFunctionReference {
-    Function {
-        function: String,
-    },
-    RawResourceConstructor {
-        resource: String,
-    },
-    RawResourceDrop {
-        resource: String,
-    },
-    RawResourceMethod {
-        resource: String,
-        method: String,
-    },
-    RawResourceStaticMethod {
-        resource: String,
-        method: String,
-    },
-    IndexedResourceConstructor {
-        resource: String,
-        resource_params: Vec<Expr>,
-    },
-    IndexedResourceMethod {
-        resource: String,
-        resource_params: Vec<Expr>,
-        method: String,
-    },
-    IndexedResourceStaticMethod {
-        resource: String,
-        resource_params: Vec<Expr>,
-        method: String,
-    },
-    IndexedResourceDrop {
-        resource: String,
-        resource_params: Vec<Expr>,
-    },
+    Function { function: String },
+    RawResourceConstructor { resource: String },
+    RawResourceDrop { resource: String },
+    RawResourceMethod { resource: String, method: String },
+    RawResourceStaticMethod { resource: String, method: String },
 }
 
 impl DynamicParsedFunctionReference {
@@ -185,25 +181,6 @@ impl DynamicParsedFunctionReference {
             DynamicParsedFunctionReference::RawResourceStaticMethod { method, .. } => {
                 method.to_string()
             }
-            DynamicParsedFunctionReference::IndexedResourceConstructor {
-                resource,
-                resource_params,
-            } => format!(
-                "{}({})",
-                resource,
-                resource_params
-                    .iter()
-                    .map(|x| x.to_string())
-                    .collect::<Vec<_>>()
-                    .join(", ")
-            ),
-            DynamicParsedFunctionReference::IndexedResourceMethod { method, .. } => {
-                method.to_string()
-            }
-            DynamicParsedFunctionReference::IndexedResourceStaticMethod { method, .. } => {
-                method.to_string()
-            }
-            DynamicParsedFunctionReference::IndexedResourceDrop { .. } => "drop".to_string(),
         }
     }
 
@@ -232,127 +209,17 @@ impl DynamicParsedFunctionReference {
                     method: method.clone(),
                 }
             }
-            Self::IndexedResourceConstructor {
-                resource,
-                resource_params,
-            } => ParsedFunctionReference::IndexedResourceConstructor {
-                resource: resource.clone(),
-                resource_params: resource_params
-                    .iter()
-                    .map(|expr| expr.to_string())
-                    .collect(),
-            },
-            Self::IndexedResourceMethod {
-                resource,
-                resource_params,
-                method,
-            } => ParsedFunctionReference::IndexedResourceMethod {
-                resource: resource.clone(),
-                resource_params: resource_params
-                    .iter()
-                    .map(|expr| expr.to_string())
-                    .collect(),
-                method: method.clone(),
-            },
-            Self::IndexedResourceStaticMethod {
-                resource,
-                resource_params,
-                method,
-            } => ParsedFunctionReference::IndexedResourceStaticMethod {
-                resource: resource.clone(),
-                resource_params: resource_params
-                    .iter()
-                    .map(|expr| expr.to_string())
-                    .collect(),
-                method: method.clone(),
-            },
-            Self::IndexedResourceDrop {
-                resource,
-                resource_params,
-            } => ParsedFunctionReference::IndexedResourceDrop {
-                resource: resource.clone(),
-                resource_params: resource_params
-                    .iter()
-                    .map(|expr| expr.to_string())
-                    .collect(),
-            },
-        }
-    }
-
-    pub fn raw_resource_params_mut(&mut self) -> Option<&mut [Expr]> {
-        match self {
-            Self::IndexedResourceConstructor {
-                resource_params, ..
-            }
-            | Self::IndexedResourceMethod {
-                resource_params, ..
-            }
-            | Self::IndexedResourceStaticMethod {
-                resource_params, ..
-            }
-            | Self::IndexedResourceDrop {
-                resource_params, ..
-            } => Some(resource_params.as_mut_slice()),
-            _ => None,
-        }
-    }
-
-    pub fn raw_resource_params(&self) -> Option<&Vec<Expr>> {
-        match self {
-            Self::IndexedResourceConstructor {
-                resource_params, ..
-            }
-            | Self::IndexedResourceMethod {
-                resource_params, ..
-            }
-            | Self::IndexedResourceStaticMethod {
-                resource_params, ..
-            }
-            | Self::IndexedResourceDrop {
-                resource_params, ..
-            } => Some(resource_params),
-            _ => None,
         }
     }
 }
 
-#[derive(Debug, PartialEq, Eq, Clone, Encode, Decode)]
+#[derive(Debug, PartialEq, Eq, Clone, Hash, Encode, Decode)]
 pub enum ParsedFunctionReference {
-    Function {
-        function: String,
-    },
-    RawResourceConstructor {
-        resource: String,
-    },
-    RawResourceDrop {
-        resource: String,
-    },
-    RawResourceMethod {
-        resource: String,
-        method: String,
-    },
-    RawResourceStaticMethod {
-        resource: String,
-        method: String,
-    },
-    IndexedResourceConstructor {
-        resource: String,
-        resource_params: Vec<String>,
-    },
-    IndexedResourceMethod {
-        resource: String,
-        resource_params: Vec<String>,
-        method: String,
-    },
-    IndexedResourceStaticMethod {
-        resource: String,
-        resource_params: Vec<String>,
-        method: String,
-    },
-    IndexedResourceDrop {
-        resource: String,
-        resource_params: Vec<String>,
-    },
+    Function { function: String },
+    RawResourceConstructor { resource: String },
+    RawResourceDrop { resource: String },
+    RawResourceMethod { resource: String, method: String },
+    RawResourceStaticMethod { resource: String, method: String },
 }
 
 impl Display for ParsedFunctionReference {
@@ -360,42 +227,11 @@ impl Display for ParsedFunctionReference {
         let function_name = match self {
             Self::Function { function } => function.clone(),
             Self::RawResourceConstructor { resource } => format!("{resource}.new"),
-            Self::IndexedResourceConstructor {
-                resource,
-                resource_params,
-            } => {
-                format!("{}({}).new", resource, resource_params.join(", "))
-            }
             Self::RawResourceMethod { resource, method } => format!("{resource}.{method}"),
             Self::RawResourceStaticMethod { resource, method } => {
                 format!("[static]{resource}.{method}")
             }
             Self::RawResourceDrop { resource } => format!("{resource}.drop"),
-            Self::IndexedResourceDrop {
-                resource,
-                resource_params,
-            } => {
-                format!("{}({}).drop", resource, resource_params.join(", "))
-            }
-            Self::IndexedResourceMethod {
-                resource,
-                resource_params,
-                method,
-            } => {
-                format!("{}({}).{}", resource, resource_params.join(", "), method)
-            }
-            Self::IndexedResourceStaticMethod {
-                resource,
-                resource_params,
-                method,
-            } => {
-                format!(
-                    "[static]{}({}).{}",
-                    resource,
-                    resource_params.join(", "),
-                    method
-                )
-            }
         };
 
         write!(f, "{function_name}")
@@ -414,31 +250,13 @@ impl ParsedFunctionReference {
             Self::RawResourceStaticMethod {
                 resource, method, ..
             } => format!("[static]{resource}.{method}"),
-            Self::IndexedResourceConstructor { resource, .. } => {
-                format!("[constructor]{resource}")
-            }
-            Self::IndexedResourceMethod {
-                resource, method, ..
-            } => {
-                format!("[method]{resource}.{method}")
-            }
-            Self::IndexedResourceStaticMethod {
-                resource, method, ..
-            } => {
-                format!("[static]{resource}.{method}")
-            }
-            Self::IndexedResourceDrop { resource, .. } => {
-                format!("[drop]{resource}")
-            }
         }
     }
 
     pub fn resource_method_name(&self) -> Option<String> {
         match self {
-            Self::IndexedResourceStaticMethod { method, .. }
-            | Self::RawResourceMethod { method, .. }
-            | Self::RawResourceStaticMethod { method, .. }
-            | Self::IndexedResourceMethod { method, .. } => Some(method.clone()),
+            Self::RawResourceMethod { method, .. }
+            | Self::RawResourceStaticMethod { method, .. } => Some(method.clone()),
             _ => None,
         }
     }
@@ -449,43 +267,7 @@ impl ParsedFunctionReference {
                 resource: resource.clone(),
                 method: method.clone(),
             }),
-            Self::IndexedResourceMethod {
-                resource,
-                resource_params,
-                method,
-            } => Some(Self::IndexedResourceStaticMethod {
-                resource: resource.clone(),
-                resource_params: resource_params.clone(),
-                method: method.clone(),
-            }),
-            _ => None,
-        }
-    }
-
-    pub fn is_indexed_resource(&self) -> bool {
-        matches!(
-            self,
-            Self::IndexedResourceConstructor { .. }
-                | Self::IndexedResourceMethod { .. }
-                | Self::IndexedResourceStaticMethod { .. }
-                | Self::IndexedResourceDrop { .. }
-        )
-    }
 
-    pub fn raw_resource_params(&self) -> Option<&Vec<String>> {
-        match self {
-            Self::IndexedResourceConstructor {
-                resource_params, ..
-            }
-            | Self::IndexedResourceMethod {
-                resource_params, ..
-            }
-            | Self::IndexedResourceStaticMethod {
-                resource_params, ..
-            }
-            | Self::IndexedResourceDrop {
-                resource_params, ..
-            } => Some(resource_params),
             _ => None,
         }
     }
@@ -495,38 +277,10 @@ impl ParsedFunctionReference {
             Self::RawResourceConstructor { resource }
             | Self::RawResourceDrop { resource }
             | Self::RawResourceMethod { resource, .. }
-            | Self::RawResourceStaticMethod { resource, .. }
-            | Self::IndexedResourceConstructor { resource, .. }
-            | Self::IndexedResourceMethod { resource, .. }
-            | Self::IndexedResourceStaticMethod { resource, .. }
-            | Self::IndexedResourceDrop { resource, .. } => Some(resource),
+            | Self::RawResourceStaticMethod { resource, .. } => Some(resource),
             _ => None,
         }
     }
-
-    pub fn resource_params(
-        &self,
-        types: &[golem_wasm_ast::analysis::AnalysedType],
-    ) -> Result<Option<Vec<ValueAndType>>, String> {
-        if let Some(raw_params) = self.raw_resource_params() {
-            if raw_params.len() != types.len() {
-                Err(format!(
-                    "Resource params count mismatch: expected {}, got {}",
-                    types.len(),
-                    raw_params.len()
-                ))
-            } else {
-                let mut result = Vec::new();
-                for (raw_param, param_type) in raw_params.iter().zip(types.iter()) {
-                    let value_and_type: ValueAndType = parse_value_and_type(param_type, raw_param)?;
-                    result.push(value_and_type);
-                }
-                Ok(Some(result))
-            }
-        } else {
-            Ok(None)
-        }
-    }
 }
 
 // DynamicParsedFunctionName is different from ParsedFunctionName.
@@ -580,10 +334,6 @@ impl DynamicParsedFunctionName {
             .resource_method_name()
     }
 
-    pub fn raw_resource_params_mut(&mut self) -> Option<&mut [Expr]> {
-        self.function.raw_resource_params_mut()
-    }
-
     //
     pub fn to_parsed_function_name(&self) -> ParsedFunctionName {
         ParsedFunctionName {
@@ -600,7 +350,7 @@ impl Display for DynamicParsedFunctionName {
     }
 }
 
-#[derive(Debug, PartialEq, Eq, Clone, Encode, Decode)]
+#[derive(Debug, PartialEq, Eq, Clone, Hash, Encode, Decode)]
 pub struct ParsedFunctionName {
     pub site: ParsedFunctionSite,
     pub function: ParsedFunctionReference,
@@ -687,10 +437,7 @@ impl ParsedFunctionName {
 
     pub fn is_constructor(&self) -> Option<&str> {
         match &self.function {
-            ParsedFunctionReference::RawResourceConstructor { resource, .. }
-            | ParsedFunctionReference::IndexedResourceConstructor { resource, .. } => {
-                Some(resource)
-            }
+            ParsedFunctionReference::RawResourceConstructor { resource, .. } => Some(resource),
             _ => None,
         }
     }
@@ -698,30 +445,30 @@ impl ParsedFunctionName {
     pub fn is_method(&self) -> Option<&str> {
         match &self.function {
             ParsedFunctionReference::RawResourceMethod { resource, .. }
-            | ParsedFunctionReference::IndexedResourceMethod { resource, .. }
-            | ParsedFunctionReference::RawResourceStaticMethod { resource, .. }
-            | ParsedFunctionReference::IndexedResourceStaticMethod { resource, .. } => {
-                Some(resource)
-            }
+            | ParsedFunctionReference::RawResourceStaticMethod { resource, .. } => Some(resource),
             _ => None,
         }
     }
 
     pub fn is_static_method(&self) -> Option<&str> {
         match &self.function {
-            ParsedFunctionReference::RawResourceStaticMethod { resource, .. }
-            | ParsedFunctionReference::IndexedResourceStaticMethod { resource, .. } => {
-                Some(resource)
-            }
+            ParsedFunctionReference::RawResourceStaticMethod { resource, .. } => Some(resource),
             _ => None,
         }
     }
+
+    pub fn with_site(&self, site: ParsedFunctionSite) -> Self {
+        Self {
+            site,
+            function: self.function.clone(),
+        }
+    }
 }
 
 #[cfg(feature = "protobuf")]
 mod protobuf {
     use crate::{
-        DynamicParsedFunctionName, DynamicParsedFunctionReference, Expr, ParsedFunctionName,
+        DynamicParsedFunctionName, DynamicParsedFunctionReference, ParsedFunctionName,
         ParsedFunctionReference, ParsedFunctionSite, SemVer,
     };
     use golem_api_grpc::proto::golem::rib::dynamic_parsed_function_reference::FunctionReference as ProtoDynamicFunctionReference;
@@ -847,32 +594,6 @@ mod protobuf {
                 DynamicParsedFunctionReference::RawResourceDrop { resource } => ProtoDynamicFunctionReference::RawResourceDrop(
                     golem_api_grpc::proto::golem::rib::RawResourceDropFunctionReference { resource },
                 ),
-                DynamicParsedFunctionReference::IndexedResourceConstructor { resource, resource_params } => ProtoDynamicFunctionReference::IndexedResourceConstructor(
-                    golem_api_grpc::proto::golem::rib::DynamicIndexedResourceConstructorFunctionReference {
-                        resource,
-                        resource_params: resource_params.into_iter().map(|x| x.into()).collect(),
-                    },
-                ),
-                DynamicParsedFunctionReference::IndexedResourceMethod { resource, resource_params, method } => ProtoDynamicFunctionReference::IndexedResourceMethod(
-                    golem_api_grpc::proto::golem::rib::DynamicIndexedResourceMethodFunctionReference {
-                        resource,
-                        resource_params: resource_params.into_iter().map(|x| x.into()).collect(),
-                        method,
-                    },
-                ),
-                DynamicParsedFunctionReference::IndexedResourceStaticMethod { resource, resource_params, method } => ProtoDynamicFunctionReference::IndexedResourceStaticMethod(
-                    golem_api_grpc::proto::golem::rib::DynamicIndexedResourceStaticMethodFunctionReference {
-                        resource,
-                        resource_params: resource_params.into_iter().map(|x| x.into()).collect(),
-                        method,
-                    },
-                ),
-                DynamicParsedFunctionReference::IndexedResourceDrop { resource, resource_params } => ProtoDynamicFunctionReference::IndexedResourceDrop(
-                    golem_api_grpc::proto::golem::rib::DynamicIndexedResourceDropFunctionReference {
-                        resource,
-                        resource_params: resource_params.into_iter().map(|x| x.into()).collect(),
-                    },
-                ),
             };
 
             golem_api_grpc::proto::golem::rib::DynamicParsedFunctionReference {
@@ -894,71 +615,31 @@ mod protobuf {
                 .ok_or("Missing function reference".to_string())?;
 
             match function {
-                ProtoDynamicFunctionReference::Function(golem_api_grpc::proto::golem::rib::FunctionFunctionReference {
-                                                            function
-                                                        }) => {
-                    Ok(Self::Function { function })
-                }
-                ProtoDynamicFunctionReference::RawResourceConstructor(golem_api_grpc::proto::golem::rib::RawResourceConstructorFunctionReference {
-                                                                          resource
-                                                                      }) => {
-                    Ok(Self::RawResourceConstructor { resource })
-                }
-                ProtoDynamicFunctionReference::RawResourceMethod(golem_api_grpc::proto::golem::rib::RawResourceMethodFunctionReference {
-                                                                     resource,
-                                                                     method
-                                                                 }) => {
-                    Ok(Self::RawResourceMethod { resource, method })
-                }
-                ProtoDynamicFunctionReference::RawResourceStaticMethod(golem_api_grpc::proto::golem::rib::RawResourceStaticMethodFunctionReference {
-                                                                           resource,
-                                                                           method
-                                                                       }) => {
-                    Ok(Self::RawResourceStaticMethod { resource, method })
-                }
-                ProtoDynamicFunctionReference::RawResourceDrop(golem_api_grpc::proto::golem::rib::RawResourceDropFunctionReference {
-                                                                   resource
-                                                               }) => {
-                    Ok(Self::RawResourceDrop { resource })
-                }
-                ProtoDynamicFunctionReference::IndexedResourceConstructor(golem_api_grpc::proto::golem::rib::DynamicIndexedResourceConstructorFunctionReference {
-                                                                              resource,
-                                                                              resource_params
-                                                                          }) => {
-                    let resource_params: Vec<Expr> =
-                        resource_params.into_iter().map(Expr::try_from).collect::<Result<Vec<Expr>, String>>()?;
-
-                    Ok(Self::IndexedResourceConstructor { resource, resource_params })
-                }
-                ProtoDynamicFunctionReference::IndexedResourceMethod(golem_api_grpc::proto::golem::rib::DynamicIndexedResourceMethodFunctionReference {
-                                                                         resource,
-                                                                         resource_params,
-                                                                         method
-                                                                     }) => {
-                    let resource_params: Vec<Expr> =
-                        resource_params.into_iter().map(Expr::try_from).collect::<Result<Vec<Expr>, String>>()?;
-
-                    Ok(Self::IndexedResourceMethod { resource, resource_params, method })
-                }
-                ProtoDynamicFunctionReference::IndexedResourceStaticMethod(golem_api_grpc::proto::golem::rib::DynamicIndexedResourceStaticMethodFunctionReference {
-                                                                               resource,
-                                                                               resource_params,
-                                                                               method
-                                                                           }) => {
-                    let resource_params: Vec<Expr> =
-                        resource_params.into_iter().map(Expr::try_from).collect::<Result<Vec<Expr>, String>>()?;
-
-                    Ok(Self::IndexedResourceStaticMethod { resource, resource_params, method })
-                }
-                ProtoDynamicFunctionReference::IndexedResourceDrop(golem_api_grpc::proto::golem::rib::DynamicIndexedResourceDropFunctionReference {
-                                                                       resource,
-                                                                       resource_params
-                                                                   }) => {
-                    let resource_params: Vec<Expr> =
-                        resource_params.into_iter().map(Expr::try_from).collect::<Result<Vec<Expr>, String>>()?;
-
-                    Ok(Self::IndexedResourceDrop { resource, resource_params })
-                }
+                ProtoDynamicFunctionReference::Function(
+                    golem_api_grpc::proto::golem::rib::FunctionFunctionReference { function },
+                ) => Ok(Self::Function { function }),
+                ProtoDynamicFunctionReference::RawResourceConstructor(
+                    golem_api_grpc::proto::golem::rib::RawResourceConstructorFunctionReference {
+                        resource,
+                    },
+                ) => Ok(Self::RawResourceConstructor { resource }),
+                ProtoDynamicFunctionReference::RawResourceMethod(
+                    golem_api_grpc::proto::golem::rib::RawResourceMethodFunctionReference {
+                        resource,
+                        method,
+                    },
+                ) => Ok(Self::RawResourceMethod { resource, method }),
+                ProtoDynamicFunctionReference::RawResourceStaticMethod(
+                    golem_api_grpc::proto::golem::rib::RawResourceStaticMethodFunctionReference {
+                        resource,
+                        method,
+                    },
+                ) => Ok(Self::RawResourceStaticMethod { resource, method }),
+                ProtoDynamicFunctionReference::RawResourceDrop(
+                    golem_api_grpc::proto::golem::rib::RawResourceDropFunctionReference {
+                        resource,
+                    },
+                ) => Ok(Self::RawResourceDrop { resource }),
             }
         }
     }
@@ -1002,46 +683,6 @@ mod protobuf {
                                                                                                                  }) => {
                     Ok(Self::RawResourceDrop { resource })
                 }
-                golem_api_grpc::proto::golem::rib::parsed_function_reference::FunctionReference::IndexedResourceConstructor(golem_api_grpc::proto::golem::rib::IndexedResourceConstructorFunctionReference {
-                                                                                                                                resource,
-                                                                                                                                resource_params
-                                                                                                                            }) => {
-                    Ok(Self::IndexedResourceConstructor {
-                        resource,
-                        resource_params,
-                    })
-                }
-                golem_api_grpc::proto::golem::rib::parsed_function_reference::FunctionReference::IndexedResourceMethod(golem_api_grpc::proto::golem::rib::IndexedResourceMethodFunctionReference {
-                                                                                                                           resource,
-                                                                                                                           resource_params,
-                                                                                                                           method
-                                                                                                                       }) => {
-                    Ok(Self::IndexedResourceMethod {
-                        resource,
-                        resource_params,
-                        method,
-                    })
-                }
-                golem_api_grpc::proto::golem::rib::parsed_function_reference::FunctionReference::IndexedResourceStaticMethod(golem_api_grpc::proto::golem::rib::IndexedResourceStaticMethodFunctionReference {
-                                                                                                                                 resource,
-                                                                                                                                 resource_params,
-                                                                                                                                 method
-                                                                                                                             }) => {
-                    Ok(Self::IndexedResourceStaticMethod {
-                        resource,
-                        resource_params,
-                        method,
-                    })
-                }
-                golem_api_grpc::proto::golem::rib::parsed_function_reference::FunctionReference::IndexedResourceDrop(golem_api_grpc::proto::golem::rib::IndexedResourceDropFunctionReference {
-                                                                                                                         resource,
-                                                                                                                         resource_params
-                                                                                                                     }) => {
-                    Ok(Self::IndexedResourceDrop {
-                        resource,
-                        resource_params,
-                    })
-                }
             }
         }
     }
@@ -1078,46 +719,6 @@ mod protobuf {
                 ParsedFunctionReference::RawResourceDrop { resource } => golem_api_grpc::proto::golem::rib::parsed_function_reference::FunctionReference::RawResourceDrop(
                     golem_api_grpc::proto::golem::rib::RawResourceDropFunctionReference { resource },
                 ),
-                ParsedFunctionReference::IndexedResourceConstructor {
-                    resource,
-                    resource_params,
-                } => golem_api_grpc::proto::golem::rib::parsed_function_reference::FunctionReference::IndexedResourceConstructor(
-                    golem_api_grpc::proto::golem::rib::IndexedResourceConstructorFunctionReference {
-                        resource,
-                        resource_params,
-                    },
-                ),
-                ParsedFunctionReference::IndexedResourceMethod {
-                    resource,
-                    resource_params,
-                    method,
-                } => golem_api_grpc::proto::golem::rib::parsed_function_reference::FunctionReference::IndexedResourceMethod(
-                    golem_api_grpc::proto::golem::rib::IndexedResourceMethodFunctionReference {
-                        resource,
-                        resource_params,
-                        method,
-                    },
-                ),
-                ParsedFunctionReference::IndexedResourceStaticMethod {
-                    resource,
-                    resource_params,
-                    method,
-                } => golem_api_grpc::proto::golem::rib::parsed_function_reference::FunctionReference::IndexedResourceStaticMethod(
-                    golem_api_grpc::proto::golem::rib::IndexedResourceStaticMethodFunctionReference {
-                        resource,
-                        resource_params,
-                        method,
-                    },
-                ),
-                ParsedFunctionReference::IndexedResourceDrop {
-                    resource,
-                    resource_params,
-                } => golem_api_grpc::proto::golem::rib::parsed_function_reference::FunctionReference::IndexedResourceDrop(
-                    golem_api_grpc::proto::golem::rib::IndexedResourceDropFunctionReference {
-                        resource,
-                        resource_params,
-                    },
-                ),
             };
             golem_api_grpc::proto::golem::rib::ParsedFunctionReference {
                 function_reference: Some(function),
@@ -1179,8 +780,6 @@ mod protobuf {
 #[cfg(test)]
 mod function_name_tests {
     use super::{ParsedFunctionName, ParsedFunctionReference, ParsedFunctionSite, SemVer};
-    use golem_wasm_ast::analysis::analysed_type::{field, record, u64};
-    use golem_wasm_rpc::Value;
     use test_r::test;
 
     #[test]
@@ -1330,216 +929,6 @@ mod function_name_tests {
         );
     }
 
-    #[test]
-    fn parse_function_name_indexed_constructor_1() {
-        let parsed = ParsedFunctionName::parse("ns:name/interface.{resource1().new}")
-            .expect("Parsing failed");
-        assert_eq!(
-            parsed.site().interface_name(),
-            Some("ns:name/interface".to_string())
-        );
-        assert_eq!(
-            parsed.function().function_name(),
-            "[constructor]resource1".to_string()
-        );
-        assert!(parsed.function().is_indexed_resource());
-        assert_eq!(parsed.function().raw_resource_params(), Some(&vec![]));
-        assert_eq!(
-            parsed,
-            ParsedFunctionName {
-                site: ParsedFunctionSite::PackagedInterface {
-                    namespace: "ns".to_string(),
-                    package: "name".to_string(),
-                    interface: "interface".to_string(),
-                    version: None,
-                },
-                function: ParsedFunctionReference::IndexedResourceConstructor {
-                    resource: "resource1".to_string(),
-                    resource_params: vec![],
-                },
-            }
-        );
-    }
-
-    #[test]
-    fn parse_function_name_indexed_constructor_2() {
-        let parsed =
-            ParsedFunctionName::parse("ns:name/interface.{resource1(\"hello\", 1, true).new}")
-                .expect("Parsing failed");
-        assert_eq!(
-            parsed.site().interface_name(),
-            Some("ns:name/interface".to_string())
-        );
-        assert_eq!(
-            parsed.function().function_name(),
-            "[constructor]resource1".to_string()
-        );
-        assert!(parsed.function().is_indexed_resource());
-        assert_eq!(
-            parsed.function().raw_resource_params(),
-            Some(&vec![
-                "\"hello\"".to_string(),
-                "1".to_string(),
-                "true".to_string(),
-            ])
-        );
-        assert_eq!(
-            parsed,
-            ParsedFunctionName {
-                site: ParsedFunctionSite::PackagedInterface {
-                    namespace: "ns".to_string(),
-                    package: "name".to_string(),
-                    interface: "interface".to_string(),
-                    version: None,
-                },
-                function: ParsedFunctionReference::IndexedResourceConstructor {
-                    resource: "resource1".to_string(),
-                    resource_params: vec![
-                        "\"hello\"".to_string(),
-                        "1".to_string(),
-                        "true".to_string(),
-                    ],
-                },
-            },
-        );
-    }
-
-    #[test]
-    fn parse_function_name_indexed_constructor_3() {
-        let parsed = ParsedFunctionName::parse(
-            "ns:name/interface.{resource1(\"hello\", { field-a: some(1) }).new}",
-        )
-        .expect("Parsing failed");
-        assert_eq!(
-            parsed.site().interface_name(),
-            Some("ns:name/interface".to_string())
-        );
-        assert_eq!(
-            parsed.function().function_name(),
-            "[constructor]resource1".to_string()
-        );
-        assert!(parsed.function().is_indexed_resource());
-        assert_eq!(
-            parsed.function().raw_resource_params(),
-            Some(&vec![
-                "\"hello\"".to_string(),
-                "{field-a: some(1)}".to_string(),
-            ])
-        );
-        assert_eq!(
-            parsed,
-            ParsedFunctionName {
-                site: ParsedFunctionSite::PackagedInterface {
-                    namespace: "ns".to_string(),
-                    package: "name".to_string(),
-                    interface: "interface".to_string(),
-                    version: None,
-                },
-                function: ParsedFunctionReference::IndexedResourceConstructor {
-                    resource: "resource1".to_string(),
-                    resource_params: vec![
-                        "\"hello\"".to_string(),
-                        "{field-a: some(1)}".to_string(),
-                    ],
-                },
-            },
-        );
-    }
-
-    #[test]
-    fn parse_function_name_indexed_method() {
-        let parsed = ParsedFunctionName::parse(
-            "ns:name/interface.{resource1(\"hello\", { field-a: some(1) }).something}",
-        )
-        .expect("Parsing failed");
-        assert_eq!(
-            parsed.site().interface_name(),
-            Some("ns:name/interface".to_string())
-        );
-        assert_eq!(
-            parsed.function().function_name(),
-            "[method]resource1.something".to_string()
-        );
-        assert!(parsed.function().is_indexed_resource());
-        assert_eq!(
-            parsed.function().raw_resource_params(),
-            Some(&vec![
-                "\"hello\"".to_string(),
-                "{field-a: some(1)}".to_string(),
-            ])
-        );
-        assert_eq!(
-            parsed.function().resource_method_name(),
-            Some("something".to_string())
-        );
-        assert_eq!(
-            parsed,
-            ParsedFunctionName {
-                site: ParsedFunctionSite::PackagedInterface {
-                    namespace: "ns".to_string(),
-                    package: "name".to_string(),
-                    interface: "interface".to_string(),
-                    version: None,
-                },
-                function: ParsedFunctionReference::IndexedResourceMethod {
-                    resource: "resource1".to_string(),
-                    resource_params: vec![
-                        "\"hello\"".to_string(),
-                        "{field-a: some(1)}".to_string(),
-                    ],
-                    method: "something".to_string(),
-                },
-            },
-        );
-    }
-
-    #[test]
-    fn parse_function_name_indexed_static_method() {
-        let parsed = ParsedFunctionName::parse(
-            "ns:name/interface.{[static]resource1(\"hello\", { field-a: some(1) }).something}",
-        )
-        .expect("Parsing failed");
-        assert_eq!(
-            parsed.site().interface_name(),
-            Some("ns:name/interface".to_string())
-        );
-        assert_eq!(
-            parsed.function().function_name(),
-            "[static]resource1.something".to_string()
-        );
-        assert!(parsed.function().is_indexed_resource());
-        assert_eq!(
-            parsed.function().raw_resource_params(),
-            Some(&vec![
-                "\"hello\"".to_string(),
-                "{field-a: some(1)}".to_string(),
-            ])
-        );
-        assert_eq!(
-            parsed.function().resource_method_name(),
-            Some("something".to_string())
-        );
-        assert_eq!(
-            parsed,
-            ParsedFunctionName {
-                site: ParsedFunctionSite::PackagedInterface {
-                    namespace: "ns".to_string(),
-                    package: "name".to_string(),
-                    interface: "interface".to_string(),
-                    version: None,
-                },
-                function: ParsedFunctionReference::IndexedResourceStaticMethod {
-                    resource: "resource1".to_string(),
-                    resource_params: vec![
-                        "\"hello\"".to_string(),
-                        "{field-a: some(1)}".to_string(),
-                    ],
-                    method: "something".to_string(),
-                },
-            },
-        );
-    }
-
     #[test]
     fn parse_function_name_method_syntax_sugar() {
         let parsed = ParsedFunctionName::parse("ns:name/interface.{resource1.do-something}")
@@ -1690,122 +1079,6 @@ mod function_name_tests {
         );
     }
 
-    #[test]
-    fn parse_function_name_indexed_drop_1() {
-        let parsed = ParsedFunctionName::parse("ns:name/interface.{resource1().drop}")
-            .expect("Parsing failed");
-        assert_eq!(
-            parsed.site().interface_name(),
-            Some("ns:name/interface".to_string())
-        );
-        assert_eq!(
-            parsed.function().function_name(),
-            "[drop]resource1".to_string()
-        );
-        assert!(parsed.function().is_indexed_resource());
-        assert_eq!(parsed.function().raw_resource_params(), Some(&vec![]));
-        assert_eq!(
-            parsed,
-            ParsedFunctionName {
-                site: ParsedFunctionSite::PackagedInterface {
-                    namespace: "ns".to_string(),
-                    package: "name".to_string(),
-                    interface: "interface".to_string(),
-                    version: None,
-                },
-                function: ParsedFunctionReference::IndexedResourceDrop {
-                    resource: "resource1".to_string(),
-                    resource_params: vec![],
-                },
-            }
-        )
-    }
-
-    #[test]
-    fn parse_function_name_indexed_drop_2() {
-        let parsed =
-            ParsedFunctionName::parse("ns:name/interface.{resource1(\"hello\", 1, true).drop}")
-                .expect("Parsing failed");
-        assert_eq!(
-            parsed.site().interface_name(),
-            Some("ns:name/interface".to_string())
-        );
-        assert_eq!(
-            parsed.function().function_name(),
-            "[drop]resource1".to_string()
-        );
-        assert!(parsed.function().is_indexed_resource());
-        assert_eq!(
-            parsed.function().raw_resource_params(),
-            Some(&vec![
-                "\"hello\"".to_string(),
-                "1".to_string(),
-                "true".to_string(),
-            ])
-        );
-        assert_eq!(
-            parsed,
-            ParsedFunctionName {
-                site: ParsedFunctionSite::PackagedInterface {
-                    namespace: "ns".to_string(),
-                    package: "name".to_string(),
-                    interface: "interface".to_string(),
-                    version: None,
-                },
-                function: ParsedFunctionReference::IndexedResourceDrop {
-                    resource: "resource1".to_string(),
-                    resource_params: vec![
-                        "\"hello\"".to_string(),
-                        "1".to_string(),
-                        "true".to_string(),
-                    ],
-                },
-            }
-        );
-    }
-
-    #[test]
-    fn parse_function_name_indexed_drop_3() {
-        let parsed = ParsedFunctionName::parse(
-            "ns:name/interface.{resource1(\"hello\", { field-a: some(1) }).drop}",
-        )
-        .expect("Parsing failed");
-        assert_eq!(
-            parsed.site().interface_name(),
-            Some("ns:name/interface".to_string())
-        );
-        assert_eq!(
-            parsed.function().function_name(),
-            "[drop]resource1".to_string()
-        );
-        assert!(parsed.function().is_indexed_resource());
-        assert_eq!(
-            parsed.function().raw_resource_params(),
-            Some(&vec![
-                "\"hello\"".to_string(),
-                "{field-a: some(1)}".to_string(),
-            ])
-        );
-        assert_eq!(
-            parsed,
-            ParsedFunctionName {
-                site: ParsedFunctionSite::PackagedInterface {
-                    namespace: "ns".to_string(),
-                    package: "name".to_string(),
-                    interface: "interface".to_string(),
-                    version: None,
-                },
-                function: ParsedFunctionReference::IndexedResourceDrop {
-                    resource: "resource1".to_string(),
-                    resource_params: vec![
-                        "\"hello\"".to_string(),
-                        "{field-a: some(1)}".to_string(),
-                    ],
-                },
-            },
-        );
-    }
-
     #[test]
     fn parse_function_name_drop() {
         let parsed = ParsedFunctionName::parse("ns:name/interface.{[drop]resource1}")
@@ -1849,62 +1122,9 @@ mod function_name_tests {
         round_trip_function_name_parse("wasi:cli/run@0.2.0.{run}");
         round_trip_function_name_parse("ns:name/interface.{resource1.new}");
         round_trip_function_name_parse("ns:name/interface.{[constructor]resource1}");
-        round_trip_function_name_parse("ns:name/interface.{resource1().new}");
-        round_trip_function_name_parse("ns:name/interface.{resource1(\"hello\", 1, true).new}");
-        round_trip_function_name_parse(
-            "ns:name/interface.{resource1(\"hello\", { field-a: some(1) }).new}",
-        );
         round_trip_function_name_parse("ns:name/interface.{resource1.do-something}");
-        round_trip_function_name_parse(
-            "ns:name/interface.{resource1(\"hello\", 1, true).do-something}",
-        );
-        round_trip_function_name_parse(
-            "ns:name/interface.{resource1(\"hello\", 1, { field-a: some(1) }).do-something}",
-        );
         round_trip_function_name_parse("ns:name/interface.{[static]resource1.do-something-static}");
-        round_trip_function_name_parse(
-            "ns:name/interface.{[static]resource1(\"hello\", 1, true).do-something-static}",
-        );
-        round_trip_function_name_parse("ns:name/interface.{[static]resource1(\"hello\", 1, { field-a: some(1) }).do-something-static}");
         round_trip_function_name_parse("ns:name/interface.{resource1.drop}");
-        round_trip_function_name_parse("ns:name/interface.{resource1().drop}");
-        round_trip_function_name_parse("ns:name/interface.{resource1(\"hello\", 1, true).drop}");
-        round_trip_function_name_parse(
-            "ns:name/interface.{resource1(\"hello\", { field-a: some(1) }).drop}",
-        );
         round_trip_function_name_parse("ns:name/interface.{[drop]resource1}");
     }
-
-    #[test]
-    fn test_parsed_function_name_complex_resource_args() {
-        round_trip_function_name_parse(
-            r#"golem:api/oplog-processor@1.1.0-rc1.{processor({ account-id: { value: "-1" } }, { high-bits: 11637111831105389641, low-bits: 11277240687824975272 }, []).process}"#,
-        )
-    }
-
-    #[test]
-    fn test_parsed_function_name_complex_resource_args_large_nums() {
-        let parsed = ParsedFunctionName::parse(r#"golem:api/oplog-processor@1.1.0-rc1.{processor({ high-bits: 18389549593665948372, low-bits: 12287617583649128209 }).process}"#).expect("Input Parsing failed");
-        let args = parsed
-            .function
-            .resource_params(&[record(vec![
-                field("high-bits", u64()),
-                field("low-bits", u64()),
-            ])])
-            .expect("Resource params parsing failed")
-            .expect("Resource params not found");
-        let nums = if let Value::Record(nums) = &args[0].value {
-            nums.clone()
-        } else {
-            panic!("Expected record")
-        };
-
-        assert_eq!(
-            nums,
-            vec![
-                Value::U64(18389549593665948372u64),
-                Value::U64(12287617583649128209u64),
-            ]
-        )
-    }
 }
diff --git a/golem-rib/src/inferred_type/mod.rs b/golem-rib/src/inferred_type/mod.rs
index 2216fc25..020476a2 100644
--- a/golem-rib/src/inferred_type/mod.rs
+++ b/golem-rib/src/inferred_type/mod.rs
@@ -319,11 +319,18 @@ impl InferredType {
         }
     }
 
-    pub fn resource(resource_id: u64, resource_mode: u8) -> InferredType {
+    pub fn resource(
+        resource_id: u64,
+        resource_mode: u8,
+        owner: Option<String>,
+        name: Option<String>,
+    ) -> InferredType {
         InferredType {
             inner: Box::new(TypeInternal::Resource {
                 resource_id,
                 resource_mode,
+                owner,
+                name,
             }),
             origin: TypeOrigin::NoOrigin,
         }
@@ -690,15 +697,20 @@ impl From<&AnalysedType> for InferredType {
                 )
             }
             AnalysedType::Variant(vs) => InferredType::from_type_variant(vs),
-            AnalysedType::Handle(golem_wasm_ast::analysis::TypeHandle { resource_id, mode }) => {
-                InferredType::resource(
-                    resource_id.0,
-                    match mode {
-                        AnalysedResourceMode::Owned => 0,
-                        AnalysedResourceMode::Borrowed => 1,
-                    },
-                )
-            }
+            AnalysedType::Handle(TypeHandle {
+                resource_id,
+                mode,
+                name,
+                owner,
+            }) => InferredType::resource(
+                resource_id.0,
+                match mode {
+                    AnalysedResourceMode::Owned => 0,
+                    AnalysedResourceMode::Borrowed => 1,
+                },
+                owner.clone(),
+                name.clone(),
+            ),
         }
     }
 }
diff --git a/golem-rib/src/instance_type.rs b/golem-rib/src/instance_type.rs
index 240e3757..fc4f297f 100644
--- a/golem-rib/src/instance_type.rs
+++ b/golem-rib/src/instance_type.rs
@@ -170,8 +170,6 @@ impl InstanceType {
         }
     }
 
-    // Get InstanceType::Resource from the fully qualified resource constructor
-    // from an existing instance type
     pub fn get_resource_instance_type(
         &self,
         fully_qualified_resource_constructor: FullyQualifiedResourceConstructor,
@@ -617,6 +615,7 @@ fn search_function_in_instance(
                     _ => {
                         let function =
                             search_function_in_multiple_packages(function_name, package_map)?;
+
                         component_info_functions.push((info.clone(), function));
                     }
                 }
@@ -765,6 +764,7 @@ mod protobuf {
                 method_name: proto.method_name,
                 package_name: proto.package_name.map(TryFrom::try_from).transpose()?,
                 interface_name: proto.interface_name.map(TryFrom::try_from).transpose()?,
+                static_function: false, //FIXME
             })
         }
     }
diff --git a/golem-rib/src/interpreter/rib_interpreter.rs b/golem-rib/src/interpreter/rib_interpreter.rs
index bf7b3e6a..501da824 100644
--- a/golem-rib/src/interpreter/rib_interpreter.rs
+++ b/golem-rib/src/interpreter/rib_interpreter.rs
@@ -382,7 +382,7 @@ mod internal {
             &self,
             _component_dependency_key: ComponentDependencyKey,
             _instruction_id: &InstructionId,
-            _worker_name: Option<EvaluatedWorkerName>,
+            _worker_name: EvaluatedWorkerName,
             _function_name: EvaluatedFqFn,
             _args: EvaluatedFnArgs,
             _return_type: Option<AnalysedType>,
@@ -1179,130 +1179,6 @@ mod internal {
                     function: ParsedFunctionReference::RawResourceStaticMethod { resource, method },
                 };
 
-                interpreter_stack.push_val(parsed_function_name.to_string().into_value_and_type());
-            }
-            FunctionReferenceType::IndexedResourceConstructor { resource, arg_size } => {
-                let last_n_elements = interpreter_stack
-                    .pop_n(arg_size)
-                    .ok_or_else(|| insufficient_stack_items(arg_size))?;
-
-                let parameter_values = last_n_elements
-                    .iter()
-                    .map(|interpreter_result| {
-                        interpreter_result.get_val().ok_or_else(|| {
-                            internal_corrupted_state!("failed to construct resource")
-                        })
-                    })
-                    .collect::<RibInterpreterResult<Vec<ValueAndType>>>()?;
-
-                let parsed_function_name = ParsedFunctionName {
-                    site,
-                    function: ParsedFunctionReference::IndexedResourceConstructor {
-                        resource,
-                        resource_params: parameter_values
-                            .iter()
-                            .map(|x| x.to_string())
-                            .collect::<Vec<_>>(),
-                    },
-                };
-
-                interpreter_stack.push_val(parsed_function_name.to_string().into_value_and_type());
-            }
-            FunctionReferenceType::IndexedResourceMethod {
-                resource,
-                arg_size,
-                method,
-            } => {
-                let last_n_elements = interpreter_stack
-                    .pop_n(arg_size)
-                    .ok_or_else(|| insufficient_stack_items(arg_size))?;
-
-                let param_values = last_n_elements
-                    .iter()
-                    .map(|interpreter_result| {
-                        interpreter_result.get_val().ok_or_else(|| {
-                            internal_corrupted_state!(
-                                "internal error: failed to call indexed resource method {}",
-                                method
-                            )
-                        })
-                    })
-                    .collect::<RibInterpreterResult<Vec<ValueAndType>>>()?;
-
-                let parsed_function_name = ParsedFunctionName {
-                    site,
-                    function: ParsedFunctionReference::IndexedResourceMethod {
-                        resource,
-                        resource_params: param_values
-                            .iter()
-                            .map(|x| x.to_string())
-                            .collect::<Vec<String>>(),
-                        method,
-                    },
-                };
-
-                interpreter_stack.push_val(parsed_function_name.to_string().into_value_and_type());
-            }
-            FunctionReferenceType::IndexedResourceStaticMethod {
-                resource,
-                arg_size,
-                method,
-            } => {
-                let last_n_elements = interpreter_stack
-                    .pop_n(arg_size)
-                    .ok_or_else(|| insufficient_stack_items(arg_size))?;
-
-                let param_values = last_n_elements
-                    .iter()
-                    .map(|interpreter_result| {
-                        interpreter_result.get_val().ok_or_else(|| {
-                            internal_corrupted_state!(
-                                "failed to call static resource method {}",
-                                method
-                            )
-                        })
-                    })
-                    .collect::<RibInterpreterResult<Vec<ValueAndType>>>()?;
-
-                let parsed_function_name = ParsedFunctionName {
-                    site,
-                    function: ParsedFunctionReference::IndexedResourceStaticMethod {
-                        resource,
-                        resource_params: param_values
-                            .iter()
-                            .map(|x| x.to_string())
-                            .collect::<Vec<_>>(),
-                        method,
-                    },
-                };
-
-                interpreter_stack.push_val(parsed_function_name.to_string().into_value_and_type());
-            }
-            FunctionReferenceType::IndexedResourceDrop { resource, arg_size } => {
-                let last_n_elements = interpreter_stack
-                    .pop_n(arg_size)
-                    .ok_or_else(|| insufficient_stack_items(arg_size))?;
-
-                let param_values = last_n_elements
-                    .iter()
-                    .map(|interpreter_result| {
-                        interpreter_result.get_val().ok_or_else(|| {
-                            internal_corrupted_state!("failed to call indexed resource drop")
-                        })
-                    })
-                    .collect::<RibInterpreterResult<Vec<ValueAndType>>>()?;
-
-                let parsed_function_name = ParsedFunctionName {
-                    site,
-                    function: ParsedFunctionReference::IndexedResourceDrop {
-                        resource,
-                        resource_params: param_values
-                            .iter()
-                            .map(|x| x.to_string())
-                            .collect::<Vec<_>>(),
-                    },
-                };
-
                 interpreter_stack.push_val(parsed_function_name.to_string().into_value_and_type());
             }
         }
@@ -1375,7 +1251,32 @@ mod internal {
                     .invoke_worker_function_async(
                         component_info,
                         instruction_id,
-                        Some(worker_id_string),
+                        worker_id_string,
+                        function_name_cloned,
+                        parameter_values,
+                        expected_result_type.clone(),
+                    )
+                    .await
+                    .map_err(|err| function_invoke_fail(function_name.as_str(), err))?;
+
+                match result {
+                    None => {
+                        interpreter_stack.push(RibInterpreterStackValue::Unit);
+                    }
+                    Some(result) => {
+                        interpreter_stack.push(RibInterpreterStackValue::Val(result));
+                    }
+                }
+            }
+
+            InstanceVariable::WitResource(variable_id)
+                if variable_id == VariableId::global("___STATIC_WIT_RESOURCE".to_string()) =>
+            {
+                let result = interpreter_env
+                    .invoke_worker_function_async(
+                        component_info,
+                        instruction_id,
+                        "___STATIC_WIT_RESOURCE".to_string(),
                         function_name_cloned,
                         parameter_values,
                         expected_result_type.clone(),
@@ -1425,7 +1326,7 @@ mod internal {
                             .invoke_worker_function_async(
                                 component_info,
                                 instruction_id,
-                                Some(worker_name.to_string()),
+                                worker_name.to_string(),
                                 function_name_cloned.clone(),
                                 final_args,
                                 expected_result_type.clone(),
@@ -1553,7 +1454,7 @@ mod internal {
         let value = interpreter_stack.try_pop_val()?;
 
         match analysed_type {
-            AnalysedType::Result(TypeResult { ok, err }) => {
+            AnalysedType::Result(TypeResult { ok, err, .. }) => {
                 interpreter_stack.push_ok(value.value, ok.as_deref(), err.as_deref());
                 Ok(())
             }
@@ -1574,7 +1475,7 @@ mod internal {
         let value = interpreter_stack.try_pop_val()?;
 
         match analysed_type {
-            AnalysedType::Result(TypeResult { ok, err }) => {
+            AnalysedType::Result(TypeResult { ok, err, .. }) => {
                 interpreter_stack.push_err(value.value, ok.as_deref(), err.as_deref());
                 Ok(())
             }
@@ -2846,6 +2747,72 @@ mod tests {
         assert_eq!(result.get_val().unwrap().value, expected_value);
     }
 
+    #[test]
+    async fn test_interpreter_with_indexed_resources_static_functions_1() {
+        let expr = r#"
+           let worker = instance();
+           let result = worker.cart.create("afsal");
+           result.checkout()
+        "#;
+
+        let expr = Expr::from_text(expr).unwrap();
+
+        let test_deps = RibTestDeps::test_deps_with_indexed_resource_functions(None);
+
+        let compiler_config =
+            RibCompilerConfig::new(test_deps.component_dependencies.clone(), vec![]);
+        let compiler = RibCompiler::new(compiler_config);
+
+        let compiled = compiler.compile(expr).unwrap();
+
+        let mut rib_executor = test_deps.interpreter;
+        let result = rib_executor.run(compiled.byte_code).await.unwrap();
+
+        let expected_value = Value::Variant {
+            case_idx: 1,
+            case_value: Some(Box::new(Value::Record(vec![Value::String(
+                "foo".to_string(),
+            )]))),
+        };
+
+        assert_eq!(result.get_val().unwrap().value, expected_value);
+    }
+
+    #[test]
+    async fn test_interpreter_with_indexed_resources_static_functions_2() {
+        let expr = r#"
+           let worker = instance();
+           let default-cart = worker.cart("default");
+           let alternate-cart = worker.cart.create-safe("afsal");
+           match alternate-cart {
+             ok(alt) => alt.checkout(),
+             err(_) => default-cart.checkout()
+           }
+        "#;
+
+        let expr = Expr::from_text(expr).unwrap();
+
+        let test_deps = RibTestDeps::test_deps_with_indexed_resource_functions(None);
+
+        let compiler_config =
+            RibCompilerConfig::new(test_deps.component_dependencies.clone(), vec![]);
+        let compiler = RibCompiler::new(compiler_config);
+
+        let compiled = compiler.compile(expr).unwrap();
+
+        let mut rib_executor = test_deps.interpreter;
+        let result = rib_executor.run(compiled.byte_code).await.unwrap();
+
+        let expected_value = Value::Variant {
+            case_idx: 1,
+            case_value: Some(Box::new(Value::Record(vec![Value::String(
+                "foo".to_string(),
+            )]))),
+        };
+
+        assert_eq!(result.get_val().unwrap().value, expected_value);
+    }
+
     #[test]
     async fn test_interpreter_with_indexed_resource_get_cart_contents() {
         let expr = r#"
@@ -4764,7 +4731,7 @@ mod tests {
         };
         use golem_wasm_ast::analysis::{
             AnalysedExport, AnalysedFunction, AnalysedFunctionParameter, AnalysedFunctionResult,
-            AnalysedInstance, AnalysedResourceId, AnalysedResourceMode, AnalysedType,
+            AnalysedInstance, AnalysedResourceId, AnalysedResourceMode, AnalysedType, TypeHandle,
         };
         use golem_wasm_rpc::{IntoValueAndType, Value, ValueAndType};
         use std::sync::Arc;
@@ -4991,6 +4958,39 @@ mod tests {
                             typ: handle(AnalysedResourceId(0), AnalysedResourceMode::Owned),
                         }),
                     },
+                    AnalysedFunction {
+                        name: "[static]cart.create".to_string(),
+                        parameters: vec![AnalysedFunctionParameter {
+                            name: "item-name".to_string(),
+                            typ: str(),
+                        }],
+                        result: Some(AnalysedFunctionResult {
+                            typ: AnalysedType::Handle(TypeHandle {
+                                name: Some("cart".to_string()),
+                                owner: Some("golem:it/api".to_string()),
+                                resource_id: AnalysedResourceId(0),
+                                mode: AnalysedResourceMode::Owned,
+                            }),
+                        }),
+                    },
+                    AnalysedFunction {
+                        name: "[static]cart.create-safe".to_string(),
+                        parameters: vec![AnalysedFunctionParameter {
+                            name: "item-name".to_string(),
+                            typ: str(),
+                        }],
+                        result: Some(AnalysedFunctionResult {
+                            typ: result(
+                                AnalysedType::Handle(TypeHandle {
+                                    name: Some("cart".to_string()),
+                                    owner: Some("golem:it/api".to_string()),
+                                    resource_id: AnalysedResourceId(0),
+                                    mode: AnalysedResourceMode::Owned,
+                                }),
+                                str(),
+                            ),
+                        }),
+                    },
                     AnalysedFunction {
                         name: "[method]cart.add-item".to_string(),
                         parameters: vec![
@@ -5180,7 +5180,7 @@ mod tests {
                 &self,
                 _component_dependency_key: ComponentDependencyKey,
                 _instruction_id: &InstructionId,
-                _worker_name: Option<EvaluatedWorkerName>,
+                _worker_name: EvaluatedWorkerName,
                 _fqn: EvaluatedFqFn,
                 _args: EvaluatedFnArgs,
                 _return_type: Option<AnalysedType>,
@@ -5198,7 +5198,7 @@ mod tests {
                 &self,
                 _component_dependency_key: ComponentDependencyKey,
                 _instruction_id: &InstructionId,
-                worker_name: Option<EvaluatedWorkerName>,
+                worker_name: EvaluatedWorkerName,
                 function_name: EvaluatedFqFn,
                 args: EvaluatedFnArgs,
                 _return_type: Option<AnalysedType>,
@@ -5210,7 +5210,7 @@ mod tests {
                     field("args1", u32()),
                 ]);
 
-                let worker_name = Value::String(worker_name.map(|x| x.0).unwrap_or_default());
+                let worker_name = Value::String(worker_name.0);
                 let function_name = Value::String(function_name.0);
                 let args0 = args.0[0].value.clone();
                 let args1 = args.0[1].value.clone();
@@ -5229,14 +5229,14 @@ mod tests {
                 &self,
                 _component_dependency_key: ComponentDependencyKey,
                 _instruction_id: &InstructionId,
-                worker_name: Option<EvaluatedWorkerName>,
+                worker_name: EvaluatedWorkerName,
                 function_name: EvaluatedFqFn,
                 args: EvaluatedFnArgs,
                 _return_type: Option<AnalysedType>,
             ) -> RibFunctionInvokeResult {
                 match function_name.0.as_str() {
                     "golem:it/api.{cart.new}" => {
-                        let worker_name = worker_name.map(|x| x.0).unwrap_or_default();
+                        let worker_name = worker_name.0;
 
                         let uri = format!(
                             "urn:worker:99738bab-a3bf-4a12-8830-b6fd783d1ef2/{worker_name}"
@@ -5293,8 +5293,47 @@ mod tests {
                         Ok(Some(ValueAndType::new(Value::List(vec![value]), typ)))
                     }
 
+                    "golem:it/api.{[static]cart.create}" => {
+                        let uri = format!(
+                            "urn:worker:99738bab-a3bf-4a12-8830-b6fd783d1ef2/{}",
+                            worker_name.0
+                        );
+
+                        let value = Value::Handle {
+                            uri,
+                            resource_id: 0,
+                        };
+
+                        Ok(Some(ValueAndType::new(
+                            value,
+                            handle(AnalysedResourceId(0), AnalysedResourceMode::Owned),
+                        )))
+                    }
+
+                    "golem:it/api.{[static]cart.create-safe}" => {
+                        let uri = format!(
+                            "urn:worker:99738bab-a3bf-4a12-8830-b6fd783d1ef2/{}",
+                            worker_name.0
+                        );
+
+                        let resource = Value::Handle {
+                            uri,
+                            resource_id: 0,
+                        };
+
+                        let value = Value::Result(Ok(Some(Box::new(resource))));
+
+                        Ok(Some(ValueAndType::new(
+                            value,
+                            result(
+                                handle(AnalysedResourceId(0), AnalysedResourceMode::Owned),
+                                str(),
+                            ),
+                        )))
+                    }
+
                     "golem:it/api.{cart.pass-through}" => {
-                        let worker_name = worker_name.map(|x| x.0);
+                        let worker_name = worker_name.0;
                         let function_args = args.0[1..].to_vec();
 
                         let mut arg_types = vec![];
@@ -5308,15 +5347,13 @@ mod tests {
                         let function_name = function_name.0.into_value_and_type();
 
                         let mut analysed_type_pairs = vec![];
-                        analysed_type_pairs.push(field("worker-name", option(str())));
+                        analysed_type_pairs.push(field("worker-name", str()));
                         analysed_type_pairs.push(field("function-name", str()));
                         analysed_type_pairs.extend(arg_types);
 
                         let mut values = vec![];
 
-                        values.push(Value::Option(
-                            worker_name.map(|x| Box::new(Value::String(x))),
-                        ));
+                        values.push(Value::String(worker_name));
                         values.push(function_name.value);
 
                         for arg_value in function_args {
@@ -5342,7 +5379,7 @@ mod tests {
                 &self,
                 _component_dependency_key: ComponentDependencyKey,
                 _instruction_id: &InstructionId,
-                _worker_name: Option<EvaluatedWorkerName>,
+                _worker_name: EvaluatedWorkerName,
                 function_name: EvaluatedFqFn,
                 _args: EvaluatedFnArgs,
                 _return_type: Option<AnalysedType>,
@@ -5595,7 +5632,7 @@ mod tests {
                 &self,
                 _component_dependency: ComponentDependencyKey,
                 _instruction_id: &InstructionId,
-                _worker_name: Option<EvaluatedWorkerName>,
+                _worker_name: EvaluatedWorkerName,
                 function_name: EvaluatedFqFn,
                 args: EvaluatedFnArgs,
                 _return_type: Option<AnalysedType>,
diff --git a/golem-rib/src/parser/call.rs b/golem-rib/src/parser/call.rs
index 1256253e..98114052 100644
--- a/golem-rib/src/parser/call.rs
+++ b/golem-rib/src/parser/call.rs
@@ -19,12 +19,11 @@ use crate::parser::generic_type_parameter::generic_type_parameter;
 use crate::parser::rib_expr::rib_expr;
 use crate::rib_source_span::GetSourcePosition;
 use crate::{DynamicParsedFunctionName, DynamicParsedFunctionReference};
-use combine::error::{Commit, StreamError};
 use combine::parser::char::{alpha_num, string};
 use combine::parser::char::{char, spaces};
 use combine::parser::repeat::take_until;
-use combine::{any, attempt, between, choice, many1, optional, parser, token, ParseError, Parser};
-use combine::{sep_by, ParseResult, Positioned};
+use combine::sep_by;
+use combine::{attempt, between, choice, many1, optional, token, ParseError, Parser};
 
 // A call can be a function or constructing an anonymous variant at the type of writing Rib which user expects to work at runtime
 pub fn call<Input>() -> impl Parser<Input, Output = Expr>
@@ -65,77 +64,6 @@ where
     let ns_pkg = (namespace, token(':'), package).map(|(ns, _, pkg)| (ns, pkg));
     let interface = many1(identifier());
 
-    let capture_resource_params = || {
-        parser(|input| {
-            let _: &mut Input = input;
-            let mut nesting = 1;
-            let mut current_param = String::new();
-            let mut result = Vec::new();
-            let mut result_committed: Option<Commit<()>> = None;
-
-            while nesting > 0 {
-                let (next_char, committed) = any().parse_stream(input).into_result()?;
-
-                if next_char == ')' {
-                    nesting -= 1;
-                    if nesting > 0 {
-                        current_param.push(next_char);
-                    }
-                } else if next_char == '(' || next_char == '{' || next_char == '[' {
-                    nesting += 1;
-                    current_param.push(next_char);
-                } else if next_char == '}' || next_char == ']' {
-                    nesting -= 1;
-                    current_param.push(next_char);
-                } else if next_char == ',' && nesting == 1 {
-                    let expr = Expr::from_text(current_param.trim());
-                    match expr {
-                        Ok(expr) => {
-                            result.push(expr);
-                            current_param.clear();
-                        }
-                        Err(err) => {
-                            return ParseResult::CommitErr(ParseError::from_error(
-                                input.position(),
-                                StreamError::message_format(format!(
-                                    "Failed to parse resource parameter {current_param}: {err}"
-                                )),
-                            ))
-                            .into_result();
-                        }
-                    }
-                } else {
-                    current_param.push(next_char);
-                }
-
-                result_committed = match result_committed {
-                    Some(c) => Some(c.merge(committed)),
-                    None => Some(committed),
-                };
-            }
-
-            if !current_param.is_empty() {
-                let expr = Expr::from_text(current_param.trim());
-                match expr {
-                    Ok(expr) => {
-                        result.push(expr);
-                    }
-                    Err(err) => {
-                        return ParseResult::CommitErr(ParseError::from_error(
-                            input.position(),
-                            StreamError::message_format(format!(
-                                "Failed to parse resource parameter {err}"
-                            )),
-                        ))
-                        .into_result();
-                    }
-                }
-            }
-
-            Ok((result, result_committed.unwrap()))
-        })
-    };
-
     let version = attempt(token('@'))
         .with(take_until(attempt(string(".{"))))
         .and_then(|v: String| {
@@ -150,44 +78,6 @@ where
     let single_function =
         identifier().map(|id| DynamicParsedFunctionReference::Function { function: id });
 
-    let indexed_resource_syntax = || (identifier(), token('(').with(capture_resource_params()));
-    let indexed_constructor_syntax = (indexed_resource_syntax(), token('.'), string("new")).map(
-        |((resource, resource_params), _, _)| {
-            DynamicParsedFunctionReference::IndexedResourceConstructor {
-                resource,
-                resource_params,
-            }
-        },
-    );
-    let indexed_drop_syntax = (indexed_resource_syntax(), token('.'), string("drop")).map(
-        |((resource, resource_params), _, _)| DynamicParsedFunctionReference::IndexedResourceDrop {
-            resource,
-            resource_params,
-        },
-    );
-    let indexed_method_syntax = (indexed_resource_syntax(), token('.'), identifier()).map(
-        |((resource, resource_params), _, method)| {
-            DynamicParsedFunctionReference::IndexedResourceMethod {
-                resource,
-                resource_params,
-                method,
-            }
-        },
-    );
-    let indexed_static_method_syntax = (
-        string("[static]"),
-        indexed_resource_syntax(),
-        token('.'),
-        identifier(),
-    )
-        .map(|(_, (resource, resource_params), _, method)| {
-            DynamicParsedFunctionReference::IndexedResourceStaticMethod {
-                resource,
-                resource_params,
-                method,
-            }
-        });
-
     let raw_constructor_syntax = (identifier(), token('.'), string("new"))
         .map(|(resource, _, _)| DynamicParsedFunctionReference::RawResourceConstructor { resource })
         .or(
@@ -223,10 +113,6 @@ where
         );
 
     let function = choice((
-        attempt(indexed_constructor_syntax),
-        attempt(indexed_drop_syntax),
-        attempt(indexed_method_syntax),
-        attempt(indexed_static_method_syntax),
         attempt(raw_constructor_syntax),
         attempt(raw_drop_syntax),
         attempt(raw_method_syntax),
@@ -264,7 +150,6 @@ where
 }
 #[cfg(test)]
 mod function_call_tests {
-    use bigdecimal::BigDecimal;
     use test_r::test;
 
     use crate::{DynamicParsedFunctionName, DynamicParsedFunctionReference};
@@ -806,93 +691,6 @@ mod function_call_tests {
         assert_eq!(result, expected);
     }
 
-    #[test]
-    fn test_call_with_function_name_indexed_constructor1() {
-        let input = "ns:name/interface.{resource1().new}({bar, baz})";
-        let result = Expr::from_text(input);
-        let expected = Ok(Expr::call_worker_function(
-            DynamicParsedFunctionName {
-                site: ParsedFunctionSite::PackagedInterface {
-                    namespace: "ns".to_string(),
-                    package: "name".to_string(),
-                    interface: "interface".to_string(),
-                    version: None,
-                },
-                function: DynamicParsedFunctionReference::IndexedResourceConstructor {
-                    resource: "resource1".to_string(),
-                    resource_params: vec![],
-                },
-            },
-            None,
-            None,
-            vec![Expr::flags(vec!["bar".to_string(), "baz".to_string()])],
-            None,
-        ));
-        assert_eq!(result, expected);
-    }
-
-    // TODO: The resource parameters can be identifiers, but currently function name parser parses all arguments to be just string
-    #[test]
-    fn test_call_with_function_name_indexed_constructor2() {
-        let input = "ns:name/interface.{resource1(\"hello\", 1, true).new}({bar, baz})";
-        let result = Expr::from_text(input);
-        let expected = Ok(Expr::call_worker_function(
-            DynamicParsedFunctionName {
-                site: ParsedFunctionSite::PackagedInterface {
-                    namespace: "ns".to_string(),
-                    package: "name".to_string(),
-                    interface: "interface".to_string(),
-                    version: None,
-                },
-                function: DynamicParsedFunctionReference::IndexedResourceConstructor {
-                    resource: "resource1".to_string(),
-                    resource_params: vec![
-                        Expr::literal("hello"),
-                        Expr::number(BigDecimal::from(1)),
-                        Expr::boolean(true),
-                    ],
-                },
-            },
-            None,
-            None,
-            vec![Expr::flags(vec!["bar".to_string(), "baz".to_string()])],
-            None,
-        ));
-        assert_eq!(result, expected);
-    }
-
-    #[test]
-    fn test_call_with_function_name_indexed_constructor3() {
-        let input =
-            "ns:name/interface.{resource1(\"hello\", { field-a: some(1) }).new}({bar, baz})";
-        let result = Expr::from_text(input);
-        let expected = Ok(Expr::call_worker_function(
-            DynamicParsedFunctionName {
-                site: ParsedFunctionSite::PackagedInterface {
-                    namespace: "ns".to_string(),
-                    package: "name".to_string(),
-                    interface: "interface".to_string(),
-                    version: None,
-                },
-                function: DynamicParsedFunctionReference::IndexedResourceConstructor {
-                    resource: "resource1".to_string(),
-                    resource_params: vec![
-                        Expr::literal("hello"),
-                        Expr::record(vec![(
-                            "field-a".to_string(),
-                            Expr::option(Some(Expr::number(BigDecimal::from(1)))),
-                        )]),
-                    ],
-                },
-            },
-            None,
-            None,
-            vec![Expr::flags(vec!["bar".to_string(), "baz".to_string()])],
-            None,
-        ));
-        assert_eq!(result, expected);
-    }
-
     #[test]
     fn test_call_with_function_name_method_syntax_sugar() {
         let input = "ns:name/interface.{resource1.do-something}({bar, baz})";
@@ -1018,92 +816,6 @@ mod function_call_tests {
         assert_eq!(result, expected);
     }
 
-    #[test]
-    fn test_call_with_function_name_indexed_drop_1() {
-        let input = "ns:name/interface.{resource1().drop}({bar, baz})";
-        let result = Expr::from_text(input);
-        let expected = Ok(Expr::call_worker_function(
-            DynamicParsedFunctionName {
-                site: ParsedFunctionSite::PackagedInterface {
-                    namespace: "ns".to_string(),
-                    package: "name".to_string(),
-                    interface: "interface".to_string(),
-                    version: None,
-                },
-                function: DynamicParsedFunctionReference::IndexedResourceDrop {
-                    resource: "resource1".to_string(),
-                    resource_params: vec![],
-                },
-            },
-            None,
-            None,
-            vec![Expr::flags(vec!["bar".to_string(), "baz".to_string()])],
-            None,
-        ));
-        assert_eq!(result, expected);
-    }
-
-    #[test]
-    fn test_call_with_function_name_indexed_drop_2() {
-        let input = "ns:name/interface.{resource1(\"hello\", 1, true).drop}({bar, baz})";
-        let result = Expr::from_text(input);
-        let expected = Ok(Expr::call_worker_function(
-            DynamicParsedFunctionName {
-                site: ParsedFunctionSite::PackagedInterface {
-                    namespace: "ns".to_string(),
-                    package: "name".to_string(),
-                    interface: "interface".to_string(),
-                    version: None,
-                },
-                function: DynamicParsedFunctionReference::IndexedResourceDrop {
-                    resource: "resource1".to_string(),
-                    resource_params: vec![
-                        Expr::literal("hello"),
-                        Expr::number(BigDecimal::from(1)),
-                        Expr::boolean(true),
-                    ],
-                },
-            },
-            None,
-            None,
-            vec![Expr::flags(vec!["bar".to_string(), "baz".to_string()])],
-            None,
-        ));
-        assert_eq!(result, expected);
-    }
-
-    #[test]
-    fn test_call_with_function_name_indexed_drop_3() {
-        let input =
-            "ns:name/interface.{resource1(\"hello\", { field-a: some(1) }).drop}({bar, baz})";
-        let result = Expr::from_text(input);
-        let expected = Ok(Expr::call_worker_function(
-            DynamicParsedFunctionName {
-                site: ParsedFunctionSite::PackagedInterface {
-                    namespace: "ns".to_string(),
-                    package: "name".to_string(),
-                    interface: "interface".to_string(),
-                    version: None,
-                },
-                function: DynamicParsedFunctionReference::IndexedResourceDrop {
-                    resource: "resource1".to_string(),
-                    resource_params: vec![
-                        Expr::literal("hello"),
-                        Expr::record(vec![(
-                            "field-a".to_string(),
-                            Expr::option(Some(Expr::number(BigDecimal::from(1)))),
-                        )]),
-                    ],
-                },
-            },
-            None,
-            None,
-            vec![Expr::flags(vec!["bar".to_string(), "baz".to_string()])],
-            None,
-        ));
-        assert_eq!(result, expected);
-    }
-
     #[test]
     fn test_call_with_function_name_drop() {
         let input = "ns:name/interface.{[drop]resource1}({bar, baz})";
diff --git a/golem-rib/src/parser/type_name.rs b/golem-rib/src/parser/type_name.rs
index 6fcf59fb..8eb60861 100644
--- a/golem-rib/src/parser/type_name.rs
+++ b/golem-rib/src/parser/type_name.rs
@@ -199,7 +199,7 @@ impl TryFrom<AnalysedType> for TypeName {
             AnalysedType::Option(type_option) => Ok(TypeName::Option(Box::new(
                 type_option.inner.deref().clone().try_into()?,
             ))),
-            AnalysedType::Result(TypeResult { ok, err }) => match (ok, err) {
+            AnalysedType::Result(TypeResult { ok, err, .. }) => match (ok, err) {
                 (Some(ok), Some(err)) => Ok(TypeName::Result {
                     ok: Some(Box::new(ok.deref().clone().try_into()?)),
                     error: Some(Box::new(err.deref().clone().try_into()?)),
diff --git a/golem-rib/src/registry/component_dependencies.rs b/golem-rib/src/registry/component_dependencies.rs
index 303d5506..825bd02a 100644
--- a/golem-rib/src/registry/component_dependencies.rs
+++ b/golem-rib/src/registry/component_dependencies.rs
@@ -55,14 +55,14 @@ impl ComponentDependencies {
         &self,
         component_info: &Option<ComponentDependencyKey>,
         function_name: &FunctionName,
-    ) -> Result<FunctionType, String> {
+    ) -> Result<(ComponentDependencyKey, FunctionType), String> {
         // If function name is unique across all components, we are not in need of a component_info per se
         // and we can return the exact component dependency
         match component_info {
             None => {
                 let mut function_types_in_component = vec![];
 
-                for (component_info, function_dict) in &self.dependencies {
+                for (component_dependency_key, function_dict) in &self.dependencies {
                     let types = function_dict
                         .name_and_types
                         .iter()
@@ -75,7 +75,7 @@ impl ComponentDependencies {
                         })
                         .collect::<Vec<_>>();
 
-                    function_types_in_component.push((component_info.clone(), types));
+                    function_types_in_component.push((component_dependency_key.clone(), types));
                 }
 
                 if function_types_in_component.is_empty() {
@@ -85,25 +85,24 @@ impl ComponentDependencies {
                         "function `{function_name}` is ambiguous across components"
                     ))
                 } else {
-                    let function_types = function_types_in_component.pop().unwrap();
-                    let function_type = function_types.1;
+                    let (key, types) = function_types_in_component.pop().unwrap();
 
-                    if function_type.is_empty() {
+                    if types.is_empty() {
                         Err("unknown function".to_string())
                     } else {
-                        Ok(function_type[0].clone())
+                        Ok((key, types[0].clone()))
                     }
                 }
             }
-            Some(component_info) => {
+            Some(component_dep_key) => {
                 let function_dictionary = self
                     .dependencies
-                    .get(component_info)
+                    .get(component_dep_key)
                     .cloned()
                     .ok_or_else(|| {
                         format!(
                             "component dependency for `{}` not found",
-                            component_info.component_name
+                            component_dep_key.component_name
                         )
                     })?;
 
@@ -118,11 +117,11 @@ impl ComponentDependencies {
                 );
 
                 if let Some(function_type) = function_type {
-                    Ok(function_type)
+                    Ok((component_dep_key.clone(), function_type))
                 } else {
                     Err(format!(
                         "function `{}` not found in component `{}`",
-                        function_name, component_info.component_name
+                        function_name, component_dep_key.component_name
                     ))
                 }
             }
diff --git a/golem-rib/src/registry/function_dictionary.rs b/golem-rib/src/registry/function_dictionary.rs
index 4574069c..18353bbb 100644
--- a/golem-rib/src/registry/function_dictionary.rs
+++ b/golem-rib/src/registry/function_dictionary.rs
@@ -115,7 +115,7 @@ impl From<&ResourceMethodDictionary> for FunctionDictionary {
 }
 
 impl FunctionDictionary {
-    pub fn from_exports(exports: &Vec<AnalysedExport>) -> Result<FunctionDictionary, String> {
+    pub fn from_exports(exports: &[AnalysedExport]) -> Result<FunctionDictionary, String> {
         let registry = FunctionTypeRegistry::from_export_metadata(exports);
         Self::from_function_type_registry(&registry)
     }
@@ -255,15 +255,29 @@ fn resolve_function_name(
                     interface_name,
                     resource_name: constructor,
                     method_name: method,
+                    static_function: false,
                 }))
             }
-            Ok(None) => Ok(FunctionName::Function(FullyQualifiedFunctionName {
-                package_name,
-                interface_name,
-                function_name: function_name.to_string(),
-            })),
+            Ok(None) => match get_resource_static_method_name(function_name) {
+                Ok(Some((constructor, method))) => {
+                    Ok(FunctionName::ResourceMethod(FullyQualifiedResourceMethod {
+                        package_name,
+                        interface_name,
+                        resource_name: constructor,
+                        method_name: method,
+                        static_function: true,
+                    }))
+                }
+                Ok(None) => Ok(FunctionName::Function(FullyQualifiedFunctionName {
+                    package_name,
+                    interface_name,
+                    function_name: function_name.to_string(),
+                })),
 
-            Err(e) => Err(format!("invalid function call. {e}")),
+                Err(e) => Err(format!("invalid resource static method call. {e}")),
+            },
+
+            Err(e) => Err(format!("invalid resource method call. {e}")),
         },
     }
 }
@@ -280,6 +294,26 @@ fn get_resource_name(function_name: &str) -> Option<String> {
     }
 }
 
+fn get_resource_static_method_name(
+    function_name: &str,
+) -> Result<Option<(String, String)>, String> {
+    if function_name.starts_with("[static]") {
+        let constructor_and_method = function_name.trim_start_matches("[static]").to_string();
+        let mut constructor_and_method = constructor_and_method.split('.');
+        let constructor = constructor_and_method.next();
+        let method = constructor_and_method.next();
+
+        match (constructor, method) {
+            (Some(constructor), Some(method)) => {
+                Ok(Some((constructor.to_string(), method.to_string())))
+            }
+            _ => Err(format!("Invalid resource method name: {function_name}")),
+        }
+    } else {
+        Ok(None)
+    }
+}
+
 fn get_resource_method_name(function_name: &str) -> Result<Option<(String, String)>, String> {
     if function_name.starts_with("[method]") {
         let constructor_and_method = function_name.trim_start_matches("[method]").to_string();
@@ -370,6 +404,7 @@ impl FunctionName {
                     interface_name,
                     resource_name: resource.clone(),
                     method_name: "drop".to_string(),
+                    static_function: false,
                 })
             }
             DynamicParsedFunctionReference::RawResourceMethod { resource, method } => {
@@ -378,6 +413,7 @@ impl FunctionName {
                     interface_name,
                     resource_name: resource.clone(),
                     method_name: method.clone(),
+                    static_function: false,
                 })
             }
             DynamicParsedFunctionReference::RawResourceStaticMethod { resource, method } => {
@@ -386,39 +422,7 @@ impl FunctionName {
                     interface_name,
                     resource_name: resource.clone(),
                     method_name: method.clone(),
-                })
-            }
-            DynamicParsedFunctionReference::IndexedResourceConstructor { resource, .. } => {
-                FunctionName::ResourceConstructor(FullyQualifiedResourceConstructor {
-                    package_name,
-                    interface_name,
-                    resource_name: resource.clone(),
-                })
-            }
-            DynamicParsedFunctionReference::IndexedResourceMethod {
-                resource, method, ..
-            } => FunctionName::ResourceMethod(FullyQualifiedResourceMethod {
-                package_name,
-                interface_name,
-                resource_name: resource.clone(),
-                method_name: method.clone(),
-            }),
-            DynamicParsedFunctionReference::IndexedResourceStaticMethod {
-                resource,
-                method,
-                ..
-            } => FunctionName::ResourceMethod(FullyQualifiedResourceMethod {
-                package_name,
-                interface_name,
-                resource_name: resource.clone(),
-                method_name: method.clone(),
-            }),
-            DynamicParsedFunctionReference::IndexedResourceDrop { resource, .. } => {
-                FunctionName::ResourceMethod(FullyQualifiedResourceMethod {
-                    package_name,
-                    interface_name,
-                    resource_name: resource.clone(),
-                    method_name: "drop".to_string(),
+                    static_function: true,
                 })
             }
         }
@@ -514,6 +518,7 @@ pub struct FullyQualifiedResourceMethod {
     pub interface_name: Option<InterfaceName>,
     pub resource_name: String,
     pub method_name: String,
+    pub static_function: bool,
 }
 
 impl FullyQualifiedResourceMethod {
@@ -525,7 +530,8 @@ impl FullyQualifiedResourceMethod {
         }
     }
 
-    // We rely on the fully parsed function name itself to retrieve the original function name
+    // TODO; Remove this conversion inside Rib.
+    // FunctionName (the structure used by rib) can be used in all places of usage of DynamicParsedFunctionName
     pub fn dynamic_parsed_function_name(&self) -> Result<DynamicParsedFunctionName, String> {
         let mut dynamic_parsed_str = String::new();
 
@@ -542,6 +548,11 @@ impl FullyQualifiedResourceMethod {
 
         // Start the dynamic function name with resource
         dynamic_parsed_str.push('{');
+        if self.static_function {
+            dynamic_parsed_str.push_str("[static]");
+        } else {
+            dynamic_parsed_str.push_str("[method]");
+        }
         dynamic_parsed_str.push_str(&self.resource_name);
         dynamic_parsed_str.push('.');
         dynamic_parsed_str.push_str(&self.method_name);
diff --git a/golem-rib/src/registry/raw_type_registry.rs b/golem-rib/src/registry/raw_type_registry.rs
index 9991adbe..0b82dc71 100644
--- a/golem-rib/src/registry/raw_type_registry.rs
+++ b/golem-rib/src/registry/raw_type_registry.rs
@@ -86,7 +86,7 @@ impl FunctionTypeRegistry {
         }
     }
 
-    pub fn from_export_metadata(exports: &Vec<AnalysedExport>) -> Self {
+    pub fn from_export_metadata(exports: &[AnalysedExport]) -> Self {
         let mut map = HashMap::new();
 
         let mut types = HashSet::new();
@@ -347,6 +347,7 @@ mod internal {
             AnalysedType::Result(TypeResult {
                 ok: Some(ok_type),
                 err: Some(err_type),
+                ..
             }) => {
                 update_registry(ok_type.as_ref(), registry);
                 update_registry(err_type.as_ref(), registry);
@@ -354,12 +355,14 @@ mod internal {
             AnalysedType::Result(TypeResult {
                 ok: None,
                 err: Some(err_type),
+                ..
             }) => {
                 update_registry(err_type.as_ref(), registry);
             }
             AnalysedType::Result(TypeResult {
                 ok: Some(ok_type),
                 err: None,
+                ..
             }) => {
                 update_registry(ok_type.as_ref(), registry);
             }
@@ -369,6 +372,7 @@ mod internal {
             AnalysedType::Result(TypeResult {
                 ok: None,
                 err: None,
+                ..
             }) => {}
             AnalysedType::Flags(_) => {}
             AnalysedType::Str(_) => {}
diff --git a/golem-rib/src/type_inference/call_arguments_inference.rs b/golem-rib/src/type_inference/call_arguments_inference.rs
index 12c7788f..05c02d1c 100644
--- a/golem-rib/src/type_inference/call_arguments_inference.rs
+++ b/golem-rib/src/type_inference/call_arguments_inference.rs
@@ -12,7 +12,8 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use crate::{ComponentDependencies, Expr, ExprVisitor, FunctionCallError};
+use crate::{ComponentDependencies, Expr, FunctionCallError};
+use std::collections::VecDeque;
 
 // Resolving function arguments and return types based on function type registry
 // If the function call is a mere instance creation, then the return type
@@ -23,7 +24,8 @@ pub fn infer_function_call_types(
     expr: &mut Expr,
     component_dependency: &ComponentDependencies,
 ) -> Result<(), FunctionCallError> {
-    let mut visitor = ExprVisitor::bottom_up(expr);
+    let mut visitor = VecDeque::new();
+    visitor.push_back(expr);
     while let Some(expr) = visitor.pop_back() {
         let source_span = expr.source_span();
 
@@ -41,6 +43,8 @@ pub fn infer_function_call_types(
                 args,
                 inferred_type,
             )?;
+        } else {
+            expr.visit_expr_nodes_lazy(&mut visitor);
         }
     }
 
@@ -217,13 +221,14 @@ mod internal {
         args: &mut [Expr],
         function_result_inferred_type: Option<&mut InferredType>,
     ) -> Result<(), FunctionCallError> {
-        let function_type = component_dependency
-            .get_function_type(&None, key)
-            .map_err(|err| FunctionCallError::InvalidFunctionCall {
-                function_name: function_name.to_string(),
-                source_span: original_source_span.clone(),
-                message: err.to_string(),
-            })?;
+        let (_, function_type) =
+            component_dependency
+                .get_function_type(&None, key)
+                .map_err(|err| FunctionCallError::InvalidFunctionCall {
+                    function_name: function_name.to_string(),
+                    source_span: original_source_span.clone(),
+                    message: err.to_string(),
+                })?;
 
         let mut parameter_types: Vec<AnalysedType> = function_type
             .parameter_types
@@ -384,12 +389,13 @@ mod internal {
         expected: &AnalysedType,
         provided: &Expr,
     ) -> Result<(), FunctionCallError> {
-        let is_valid = if provided.inferred_type().is_unknown() {
-            true
-        } else {
-            provided.inferred_type().get_type_hint().get_type_kind()
-                == expected.get_type_hint().get_type_kind()
-        };
+        let is_valid =
+            if provided.inferred_type().is_unknown() | provided.inferred_type().is_all_of() {
+                true
+            } else {
+                provided.inferred_type().get_type_hint().get_type_kind()
+                    == expected.get_type_hint().get_type_kind()
+            };
 
         if is_valid {
             Ok(())
diff --git a/golem-rib/src/type_inference/identify_instance_creation.rs b/golem-rib/src/type_inference/identify_instance_creation.rs
index 5bf45c26..9b9efe75 100644
--- a/golem-rib/src/type_inference/identify_instance_creation.rs
+++ b/golem-rib/src/type_inference/identify_instance_creation.rs
@@ -24,10 +24,10 @@ use crate::{ComponentDependencies, Expr};
 // instance[foo]("worker-name")
 pub fn identify_instance_creation(
     expr: &mut Expr,
-    function_type_registry: &ComponentDependencies,
+    component_dependencies: &ComponentDependencies,
 ) -> Result<(), RibTypeErrorInternal> {
     internal::search_for_invalid_instance_declarations(expr)?;
-    internal::identify_instance_creation_with_worker(expr, function_type_registry)
+    internal::identify_instance_creation_with_worker(expr, component_dependencies)
 }
 
 mod internal {
diff --git a/golem-rib/src/type_inference/mod.rs b/golem-rib/src/type_inference/mod.rs
index 0d930ec7..037e6389 100644
--- a/golem-rib/src/type_inference/mod.rs
+++ b/golem-rib/src/type_inference/mod.rs
@@ -68,8 +68,7 @@ mod tests {
     use crate::type_checker::Path;
     use crate::type_inference::global_variable_type_binding::GlobalVariableTypeSpec;
     use crate::type_inference::tests::test_utils::{
-        call, concat, cond, equal_to, expr_block, get_analysed_type_enum,
-        get_analysed_type_variant, get_test_rib_compiler_with, greater_than,
+        call, concat, cond, equal_to, expr_block, get_test_rib_compiler_with, greater_than,
         greater_than_or_equal_to, identifier, less_than, less_than_or_equal_to, let_binding,
         number, option, pattern_match, plus, record, result, select_dynamic, select_field,
         sequence, tuple,
@@ -81,8 +80,11 @@ mod tests {
         RibCompilerConfig, TypeName, VariableId,
     };
     use bigdecimal::BigDecimal;
-    use golem_wasm_ast::analysis::analysed_type::{list, str, u64};
+    use golem_wasm_ast::analysis::analysed_type::{
+        case, field, list, r#enum, str, u64, unit_case, variant,
+    };
 
+    use golem_wasm_ast::analysis::analysed_type;
     use test_r::test;
 
     #[test]
@@ -751,9 +753,8 @@ mod tests {
 
     #[test]
     async fn test_inference_enum_construction_and_pattern_match() {
-        let input_enum_type = get_analysed_type_enum(vec!["foo", "bar", "foo-bar"]);
-
-        let output_enum_type = get_analysed_type_enum(vec!["success", "failure", "in-progress"]);
+        let input_enum_type = r#enum(&["foo", "bar", "foo-bar"]);
+        let output_enum_type = r#enum(&["success", "failure", "in-progress"]);
 
         let rib_compiler = get_test_rib_compiler_with(
             "process",
@@ -808,16 +809,16 @@ mod tests {
 
     #[test]
     async fn test_inference_variant_construction_and_pattern_match() {
-        let input_variant_type = get_analysed_type_variant(vec![
-            ("foo", Some(u64())),
-            ("bar-baz", Some(str())),
-            ("foo-bar", None),
+        let input_variant_type = variant(vec![
+            case("foo", u64()),
+            case("bar-baz", str()),
+            unit_case("foo-bar"),
         ]);
 
-        let output_variant_type = get_analysed_type_variant(vec![
-            ("success", Some(u64())),
-            ("in-progress", Some(str())),
-            ("failure", None),
+        let output_variant_type = variant(vec![
+            case("success", u64()),
+            case("in-progress", str()),
+            unit_case("failure"),
         ]);
 
         let rib_compiler = get_test_rib_compiler_with(
@@ -2182,27 +2183,20 @@ mod tests {
 
     #[test]
     fn test_inference_record_select_with_function_call() {
-        let request_body_type = test_utils::get_analysed_type_record(vec![
-            ("id".to_string(), str()),
-            ("name".to_string(), str()),
-            ("titles".to_string(), list(str())),
-            (
-                "address".to_string(),
-                test_utils::get_analysed_type_record(vec![
-                    ("street".to_string(), str()),
-                    ("city".to_string(), str()),
-                ]),
+        let request_body_type = analysed_type::record(vec![
+            field("id", str()),
+            field("name", str()),
+            field("titles", list(str())),
+            field(
+                "address",
+                analysed_type::record(vec![field("street", str()), field("city", str())]),
             ),
         ]);
 
         let worker_response = test_utils::create_none(&str());
 
-        let request_type = test_utils::get_analysed_type_record(vec![(
-            "body".to_string(),
-            request_body_type.clone(),
-        )]);
-
-        let return_type = golem_wasm_ast::analysis::analysed_type::option(worker_response.typ);
+        let request_type = analysed_type::record(vec![field("body", request_body_type.clone())]);
+        let return_type = analysed_type::option(worker_response.typ);
 
         let rib_compiler =
             get_test_rib_compiler_with("foo", vec![request_type.clone()], return_type);
@@ -2468,10 +2462,9 @@ mod tests {
         };
         use bigdecimal::BigDecimal;
         use golem_wasm_ast::analysis::analysed_type::u64;
-        use golem_wasm_ast::analysis::TypeVariant;
         use golem_wasm_ast::analysis::{
             AnalysedExport, AnalysedFunction, AnalysedFunctionParameter, AnalysedFunctionResult,
-            AnalysedType, NameOptionTypePair, NameTypePair, TypeEnum, TypeRecord, TypeU32,
+            AnalysedType, TypeU32,
         };
         use golem_wasm_rpc::{Value, ValueAndType};
         use uuid::Uuid;
@@ -2769,42 +2762,6 @@ mod tests {
             ))
         }
 
-        pub(crate) fn get_analysed_type_enum(cases: Vec<&str>) -> AnalysedType {
-            let type_enum = TypeEnum {
-                cases: cases.into_iter().map(|s| s.to_string()).collect(),
-            };
-
-            AnalysedType::Enum(type_enum)
-        }
-
-        pub(crate) fn get_analysed_type_variant(
-            variants: Vec<(&str, Option<AnalysedType>)>,
-        ) -> AnalysedType {
-            let name_option_pairs = variants
-                .into_iter()
-                .map(|(name, typ)| NameOptionTypePair {
-                    name: name.to_string(),
-                    typ,
-                })
-                .collect::<Vec<_>>();
-
-            AnalysedType::Variant(TypeVariant {
-                cases: name_option_pairs,
-            })
-        }
-
-        pub(crate) fn get_analysed_type_record(
-            record_type: Vec<(String, AnalysedType)>,
-        ) -> AnalysedType {
-            let record = TypeRecord {
-                fields: record_type
-                    .into_iter()
-                    .map(|(name, typ)| NameTypePair { name, typ })
-                    .collect(),
-            };
-            AnalysedType::Record(record)
-        }
-
         pub(crate) fn create_none(typ: &AnalysedType) -> ValueAndType {
             ValueAndType::new(
                 Value::Option(None),
diff --git a/golem-rib/src/type_inference/type_pull_up.rs b/golem-rib/src/type_inference/type_pull_up.rs
index 7f60d1e1..9ae94239 100644
--- a/golem-rib/src/type_inference/type_pull_up.rs
+++ b/golem-rib/src/type_inference/type_pull_up.rs
@@ -12,16 +12,23 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
+use crate::rib_source_span::SourceSpan;
 use crate::rib_type_error::RibTypeErrorInternal;
 use crate::type_inference::type_hint::TypeHint;
 use crate::type_refinement::precise_types::{ListType, RecordType};
 use crate::type_refinement::TypeRefinement;
+use crate::FunctionName;
 use crate::{
-    ActualType, ExpectedType, GetTypeHint, InferredType, MatchArm, Path, Range, TypeMismatchError,
+    ActualType, ComponentDependencies, ExpectedType, FullyQualifiedResourceMethod, GetTypeHint,
+    InferredType, InstanceIdentifier, InterfaceName, MatchArm, PackageName, Path, Range,
+    TypeInternal, TypeMismatchError,
 };
 use crate::{CustomError, Expr, ExprVisitor};
 
-pub fn type_pull_up(expr: &mut Expr) -> Result<(), RibTypeErrorInternal> {
+pub fn type_pull_up(
+    expr: &mut Expr,
+    component_dependencies: &ComponentDependencies,
+) -> Result<(), RibTypeErrorInternal> {
     let mut visitor = ExprVisitor::bottom_up(expr);
 
     while let Some(expr) = visitor.pop_front() {
@@ -42,13 +49,17 @@ pub fn type_pull_up(expr: &mut Expr) -> Result<(), RibTypeErrorInternal> {
                 lhs,
                 method,
                 source_span,
+                args,
                 ..
             } => {
-                return Err(CustomError {
-                    source_span:  source_span.clone(),
-                    help_message: vec![],
-                    message: format!("invalid method invocation `{lhs}.{method}`. make sure `{lhs}` is defined and is a valid instance type (i.e, resource or worker)"),
-                }.into());
+                let new_call = handle_residual_method_invokes(
+                    lhs,
+                    method,
+                    source_span,
+                    args,
+                    component_dependencies,
+                )?;
+                *expr = new_call
             }
 
             Expr::SelectField {
@@ -416,6 +427,109 @@ fn get_inferred_type_of_selected_field(
     Ok(refined_record.inner_type_by_name(field))
 }
 
+// This is not an ideal logic yet,
+// but alternate solution requires refactoring which can be done later
+fn handle_residual_method_invokes(
+    lhs: &Expr,
+    method: &str,
+    source_span: &SourceSpan,
+    args: &[Expr],
+    component_dependencies: &ComponentDependencies,
+) -> Result<Expr, RibTypeErrorInternal> {
+    let possible_resource = lhs.inferred_type().internal_type().clone();
+
+    match possible_resource {
+        TypeInternal::Resource {
+            name,
+            owner,
+            ..
+        } => {
+
+            let fully_qualified_resource_method = if let Some(owner) = owner {
+                let owner_string : String = owner;
+                let parts: Vec<&str> = owner_string.split('/').collect();
+                let namespace_and_package = parts.first().map(|s| s.to_string());
+
+                let namespace = namespace_and_package
+                    .as_ref()
+                    .and_then(|s| s.split(':').next())
+                    .map(|s| s.to_string());
+                let package_name = namespace_and_package
+                    .as_ref()
+                    .and_then(|s| s.split(':').nth(1))
+                    .map(|s| s.to_string());
+
+                let interface_name = parts.get(1).map(|s| s.to_string());
+
+                FullyQualifiedResourceMethod {
+                    package_name: namespace.map(|namespace| PackageName {
+                        namespace,
+                        package_name: package_name.unwrap(),
+                        version: None,
+                    }),
+                    interface_name: interface_name.map(|name| InterfaceName {
+                        name,
+                        version: None,
+                    }),
+                    resource_name: name.clone().unwrap(),
+                    method_name: method.to_string(),
+                    static_function: false,
+                }
+            } else {
+                FullyQualifiedResourceMethod {
+                    package_name: None,
+                    interface_name: None,
+                    resource_name: name.clone().unwrap(),
+                    method_name: method.to_string(),
+                    static_function: false,
+                }
+            };
+
+            let function_name = FunctionName::ResourceMethod(fully_qualified_resource_method.clone());
+            let (key, function_type) =
+                component_dependencies.get_function_type(&None, &function_name).unwrap();
+
+            let inferred_type = if let Some(new_inferred_type) = function_type.return_type {
+                new_inferred_type
+            } else {
+                InferredType::unit()
+            };
+
+            let dynamic_parsed_function_name = fully_qualified_resource_method
+                .dynamic_parsed_function_name().unwrap();
+
+            let variable_id = match &lhs {
+                Expr::Identifier { variable_id, .. } => Some(variable_id),
+                _ => None,
+            };
+
+            let new_call = Expr::call_worker_function(
+                dynamic_parsed_function_name,
+                None,
+                Some(InstanceIdentifier::WitResource {
+                    variable_id: variable_id.cloned(),
+                    worker_name: None,
+                    resource_name: name.unwrap().to_string()
+                }),
+                args.to_vec(),
+                Some(key)
+            )
+                .with_inferred_type(inferred_type)
+                .with_source_span(source_span.clone());
+
+            Ok(new_call)
+        }
+
+        _ => {
+            Err(CustomError {
+                source_span: source_span.clone(),
+                help_message: vec![],
+                message: format!("invalid method invocation `{lhs}.{method}`. make sure `{lhs}` is defined and is a valid instance type (i.e, resource or worker)"),
+            }.into())
+        }
+    }
+}
+
 fn get_inferred_type_of_selection_dynamic(
     select_from: &Expr,
     index: &Expr,
@@ -455,7 +569,7 @@ mod type_pull_up_tests {
 
     use crate::call_type::CallType;
     use crate::function_name::DynamicParsedFunctionName;
-    use crate::DynamicParsedFunctionReference::IndexedResourceMethod;
+    use crate::DynamicParsedFunctionReference::Function;
     use crate::ParsedFunctionSite::PackagedInterface;
     use crate::{ArmPattern, ComponentDependencies, Expr, InferredType, MatchArm, VariableId};
 
@@ -464,7 +578,8 @@ mod type_pull_up_tests {
         let expr = "foo";
         let mut expr = Expr::from_text(expr).unwrap();
         expr.add_infer_type_mut(InferredType::string());
-        expr.pull_types_up().unwrap();
+        expr.pull_types_up(&ComponentDependencies::default())
+            .unwrap();
         assert_eq!(expr.inferred_type(), InferredType::string());
     }
 
@@ -477,7 +592,8 @@ mod type_pull_up_tests {
             )]));
         let select_expr = Expr::select_field(record_identifier, "foo", None);
         let mut expr = Expr::select_field(select_expr, "bar", None);
-        expr.pull_types_up().unwrap();
+        expr.pull_types_up(&ComponentDependencies::default())
+            .unwrap();
         assert_eq!(expr.inferred_type(), InferredType::u64());
     }
 
@@ -486,7 +602,8 @@ mod type_pull_up_tests {
         let identifier = Expr::identifier_global("foo", None)
             .merge_inferred_type(InferredType::list(InferredType::u64()));
         let mut expr = Expr::select_index(identifier.clone(), Expr::number(BigDecimal::from(0)));
-        expr.pull_types_up().unwrap();
+        expr.pull_types_up(&ComponentDependencies::default())
+            .unwrap();
         let expected = Expr::select_index(identifier, Expr::number(BigDecimal::from(0)))
             .merge_inferred_type(InferredType::u64());
         assert_eq!(expr, expected);
@@ -501,7 +618,8 @@ mod type_pull_up_tests {
 
         let mut expr =
             Expr::sequence(elems.clone(), None).with_inferred_type(InferredType::unknown());
-        expr.pull_types_up().unwrap();
+        expr.pull_types_up(&ComponentDependencies::default())
+            .unwrap();
 
         assert_eq!(
             expr,
@@ -516,7 +634,8 @@ mod type_pull_up_tests {
             Expr::number_inferred(BigDecimal::from(1), None, InferredType::u64()),
         ]);
 
-        expr.pull_types_up().unwrap();
+        expr.pull_types_up(&ComponentDependencies::default())
+            .unwrap();
 
         assert_eq!(
             expr.inferred_type(),
@@ -541,7 +660,8 @@ mod type_pull_up_tests {
             ("bar".to_string(), InferredType::unknown()),
         ]));
 
-        expr.pull_types_up().unwrap();
+        expr.pull_types_up(&ComponentDependencies::default())
+            .unwrap();
 
         assert_eq!(
             expr,
@@ -561,7 +681,8 @@ mod type_pull_up_tests {
     #[test]
     pub fn test_pull_up_for_concat() {
         let mut expr = Expr::concat(vec![Expr::literal("foo"), Expr::literal("bar")]);
-        expr.pull_types_up().unwrap();
+        expr.pull_types_up(&ComponentDependencies::default())
+            .unwrap();
         let expected = Expr::concat(vec![Expr::literal("foo"), Expr::literal("bar")])
             .with_inferred_type(InferredType::string());
         assert_eq!(expr, expected);
@@ -570,7 +691,8 @@ mod type_pull_up_tests {
     #[test]
     pub fn test_pull_up_for_not() {
         let mut expr = Expr::not(Expr::boolean(true));
-        expr.pull_types_up().unwrap();
+        expr.pull_types_up(&ComponentDependencies::default())
+            .unwrap();
         assert_eq!(expr.inferred_type(), InferredType::bool());
     }
 
@@ -594,7 +716,8 @@ mod type_pull_up_tests {
             select_index4.clone(),
         );
 
-        expr.pull_types_up().unwrap();
+        expr.pull_types_up(&ComponentDependencies::default())
+            .unwrap();
         let expected = Expr::cond(
             Expr::greater_than(
                 Expr::select_index(
@@ -640,7 +763,8 @@ mod type_pull_up_tests {
         let select_field2 = Expr::select_field(inner, "baz", None);
         let mut expr = Expr::greater_than(select_field1.clone(), select_field2.clone());
 
-        expr.pull_types_up().unwrap();
+        expr.pull_types_up(&ComponentDependencies::default())
+            .unwrap();
 
         let expected = Expr::greater_than(
             select_field1.merge_inferred_type(InferredType::string()),
@@ -659,7 +783,8 @@ mod type_pull_up_tests {
         let select_index2 = Expr::select_index(inner, Expr::number(BigDecimal::from(1)));
         let mut expr = Expr::greater_than_or_equal_to(select_index1.clone(), select_index2.clone());
 
-        expr.pull_types_up().unwrap();
+        expr.pull_types_up(&ComponentDependencies::default())
+            .unwrap();
 
         let expected = Expr::greater_than_or_equal_to(
             select_index1.merge_inferred_type(InferredType::u64()),
@@ -694,7 +819,8 @@ mod type_pull_up_tests {
             select_field_from_second.clone(),
         );
 
-        expr.pull_types_up().unwrap();
+        expr.pull_types_up(&ComponentDependencies::default())
+            .unwrap();
 
         let new_select_field_from_first = Expr::select_field(
             Expr::select_index(inner.clone(), Expr::number(BigDecimal::from(0)))
@@ -725,7 +851,8 @@ mod type_pull_up_tests {
             Expr::number(BigDecimal::from(1)),
             Expr::number(BigDecimal::from(2)),
         );
-        expr.pull_types_up().unwrap();
+        expr.pull_types_up(&ComponentDependencies::default())
+            .unwrap();
         assert_eq!(expr.inferred_type(), InferredType::bool());
     }
 
@@ -736,7 +863,8 @@ mod type_pull_up_tests {
             Expr::number(BigDecimal::from(2)),
         );
 
-        expr.pull_types_up().unwrap();
+        expr.pull_types_up(&ComponentDependencies::default())
+            .unwrap();
 
         assert_eq!(expr.inferred_type(), InferredType::bool());
     }
@@ -751,7 +879,8 @@ mod type_pull_up_tests {
             None,
         );
 
-        expr.pull_types_up().unwrap();
+        expr.pull_types_up(&ComponentDependencies::default())
+            .unwrap();
 
         assert_eq!(expr.inferred_type(), InferredType::unknown());
     }
@@ -760,7 +889,7 @@ mod type_pull_up_tests {
     pub fn test_pull_up_for_dynamic_call() {
         let rib = r#"
            let input = { foo: "afs", bar: "al" };
-           golem:it/api.{cart(input.foo).checkout}()
+           golem:it/api.{cart-checkout}(input.foo)
         "#;
 
         let mut expr = Expr::from_text(rib).unwrap();
@@ -769,7 +898,8 @@ mod type_pull_up_tests {
         expr.infer_types_initial_phase(&component_dependencies, &vec![])
             .unwrap();
         expr.infer_all_identifiers();
-        expr.pull_types_up().unwrap();
+        expr.pull_types_up(&ComponentDependencies::default())
+            .unwrap();
 
         let expected = Expr::expr_block(vec![
             Expr::let_binding_with_variable_id(
@@ -799,26 +929,24 @@ mod type_pull_up_tests {
                             interface: "api".to_string(),
                             version: None,
                         },
-                        function: IndexedResourceMethod {
-                            resource: "cart".to_string(),
-                            resource_params: vec![Expr::select_field(
-                                Expr::identifier_local("input", 0, None).with_inferred_type(
-                                    InferredType::record(vec![
-                                        ("foo".to_string(), InferredType::string()),
-                                        ("bar".to_string(), InferredType::string()),
-                                    ]),
-                                ),
-                                "foo",
-                                None,
-                            )
-                            .with_inferred_type(InferredType::string())],
-                            method: "checkout".to_string(),
+                        function: Function {
+                            function: "cart-checkout".to_string(),
                         },
                     },
                     None,
                 ),
                 None,
-                vec![],
+                vec![Expr::select_field(
+                    Expr::identifier_local("input", 0, None).with_inferred_type(
+                        InferredType::record(vec![
+                            ("foo".to_string(), InferredType::string()),
+                            ("bar".to_string(), InferredType::string()),
+                        ]),
+                    ),
+                    "foo",
+                    None,
+                )
+                .with_inferred_type(InferredType::string())],
             ),
         ]);
 
@@ -830,7 +958,8 @@ mod type_pull_up_tests {
         let mut number = Expr::number(BigDecimal::from(1));
         number.with_inferred_type_mut(InferredType::f64());
         let mut expr = Expr::option(Some(number)).unwrap();
-        expr.pull_types_up().unwrap();
+        expr.pull_types_up(&ComponentDependencies::default())
+            .unwrap();
         assert_eq!(
             expr.inferred_type(),
             InferredType::option(InferredType::f64())
@@ -842,7 +971,8 @@ mod type_pull_up_tests {
         let mut number = Expr::number(BigDecimal::from(1));
         number.with_inferred_type_mut(InferredType::f64());
         let mut expr = Expr::get_tag(Expr::option(Some(number)));
-        expr.pull_types_up().unwrap();
+        expr.pull_types_up(&ComponentDependencies::default())
+            .unwrap();
         assert_eq!(
             expr.inferred_type(),
             InferredType::option(InferredType::f64())
@@ -910,7 +1040,8 @@ mod type_pull_up_tests {
             ],
         );
 
-        expr.pull_types_up().unwrap();
+        expr.pull_types_up(&ComponentDependencies::default())
+            .unwrap();
 
         let expected = internal::expected_pattern_match();
 
diff --git a/golem-rib/src/type_inference/worker_function_invocation.rs b/golem-rib/src/type_inference/worker_function_invocation.rs
index e58ed904..d4d7847a 100644
--- a/golem-rib/src/type_inference/worker_function_invocation.rs
+++ b/golem-rib/src/type_inference/worker_function_invocation.rs
@@ -16,8 +16,8 @@ use crate::call_type::{CallType, InstanceCreationType, InstanceIdentifier};
 use crate::rib_type_error::RibTypeErrorInternal;
 use crate::type_parameter::TypeParameter;
 use crate::{
-    CustomError, DynamicParsedFunctionName, Expr, FunctionCallError, InferredType, TypeInternal,
-    TypeOrigin,
+    CustomError, DynamicParsedFunctionName, Expr, FullyQualifiedResourceConstructor,
+    FunctionCallError, InferredType, TypeInternal, TypeOrigin,
 };
 use crate::{FunctionName, InstanceType};
 use std::collections::VecDeque;
@@ -30,7 +30,87 @@ pub fn infer_worker_function_invokes(expr: &mut Expr) -> Result<(), RibTypeError
     queue.push_back(expr);
 
     while let Some(expr) = queue.pop_back() {
-        if let Expr::InvokeMethodLazy {
+        if let Expr::SelectField {
+            expr: lhs,
+            field,
+            source_span,
+            ..
+        } = expr
+        {
+            let lhs_inferred_type = lhs.inferred_type().internal_type().clone();
+
+            if let TypeInternal::Instance { instance_type } = lhs_inferred_type {
+                let (component, function) =
+                    instance_type.get_function(field, None).map_err(|err| {
+                        FunctionCallError::invalid_function_call(field, source_span.clone(), err)
+                    })?;
+
+                let module = get_instance_identifier(&instance_type, lhs);
+
+                lhs.inferred_type_mut()
+                    .internal_type_mut()
+                    .narrow_to_single_component(&component);
+
+                if let FunctionName::ResourceConstructor(fully_qualified_resource_constructor) =
+                    function.function_name
+                {
+                    let (resource_id, resource_mode) =
+                        match function.function_type.return_type {
+                            Some(return_type) => match return_type.internal_type() {
+                                TypeInternal::Resource {
+                                    resource_id,
+                                    resource_mode,
+                                    ..
+                                } => (*resource_id, *resource_mode),
+                                _ => return Err(RibTypeErrorInternal::from(CustomError::new(
+                                    expr.source_span(),
+                                    "expected resource type as return type of resource constructor",
+                                ))),
+                            },
+
+                            None => {
+                                return Err(RibTypeErrorInternal::from(CustomError::new(
+                                    expr.source_span(),
+                                    "resource constructor must have a return type",
+                                )));
+                            }
+                        };
+
+                    let resource_instance_type = instance_type
+                        .get_resource_instance_type(
+                            fully_qualified_resource_constructor.clone(),
+                            vec![],
+                            instance_type.worker_name(),
+                            resource_id,
+                            resource_mode,
+                        )
+                        .map_err(|err| {
+                            RibTypeErrorInternal::from(CustomError::new(
+                                lhs.source_span(),
+                                format!("Failed to get resource instance type: {err}"),
+                            ))
+                        })?;
+
+                    let new_inferred_type = InferredType::new(
+                        TypeInternal::Instance {
+                            instance_type: Box::new(resource_instance_type),
+                        },
+                        TypeOrigin::NoOrigin,
+                    );
+
+                    let new_call_type =
+                        CallType::InstanceCreation(InstanceCreationType::WitResource {
+                            component_info: Some(component.clone()),
+                            module: Some(module),
+                            resource_name: fully_qualified_resource_constructor.clone(),
+                        });
+
+                    *expr = Expr::call(new_call_type, None, vec![])
+                        .with_inferred_type(new_inferred_type)
+                        .with_source_span(source_span.clone());
+                }
+            }
+        } else if let Expr::InvokeMethodLazy {
             lhs,
             method,
             generic_type_parameter,
@@ -108,7 +188,7 @@ pub fn infer_worker_function_invokes(expr: &mut Expr) -> Result<(), RibTypeError
                         FunctionName::ResourceConstructor(fully_qualified_resource_constructor) => {
                             let (resource_id, resource_mode) = match function.function_type.return_type {
                                 Some(return_type) => match return_type.internal_type()  {
-                                    TypeInternal::Resource {resource_id, resource_mode} =>  {
+                                    TypeInternal::Resource {resource_id, resource_mode, ..} =>  {
                                         (*resource_id, *resource_mode)
                                     }
                                     _ => return Err(RibTypeErrorInternal::from(CustomError::new(expr.source_span(), "expected resource type as return type of resource constructor"))),
@@ -155,6 +235,7 @@ pub fn infer_worker_function_invokes(expr: &mut Expr) -> Result<(), RibTypeError
                                 .with_inferred_type(new_inferred_type)
                                 .with_source_span(source_span.clone());
                         }
+
                         // If resource method is called, we could convert to strict call
                         // however it can only be possible if the instance type of LHS is
                         // a resource type
@@ -162,7 +243,7 @@ pub fn infer_worker_function_invokes(expr: &mut Expr) -> Result<(), RibTypeError
                             let resource_method_dictionary =
                                 instance_type.resource_method_dictionary();
 
-                            let _ =
+                            let resource_method_info =
                                 resource_method_dictionary.get(&FunctionName::ResourceMethod(resource_method.clone()))
                                     .ok_or(FunctionCallError::invalid_function_call(
                                         resource_method.method_name(),
@@ -173,6 +254,53 @@ pub fn infer_worker_function_invokes(expr: &mut Expr) -> Result<(), RibTypeError
                                     ),
                                 ))?;
 
+                            let resource_method_return_type = resource_method_info
+                                .return_type
+                                .clone()
+                                .unwrap_or(InferredType::unknown());
+
+                            let new_inferred_type = match resource_method_return_type
+                                .internal_type()
+                            {
+                                TypeInternal::Resource {
+                                    resource_id,
+                                    resource_mode,
+                                    ..
+                                } => {
+                                    let resource_instance_type = instance_type
+                                        .get_resource_instance_type(
+                                            FullyQualifiedResourceConstructor {
+                                                package_name: resource_method.package_name.clone(),
+                                                interface_name: resource_method
+                                                    .interface_name
+                                                    .clone(),
+                                                resource_name: "cart".to_string(),
+                                            },
+                                            args.clone(),
+                                            instance_type.worker_name(),
+                                            *resource_id,
+                                            *resource_mode,
+                                        )
+                                        .map_err(|err| {
+                                            RibTypeErrorInternal::from(CustomError::new(
+                                                lhs.source_span(),
+                                                format!(
+                                                    "Failed to get resource instance type: {err}"
+                                                ),
+                                            ))
+                                        })?;
+
+                                    InferredType::new(
+                                        TypeInternal::Instance {
+                                            instance_type: Box::new(resource_instance_type),
+                                        },
+                                        TypeOrigin::NoOrigin,
+                                    )
+                                }
+
+                                _ => InferredType::unknown(),
+                            };
+
                             let dynamic_parsed_function_name = resource_method
                                 .dynamic_parsed_function_name()
                                 .map_err(|err| {
@@ -190,6 +318,7 @@ pub fn infer_worker_function_invokes(expr: &mut Expr) -> Result<(), RibTypeError
                                 args.clone(),
                                 Some(component),
                             )
+                            .with_inferred_type(new_inferred_type)
                             .with_source_span(source_span.clone());
 
                             *expr = new_call;
diff --git a/golem-rib/src/type_refinement/mod.rs b/golem-rib/src/type_refinement/mod.rs
index f3d47baf..95e78df8 100644
--- a/golem-rib/src/type_refinement/mod.rs
+++ b/golem-rib/src/type_refinement/mod.rs
@@ -170,7 +170,6 @@ impl TypeRefinement for StringType {
     }
 }
 
-#[allow(dead_code)]
 impl TypeRefinement for NumberType {
     fn refine(inferred_type: &InferredType) -> Option<RefinedType<Self>> {
         internal::refine_inferred_type(inferred_type, &|inferred_type| match inferred_type
@@ -192,7 +191,6 @@ impl TypeRefinement for NumberType {
     }
 }
 
-#[allow(dead_code)]
 impl TypeRefinement for BoolType {
     fn refine(inferred_type: &InferredType) -> Option<RefinedType<Self>> {
         internal::refine_inferred_type(inferred_type, &|inferred_type| {
@@ -205,7 +203,6 @@ impl TypeRefinement for BoolType {
     }
 }
 
-#[allow(dead_code)]
 impl TypeRefinement for CharType {
     fn refine(inferred_type: &InferredType) -> Option<RefinedType<Self>> {
         internal::refine_inferred_type(inferred_type, &|inferred_type| {
@@ -218,7 +215,6 @@ impl TypeRefinement for CharType {
     }
 }
 
-#[allow(dead_code)]
 impl TypeRefinement for FlagsType {
     fn refine(inferred_type: &InferredType) -> Option<RefinedType<Self>> {
         internal::refine_inferred_type(inferred_type, &|inferred_type| {
@@ -231,7 +227,6 @@ impl TypeRefinement for FlagsType {
     }
 }
 
-#[allow(dead_code)]
 impl TypeRefinement for EnumType {
     fn refine(inferred_type: &InferredType) -> Option<RefinedType<Self>> {
         internal::refine_inferred_type(inferred_type, &|inferred_type| {
diff --git a/golem-service-base/Cargo.toml b/golem-service-base/Cargo.toml
index db0f983e..bf7f139a 100644
--- a/golem-service-base/Cargo.toml
+++ b/golem-service-base/Cargo.toml
@@ -19,13 +19,11 @@ default = []
 worker-executor = [ "dep:wasmtime-wasi" ]
 
 [dependencies]
-golem-api-grpc = { path = "../golem-api-grpc", version = "=0.0.0" }
-golem-common = { path = "../golem-common", version = "=0.0.0" }
-golem-wasm-ast = { path = "../wasm-ast", version = "=0.0.0" }
-golem-wasm-rpc = { path = "../wasm-rpc", version = "=0.0.0", default-features = false, features = [
-    "host",
-] }
-golem-wasm-rpc-derive = { path = "../wasm-rpc-derive", version = "=0.0.0" }
+golem-api-grpc = { workspace = true }
+golem-common = { workspace = true, default-features = true}
+golem-wasm-ast = { workspace = true, default-features = true }
+golem-wasm-rpc = { workspace = true, features = ["host"] }
+golem-wasm-rpc-derive = { workspace = true }
 
 anyhow = { workspace = true }
 applying = { workspace = true }
@@ -36,7 +34,7 @@ axum = { workspace = true }
 aws-config = { workspace = true }
 aws-sdk-s3 = { workspace = true }
 bincode = { workspace = true }
-bitflags = "2.6.0"
+bitflags = { workspace = true }
 bytes = { workspace = true }
 chrono = { workspace = true }
 conditional-trait-gen = { workspace = true }
@@ -51,7 +49,7 @@ http-body-util = { workspace = true }
 humantime-serde = { workspace = true }
 include_dir = { workspace = true }
 lazy_static = { workspace = true }
-pin-project = "1.1.10"
+pin-project = { workspace = true }
 poem = { workspace = true }
 poem-openapi = { workspace = true }
 poem-openapi-derive = { workspace = true }
@@ -77,7 +75,6 @@ tonic = { workspace = true }
 tracing = { workspace = true }
 url = { workspace = true }
 uuid = { workspace = true }
-unix_path = "1.0.1"
 wasmtime-wasi = { workspace = true, optional = true }
 
 [dev-dependencies]
diff --git a/golem-service-base/src/api_tags.rs b/golem-service-base/src/api_tags.rs
index a082c7a3..e869ffbe 100644
--- a/golem-service-base/src/api_tags.rs
+++ b/golem-service-base/src/api_tags.rs
@@ -46,4 +46,6 @@ pub enum ApiTags {
     /// The token API allows creating custom access tokens for the Golem Cloud REST API to be used by tools and services.
     Token,
     Worker,
+    /// API working on registered agent types
+    AgentTypes,
 }
diff --git a/golem-service-base/src/clients/mod.rs b/golem-service-base/src/clients/mod.rs
index 9bf1b92e..ed835905 100644
--- a/golem-service-base/src/clients/mod.rs
+++ b/golem-service-base/src/clients/mod.rs
@@ -20,8 +20,10 @@ pub mod project;
 use golem_common::config::{ConfigExample, HasConfigExamples};
 use golem_common::model::auth::TokenSecret;
 use golem_common::model::RetryConfig;
+use golem_common::SafeDisplay;
 use http::Uri;
 use serde::{Deserialize, Serialize};
+use std::fmt::Write;
 use std::str::FromStr;
 use tonic::metadata::MetadataMap;
 use url::Url;
@@ -51,6 +53,18 @@ impl RemoteServiceConfig {
     }
 }
 
+impl SafeDisplay for RemoteServiceConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "host: {}", self.host);
+        let _ = writeln!(&mut result, "port: {}", self.port);
+        let _ = writeln!(&mut result, "access_token: ****");
+        let _ = writeln!(&mut result, "retries:");
+        let _ = writeln!(&mut result, "{}", self.retries.to_safe_string_indented());
+        result
+    }
+}
+
 impl Default for RemoteServiceConfig {
     fn default() -> Self {
         Self {
diff --git a/golem-service-base/src/clients/project.rs b/golem-service-base/src/clients/project.rs
index a96b8c12..7645a5ed 100644
--- a/golem-service-base/src/clients/project.rs
+++ b/golem-service-base/src/clients/project.rs
@@ -168,6 +168,78 @@ impl From<golem_api_grpc::proto::golem::project::v1::ProjectError> for ProjectEr
     }
 }
 
+impl From<ProjectError> for golem_api_grpc::proto::golem::worker::v1::worker_error::Error {
+    fn from(error: ProjectError) -> Self {
+        match error {
+            ProjectError::Server(project_error) =>
+                match project_error.error {
+                    Some(golem_api_grpc::proto::golem::project::v1::project_error::Error::BadRequest(error)) =>
+                        golem_api_grpc::proto::golem::worker::v1::worker_error::Error::BadRequest(error)
+                    ,
+                    Some(golem_api_grpc::proto::golem::project::v1::project_error::Error::InternalError(error)) =>
+                        golem_api_grpc::proto::golem::worker::v1::worker_error::Error::InternalError(
+                            golem_api_grpc::proto::golem::worker::v1::WorkerExecutionError {
+                                error: Some(golem_api_grpc::proto::golem::worker::v1::worker_execution_error::Error::Unknown(
+                                    golem_api_grpc::proto::golem::worker::v1::UnknownError {
+                                        details: format!("Internal project server error: {}", error.error),
+                                    },
+                                )),
+                            })
+                    ,
+                    Some(golem_api_grpc::proto::golem::project::v1::project_error::Error::NotFound(error)) =>
+                        golem_api_grpc::proto::golem::worker::v1::worker_error::Error::NotFound(error)
+                    ,
+                    Some(golem_api_grpc::proto::golem::project::v1::project_error::Error::Unauthorized(error)) =>
+                        golem_api_grpc::proto::golem::worker::v1::worker_error::Error::Unauthorized(error)
+                    ,
+                    Some(golem_api_grpc::proto::golem::project::v1::project_error::Error::LimitExceeded(error)) =>
+                        golem_api_grpc::proto::golem::worker::v1::worker_error::Error::LimitExceeded(error)
+                    ,
+                    None => golem_api_grpc::proto::golem::worker::v1::worker_error::Error::InternalError(
+                        golem_api_grpc::proto::golem::worker::v1::WorkerExecutionError {
+                            error: Some(golem_api_grpc::proto::golem::worker::v1::worker_execution_error::Error::Unknown(
+                                golem_api_grpc::proto::golem::worker::v1::UnknownError {
+                                    details: "Unknown project error".to_string(),
+                                },
+                            )),
+                        },
+                    ),
+                },
+            ProjectError::Connection(error) => golem_api_grpc::proto::golem::worker::v1::worker_error::Error::InternalError(
+                golem_api_grpc::proto::golem::worker::v1::WorkerExecutionError {
+                    error: Some(golem_api_grpc::proto::golem::worker::v1::worker_execution_error::Error::Unknown(
+                        golem_api_grpc::proto::golem::worker::v1::UnknownError {
+                            details: format!("Project server connection error: {error}"),
+                        },
+                    )),
+                },
+            ),
+            ProjectError::Transport(error) => {
+                golem_api_grpc::proto::golem::worker::v1::worker_error::Error::InternalError(
+                    golem_api_grpc::proto::golem::worker::v1::WorkerExecutionError {
+                        error: Some(golem_api_grpc::proto::golem::worker::v1::worker_execution_error::Error::Unknown(
+                            golem_api_grpc::proto::golem::worker::v1::UnknownError {
+                                details: format!("Project server transport error: {error}"),
+                            },
+                        )),
+                    },
+                )
+            }
+            ProjectError::Unknown(error) => {
+                golem_api_grpc::proto::golem::worker::v1::worker_error::Error::InternalError(
+                    golem_api_grpc::proto::golem::worker::v1::WorkerExecutionError {
+                        error: Some(golem_api_grpc::proto::golem::worker::v1::worker_execution_error::Error::Unknown(
+                            golem_api_grpc::proto::golem::worker::v1::UnknownError {
+                                details: format!("Project server unknown error: {error}"),
+                            },
+                        )),
+                    },
+                )
+            }
+        }
+    }
+}
+
 impl From<Status> for ProjectError {
     fn from(value: Status) -> Self {
         Self::Connection(value)
diff --git a/golem-service-base/src/config.rs b/golem-service-base/src/config.rs
index 33929f48..2351e639 100644
--- a/golem-service-base/src/config.rs
+++ b/golem-service-base/src/config.rs
@@ -15,8 +15,9 @@
 use golem_common::config::DbSqliteConfig;
 use golem_common::config::{ConfigLoader, ConfigLoaderConfig};
 use golem_common::model::RetryConfig;
+use golem_common::SafeDisplay;
 use serde::{Deserialize, Serialize};
-use std::{path::PathBuf, time::Duration};
+use std::{fmt::Write, path::PathBuf, time::Duration};
 
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct WorkerExecutorClientCacheConfig {
@@ -45,6 +46,36 @@ pub enum BlobStorageConfig {
     InMemory(InMemoryBlobStorageConfig),
 }
 
+impl SafeDisplay for BlobStorageConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        match self {
+            BlobStorageConfig::S3(inner) => {
+                let _ = writeln!(&mut result, "S3:");
+                let _ = writeln!(&mut result, "{}", inner.to_safe_string_indented());
+            }
+            BlobStorageConfig::LocalFileSystem(inner) => {
+                let _ = writeln!(&mut result, "local file system:");
+                let _ = writeln!(&mut result, "{}", inner.to_safe_string_indented());
+            }
+            BlobStorageConfig::KVStoreSqlite(inner) => {
+                let _ = writeln!(&mut result, "sqlite kv-store:");
+                let _ = writeln!(&mut result, "{}", inner.to_safe_string_indented());
+            }
+            BlobStorageConfig::Sqlite(inner) => {
+                let _ = writeln!(&mut result, "sqlite:");
+                let _ = writeln!(&mut result, "{}", inner.to_safe_string_indented());
+            }
+            BlobStorageConfig::InMemory(inner) => {
+                let _ = writeln!(&mut result, "in-memory:");
+                let _ = writeln!(&mut result, "{}", inner.to_safe_string_indented());
+            }
+        }
+
+        result
+    }
+}
+
 impl Default for BlobStorageConfig {
     fn default() -> Self {
         Self::default_local_file_system()
@@ -81,6 +112,58 @@ pub struct S3BlobStorageConfig {
     pub plugin_wasm_files_bucket: String,
 }
 
+impl SafeDisplay for S3BlobStorageConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+
+        let _ = writeln!(&mut result, "retries:");
+        let _ = writeln!(&mut result, "{}", self.retries.to_safe_string_indented());
+        let _ = writeln!(&mut result, "region: {}", self.region);
+        let _ = writeln!(&mut result, "object_prefix: {}", self.object_prefix);
+        if let Some(endpoint_url) = &self.aws_endpoint_url {
+            let _ = writeln!(&mut result, "aws_endpoint_url: {}", endpoint_url);
+        }
+        let _ = writeln!(
+            &mut result,
+            "compilation cache bucket: {}",
+            self.compilation_cache_bucket
+        );
+        let _ = writeln!(
+            &mut result,
+            "custom data bucket: {}",
+            self.custom_data_bucket
+        );
+        let _ = writeln!(
+            &mut result,
+            "oplog payload bucket: {}",
+            self.oplog_payload_bucket
+        );
+        let _ = writeln!(
+            &mut result,
+            "compressed oplog buckets: {:?}",
+            self.compressed_oplog_buckets
+        );
+        let _ = writeln!(
+            &mut result,
+            "use MinIO credentials: {}",
+            self.use_minio_credentials
+        );
+        let _ = writeln!(
+            &mut result,
+            "initial component files bucket: {}",
+            self.initial_component_files_bucket
+        );
+        let _ = writeln!(&mut result, "components bucket: {}", self.components_bucket);
+        let _ = writeln!(
+            &mut result,
+            "plugin wasm files bucket: {}",
+            self.plugin_wasm_files_bucket
+        );
+
+        result
+    }
+}
+
 impl Default for S3BlobStorageConfig {
     fn default() -> Self {
         Self {
@@ -112,12 +195,32 @@ impl Default for LocalFileSystemBlobStorageConfig {
     }
 }
 
+impl SafeDisplay for LocalFileSystemBlobStorageConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "root: {:?}", self.root);
+        result
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct KVStoreSqliteBlobStorageConfig {}
 
+impl SafeDisplay for KVStoreSqliteBlobStorageConfig {
+    fn to_safe_string(&self) -> String {
+        "".to_string()
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct InMemoryBlobStorageConfig {}
 
+impl SafeDisplay for InMemoryBlobStorageConfig {
+    fn to_safe_string(&self) -> String {
+        "".to_string()
+    }
+}
+
 pub struct MergedConfigLoader<T> {
     config_file_name: PathBuf,
     config: figment::Result<T>,
diff --git a/golem-service-base/src/model/mod.rs b/golem-service-base/src/model/mod.rs
index fc7c047b..1ad39e04 100644
--- a/golem-service-base/src/model/mod.rs
+++ b/golem-service-base/src/model/mod.rs
@@ -27,23 +27,14 @@ use golem_common::model::{
     ComponentType, ComponentVersion, InitialComponentFile, ScanCursor, Timestamp, WorkerFilter,
     WorkerId,
 };
-use golem_wasm_rpc::json::OptionallyTypeAnnotatedValueJson;
-use golem_wasm_rpc::protobuf::type_annotated_value::TypeAnnotatedValue;
+use golem_wasm_rpc::json::OptionallyValueAndTypeJson;
+use golem_wasm_rpc::ValueAndType;
 use golem_wasm_rpc_derive::IntoValue;
 use poem_openapi::{Enum, NewType, Object, Union};
 use serde::{Deserialize, Serialize};
 use std::time::SystemTime;
 use std::{collections::HashMap, fmt::Display, fmt::Formatter};
 
-#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize, Object)]
-#[oai(rename_all = "camelCase")]
-#[serde(rename_all = "camelCase")]
-pub struct WorkerCreationRequest {
-    pub name: String,
-    pub args: Vec<String>,
-    pub env: HashMap<String, String>,
-}
-
 #[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize, Object)]
 #[serde(rename_all = "camelCase")]
 #[oai(rename_all = "camelCase")]
@@ -83,7 +74,7 @@ impl From<CompleteParameters> for golem_api_grpc::proto::golem::worker::Complete
 #[oai(rename_all = "camelCase")]
 #[serde(rename_all = "camelCase")]
 pub struct InvokeParameters {
-    pub params: Vec<OptionallyTypeAnnotatedValueJson>,
+    pub params: Vec<OptionallyValueAndTypeJson>,
 }
 
 #[derive(Debug, Clone, PartialEq, Eq, Hash, Ord, PartialOrd, Serialize, Deserialize, Object)]
@@ -186,9 +177,7 @@ pub struct PublicOplogEntryWithIndex {
     pub entry: PublicOplogEntry,
 }
 
-impl TryFrom<golem_api_grpc::proto::golem::worker::OplogEntryWithIndex>
-    for PublicOplogEntryWithIndex
-{
+impl TryFrom<OplogEntryWithIndex> for PublicOplogEntryWithIndex {
     type Error = String;
 
     fn try_from(value: OplogEntryWithIndex) -> Result<Self, Self::Error> {
@@ -199,9 +188,7 @@ impl TryFrom<golem_api_grpc::proto::golem::worker::OplogEntryWithIndex>
     }
 }
 
-impl TryFrom<PublicOplogEntryWithIndex>
-    for golem_api_grpc::proto::golem::worker::OplogEntryWithIndex
-{
+impl TryFrom<PublicOplogEntryWithIndex> for OplogEntryWithIndex {
     type Error = String;
 
     fn try_from(value: PublicOplogEntryWithIndex) -> Result<Self, Self::Error> {
@@ -366,67 +353,11 @@ impl From<UpdateRecord> for golem_api_grpc::proto::golem::worker::UpdateRecord {
     }
 }
 
-#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize, Object)]
-#[serde(rename_all = "camelCase")]
-#[oai(rename_all = "camelCase")]
-pub struct ResourceMetadata {
-    pub created_at: Timestamp,
-    pub indexed: Option<IndexedWorkerMetadata>,
-}
-
-impl TryFrom<golem_api_grpc::proto::golem::worker::ResourceMetadata> for ResourceMetadata {
-    type Error = String;
-
-    fn try_from(
-        value: golem_api_grpc::proto::golem::worker::ResourceMetadata,
-    ) -> Result<Self, Self::Error> {
-        Ok(Self {
-            created_at: value.created_at.ok_or("Missing created_at")?.into(),
-            indexed: value.indexed.map(|i| i.into()),
-        })
-    }
-}
-
-impl From<ResourceMetadata> for golem_api_grpc::proto::golem::worker::ResourceMetadata {
-    fn from(value: ResourceMetadata) -> Self {
-        Self {
-            created_at: Some(value.created_at.into()),
-            indexed: value.indexed.map(|i| i.into()),
-        }
-    }
-}
-
-#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize, Object)]
-#[serde(rename_all = "camelCase")]
-#[oai(rename_all = "camelCase")]
-pub struct IndexedWorkerMetadata {
-    pub resource_name: String,
-    pub resource_params: Vec<String>,
-}
-
-impl From<golem_api_grpc::proto::golem::worker::IndexedResourceMetadata> for IndexedWorkerMetadata {
-    fn from(value: golem_api_grpc::proto::golem::worker::IndexedResourceMetadata) -> Self {
-        Self {
-            resource_name: value.resource_name,
-            resource_params: value.resource_params,
-        }
-    }
-}
-
-impl From<IndexedWorkerMetadata> for golem_api_grpc::proto::golem::worker::IndexedResourceMetadata {
-    fn from(value: IndexedWorkerMetadata) -> Self {
-        Self {
-            resource_name: value.resource_name,
-            resource_params: value.resource_params,
-        }
-    }
-}
-
 #[derive(Debug, Clone, PartialEq, Serialize, Deserialize, Object)]
 #[oai(rename_all = "camelCase")]
 #[serde(rename_all = "camelCase")]
 pub struct InvokeResult {
-    pub result: Option<TypeAnnotatedValue>,
+    pub result: Option<ValueAndType>,
 }
 
 #[derive(Debug, Clone)]
@@ -507,6 +438,28 @@ impl TryFrom<golem_api_grpc::proto::golem::component::Component> for Component {
     }
 }
 
+impl From<Component> for golem_api_grpc::proto::golem::component::Component {
+    fn from(value: Component) -> Self {
+        Self {
+            account_id: Some(value.owner.account_id.into()),
+            project_id: Some(value.owner.project_id.into()),
+            versioned_component_id: Some(value.versioned_component_id.into()),
+            component_name: value.component_name.0,
+            component_size: value.component_size,
+            metadata: Some(value.metadata.into()),
+            created_at: Some(SystemTime::from(value.created_at).into()),
+            component_type: Some(value.component_type as i32),
+            files: value.files.into_iter().map(Into::into).collect(),
+            installed_plugins: value
+                .installed_plugins
+                .into_iter()
+                .map(Into::into)
+                .collect(),
+            env: value.env,
+        }
+    }
+}
+
 #[derive(Debug, Clone, PartialEq, Eq, Hash, Ord, PartialOrd, Serialize, Deserialize, Object)]
 #[serde(rename_all = "camelCase")]
 #[oai(rename_all = "camelCase")]
diff --git a/golem-service-base/src/service/initial_component_files.rs b/golem-service-base/src/service/initial_component_files.rs
index 59879a6a..f8185b3f 100644
--- a/golem-service-base/src/service/initial_component_files.rs
+++ b/golem-service-base/src/service/initial_component_files.rs
@@ -18,7 +18,7 @@ use crate::replayable_stream::{ContentHash, ReplayableStream};
 use crate::storage::blob::{BlobStorage, BlobStorageNamespace};
 use bytes::Bytes;
 use futures::stream::BoxStream;
-use golem_common::model::{AccountId, InitialComponentFileKey};
+use golem_common::model::{InitialComponentFileKey, ProjectId};
 use tracing::debug;
 
 const INITIAL_COMPONENT_FILES_LABEL: &str = "initial_component_files";
@@ -36,7 +36,7 @@ impl InitialComponentFilesService {
 
     pub async fn exists(
         &self,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         key: &InitialComponentFileKey,
     ) -> Result<bool, String> {
         let path = PathBuf::from(key.0.clone());
@@ -47,7 +47,7 @@ impl InitialComponentFilesService {
                 INITIAL_COMPONENT_FILES_LABEL,
                 "exists",
                 BlobStorageNamespace::InitialComponentFiles {
-                    account_id: account_id.clone(),
+                    project_id: project_id.clone(),
                 },
                 &path,
             )
@@ -59,7 +59,7 @@ impl InitialComponentFilesService {
 
     pub async fn get(
         &self,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         key: &InitialComponentFileKey,
     ) -> Result<Option<BoxStream<'static, Result<Bytes, String>>>, String> {
         self.blob_storage
@@ -67,7 +67,7 @@ impl InitialComponentFilesService {
                 INITIAL_COMPONENT_FILES_LABEL,
                 "get",
                 BlobStorageNamespace::InitialComponentFiles {
-                    account_id: account_id.clone(),
+                    project_id: project_id.clone(),
                 },
                 &PathBuf::from(key.0.clone()),
             )
@@ -76,7 +76,7 @@ impl InitialComponentFilesService {
 
     pub async fn put_if_not_exists(
         &self,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         data: impl ReplayableStream<Item = Result<Bytes, String>, Error = String>,
     ) -> Result<InitialComponentFileKey, String> {
         let hash = data.content_hash().await?;
@@ -89,7 +89,7 @@ impl InitialComponentFilesService {
                 INITIAL_COMPONENT_FILES_LABEL,
                 "get_metadata",
                 BlobStorageNamespace::InitialComponentFiles {
-                    account_id: account_id.clone(),
+                    project_id: project_id.clone(),
                 },
                 &key,
             )
@@ -104,7 +104,7 @@ impl InitialComponentFilesService {
                     INITIAL_COMPONENT_FILES_LABEL,
                     "put",
                     BlobStorageNamespace::InitialComponentFiles {
-                        account_id: account_id.clone(),
+                        project_id: project_id.clone(),
                     },
                     &key,
                     &data.erased(),
diff --git a/golem-service-base/src/service/routing_table.rs b/golem-service-base/src/service/routing_table.rs
index cc832916..1f202118 100644
--- a/golem-service-base/src/service/routing_table.rs
+++ b/golem-service-base/src/service/routing_table.rs
@@ -12,21 +12,7 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use std::fmt::Display;
-use std::ops::Deref;
-use std::sync::Arc;
-use std::time::Duration;
-
 use async_trait::async_trait;
-use http::Uri;
-use serde::Deserialize;
-use serde::Serialize;
-use tokio::sync::RwLock;
-use tokio::time::Instant;
-use tonic::codec::CompressionEncoding;
-use tonic::transport::Channel;
-use tonic::Status;
-
 use golem_api_grpc::proto::golem::shardmanager;
 use golem_api_grpc::proto::golem::shardmanager::v1::shard_manager_error::Error;
 use golem_api_grpc::proto::golem::shardmanager::v1::shard_manager_service_client::ShardManagerServiceClient;
@@ -35,6 +21,19 @@ use golem_common::cache::*;
 use golem_common::client::{GrpcClient, GrpcClientConfig};
 use golem_common::model::{RetryConfig, RoutingTable};
 use golem_common::retriable_error::IsRetriableError;
+use golem_common::SafeDisplay;
+use http::Uri;
+use serde::Deserialize;
+use serde::Serialize;
+use std::fmt::{Display, Write};
+use std::ops::Deref;
+use std::sync::Arc;
+use std::time::Duration;
+use tokio::sync::RwLock;
+use tokio::time::Instant;
+use tonic::codec::CompressionEncoding;
+use tonic::transport::Channel;
+use tonic::Status;
 
 #[derive(Debug, Clone)]
 pub enum RoutingTableError {
@@ -111,6 +110,23 @@ impl RoutingTableConfig {
     }
 }
 
+impl SafeDisplay for RoutingTableConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "host: {}", self.host);
+        let _ = writeln!(&mut result, "port: {}", self.port);
+        let _ = writeln!(
+            &mut result,
+            "invalidation minimum delay: {:?}",
+            self.invalidation_min_delay
+        );
+        let _ = writeln!(&mut result, "connect timeout: {:?}", self.connect_timeout);
+        let _ = writeln!(&mut result, "retries:");
+        let _ = writeln!(&mut result, "{}", self.retries.to_safe_string_indented());
+        result
+    }
+}
+
 impl Default for RoutingTableConfig {
     fn default() -> Self {
         Self {
@@ -242,6 +258,6 @@ impl RoutingTableService for RoutingTableServiceNoop {
     }
 
     async fn try_invalidate_routing_table(&self) -> bool {
-        return false;
+        false
     }
 }
diff --git a/golem-service-base/src/storage/blob/memory.rs b/golem-service-base/src/storage/blob/memory.rs
index 02a5e79c..f602a349 100644
--- a/golem-service-base/src/storage/blob/memory.rs
+++ b/golem-service-base/src/storage/blob/memory.rs
@@ -12,7 +12,7 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use super::{as_unix_path, ErasedReplayableStream};
+use super::ErasedReplayableStream;
 use crate::storage::blob::{BlobMetadata, BlobStorage, BlobStorageNamespace, ExistsResult};
 use async_trait::async_trait;
 use bytes::Bytes;
@@ -24,8 +24,6 @@ use std::{
     path::{Path, PathBuf},
     pin::Pin,
 };
-use unix_path::Path as UnixPath;
-use unix_path::PathBuf as UnixPathBuf;
 
 #[derive(Debug)]
 pub struct InMemoryBlobStorage {
@@ -61,12 +59,11 @@ impl BlobStorage for InMemoryBlobStorage {
         namespace: BlobStorageNamespace,
         path: &Path,
     ) -> Result<Option<Bytes>, String> {
-        let u_path = as_unix_path(path);
-        let dir = u_path
+        let dir = path
             .parent()
             .map(|p| p.to_string_lossy().to_string())
             .unwrap_or_default();
-        let key = u_path
+        let key = path
             .file_name()
             .expect("Path must have a file name")
             .to_string_lossy()
@@ -85,12 +82,11 @@ impl BlobStorage for InMemoryBlobStorage {
         namespace: BlobStorageNamespace,
         path: &Path,
     ) -> Result<Option<BoxStream<'static, Result<Bytes, String>>>, String> {
-        let u_path = as_unix_path(path);
-        let dir = u_path
+        let dir = path
             .parent()
             .map(|p| p.to_string_lossy().to_string())
             .unwrap_or_default();
-        let key = u_path
+        let key = path
             .file_name()
             .expect("Path must have a file name")
             .to_string_lossy()
@@ -117,12 +113,11 @@ impl BlobStorage for InMemoryBlobStorage {
         namespace: BlobStorageNamespace,
         path: &Path,
     ) -> Result<Option<BlobMetadata>, String> {
-        let u_path = as_unix_path(path);
-        let dir = u_path
+        let dir = path
             .parent()
             .map(|p| p.to_string_lossy().to_string())
             .unwrap_or_default();
-        let key = u_path
+        let key = path
             .file_name()
             .expect("Path must have a file name")
             .to_string_lossy()
@@ -142,12 +137,11 @@ impl BlobStorage for InMemoryBlobStorage {
         path: &Path,
         data: &[u8],
     ) -> Result<(), String> {
-        let u_path = as_unix_path(path);
-        let dir = u_path
+        let dir = path
             .parent()
             .map(|p| p.to_string_lossy().to_string())
             .unwrap_or_default();
-        let key = u_path
+        let key = path
             .file_name()
             .expect("Path must have a file name")
             .to_string_lossy()
@@ -176,13 +170,12 @@ impl BlobStorage for InMemoryBlobStorage {
         path: &Path,
         stream: &dyn ErasedReplayableStream<Item = Result<Bytes, String>, Error = String>,
     ) -> Result<(), String> {
-        let u_path = as_unix_path(path);
-        let dir = u_path
+        let dir = path
             .parent()
             .map(|p| p.to_string_lossy().to_string())
             .unwrap_or_default();
 
-        let key = u_path
+        let key = path
             .file_name()
             .expect("Path must have a file name")
             .to_string_lossy()
@@ -218,12 +211,11 @@ impl BlobStorage for InMemoryBlobStorage {
         namespace: BlobStorageNamespace,
         path: &Path,
     ) -> Result<(), String> {
-        let u_path = as_unix_path(path);
-        let dir = u_path
+        let dir = path
             .parent()
             .map(|p| p.to_string_lossy().to_string())
             .unwrap_or_default();
-        let key = u_path
+        let key = path
             .file_name()
             .expect("Path must have a file name")
             .to_string_lossy()
@@ -244,8 +236,7 @@ impl BlobStorage for InMemoryBlobStorage {
         namespace: BlobStorageNamespace,
         path: &Path,
     ) -> Result<(), String> {
-        let u_path = as_unix_path(path);
-        let dir = u_path.to_string_lossy().to_string();
+        let dir = path.to_string_lossy().to_string();
         self.data
             .entry(namespace)
             .or_default()
@@ -261,8 +252,7 @@ impl BlobStorage for InMemoryBlobStorage {
         namespace: BlobStorageNamespace,
         path: &Path,
     ) -> Result<Vec<PathBuf>, String> {
-        let u_path = as_unix_path(path);
-        let dir = u_path.to_string_lossy().to_string();
+        let dir = path.to_string_lossy().to_string();
 
         if let Some(namespace_data) = self.data.get(&namespace) {
             let mut result: Vec<PathBuf> = Vec::new();
@@ -270,11 +260,9 @@ impl BlobStorage for InMemoryBlobStorage {
                 let file_result: Vec<PathBuf> = directory
                     .iter()
                     .map(|entry| {
-                        let mut pathnew = UnixPathBuf::new();
-                        pathnew.push(path.to_str().unwrap());
-                        pathnew.push(entry.key().as_str());
-                        // this does not re-convert the path to os-separator, keeps expected unix
-                        Path::new(pathnew.to_str().unwrap()).to_path_buf()
+                        let mut path = path.to_path_buf();
+                        path.push(entry.key());
+                        path
                     })
                     .collect();
                 result.extend(file_result);
@@ -289,12 +277,7 @@ impl BlobStorage for InMemoryBlobStorage {
                 .iter()
                 .filter(|entry| entry.key() != &dir && entry.key().starts_with(&prefix))
                 .for_each(|entry| {
-                    let mut pathnew = UnixPathBuf::new();
-                    pathnew.push(entry.key().as_str());
-
-                    // this does not re-convert the path to os-separator, keeps expected unix
-                    let std_pathnew = Path::new(pathnew.to_str().unwrap()).to_path_buf();
-                    result.push(std_pathnew);
+                    result.push(Path::new(entry.key()).to_path_buf());
                 });
 
             Ok(result)
@@ -310,8 +293,7 @@ impl BlobStorage for InMemoryBlobStorage {
         namespace: BlobStorageNamespace,
         path: &Path,
     ) -> Result<bool, String> {
-        let u_path = as_unix_path(path);
-        let dir = u_path.to_string_lossy().to_string();
+        let dir = path.to_string_lossy().to_string();
         let result = self
             .data
             .get(&namespace)
@@ -326,28 +308,27 @@ impl BlobStorage for InMemoryBlobStorage {
         namespace: BlobStorageNamespace,
         path: &Path,
     ) -> Result<ExistsResult, String> {
-        let u_path = as_unix_path(path);
         if self
             .data
             .get(&namespace)
             .map(|namespace_data| {
-                namespace_data.contains_key::<str>(u_path.to_string_lossy().as_ref())
+                namespace_data.contains_key::<str>(path.to_string_lossy().as_ref())
             })
             .unwrap_or_default()
         {
             Ok(ExistsResult::Directory)
-        } else if u_path == UnixPath::new("") {
+        } else if path == Path::new("") {
             if self.data.get(&namespace).is_some() {
                 Ok(ExistsResult::Directory)
             } else {
                 Ok(ExistsResult::DoesNotExist)
             }
         } else {
-            let dir = u_path
+            let dir = path
                 .parent()
                 .map(|p| p.to_string_lossy().to_string())
                 .unwrap_or_default();
-            let key = u_path
+            let key = path
                 .file_name()
                 .expect("Path must have a file name")
                 .to_string_lossy()
diff --git a/golem-service-base/src/storage/blob/mod.rs b/golem-service-base/src/storage/blob/mod.rs
index 7f0dabfa..f023744c 100644
--- a/golem-service-base/src/storage/blob/mod.rs
+++ b/golem-service-base/src/storage/blob/mod.rs
@@ -17,34 +17,16 @@ use async_trait::async_trait;
 use bincode::{Decode, Encode};
 use bytes::Bytes;
 use futures::stream::BoxStream;
-use golem_common::model::{AccountId, ComponentId, Timestamp, WorkerId};
+use golem_common::model::{AccountId, ComponentId, ProjectId, Timestamp, WorkerId};
 use golem_common::serialization::{deserialize, serialize};
 use std::fmt::Debug;
 use std::path::{Path, PathBuf};
-use unix_path::Path as UnixPath;
-use unix_path::PathBuf as UnixPathBuf;
 
 pub mod fs;
 pub mod memory;
 pub mod s3;
 pub mod sqlite;
 
-pub fn as_std_path(u_path: &UnixPath) -> PathBuf {
-    let mut path = PathBuf::new();
-    for part in u_path.iter() {
-        path = path.join(part.to_str().unwrap());
-    }
-    path
-}
-
-pub fn as_unix_path(path: &Path) -> UnixPathBuf {
-    let mut u_path = UnixPathBuf::new();
-    for part in path.iter() {
-        u_path = u_path.join(part.to_str().unwrap());
-    }
-    u_path
-}
-
 #[async_trait]
 pub trait BlobStorage: Debug + Send + Sync {
     async fn get_raw(
@@ -366,22 +348,27 @@ impl<'a, S: BlobStorage + ?Sized + Sync> LabelledBlobStorage<'a, S> {
 
 #[derive(Debug, Clone, PartialEq, Eq, Hash)]
 pub enum BlobStorageNamespace {
-    CompilationCache,
+    CompilationCache {
+        project_id: ProjectId,
+    },
     InitialComponentFiles {
-        account_id: AccountId,
+        project_id: ProjectId,
+    },
+    CustomStorage {
+        project_id: ProjectId,
     },
-    CustomStorage(AccountId),
     OplogPayload {
-        account_id: AccountId,
+        project_id: ProjectId,
         worker_id: WorkerId,
     },
     CompressedOplog {
-        account_id: AccountId,
+        project_id: ProjectId,
         component_id: ComponentId,
         level: usize,
     },
-    // TODO: prefix with account_id and move existing data
-    Components,
+    Components {
+        project_id: ProjectId,
+    },
     PluginWasmFiles {
         account_id: AccountId,
     },
diff --git a/golem-service-base/src/storage/blob/s3.rs b/golem-service-base/src/storage/blob/s3.rs
index 61367a36..910921b2 100644
--- a/golem-service-base/src/storage/blob/s3.rs
+++ b/golem-service-base/src/storage/blob/s3.rs
@@ -12,7 +12,6 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use super::as_unix_path;
 use crate::config::S3BlobStorageConfig;
 use crate::replayable_stream::ErasedReplayableStream;
 use crate::storage::blob::{BlobMetadata, BlobStorage, BlobStorageNamespace, ExistsResult};
@@ -35,12 +34,10 @@ use http_body::SizeHint;
 use http_body_util::combinators::BoxBody;
 use http_body_util::BodyExt;
 use std::error::Error;
-use std::ffi::OsStr;
 use std::future::Future;
 use std::path::{Path, PathBuf};
 use std::pin::Pin;
 use tracing::info;
-use unix_path::PathBuf as UnixPathBuf;
 
 #[derive(Debug)]
 pub struct S3BlobStorage {
@@ -74,19 +71,10 @@ impl S3BlobStorage {
         }
     }
 
-    fn s3_key(&self, namespace: &BlobStorageNamespace, path: &Path) -> UnixPathBuf {
-        // push of components is done to prevent mixed-separator paths
-        let mut pre = self.prefix_of(namespace);
-        path.components().for_each(|comp| {
-            pre.push(comp.as_os_str().to_string_lossy().to_string());
-        });
-        pre
-    }
-
     fn bucket_of(&self, namespace: &BlobStorageNamespace) -> &String {
         match namespace {
-            BlobStorageNamespace::CompilationCache => &self.config.compilation_cache_bucket,
-            BlobStorageNamespace::CustomStorage(_account_id) => &self.config.custom_data_bucket,
+            BlobStorageNamespace::CompilationCache { .. } => &self.config.compilation_cache_bucket,
+            BlobStorageNamespace::CustomStorage { .. } => &self.config.custom_data_bucket,
             BlobStorageNamespace::OplogPayload { .. } => &self.config.oplog_payload_bucket,
             BlobStorageNamespace::CompressedOplog { level, .. } => {
                 &self.config.compressed_oplog_buckets[*level]
@@ -94,57 +82,72 @@ impl S3BlobStorage {
             BlobStorageNamespace::InitialComponentFiles { .. } => {
                 &self.config.initial_component_files_bucket
             }
-            BlobStorageNamespace::Components => &self.config.components_bucket,
+            BlobStorageNamespace::Components { .. } => &self.config.components_bucket,
             BlobStorageNamespace::PluginWasmFiles { .. } => &self.config.plugin_wasm_files_bucket,
         }
     }
 
-    fn prefix_of(&self, namespace: &BlobStorageNamespace) -> UnixPathBuf {
-        let mut base = UnixPathBuf::new();
-        if !self.config.object_prefix.is_empty() {
-            base.push(&self.config.object_prefix);
-        }
+    fn prefix_of(&self, namespace: &BlobStorageNamespace) -> PathBuf {
         match namespace {
-            BlobStorageNamespace::CompilationCache => {
-                // none
-            }
-            BlobStorageNamespace::Components => {
-                // none
-            }
-            BlobStorageNamespace::CustomStorage(account_id) => {
-                let account_id_string = account_id.to_string();
-                base.push(&account_id_string);
+            BlobStorageNamespace::CompilationCache { project_id }
+            | BlobStorageNamespace::CustomStorage { project_id }
+            | BlobStorageNamespace::InitialComponentFiles { project_id }
+            | BlobStorageNamespace::Components { project_id } => {
+                let project_id_string = project_id.to_string();
+                if self.config.object_prefix.is_empty() {
+                    Path::new(&project_id_string).to_path_buf()
+                } else {
+                    Path::new(&self.config.object_prefix)
+                        .join(project_id_string)
+                        .to_path_buf()
+                }
             }
             BlobStorageNamespace::OplogPayload {
-                account_id,
+                project_id,
                 worker_id,
             } => {
-                let account_id_string = account_id.to_string();
+                let project_id_string = project_id.to_string();
                 let worker_id_string = worker_id.to_string();
-                base.push(account_id_string);
-                base.push(worker_id_string);
+                if self.config.object_prefix.is_empty() {
+                    Path::new(&project_id_string)
+                        .join(worker_id_string)
+                        .to_path_buf()
+                } else {
+                    Path::new(&self.config.object_prefix)
+                        .join(project_id_string)
+                        .join(worker_id_string)
+                        .to_path_buf()
+                }
             }
             BlobStorageNamespace::CompressedOplog {
-                account_id,
+                project_id,
                 component_id,
                 ..
             } => {
-                let account_id_string = account_id.to_string();
+                let project_id_string = project_id.to_string();
                 let component_id_string = component_id.to_string();
-                base.push(account_id_string);
-                base.push(component_id_string);
-            }
-            BlobStorageNamespace::InitialComponentFiles { account_id } => {
-                let account_id_string = account_id.to_string();
-                base.push(account_id_string);
+                if self.config.object_prefix.is_empty() {
+                    Path::new(&project_id_string)
+                        .join(component_id_string)
+                        .to_path_buf()
+                } else {
+                    Path::new(&self.config.object_prefix)
+                        .join(project_id_string)
+                        .join(component_id_string)
+                        .to_path_buf()
+                }
             }
             BlobStorageNamespace::PluginWasmFiles { account_id } => {
                 let account_id_string = account_id.to_string();
-                base.push(account_id_string);
+                if self.config.object_prefix.is_empty() {
+                    PathBuf::from(&account_id_string)
+                } else {
+                    Path::new(&self.config.object_prefix)
+                        .join(account_id_string)
+                        .to_path_buf()
+                }
             }
         }
-
-        base.to_path_buf()
     }
 
     async fn list_objects(
@@ -154,7 +157,6 @@ impl S3BlobStorage {
         bucket: &str,
         prefix: &Path,
     ) -> Result<Vec<Object>, String> {
-        let u_path = as_unix_path(prefix);
         let mut result = Vec::new();
         let mut cont: Option<String> = None;
 
@@ -162,19 +164,15 @@ impl S3BlobStorage {
             let response = with_retries_customized(
                 target_label,
                 op_label,
-                Some(format!("{bucket} - {}", u_path.to_string_lossy())),
+                Some(format!("{bucket} - {}", prefix.to_string_lossy())),
                 &self.config.retries,
-                &(self.client.clone(), bucket, u_path.clone(), cont),
-                |(client, bucket, u_path, cont)| {
+                &(self.client.clone(), bucket, prefix, cont),
+                |(client, bucket, prefix, cont)| {
                     Box::pin(async move {
-                        let prefix = if u_path.to_string_lossy().ends_with('/') {
-                            u_path
-                                .to_string_lossy()
-                                .strip_suffix("/")
-                                .unwrap()
-                                .to_string()
+                        let prefix = if prefix.to_string_lossy().ends_with('/') {
+                            prefix.to_string_lossy().to_string()
                         } else {
-                            u_path.to_string_lossy().to_string()
+                            format!("{}/", prefix.to_string_lossy())
                         };
                         client
                             .list_objects_v2()
@@ -186,7 +184,7 @@ impl S3BlobStorage {
                     })
                 },
                 Self::is_list_objects_v2_error_retriable,
-                Self::as_loggable_generic,
+                Self::sdk_error_as_loggable_string,
                 false,
             )
             .await
@@ -272,7 +270,7 @@ impl S3BlobStorage {
         }
     }
 
-    fn as_loggable_generic<T: Error>(error: &SdkError<T>) -> Option<String> {
+    fn sdk_error_as_loggable_string<T: Error>(error: &SdkError<T>) -> Option<String> {
         Some(Self::error_string(error))
     }
 
@@ -315,7 +313,7 @@ impl BlobStorage for S3BlobStorage {
         path: &Path,
     ) -> Result<Option<Bytes>, String> {
         let bucket = self.bucket_of(&namespace);
-        let key = self.s3_key(&namespace, path);
+        let key = self.prefix_of(&namespace).join(path);
 
         let result = with_retries_customized(
             target_label,
@@ -363,7 +361,7 @@ impl BlobStorage for S3BlobStorage {
         path: &Path,
     ) -> Result<Option<BoxStream<'static, Result<Bytes, String>>>, String> {
         let bucket = self.bucket_of(&namespace);
-        let key = self.s3_key(&namespace, path);
+        let key = self.prefix_of(&namespace).join(path);
 
         let result = with_retries_customized(
             target_label,
@@ -414,7 +412,7 @@ impl BlobStorage for S3BlobStorage {
         end: u64,
     ) -> Result<Option<Bytes>, String> {
         let bucket = self.bucket_of(&namespace);
-        let key = self.s3_key(&namespace, path);
+        let key = self.prefix_of(&namespace).join(path);
 
         let result = with_retries_customized(
             target_label,
@@ -434,7 +432,7 @@ impl BlobStorage for S3BlobStorage {
                 })
             },
             Self::is_get_object_error_retriable,
-            Self::as_loggable_generic,
+            Self::sdk_error_as_loggable_string,
             false,
         )
         .await;
@@ -463,7 +461,7 @@ impl BlobStorage for S3BlobStorage {
         path: &Path,
     ) -> Result<Option<BlobMetadata>, String> {
         let bucket = self.bucket_of(&namespace);
-        let key = self.s3_key(&namespace, path);
+        let key = self.prefix_of(&namespace).join(path);
         let op_id = format!("{bucket} - {key:?}");
 
         let file_head_result = with_retries_customized(
@@ -557,7 +555,7 @@ impl BlobStorage for S3BlobStorage {
         data: &[u8],
     ) -> Result<(), String> {
         let bucket = self.bucket_of(&namespace);
-        let key = self.s3_key(&namespace, path);
+        let key = self.prefix_of(&namespace).join(path);
 
         with_retries_customized(
             target_label,
@@ -577,7 +575,7 @@ impl BlobStorage for S3BlobStorage {
                 })
             },
             Self::is_put_object_error_retriable,
-            Self::as_loggable_generic,
+            Self::sdk_error_as_loggable_string,
             false,
         )
         .await
@@ -594,13 +592,13 @@ impl BlobStorage for S3BlobStorage {
         stream: &dyn ErasedReplayableStream<Item = Result<Bytes, String>, Error = String>,
     ) -> Result<(), String> {
         let bucket = self.bucket_of(&namespace);
-        let key = self.s3_key(&namespace, path);
+        let key = self.prefix_of(&namespace).join(path);
 
         fn go<'a>(
             args: &'a (
                 Client,
                 &String,
-                UnixPathBuf,
+                PathBuf,
                 &dyn ErasedReplayableStream<Item = Result<Bytes, String>, Error = String>,
             ),
         ) -> Pin<
@@ -659,7 +657,7 @@ impl BlobStorage for S3BlobStorage {
         path: &Path,
     ) -> Result<(), String> {
         let bucket = self.bucket_of(&namespace);
-        let key = self.s3_key(&namespace, path);
+        let key = self.prefix_of(&namespace).join(path);
 
         with_retries_customized(
             target_label,
@@ -678,7 +676,7 @@ impl BlobStorage for S3BlobStorage {
                 })
             },
             Self::is_delete_object_error_retriable,
-            Self::as_loggable_generic,
+            Self::sdk_error_as_loggable_string,
             false,
         )
         .await
@@ -700,7 +698,7 @@ impl BlobStorage for S3BlobStorage {
         let to_delete = paths
             .iter()
             .map(|path| {
-                let key = self.s3_key(&namespace, path);
+                let key = prefix.join(path);
                 ObjectIdentifier::builder()
                     .key(key.to_string_lossy())
                     .build()
@@ -730,7 +728,7 @@ impl BlobStorage for S3BlobStorage {
                 })
             },
             Self::is_delete_objects_error_retriable,
-            Self::as_loggable_generic,
+            Self::sdk_error_as_loggable_string,
             false,
         )
         .await
@@ -747,7 +745,7 @@ impl BlobStorage for S3BlobStorage {
         path: &Path,
     ) -> Result<(), String> {
         let bucket = self.bucket_of(&namespace);
-        let key = self.s3_key(&namespace, path);
+        let key = self.prefix_of(&namespace).join(path);
         let marker = key.join("__dir_marker");
 
         with_retries_customized(
@@ -768,7 +766,7 @@ impl BlobStorage for S3BlobStorage {
                 })
             },
             Self::is_put_object_error_retriable,
-            Self::as_loggable_generic,
+            Self::sdk_error_as_loggable_string,
             false,
         )
         .await
@@ -785,56 +783,34 @@ impl BlobStorage for S3BlobStorage {
         path: &Path,
     ) -> Result<Vec<PathBuf>, String> {
         let bucket = self.bucket_of(&namespace);
-        let is_empty_path = path.to_str().unwrap() == "";
-
-        let unix_namespace_root = self.prefix_of(&namespace);
-        let namespace_root = format!("{}/", unix_namespace_root.display());
-
-        let unix_key = self.s3_key(&namespace, path);
-        let key = Path::new(unix_key.to_str().unwrap()); // keep content
+        let namespace_root = self.prefix_of(&namespace);
+        let key = namespace_root.join(path);
 
         Ok(self
-            .list_objects(target_label, op_label, bucket, key)
+            .list_objects(target_label, op_label, bucket, &key)
             .await?
             .iter()
             .flat_map(|obj| obj.key.as_ref().map(|k| Path::new(k).to_path_buf()))
             .filter_map(|path| {
-                if namespace_root != "/" {
-                    path.strip_prefix(&namespace_root)
-                        .ok()
-                        .map(|p| p.to_path_buf())
+                let is_dir_marker =
+                    path.file_name().and_then(|s| s.to_str()) == Some("__dir_marker");
+                let is_nested = path.parent() != Some(&key);
+                if is_nested {
+                    if is_dir_marker {
+                        path.parent().map(|p| p.to_path_buf())
+                    } else {
+                        None
+                    }
+                } else if is_dir_marker {
+                    None
                 } else {
-                    Some(path.to_path_buf())
+                    Some(path)
                 }
             })
-            .filter_map(|path_elem| {
-                let mut components = path_elem.components().collect::<Vec<_>>();
-                let has_prefix_key: bool =
-                    is_empty_path || components[0].as_os_str() == OsStr::new(path);
-                let has_marker_dir: bool =
-                    components.last().unwrap().as_os_str() == OsStr::new("__dir_marker");
-                let is_nested: bool = if is_empty_path {
-                    components.len() > 1
-                } else {
-                    components.len() > 2
-                };
-
-                if has_prefix_key {
-                    if is_nested && has_marker_dir {
-                        components.pop(); // remove __dir_marker
-
-                        // create actual path
-                        let mut newpath = PathBuf::new();
-                        components.iter().for_each(|comp| {
-                            newpath.push(comp);
-                        });
-                        return Some(newpath);
-                    }
-                    if !is_nested && !has_marker_dir {
-                        return Some(path_elem);
-                    }
-                }
-                None
+            .filter_map(|path| {
+                path.strip_prefix(&namespace_root)
+                    .ok()
+                    .map(|p| p.to_path_buf())
             })
             .collect::<Vec<_>>())
     }
@@ -847,11 +823,10 @@ impl BlobStorage for S3BlobStorage {
         path: &Path,
     ) -> Result<bool, String> {
         let bucket = self.bucket_of(&namespace);
-        let unix_key = self.s3_key(&namespace, path);
-        let key = Path::new(unix_key.to_str().unwrap()); // keep content
+        let key = self.prefix_of(&namespace).join(path);
 
         let to_delete = self
-            .list_objects(target_label, op_label, bucket, key)
+            .list_objects(target_label, op_label, bucket, &key)
             .await?
             .iter()
             .flat_map(|obj| {
@@ -888,7 +863,7 @@ impl BlobStorage for S3BlobStorage {
                     })
                 },
                 Self::is_delete_objects_error_retriable,
-                Self::as_loggable_generic,
+                Self::sdk_error_as_loggable_string,
                 false,
             )
             .await
@@ -906,7 +881,7 @@ impl BlobStorage for S3BlobStorage {
         path: &Path,
     ) -> Result<ExistsResult, String> {
         let bucket = self.bucket_of(&namespace);
-        let key = self.s3_key(&namespace, path);
+        let key = self.prefix_of(&namespace).join(path);
         let op_id = format!("{bucket} - {key:?}");
 
         let file_head_result = with_retries_customized(
@@ -980,8 +955,8 @@ impl BlobStorage for S3BlobStorage {
         to: &Path,
     ) -> Result<(), String> {
         let bucket = self.bucket_of(&namespace);
-        let from_key = self.s3_key(&namespace, from);
-        let to_key = self.s3_key(&namespace, to);
+        let from_key = self.prefix_of(&namespace).join(from);
+        let to_key = self.prefix_of(&namespace).join(to);
 
         with_retries_customized(
             target_label,
@@ -1001,7 +976,7 @@ impl BlobStorage for S3BlobStorage {
                 })
             },
             Self::is_copy_object_error_retriable,
-            Self::as_loggable_generic,
+            Self::sdk_error_as_loggable_string,
             false,
         )
         .await
@@ -1039,7 +1014,9 @@ impl<T> SdkErrorOrCustomError<T> {
         T: Error,
     {
         match self {
-            SdkErrorOrCustomError::SdkError(err) => S3BlobStorage::as_loggable_generic(err),
+            SdkErrorOrCustomError::SdkError(err) => {
+                S3BlobStorage::sdk_error_as_loggable_string(err)
+            }
             SdkErrorOrCustomError::CustomError(err) => Some(err.clone()),
         }
     }
diff --git a/golem-service-base/tests/blob_storage.rs b/golem-service-base/tests/blob_storage.rs
index 34bb20d4..99bad76d 100644
--- a/golem-service-base/tests/blob_storage.rs
+++ b/golem-service-base/tests/blob_storage.rs
@@ -17,19 +17,16 @@ use async_trait::async_trait;
 use aws_config::meta::region::RegionProviderChain;
 use aws_config::BehaviorVersion;
 use aws_sdk_s3::config::Credentials;
-use aws_sdk_s3::types::{Delete, ObjectIdentifier};
 use aws_sdk_s3::Client;
-use aws_sdk_s3::Error;
 use bytes::{BufMut, Bytes, BytesMut};
 use futures::stream::BoxStream;
 use futures::TryStreamExt;
-use golem_common::model::{AccountId, ComponentId};
+use golem_common::model::{ComponentId, ProjectId};
 use golem_common::widen_infallible;
 use golem_service_base::config::S3BlobStorageConfig;
 use golem_service_base::db::sqlite::SqlitePool;
 use golem_service_base::replayable_stream::ErasedReplayableStream;
 use golem_service_base::replayable_stream::ReplayableStream;
-use golem_service_base::storage::blob::as_std_path;
 use golem_service_base::storage::blob::sqlite::SqliteBlobStorage;
 use golem_service_base::storage::blob::*;
 use golem_service_base::storage::blob::{fs, memory, s3, BlobStorage, BlobStorageNamespace};
@@ -38,14 +35,12 @@ use std::fmt::Debug;
 use std::path::{Path, PathBuf};
 use std::sync::atomic::AtomicU32;
 use std::sync::Arc;
+use std::time::Duration;
 use tempfile::{tempdir, TempDir};
 use test_r::{define_matrix_dimension, test, test_dep};
-use testcontainers::core::ContainerPort;
 use testcontainers::runners::AsyncRunner;
-use testcontainers::{ContainerAsync, ImageExt};
+use testcontainers::ContainerAsync;
 use testcontainers_modules::minio::MinIO;
-use tracing::warn;
-use unix_path::Path as UnixPath;
 use uuid::Uuid;
 
 #[async_trait]
@@ -115,87 +110,36 @@ impl Debug for S3Test {
 #[async_trait]
 impl GetBlobStorage for S3Test {
     async fn get_blob_storage(&self) -> Arc<dyn BlobStorage + Send + Sync> {
-        let host_port = if let Some(port) = opt_env_var("MINIO_PORT") {
-            port.parse().expect("Failed to parse MINIO_PORT")
-        } else {
-            9000
-        };
-        let host_string_option = opt_env_var("MINIO_HOST");
-        let host = if let Some(path) = &host_string_option {
-            path.as_str()
-        } else {
-            "127.0.0.1"
-        };
+        let container = tryhard::retry_fn(|| MinIO::default().start())
+            .retries(5)
+            .exponential_backoff(Duration::from_millis(10))
+            .max_delay(Duration::from_secs(10))
+            .await
+            .expect("Failed to start MinIO");
+        let host_port = container
+            .get_host_port_ipv4(9000)
+            .await
+            .expect("Failed to get host port");
 
         let config = S3BlobStorageConfig {
             retries: Default::default(),
             region: "us-east-1".to_string(),
             object_prefix: self.prefixed.clone().unwrap_or_default(),
-            aws_endpoint_url: Some(format!("http://{host}:{host_port}")),
+            aws_endpoint_url: Some(format!("http://127.0.0.1:{host_port}")),
             use_minio_credentials: true,
             ..std::default::Default::default()
         };
-        if let Some(golem_docker_services) = opt_env_var_bool("GOLEM_DOCKER_SERVICES") {
-            if golem_docker_services {
-                warn!("MinIO launched via docker at http://{host}:{host_port}");
-                let container = MinIO::default()
-                    .with_mapped_port(host_port, ContainerPort::Tcp(host_port))
-                    .start()
-                    .await
-                    .expect("Failed to start MinIO");
-
-                setup_buckets(host, host_port, &config).await;
-                let storage = s3::S3BlobStorage::new(config).await;
-
-                return Arc::new(S3BlobStorageWithContainer {
-                    storage,
-                    _container: container,
-                });
-            }
-        }
-
-        warn!("MinIO assumed to be provided at http://{host}:{host_port}");
-        setup_buckets(host, host_port, &config).await;
+        create_buckets(host_port, &config).await;
         let storage = s3::S3BlobStorage::new(config).await;
-        Arc::new(storage)
-    }
-}
-
-pub async fn delete_all_objects(client: &Client, bucket_name: &str) -> Result<(), Error> {
-    let mut object_identifiers: Vec<ObjectIdentifier> = Vec::new();
-
-    let list_response = client.list_objects_v2().bucket(bucket_name).send().await?;
-
-    if let Some(contents) = list_response.contents {
-        for object in contents {
-            if let Some(key) = object.key {
-                object_identifiers.push(ObjectIdentifier::builder().key(key).build().unwrap());
-            }
-        }
-    }
-
-    for chunk in object_identifiers.chunks(1000) {
-        let delete = Delete::builder()
-            .set_objects(Some(chunk.to_vec()))
-            .build()
-            .unwrap();
-
-        client
-            .delete_objects()
-            .bucket(bucket_name)
-            .delete(delete)
-            .send()
-            .await
-            .unwrap();
+        Arc::new(S3BlobStorageWithContainer {
+            storage,
+            _container: container,
+        })
     }
-
-    client.delete_bucket().bucket(bucket_name).send().await.ok();
-
-    Ok(())
 }
 
-async fn setup_buckets(host: &str, host_port: u16, config: &S3BlobStorageConfig) {
-    let endpoint_uri = format!("http://{host}:{host_port}");
+async fn create_buckets(host_port: u16, config: &S3BlobStorageConfig) {
+    let endpoint_uri = format!("http://127.0.0.1:{host_port}");
     let region_provider = RegionProviderChain::default_provider().or_else("us-east-1");
     let creds = Credentials::new("minioadmin", "minioadmin", None, None, "test");
     let sdk_config = aws_config::defaults(BehaviorVersion::latest())
@@ -206,21 +150,6 @@ async fn setup_buckets(host: &str, host_port: u16, config: &S3BlobStorageConfig)
         .await;
 
     let client = Client::new(&sdk_config);
-    // clear previous runs
-    delete_all_objects(&client, &config.compilation_cache_bucket)
-        .await
-        .ok();
-    delete_all_objects(&client, &config.custom_data_bucket)
-        .await
-        .ok();
-    delete_all_objects(&client, &config.oplog_payload_bucket)
-        .await
-        .ok();
-    for bucket in &config.compressed_oplog_buckets {
-        delete_all_objects(&client, bucket).await.ok();
-    }
-
-    // recreate buckets
     client
         .create_bucket()
         .bucket(&config.compilation_cache_bucket)
@@ -255,12 +184,6 @@ impl Debug for S3BlobStorageWithContainer {
     }
 }
 
-impl Drop for S3BlobStorageWithContainer {
-    fn drop(&mut self) {
-        futures::executor::block_on(self._container.stop()).expect("TODO: panic message");
-    }
-}
-
 #[async_trait]
 impl BlobStorage for S3BlobStorageWithContainer {
     async fn get_raw(
@@ -481,15 +404,15 @@ async fn sqlite() -> Arc<dyn GetBlobStorage + Send + Sync> {
 
 #[test_dep(tagged_as = "cc")]
 fn compilation_cache() -> BlobStorageNamespace {
-    BlobStorageNamespace::CompilationCache
+    BlobStorageNamespace::CompilationCache {
+        project_id: ProjectId(Uuid::parse_str("4c8c5ff4-2a42-4e81-ac48-e63005f609fd").unwrap()),
+    }
 }
 
 #[test_dep(tagged_as = "co")]
 fn compressed_oplog() -> BlobStorageNamespace {
     BlobStorageNamespace::CompressedOplog {
-        account_id: AccountId {
-            value: "test-account".to_string(),
-        },
+        project_id: ProjectId(Uuid::parse_str("4c8c5ff4-2a42-4e81-ac48-e63005f609fd").unwrap()),
         component_id: ComponentId(Uuid::new_v4()),
         level: 0,
     }
@@ -782,14 +705,9 @@ async fn list_dir(
 ) {
     let storage = test.get_blob_storage().await;
 
-    let path = UnixPath::new("test-dir");
+    let path = Path::new("test-dir");
     storage
-        .create_dir(
-            "list_dir",
-            "create-dir",
-            namespace.clone(),
-            as_std_path(path).as_path(),
-        )
+        .create_dir("list_dir", "create-dir", namespace.clone(), path)
         .await
         .unwrap();
     storage
@@ -797,7 +715,7 @@ async fn list_dir(
             "list_dir",
             "put-raw",
             namespace.clone(),
-            as_std_path(&path.join("test-file1")).as_path(),
+            &path.join("test-file1"),
             &Bytes::from("test-data1"),
         )
         .await
@@ -807,7 +725,7 @@ async fn list_dir(
             "list_dir",
             "put-raw",
             namespace.clone(),
-            as_std_path(&path.join("test-file2")).as_path(),
+            &path.join("test-file2"),
             &Bytes::from("test-data2"),
         )
         .await
@@ -817,17 +735,12 @@ async fn list_dir(
             "list_dir",
             "create-dir",
             namespace.clone(),
-            as_std_path(&path.join("inner-dir")).as_path(),
+            &path.join("inner-dir"),
         )
         .await
         .unwrap();
     let mut entries = storage
-        .list_dir(
-            "list_dir",
-            "entries",
-            namespace.clone(),
-            as_std_path(path).as_path(),
-        )
+        .list_dir("list_dir", "entries", namespace.clone(), path)
         .await
         .unwrap();
 
@@ -1056,34 +969,19 @@ async fn list_dir_same_prefix(
 ) {
     let storage = test.get_blob_storage().await;
 
-    let path1 = UnixPath::new("test-dir");
-    let path2 = UnixPath::new("test-dir2");
-    let path3 = UnixPath::new("test-dir3");
+    let path1 = Path::new("test-dir");
+    let path2 = Path::new("test-dir2");
+    let path3 = Path::new("test-dir3");
     storage
-        .create_dir(
-            "list_dir",
-            "create-dir",
-            namespace.clone(),
-            as_std_path(path1).as_path(),
-        )
+        .create_dir("list_dir", "create-dir", namespace.clone(), path1)
         .await
         .unwrap();
     storage
-        .create_dir(
-            "list_dir",
-            "create-dir-2",
-            namespace.clone(),
-            as_std_path(path2).as_path(),
-        )
+        .create_dir("list_dir", "create-dir-2", namespace.clone(), path2)
         .await
         .unwrap();
     storage
-        .create_dir(
-            "list_dir",
-            "create-dir-3",
-            namespace.clone(),
-            as_std_path(path3).as_path(),
-        )
+        .create_dir("list_dir", "create-dir-3", namespace.clone(), path3)
         .await
         .unwrap();
     storage
@@ -1091,7 +989,7 @@ async fn list_dir_same_prefix(
             "list_dir_same_prefix",
             "put-raw",
             namespace.clone(),
-            as_std_path(&path1.join("test-file1")).as_path(),
+            &path1.join("test-file1"),
             &Bytes::from("test-data1"),
         )
         .await
@@ -1101,7 +999,7 @@ async fn list_dir_same_prefix(
             "list_dir_same_prefix",
             "put-raw",
             namespace.clone(),
-            as_std_path(&path1.join("test-file2")).as_path(),
+            &path1.join("test-file2"),
             &Bytes::from("test-data2"),
         )
         .await
@@ -1111,17 +1009,12 @@ async fn list_dir_same_prefix(
             "list_dir_same_prefix",
             "create-dir",
             namespace.clone(),
-            as_std_path(&path1.join("inner-dir")).as_path(),
+            &path1.join("inner-dir"),
         )
         .await
         .unwrap();
     let mut entries = storage
-        .list_dir(
-            "list_dir_same_prefix",
-            "entries",
-            namespace.clone(),
-            as_std_path(path1).as_path(),
-        )
+        .list_dir("list_dir_same_prefix", "entries", namespace.clone(), path1)
         .await
         .unwrap();
 
@@ -1136,17 +1029,3 @@ async fn list_dir_same_prefix(
             ]
     );
 }
-
-fn opt_env_var(name: &str) -> Option<String> {
-    std::env::var(name).ok()
-}
-
-fn opt_env_var_bool(name: &str) -> Option<bool> {
-    std::env::var(name)
-        .ok()
-        .and_then(|value| match value.as_str() {
-            "true" => Some(true),
-            "false" => Some(false),
-            _ => None,
-        })
-}
diff --git a/golem-service-base/tests/lib.rs b/golem-service-base/tests/lib.rs
index bf65f56e..43e09187 100644
--- a/golem-service-base/tests/lib.rs
+++ b/golem-service-base/tests/lib.rs
@@ -12,28 +12,6 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use golem_common::tracing::{init_tracing_with_default_debug_env_filter, TracingConfig};
-use test_r::{sequential_suite, test_dep};
-
 pub mod blob_storage;
 
 test_r::enable!();
-
-sequential_suite!(blob_storage);
-
-#[derive(Debug)]
-pub struct Tracing;
-
-impl Tracing {
-    pub fn init() -> Self {
-        init_tracing_with_default_debug_env_filter(
-            &TracingConfig::test_pretty_without_time("service-base-tests").with_env_overrides(),
-        );
-        Self
-    }
-}
-
-#[test_dep]
-fn tracing() -> Tracing {
-    Tracing::init()
-}
diff --git a/golem-shard-manager/src/lib.rs b/golem-shard-manager/src/lib.rs
index a9287f86..fae0f812 100644
--- a/golem-shard-manager/src/lib.rs
+++ b/golem-shard-manager/src/lib.rs
@@ -219,7 +219,7 @@ pub async fn run(
 ) -> anyhow::Result<RunDetails> {
     debug!("Initializing shard manager");
 
-    let (mut health_reporter, health_service) = tonic_health::server::health_reporter();
+    let (health_reporter, health_service) = tonic_health::server::health_reporter();
     health_reporter
         .set_serving::<ShardManagerServiceServer<ShardManagerServiceImpl>>()
         .await;
@@ -241,23 +241,19 @@ pub async fn run(
     let persistence_service: Arc<dyn RoutingTablePersistence + Send + Sync> =
         match &shard_manager_config.persistence {
             PersistenceConfig::Redis(redis) => {
-                info!("Using Redis at {}", redis.url());
                 let pool = golem_common::redis::RedisPool::configured(redis).await?;
                 Arc::new(RoutingTableRedisPersistence::new(
                     &pool,
                     shard_manager_config.number_of_shards,
                 ))
             }
-            PersistenceConfig::FileSystem(fs) => {
-                info!("Using sharding file {:?}", fs.path);
-                Arc::new(
-                    RoutingTableFileSystemPersistence::new(
-                        &fs.path,
-                        shard_manager_config.number_of_shards,
-                    )
-                    .await?,
+            PersistenceConfig::FileSystem(fs) => Arc::new(
+                RoutingTableFileSystemPersistence::new(
+                    &fs.path,
+                    shard_manager_config.number_of_shards,
                 )
-            }
+                .await?,
+            ),
         };
     let worker_executors = Arc::new(WorkerExecutorServiceDefault::new(
         shard_manager_config.worker_executors.clone(),
@@ -294,7 +290,6 @@ pub async fn run(
 
     let shard_manager_port_str =
         env::var("GOLEM_SHARD_MANAGER_PORT").unwrap_or(shard_manager_config.grpc_port.to_string());
-    debug!("The port read from env is {}", shard_manager_port_str);
     let configured_port = shard_manager_port_str.parse::<u16>()?;
     let listener = TcpListener::bind(SocketAddrV4::new(
         Ipv4Addr::new(0, 0, 0, 0),
diff --git a/golem-shard-manager/src/rebalancing.rs b/golem-shard-manager/src/rebalancing.rs
index 1c960202..11b843e1 100644
--- a/golem-shard-manager/src/rebalancing.rs
+++ b/golem-shard-manager/src/rebalancing.rs
@@ -261,6 +261,8 @@ impl Display for Rebalance {
 mod tests {
     use test_r::test;
 
+    use tracing_test::traced_test;
+
     use golem_common::model::ShardId;
 
     use crate::model::{Pod, RoutingTable};
@@ -362,6 +364,7 @@ mod tests {
     }
 
     #[test]
+    #[traced_test]
     fn rebalance_empty_table() {
         let routing_table = new_routing_table(TestConfig {
             number_of_shards: 1000,
@@ -374,6 +377,7 @@ mod tests {
     }
 
     #[test]
+    #[traced_test]
     fn rebalance_single_pod_no_unassigned() {
         let routing_table = new_routing_table(TestConfig {
             number_of_shards: 4,
@@ -386,6 +390,7 @@ mod tests {
     }
 
     #[test]
+    #[traced_test]
     fn rebalance_single_pod_unassigned() {
         let routing_table = new_routing_table(TestConfig {
             number_of_shards: 6,
@@ -400,6 +405,7 @@ mod tests {
     }
 
     #[test]
+    #[traced_test]
     fn rebalance_three_balanced_pods_no_unassigned() {
         let routing_table = new_routing_table(TestConfig {
             number_of_shards: 9,
@@ -417,6 +423,7 @@ mod tests {
     }
 
     #[test]
+    #[traced_test]
     fn rebalance_three_balanced_pods_unassigned() {
         let routing_table = new_routing_table(TestConfig {
             number_of_shards: 9,
@@ -444,6 +451,7 @@ mod tests {
     }
 
     #[test]
+    #[traced_test]
     fn rebalance_one_new_pod() {
         let routing_table = new_routing_table(TestConfig {
             number_of_shards: 9,
@@ -479,6 +487,7 @@ mod tests {
     }
 
     #[test]
+    #[traced_test]
     fn rebalance_one_new_pod_with_threshold() {
         let routing_table = new_routing_table(TestConfig {
             number_of_shards: 9,
@@ -514,6 +523,7 @@ mod tests {
     }
 
     #[test]
+    #[traced_test]
     fn rebalance_one_new_pod_after_removing_two() {
         // 3,4,5 and 9,10,11 are unassigned
         // pod3 is empty
@@ -551,6 +561,7 @@ mod tests {
     }
 
     #[test]
+    #[traced_test]
     fn rebalance_two_new_pods() {
         let routing_table = new_routing_table(TestConfig {
             number_of_shards: 9,
@@ -582,6 +593,7 @@ mod tests {
     }
 
     #[test]
+    #[traced_test]
     fn rebalance_two_new_pods_after_removing_one() {
         // pod1 and pod2 has 4-4 shards because previously we had 3 pods for 12 shards
         // 4,5,6,11 are unassigned
@@ -622,6 +634,7 @@ mod tests {
     }
 
     #[test]
+    #[traced_test]
     fn two_empty_pods_one_filled() {
         // pod2 is empty
         // pod3 is new and empty
@@ -645,6 +658,7 @@ mod tests {
     }
 
     #[test]
+    #[traced_test]
     fn initial_assign_is_ordered_and_no_rebalance_needed() {
         let routing_table = new_routing_table(TestConfig {
             number_of_shards: 8,
@@ -669,6 +683,7 @@ mod tests {
     }
 
     #[test]
+    #[traced_test]
     fn initial_assign_is_ordered_and_no_rebalance_needed_with_less_then_opt() {
         let routing_table = new_routing_table(TestConfig {
             number_of_shards: 14,
@@ -693,6 +708,7 @@ mod tests {
     }
 
     #[test]
+    #[traced_test]
     fn initial_assign_is_ordered_and_no_rebalance_with_some_saturated_pod() {
         let routing_table = new_routing_table(TestConfig {
             number_of_shards: 8,
diff --git a/golem-shard-manager/src/shard_manager_config.rs b/golem-shard-manager/src/shard_manager_config.rs
index ef20e721..61adce0b 100644
--- a/golem-shard-manager/src/shard_manager_config.rs
+++ b/golem-shard-manager/src/shard_manager_config.rs
@@ -17,7 +17,9 @@ use crate::shard_manager_config::HealthCheckMode::K8s;
 use golem_common::config::{ConfigExample, ConfigLoader, HasConfigExamples, RedisConfig};
 use golem_common::model::RetryConfig;
 use golem_common::tracing::TracingConfig;
+use golem_common::SafeDisplay;
 use serde::{Deserialize, Serialize};
+use std::fmt::Write;
 use std::path::{Path, PathBuf};
 use std::time::Duration;
 
@@ -33,6 +35,41 @@ pub struct ShardManagerConfig {
     pub rebalance_threshold: f64,
 }
 
+impl SafeDisplay for ShardManagerConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "tracing:");
+        let _ = writeln!(&mut result, "{}", self.tracing.to_safe_string_indented());
+        let _ = writeln!(&mut result, "persistence:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.persistence.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "worker executors:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.worker_executors.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "healthcheck:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.health_check.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "HTTP port: {}", self.http_port);
+        let _ = writeln!(&mut result, "gRPC port: {}", self.grpc_port);
+        let _ = writeln!(&mut result, "number of shards: {}", self.number_of_shards);
+        let _ = writeln!(
+            &mut result,
+            "rebalance threshold: {}",
+            self.rebalance_threshold
+        );
+        result
+    }
+}
+
 impl Default for ShardManagerConfig {
     fn default() -> Self {
         Self {
@@ -79,6 +116,31 @@ pub struct WorkerExecutorServiceConfig {
     pub connect_timeout: Duration,
 }
 
+impl SafeDisplay for WorkerExecutorServiceConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(
+            &mut result,
+            "assign shards timeout: {:?}",
+            self.assign_shards_timeout
+        );
+        let _ = writeln!(
+            &mut result,
+            "health check timeout: {:?}",
+            self.health_check_timeout
+        );
+        let _ = writeln!(
+            &mut result,
+            "revoke shards timeout: {:?}",
+            self.revoke_shards_timeout
+        );
+        let _ = writeln!(&mut result, "connect timeout: {:?}", self.connect_timeout);
+        let _ = writeln!(&mut result, "retries:");
+        let _ = writeln!(&mut result, "{}", self.retries.to_safe_string_indented());
+        result
+    }
+}
+
 impl Default for WorkerExecutorServiceConfig {
     fn default() -> Self {
         Self {
@@ -99,6 +161,17 @@ pub struct HealthCheckConfig {
     pub silent: bool,
 }
 
+impl SafeDisplay for HealthCheckConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "delay: {:?}", self.delay);
+        let _ = writeln!(&mut result, "mode:");
+        let _ = writeln!(&mut result, "{}", self.mode.to_safe_string_indented());
+        let _ = writeln!(&mut result, "silent: {}", self.silent);
+        result
+    }
+}
+
 impl Default for HealthCheckConfig {
     fn default() -> Self {
         Self {
@@ -117,6 +190,23 @@ pub enum HealthCheckMode {
     K8s(HealthCheckK8sConfig),
 }
 
+impl SafeDisplay for HealthCheckMode {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        match self {
+            HealthCheckMode::Grpc(_) => {
+                let _ = writeln!(&mut result, "gRPC");
+            }
+            #[cfg(feature = "kubernetes")]
+            HealthCheckMode::K8s(inner) => {
+                let _ = writeln!(&mut result, "k8s:");
+                let _ = writeln!(&mut result, "{}", inner.to_safe_string_indented());
+            }
+        }
+        result
+    }
+}
+
 impl Default for HealthCheckMode {
     fn default() -> Self {
         Self::Grpc(Empty {})
@@ -128,6 +218,14 @@ pub struct HealthCheckK8sConfig {
     pub namespace: String,
 }
 
+impl SafeDisplay for HealthCheckK8sConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "namespace: {}", self.namespace);
+        result
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 #[serde(tag = "type", content = "config")]
 pub enum PersistenceConfig {
@@ -135,6 +233,23 @@ pub enum PersistenceConfig {
     FileSystem(FileSystemPersistenceConfig),
 }
 
+impl SafeDisplay for PersistenceConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        match self {
+            PersistenceConfig::Redis(inner) => {
+                let _ = writeln!(&mut result, "redis:");
+                let _ = writeln!(&mut result, "{}", inner.to_safe_string_indented());
+            }
+            PersistenceConfig::FileSystem(inner) => {
+                let _ = writeln!(&mut result, "filesystem:");
+                let _ = writeln!(&mut result, "path: {:?}", inner.path);
+            }
+        }
+        result
+    }
+}
+
 impl Default for PersistenceConfig {
     fn default() -> Self {
         Self::Redis(RedisConfig::default())
@@ -152,17 +267,12 @@ pub fn make_config_loader() -> ConfigLoader<ShardManagerConfig> {
 
 #[cfg(test)]
 mod tests {
-    use std::env;
-    use std::path::PathBuf;
     use test_r::test;
 
     use crate::shard_manager_config::make_config_loader;
 
     #[test]
     pub fn config_is_loadable() {
-        env::set_current_dir(PathBuf::from(env!("CARGO_MANIFEST_DIR")))
-            .expect("Failed to set current directory");
-
-        make_config_loader().load().expect("Failed to load config");
+        let _ = make_config_loader().load().expect("Failed to load config");
     }
 }
diff --git a/golem-test-framework/Cargo.toml b/golem-test-framework/Cargo.toml
index 58b80f03..cf58168b 100644
--- a/golem-test-framework/Cargo.toml
+++ b/golem-test-framework/Cargo.toml
@@ -13,28 +13,28 @@ license-file = "../LICENSE"
 harness = false
 
 [dependencies]
-golem-api-grpc = { path = "../golem-api-grpc", version = "=0.0.0" }
-golem-client = { path = "../golem-client", version = "=0.0.0" }
-golem-common = { path = "../golem-common", version = "=0.0.0" }
-golem-rib = { path = "../golem-rib", version = "=0.0.0" }
-golem-service-base = { path = "../golem-service-base", version = "=0.0.0" }
-golem-wasm-ast = { path = "../wasm-ast", version = "=0.0.0" }
-golem-wasm-rpc = { path = "../wasm-rpc", version = "=0.0.0", default-features = false, features = ["host"] }
+golem-api-grpc = { workspace = true }
+golem-client = { workspace = true }
+golem-common = { workspace = true, default-features = true, features = ["agent-extraction"] }
+golem-rib = { workspace = true, default-features = true }
+golem-service-base = { workspace = true }
+golem-wasm-ast = { workspace = true, default-features = true }
+golem-wasm-rpc = { workspace = true, features = ["host"] }
 
 anyhow = { workspace = true }
-async-dropper = { version = "0.3.1", features = ["simple", "tokio"] }
-async-dropper-simple = { version = "0.2.6", features = ["no-default-bound", "tokio"] }
+async-dropper = { workspace = true, features = ["simple", "tokio"] }
+async-dropper-simple = { workspace = true, features = ["no-default-bound", "tokio"] }
 async-trait = { workspace = true }
 async_zip = { workspace = true, features = ["tokio", "tokio-fs", "deflate"] }
 bytes = { workspace = true }
 chrono = { workspace = true }
 clap = { workspace = true }
 cli-table = { workspace = true }
-colored = "3.0.0"
-futures-util = { workspace = true }
+colored = { workspace = true }
+futures = { workspace = true }
 itertools = { workspace = true }
 k8s-openapi = { workspace = true }
-kill_tree = { version = "0.2.4", features = ["tokio"] }
+kill_tree = { workspace = true, features = ["tokio"] }
 kube = { workspace = true }
 postgres = { workspace = true }
 redis = { workspace = true }
@@ -54,7 +54,7 @@ tracing = { workspace = true }
 tryhard = { workspace = true }
 url = { workspace = true }
 uuid = { workspace = true }
-wasm-metadata = { version = "0.227.1" }
+wasm-metadata = { workspace = true }
 
 [dev-dependencies]
 test-r = { workspace = true }
diff --git a/golem-test-framework/src/components/cloud_service/docker.rs b/golem-test-framework/src/components/cloud_service/docker.rs
index 8fd3d5f2..3888e87f 100644
--- a/golem-test-framework/src/components/cloud_service/docker.rs
+++ b/golem-test-framework/src/components/cloud_service/docker.rs
@@ -200,7 +200,7 @@ impl CloudServiceImage {
 
 impl Image for CloudServiceImage {
     fn name(&self) -> &str {
-        "parvit/cloud-service"
+        "golemservices/cloud-service"
     }
 
     fn tag(&self) -> &str {
diff --git a/golem-test-framework/src/components/cloud_service/mod.rs b/golem-test-framework/src/components/cloud_service/mod.rs
index 5a1f634b..01a62ea4 100644
--- a/golem-test-framework/src/components/cloud_service/mod.rs
+++ b/golem-test-framework/src/components/cloud_service/mod.rs
@@ -29,7 +29,8 @@ pub use golem_api_grpc::proto::golem::auth::v1::cloud_auth_service_client::Cloud
 use golem_api_grpc::proto::golem::auth::v1::{get_account_response, GetAccountRequest};
 pub use golem_api_grpc::proto::golem::project::v1::cloud_project_service_client::CloudProjectServiceClient as ProjectServiceGrpcClient;
 use golem_api_grpc::proto::golem::project::v1::{
-    get_default_project_response, CreateProjectRequest, GetDefaultProjectRequest,
+    get_default_project_response, get_project_response, CreateProjectRequest,
+    GetDefaultProjectRequest, GetProjectRequest,
 };
 pub use golem_api_grpc::proto::golem::token::v1::cloud_token_service_client::CloudTokenServiceClient as TokenServiceGrpcClient;
 use golem_api_grpc::proto::golem::token::v1::CreateTokenRequest;
@@ -180,6 +181,29 @@ pub trait CloudService: Send + Sync {
         }
     }
 
+    async fn get_project_name(&self, project_id: &ProjectId) -> crate::Result<String> {
+        match self.client_protocol() {
+            GolemClientProtocol::Grpc => {
+                let mut client = self.project_grpc_client().await;
+                let request = GetProjectRequest {
+                    project_id: Some(project_id.clone().into()),
+                };
+                let response = client.get_project(request).await?;
+                match response.into_inner().result.unwrap() {
+                    get_project_response::Result::Success(result) => Ok(result
+                        .data
+                        .ok_or_else(|| anyhow!("Missing data field"))?
+                        .name),
+                    get_project_response::Result::Error(error) => Err(anyhow!("{error:?}")),
+                }
+            }
+            GolemClientProtocol::Http => {
+                let client = self.project_http_client(self.admin_token()).await;
+                Ok(client.get_project(&project_id.0).await?.project_data.name)
+            }
+        }
+    }
+
     async fn create_account(
         &self,
         token: &Uuid,
@@ -470,6 +494,7 @@ pub struct AdminOnlyStubCloudService {
     admin_account_id: AccountId,
     admin_token: Uuid,
     admin_default_project: ProjectId,
+    admin_default_project_name: String,
 }
 
 impl AdminOnlyStubCloudService {
@@ -477,39 +502,19 @@ impl AdminOnlyStubCloudService {
         admin_account_id: AccountId,
         admin_token: Uuid,
         admin_default_project: ProjectId,
+        admin_default_project_name: String,
     ) -> Self {
         Self {
             admin_account_id,
             admin_token,
             admin_default_project,
+            admin_default_project_name,
         }
     }
 }
 
 #[async_trait]
 impl CloudService for AdminOnlyStubCloudService {
-    fn admin_token(&self) -> Uuid {
-        self.admin_token
-    }
-
-    fn admin_account_id(&self) -> AccountId {
-        self.admin_account_id.clone()
-    }
-
-    async fn get_default_project(&self, token: &Uuid) -> crate::Result<ProjectId> {
-        if *token != self.admin_token {
-            Err(anyhow!("StubCloudService received unexpected token"))?
-        }
-        Ok(self.admin_default_project.clone())
-    }
-
-    async fn get_account_id(&self, token: &Uuid) -> crate::Result<AccountId> {
-        if *token != self.admin_token {
-            Err(anyhow!("StubCloudService received unexpected token"))?
-        }
-        Ok(self.admin_account_id.clone())
-    }
-
     fn client_protocol(&self) -> GolemClientProtocol {
         panic!("no cloud service running");
     }
@@ -534,6 +539,35 @@ impl CloudService for AdminOnlyStubCloudService {
         panic!("no cloud service running");
     }
 
+    async fn get_account_id(&self, token: &Uuid) -> crate::Result<AccountId> {
+        if *token != self.admin_token {
+            Err(anyhow!("StubCloudService received unexpected token"))?
+        }
+        Ok(self.admin_account_id.clone())
+    }
+
+    async fn get_default_project(&self, token: &Uuid) -> crate::Result<ProjectId> {
+        if *token != self.admin_token {
+            Err(anyhow!("StubCloudService received unexpected token"))?
+        }
+        Ok(self.admin_default_project.clone())
+    }
+
+    async fn get_project_name(&self, project_id: &ProjectId) -> crate::Result<String> {
+        if project_id != &self.admin_default_project {
+            Err(anyhow!("StubCloudService received unexpected project ID"))?
+        }
+        Ok(self.admin_default_project_name.clone())
+    }
+
+    fn admin_token(&self) -> Uuid {
+        self.admin_token
+    }
+
+    fn admin_account_id(&self) -> AccountId {
+        self.admin_account_id.clone()
+    }
+
     fn private_host(&self) -> String {
         panic!("no cloud service running");
     }
diff --git a/golem-test-framework/src/components/component_compilation_service/docker.rs b/golem-test-framework/src/components/component_compilation_service/docker.rs
index fdc16905..25a27841 100644
--- a/golem-test-framework/src/components/component_compilation_service/docker.rs
+++ b/golem-test-framework/src/components/component_compilation_service/docker.rs
@@ -132,7 +132,7 @@ impl GolemComponentCompilationServiceImage {
 
 impl Image for GolemComponentCompilationServiceImage {
     fn name(&self) -> &str {
-        "parvit/golem-component-compilation-service"
+        "golemservices/golem-component-compilation-service"
     }
 
     fn tag(&self) -> &str {
diff --git a/golem-test-framework/src/components/component_compilation_service/mod.rs b/golem-test-framework/src/components/component_compilation_service/mod.rs
index c1c7d9cc..95b22e58 100644
--- a/golem-test-framework/src/components/component_compilation_service/mod.rs
+++ b/golem-test-framework/src/components/component_compilation_service/mod.rs
@@ -28,7 +28,7 @@ use tracing::Level;
 use crate::components::component_service::ComponentService;
 use crate::components::{wait_for_startup_grpc, EnvVarBuilder};
 use golem_api_grpc::proto::golem::componentcompilation::v1::component_compilation_service_client::ComponentCompilationServiceClient;
-use golem_common::model::ComponentId;
+use golem_common::model::{ComponentId, ProjectId};
 
 use super::cloud_service::CloudService;
 
@@ -43,7 +43,12 @@ pub trait ComponentCompilationService: Send + Sync {
         new_client(&self.public_host(), self.public_grpc_port()).await
     }
 
-    async fn enqueue_compilation(&self, component_id: &ComponentId, component_version: u64) {
+    async fn enqueue_compilation(
+        &self,
+        project_id: ProjectId,
+        component_id: &ComponentId,
+        component_version: u64,
+    ) {
         let response = self
             .client()
             .await
@@ -51,6 +56,7 @@ pub trait ComponentCompilationService: Send + Sync {
                 component_id: Some(component_id.clone().into()),
                 component_version,
                 component_service_port: None,
+                project_id: Some(project_id.into()),
             })
             .await
             .expect("Failed to enqueue component compilation")
diff --git a/golem-test-framework/src/components/component_service/docker.rs b/golem-test-framework/src/components/component_service/docker.rs
index 20e8c017..0439c28f 100644
--- a/golem-test-framework/src/components/component_service/docker.rs
+++ b/golem-test-framework/src/components/component_service/docker.rs
@@ -196,7 +196,7 @@ impl GolemComponentServiceImage {
 
 impl Image for GolemComponentServiceImage {
     fn name(&self) -> &str {
-        "parvit/golem-component-service"
+        "golemservices/golem-component-service"
     }
 
     fn tag(&self) -> &str {
diff --git a/golem-test-framework/src/components/component_service/filesystem.rs b/golem-test-framework/src/components/component_service/filesystem.rs
index c50a6704..b516786a 100644
--- a/golem-test-framework/src/components/component_service/filesystem.rs
+++ b/golem-test-framework/src/components/component_service/filesystem.rs
@@ -18,7 +18,9 @@ use crate::components::component_service::{AddComponentError, ComponentService};
 use crate::config::GolemClientProtocol;
 use anyhow::Context;
 use async_trait::async_trait;
+use golem_api_grpc::proto::golem::component::v1::GetLatestComponentRequest;
 use golem_api_grpc::proto::golem::component::{Component, ComponentMetadata, VersionedComponentId};
+use golem_common::model::agent::extraction::extract_agent_types;
 use golem_common::model::component_metadata::DynamicLinkedInstance;
 use golem_common::model::{
     component_metadata::{LinearMemory, RawComponentMetadata},
@@ -123,6 +125,12 @@ impl FileSystemComponentService {
                 })?
         };
 
+        let agent_types = if skip_analysis {
+            vec![]
+        } else {
+            extract_agent_types(&target_path).await.unwrap_or_default()
+        };
+
         let size = tokio::fs::metadata(&target_path)
             .await
             .map_err(|err| {
@@ -144,6 +152,7 @@ impl FileSystemComponentService {
             dynamic_linking: dynamic_linking.clone(),
             wasm_filename,
             env: env.clone(),
+            agent_types,
         };
         write_metadata_to_file(
             metadata,
@@ -171,6 +180,7 @@ impl FileSystemComponentService {
                 binary_wit: raw_component_metadata.binary_wit,
                 root_package_name: raw_component_metadata.root_package_name,
                 root_package_version: raw_component_metadata.root_package_version,
+                agent_types: vec![],
             }),
             account_id: Some(self.account_id.clone().into()),
             project_id: Some(self.default_project_id.clone().into()),
@@ -403,6 +413,18 @@ impl ComponentService for FileSystemComponentService {
         *versions.last().unwrap_or(&0)
     }
 
+    async fn get_latest_component_metadata(
+        &self,
+        token: &Uuid,
+        request: GetLatestComponentRequest,
+    ) -> crate::Result<Component> {
+        let component_id: ComponentId = request.component_id.unwrap().try_into().unwrap();
+        let version = self.get_latest_version(token, &component_id).await;
+        let metadata = self.load_metadata(&component_id, version).await?;
+        let component: golem_service_base::model::Component = metadata.into();
+        Ok(component.into())
+    }
+
     async fn get_component_size(
         &self,
         _token: &Uuid,
diff --git a/golem-test-framework/src/components/component_service/mod.rs b/golem-test-framework/src/components/component_service/mod.rs
index f0ee3e70..c58d1129 100644
--- a/golem-test-framework/src/components/component_service/mod.rs
+++ b/golem-test-framework/src/components/component_service/mod.rs
@@ -27,7 +27,7 @@ use anyhow::{anyhow, Context as AnyhowContext};
 use async_trait::async_trait;
 use async_zip::base::write::ZipFileWriter;
 use async_zip::{Compression, ZipEntryBuilder};
-use futures_util::{stream, StreamExt, TryStreamExt};
+use futures::{stream, StreamExt, TryStreamExt};
 pub use golem_api_grpc::proto::golem::component::v1::component_service_client::ComponentServiceClient as ComponentServiceGrpcClient;
 pub use golem_api_grpc::proto::golem::component::v1::plugin_service_client::PluginServiceClient as PluginServiceGrpcClient;
 use golem_api_grpc::proto::golem::component::v1::{
@@ -512,6 +512,7 @@ pub trait ComponentService: Send + Sync {
                                     .map(|(k, v)| (k.clone(), v.clone().into())),
                             ),
                             env: env.clone(),
+                            agent_types: vec![],
                         },
                     )),
                 }];
@@ -600,6 +601,7 @@ pub trait ComponentService: Send + Sync {
                         Some(&golem_client::model::ComponentEnv {
                             key_values: env.clone(),
                         }),
+                        None,
                     )
                     .await
                 {
@@ -668,6 +670,7 @@ pub trait ComponentService: Send + Sync {
                                     .map(|(k, v)| (k.clone(), v.clone().into())),
                             ),
                             env: env.clone(),
+                            agent_types: vec![],
                         },
                     )),
                 }];
@@ -750,6 +753,7 @@ pub trait ComponentService: Send + Sync {
                         archive_file,
                         to_http_dynamic_linking(dynamic_linking).as_ref(),
                         Some(&component_env),
+                        None,
                     )
                     .await
                 {
diff --git a/golem-test-framework/src/components/k8s.rs b/golem-test-framework/src/components/k8s.rs
index 35fb2131..9ce018ab 100644
--- a/golem-test-framework/src/components/k8s.rs
+++ b/golem-test-framework/src/components/k8s.rs
@@ -123,7 +123,6 @@ impl AsyncDrop for ManagedService {
     }
 }
 
-#[allow(clippy::large_enum_variant)]
 pub enum ManagedRouting {
     Minikube { child: Option<Child> },
     Ingress(ManagedIngress),
diff --git a/golem-test-framework/src/components/mod.rs b/golem-test-framework/src/components/mod.rs
index 2c1092f7..e9d34458 100644
--- a/golem-test-framework/src/components/mod.rs
+++ b/golem-test-framework/src/components/mod.rs
@@ -214,7 +214,7 @@ impl EnvVarBuilder {
                 h2=warn,\
                 hyper=warn,\
                 tower=warn,\
-                fred=warn"
+                fred=error"
             ),
         )
     }
diff --git a/golem-test-framework/src/components/rdb/mod.rs b/golem-test-framework/src/components/rdb/mod.rs
index 0be1153d..0887a492 100644
--- a/golem-test-framework/src/components/rdb/mod.rs
+++ b/golem-test-framework/src/components/rdb/mod.rs
@@ -25,7 +25,6 @@ use tracing::{error, info};
 pub mod docker_mysql;
 pub mod docker_postgres;
 pub mod k8s_postgres;
-pub mod provided_mysql;
 pub mod provided_postgres;
 pub mod sqlite;
 
diff --git a/golem-test-framework/src/components/rdb/provided_postgres.rs b/golem-test-framework/src/components/rdb/provided_postgres.rs
index 3eceb51b..8f5414fd 100644
--- a/golem-test-framework/src/components/rdb/provided_postgres.rs
+++ b/golem-test-framework/src/components/rdb/provided_postgres.rs
@@ -26,23 +26,6 @@ impl ProvidedPostgresRdb {
 
         Self { info }
     }
-
-    pub fn public_connection_string(&self) -> String {
-        self.info.public_connection_string()
-    }
-
-    pub fn public_connection_string_to_db(&self, db_name: &str) -> String {
-        let db_info = PostgresInfo {
-            database_name: db_name.to_string(),
-            ..self.info.clone()
-        };
-
-        db_info.public_connection_string()
-    }
-
-    pub fn private_connection_string(&self) -> String {
-        panic!("Unsupported")
-    }
 }
 
 #[async_trait]
diff --git a/golem-test-framework/src/components/redis/spawned.rs b/golem-test-framework/src/components/redis/spawned.rs
index e90cb09a..31ebfc9f 100644
--- a/golem-test-framework/src/components/redis/spawned.rs
+++ b/golem-test-framework/src/components/redis/spawned.rs
@@ -15,9 +15,10 @@
 use crate::components::redis::Redis;
 use crate::components::ChildProcessLogger;
 use async_trait::async_trait;
-use std::process::Child;
+use std::process::{Child, Command, Stdio};
 use std::sync::atomic::{AtomicBool, Ordering};
 use std::sync::{Arc, Mutex};
+use std::time::Duration;
 use tracing::{info, Level};
 
 pub struct SpawnedRedis {
@@ -38,12 +39,6 @@ impl SpawnedRedis {
         )
     }
 
-    #[cfg(windows)]
-    pub fn new(_port: u16, _prefix: String, _out_level: Level, _err_level: Level) -> Self {
-        panic!("Not supported on windows");
-    }
-
-    #[cfg(not(windows))]
     pub fn new(port: u16, prefix: String, out_level: Level, err_level: Level) -> Self {
         info!("Starting Redis on port {}", port);
 
diff --git a/golem-test-framework/src/components/redis_monitor/mod.rs b/golem-test-framework/src/components/redis_monitor/mod.rs
index e770e451..ff026056 100644
--- a/golem-test-framework/src/components/redis_monitor/mod.rs
+++ b/golem-test-framework/src/components/redis_monitor/mod.rs
@@ -12,8 +12,6 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-pub mod docker;
-
 pub mod spawned;
 
 pub trait RedisMonitor: Send + Sync {
diff --git a/golem-test-framework/src/components/redis_monitor/spawned.rs b/golem-test-framework/src/components/redis_monitor/spawned.rs
index cdda882a..546e5cfc 100644
--- a/golem-test-framework/src/components/redis_monitor/spawned.rs
+++ b/golem-test-framework/src/components/redis_monitor/spawned.rs
@@ -25,11 +25,7 @@ pub struct SpawnedRedisMonitor {
 }
 
 impl SpawnedRedisMonitor {
-    pub fn new(
-        redis: impl AsRef<dyn Redis + Send + Sync + 'static>,
-        out_level: Level,
-        err_level: Level,
-    ) -> Self {
+    pub fn new(redis: impl AsRef<dyn Redis>, out_level: Level, err_level: Level) -> Self {
         info!(
             "Starting Redis monitor on port {}",
             redis.as_ref().public_port()
diff --git a/golem-test-framework/src/components/shard_manager/docker.rs b/golem-test-framework/src/components/shard_manager/docker.rs
index 97c5f6c0..81d1071f 100644
--- a/golem-test-framework/src/components/shard_manager/docker.rs
+++ b/golem-test-framework/src/components/shard_manager/docker.rs
@@ -144,7 +144,7 @@ impl ShardManagerImage {
 
 impl Image for ShardManagerImage {
     fn name(&self) -> &str {
-        "parvit/golem-shard-manager"
+        "golemservices/golem-shard-manager"
     }
 
     fn tag(&self) -> &str {
diff --git a/golem-test-framework/src/components/worker_executor/docker.rs b/golem-test-framework/src/components/worker_executor/docker.rs
index 10db07d8..d6a43dfb 100644
--- a/golem-test-framework/src/components/worker_executor/docker.rs
+++ b/golem-test-framework/src/components/worker_executor/docker.rs
@@ -174,7 +174,7 @@ impl WorkerExecutorImage {
 
 impl Image for WorkerExecutorImage {
     fn name(&self) -> &str {
-        "parvit/golem-worker-executor"
+        "golemservices/golem-worker-executor"
     }
 
     fn tag(&self) -> &str {
diff --git a/golem-test-framework/src/components/worker_service/docker.rs b/golem-test-framework/src/components/worker_service/docker.rs
index 27ceb3ca..f02e6848 100644
--- a/golem-test-framework/src/components/worker_service/docker.rs
+++ b/golem-test-framework/src/components/worker_service/docker.rs
@@ -200,7 +200,7 @@ impl GolemWorkerServiceImage {
 
 impl Image for GolemWorkerServiceImage {
     fn name(&self) -> &str {
-        "parvit/golem-worker-service"
+        "golemservices/golem-worker-service"
     }
 
     fn tag(&self) -> &str {
diff --git a/golem-test-framework/src/components/worker_service/forwarding.rs b/golem-test-framework/src/components/worker_service/forwarding.rs
index a6bdfd19..64d0974e 100644
--- a/golem-test-framework/src/components/worker_service/forwarding.rs
+++ b/golem-test-framework/src/components/worker_service/forwarding.rs
@@ -25,20 +25,19 @@ use golem_api_grpc::proto::golem::common::{Empty, ResourceLimits};
 use golem_api_grpc::proto::golem::worker::v1::{
     revert_worker_response, CancelInvocationRequest, CancelInvocationResponse,
     ConnectWorkerRequest, DeleteWorkerRequest, DeleteWorkerResponse, ForkWorkerRequest,
-    ForkWorkerResponse, GetFileContentsRequest, GetOplogRequest, GetOplogResponse,
-    GetOplogSuccessResponse, GetWorkerMetadataRequest, GetWorkerMetadataResponse,
-    GetWorkersMetadataRequest, GetWorkersMetadataResponse, GetWorkersMetadataSuccessResponse,
-    InterruptWorkerRequest, InterruptWorkerResponse, InvokeAndAwaitJsonRequest,
-    InvokeAndAwaitJsonResponse, InvokeAndAwaitResponse, InvokeAndAwaitTypedResponse,
-    InvokeJsonRequest, InvokeResponse, LaunchNewWorkerRequest, LaunchNewWorkerResponse,
-    LaunchNewWorkerSuccessResponse, ListDirectoryRequest, ListDirectoryResponse,
-    ListDirectorySuccessResponse, ResumeWorkerRequest, ResumeWorkerResponse, RevertWorkerRequest,
+    ForkWorkerResponse, GetFileContentsRequest, GetFileSystemNodeRequest,
+    GetFileSystemNodeResponse, GetOplogRequest, GetOplogResponse, GetOplogSuccessResponse,
+    GetWorkerMetadataRequest, GetWorkerMetadataResponse, GetWorkersMetadataRequest,
+    GetWorkersMetadataResponse, GetWorkersMetadataSuccessResponse, InterruptWorkerRequest,
+    InterruptWorkerResponse, InvokeAndAwaitJsonRequest, InvokeAndAwaitJsonResponse,
+    InvokeAndAwaitResponse, InvokeAndAwaitTypedResponse, InvokeJsonRequest, InvokeResponse,
+    LaunchNewWorkerRequest, LaunchNewWorkerResponse, LaunchNewWorkerSuccessResponse,
+    ListFileSystemNodeResponse, ResumeWorkerRequest, ResumeWorkerResponse, RevertWorkerRequest,
     RevertWorkerResponse, SearchOplogRequest, SearchOplogResponse, SearchOplogSuccessResponse,
     UpdateWorkerRequest, UpdateWorkerResponse, WorkerError,
 };
 use golem_api_grpc::proto::golem::worker::{
-    IdempotencyKey, InvocationContext, InvokeResult, InvokeResultTyped, LogEvent, TargetWorkerId,
-    WorkerId,
+    IdempotencyKey, InvocationContext, InvokeResult, InvokeResultTyped, LogEvent, WorkerId,
 };
 use golem_api_grpc::proto::golem::workerexecutor::v1::CreateWorkerRequest;
 use golem_api_grpc::proto::golem::{worker, workerexecutor};
@@ -104,6 +103,7 @@ impl WorkerService for ForwardingWorkerService {
         request: LaunchNewWorkerRequest,
     ) -> crate::Result<LaunchNewWorkerResponse> {
         let account_id = self.cloud_service.get_account_id(token).await?;
+        let project_id = self.cloud_service.get_default_project(token).await?;
 
         let component_id = (*request
             .component_id
@@ -129,14 +129,17 @@ impl WorkerService for ForwardingWorkerService {
                 .await?
                 .create_worker(CreateWorkerRequest {
                     worker_id: Some(worker_id.clone()),
+                    project_id: Some(project_id.clone().into()),
                     component_version: latest_component_version,
                     args: request.args.clone(),
                     env: request.env.clone(),
+                    wasi_config_vars: request.wasi_config_vars.clone(),
                     account_id: Some(account_id.into()),
                     account_limits: Some(ResourceLimits {
                         available_fuel: i64::MAX,
                         max_memory_per_worker: i64::MAX,
                     }),
+                    ignore_already_existing: request.ignore_already_existing,
                 })
                 .await;
 
@@ -182,6 +185,7 @@ impl WorkerService for ForwardingWorkerService {
     ) -> crate::Result<DeleteWorkerResponse> {
         let mut retry_count = Self::RETRY_COUNT;
         let account_id = self.cloud_service.get_account_id(token).await?;
+        let project_id = self.cloud_service.get_default_project(token).await?;
         let result = loop {
             let account_id = account_id.clone();
             let result = self
@@ -191,6 +195,7 @@ impl WorkerService for ForwardingWorkerService {
                 .delete_worker(workerexecutor::v1::DeleteWorkerRequest {
                     worker_id: request.worker_id.clone(),
                     account_id: Some(account_id.into()),
+                    project_id: Some(project_id.clone().into()),
                 })
                 .await;
 
@@ -232,9 +237,8 @@ impl WorkerService for ForwardingWorkerService {
         request: GetWorkerMetadataRequest,
     ) -> crate::Result<GetWorkerMetadataResponse> {
         let mut retry_count = Self::RETRY_COUNT;
-        let account_id = self.cloud_service.get_account_id(token).await?;
+        let project_id = self.cloud_service.get_default_project(token).await?;
         let result = loop {
-            let account_id = account_id.clone();
             let result = self
                 .worker_executor
                 .client()
@@ -246,7 +250,7 @@ impl WorkerService for ForwardingWorkerService {
                             .clone()
                             .ok_or(anyhow!("Worker ID is required"))?,
                     ),
-                    account_id: Some(account_id.into()),
+                    project_id: Some(project_id.clone().into()),
                 })
                 .await;
 
@@ -289,6 +293,7 @@ impl WorkerService for ForwardingWorkerService {
     ) -> crate::Result<GetWorkersMetadataResponse> {
         let mut retry_count = Self::RETRY_COUNT;
         let account_id = self.cloud_service.get_account_id(token).await?;
+        let project_id = self.cloud_service.get_default_project(token).await?;
         let result = loop {
             let account_id = account_id.clone();
             let result = self
@@ -302,6 +307,7 @@ impl WorkerService for ForwardingWorkerService {
                     count: request.count,
                     precise: request.precise,
                     account_id: Some(account_id.into()),
+                    project_id: Some(project_id.clone().into()),
                 })
                 .await;
 
@@ -343,7 +349,7 @@ impl WorkerService for ForwardingWorkerService {
     async fn invoke(
         &self,
         token: &Uuid,
-        worker_id: TargetWorkerId,
+        worker_id: WorkerId,
         idempotency_key: Option<IdempotencyKey>,
         function: String,
         invoke_parameters: Vec<ValueAndType>,
@@ -351,6 +357,7 @@ impl WorkerService for ForwardingWorkerService {
     ) -> crate::Result<InvokeResponse> {
         let mut retry_count = Self::RETRY_COUNT;
         let account_id = self.cloud_service.get_account_id(token).await?;
+        let project_id = self.cloud_service.get_default_project(token).await?;
         let result = loop {
             let account_id = account_id.clone();
 
@@ -360,6 +367,7 @@ impl WorkerService for ForwardingWorkerService {
                 .await?
                 .invoke_worker(workerexecutor::v1::InvokeWorkerRequest {
                     worker_id: Some(worker_id.clone()),
+                    project_id: Some(project_id.clone().into()),
                     idempotency_key: idempotency_key.clone(),
                     name: function.clone(),
                     input: invoke_parameters
@@ -415,7 +423,7 @@ impl WorkerService for ForwardingWorkerService {
     async fn invoke_and_await(
         &self,
         token: &Uuid,
-        worker_id: TargetWorkerId,
+        worker_id: WorkerId,
         idempotency_key: Option<IdempotencyKey>,
         function: String,
         invoke_parameters: Vec<ValueAndType>,
@@ -423,6 +431,7 @@ impl WorkerService for ForwardingWorkerService {
     ) -> crate::Result<InvokeAndAwaitResponse> {
         let mut retry_count = Self::RETRY_COUNT;
         let account_id = self.cloud_service.get_account_id(token).await?;
+        let project_id = self.cloud_service.get_default_project(token).await?;
         let result = loop {
             let account_id = account_id.clone();
             let result = self
@@ -431,6 +440,7 @@ impl WorkerService for ForwardingWorkerService {
                 .await?
                 .invoke_and_await_worker(workerexecutor::v1::InvokeAndAwaitWorkerRequest {
                     worker_id: Some(worker_id.clone()),
+                    project_id: Some(project_id.clone().into()),
                     idempotency_key: idempotency_key.clone(),
                     name: function.clone(),
                     input: invoke_parameters
@@ -484,7 +494,7 @@ impl WorkerService for ForwardingWorkerService {
     async fn invoke_and_await_typed(
         &self,
         token: &Uuid,
-        worker_id: TargetWorkerId,
+        worker_id: WorkerId,
         idempotency_key: Option<IdempotencyKey>,
         function: String,
         invoke_parameters: Vec<ValueAndType>,
@@ -492,6 +502,7 @@ impl WorkerService for ForwardingWorkerService {
     ) -> crate::Result<InvokeAndAwaitTypedResponse> {
         let mut retry_count = Self::RETRY_COUNT;
         let account_id = self.cloud_service.get_account_id(token).await?;
+        let project_id = self.cloud_service.get_default_project(token).await?;
         let result = loop {
             let account_id = account_id.clone();
             let result = self
@@ -500,6 +511,7 @@ impl WorkerService for ForwardingWorkerService {
                 .await?
                 .invoke_and_await_worker_typed(workerexecutor::v1::InvokeAndAwaitWorkerRequest {
                     worker_id: Some(worker_id.clone()),
+                    project_id: Some(project_id.clone().into()),
                     idempotency_key: idempotency_key.clone(),
                     name: function.clone(),
                     input: invoke_parameters
@@ -567,6 +579,7 @@ impl WorkerService for ForwardingWorkerService {
     ) -> crate::Result<Box<dyn WorkerLogEventStream>> {
         let mut retry_count = Self::RETRY_COUNT;
         let account_id = self.cloud_service.get_account_id(token).await?;
+        let project_id = self.cloud_service.get_default_project(token).await?;
         let result = loop {
             let account_id = account_id.clone();
             let result = self
@@ -575,6 +588,7 @@ impl WorkerService for ForwardingWorkerService {
                 .await?
                 .connect_worker(workerexecutor::v1::ConnectWorkerRequest {
                     worker_id: request.worker_id.clone(),
+                    project_id: Some(project_id.clone().into()),
                     account_id: Some(account_id.into()),
                     account_limits: Some(ResourceLimits {
                         available_fuel: i64::MAX,
@@ -604,6 +618,7 @@ impl WorkerService for ForwardingWorkerService {
     ) -> crate::Result<ResumeWorkerResponse> {
         let mut retry_count = Self::RETRY_COUNT;
         let account_id = self.cloud_service.get_account_id(token).await?;
+        let project_id = self.cloud_service.get_default_project(token).await?;
         let result = loop {
             let account_id = account_id.clone();
             let result = self
@@ -613,6 +628,7 @@ impl WorkerService for ForwardingWorkerService {
                 .resume_worker(workerexecutor::v1::ResumeWorkerRequest {
                     worker_id: request.worker_id.clone(),
                     account_id: Some(account_id.into()),
+                    project_id: Some(project_id.clone().into()),
                     force: request.force,
                 })
                 .await;
@@ -656,6 +672,7 @@ impl WorkerService for ForwardingWorkerService {
     ) -> crate::Result<InterruptWorkerResponse> {
         let mut retry_count = Self::RETRY_COUNT;
         let account_id = self.cloud_service.get_account_id(token).await?;
+        let project_id = self.cloud_service.get_default_project(token).await?;
         let result = loop {
             let account_id = account_id.clone();
             let result = self
@@ -666,6 +683,7 @@ impl WorkerService for ForwardingWorkerService {
                     worker_id: request.worker_id.clone(),
                     recover_immediately: request.recover_immediately,
                     account_id: Some(account_id.into()),
+                    project_id: Some(project_id.clone().into()),
                 })
                 .await;
 
@@ -708,6 +726,7 @@ impl WorkerService for ForwardingWorkerService {
     ) -> crate::Result<UpdateWorkerResponse> {
         let mut retry_count = Self::RETRY_COUNT;
         let account_id = self.cloud_service.get_account_id(token).await?;
+        let project_id = self.cloud_service.get_default_project(token).await?;
         let result = loop {
             let account_id = account_id.clone();
             let result = self
@@ -719,6 +738,7 @@ impl WorkerService for ForwardingWorkerService {
                     target_version: request.target_version,
                     mode: request.mode,
                     account_id: Some(account_id.into()),
+                    project_id: Some(project_id.clone().into()),
                 })
                 .await;
 
@@ -760,16 +780,15 @@ impl WorkerService for ForwardingWorkerService {
         request: GetOplogRequest,
     ) -> crate::Result<GetOplogResponse> {
         let mut retry_count = Self::RETRY_COUNT;
-        let account_id = self.cloud_service.get_account_id(token).await?;
+        let project_id = self.cloud_service.get_default_project(token).await?;
         let result = loop {
-            let account_id = account_id.clone();
             let result = self
                 .worker_executor
                 .client()
                 .await?
                 .get_oplog(workerexecutor::v1::GetOplogRequest {
                     worker_id: request.worker_id.clone(),
-                    account_id: Some(account_id.into()),
+                    project_id: Some(project_id.clone().into()),
                     from_oplog_index: request.from_oplog_index,
                     cursor: request.cursor,
                     count: request.count,
@@ -816,14 +835,14 @@ impl WorkerService for ForwardingWorkerService {
         token: &Uuid,
         request: SearchOplogRequest,
     ) -> crate::Result<SearchOplogResponse> {
-        let account_id = self.cloud_service.get_account_id(token).await?;
+        let project_id = self.cloud_service.get_default_project(token).await?;
         let result = self
             .worker_executor
             .client()
             .await?
             .search_oplog(workerexecutor::v1::SearchOplogRequest {
                 worker_id: request.worker_id,
-                account_id: Some(account_id.into()),
+                project_id: Some(project_id.into()),
                 query: request.query,
                 cursor: request.cursor,
                 count: request.count,
@@ -858,19 +877,21 @@ impl WorkerService for ForwardingWorkerService {
         }
     }
 
-    async fn list_directory(
+    async fn get_file_system_node(
         &self,
         token: &Uuid,
-        request: ListDirectoryRequest,
-    ) -> crate::Result<ListDirectoryResponse> {
+        request: GetFileSystemNodeRequest,
+    ) -> crate::Result<GetFileSystemNodeResponse> {
         let account_id = self.cloud_service.get_account_id(token).await?;
+        let project_id = self.cloud_service.get_default_project(token).await?;
         let result = self
             .worker_executor
             .client()
             .await?
-            .list_directory(workerexecutor::v1::ListDirectoryRequest {
+            .get_file_system_node(workerexecutor::v1::GetFileSystemNodeRequest {
                 worker_id: request.worker_id,
                 account_id: Some(account_id.into()),
+                project_id: Some(project_id.into()),
                 account_limits: Some(ResourceLimits {
                     available_fuel: i64::MAX,
                     max_memory_per_worker: i64::MAX,
@@ -884,22 +905,31 @@ impl WorkerService for ForwardingWorkerService {
             None => Err(anyhow!(
                 "No response from golem-worker-executor list-directory call"
             )),
-            Some(workerexecutor::v1::list_directory_response::Result::Success(data)) => {
-                Ok(ListDirectoryResponse {
-                    result: Some(worker::v1::list_directory_response::Result::Success(
-                        ListDirectorySuccessResponse { nodes: data.nodes },
+            Some(workerexecutor::v1::get_file_system_node_response::Result::DirSuccess(data)) => {
+                Ok(GetFileSystemNodeResponse {
+                    result: Some(worker::v1::get_file_system_node_response::Result::Success(
+                        ListFileSystemNodeResponse { nodes: data.nodes },
                     )),
                 })
             }
-            Some(workerexecutor::v1::list_directory_response::Result::Failure(error)) => {
-                Ok(ListDirectoryResponse {
-                    result: Some(worker::v1::list_directory_response::Result::Error(
+            Some(workerexecutor::v1::get_file_system_node_response::Result::Failure(error)) => {
+                Ok(GetFileSystemNodeResponse {
+                    result: Some(worker::v1::get_file_system_node_response::Result::Error(
                         WorkerError {
                             error: Some(worker::v1::worker_error::Error::InternalError(error)),
                         },
                     )),
                 })
             }
+            Some(workerexecutor::v1::get_file_system_node_response::Result::FileSuccess(data)) => {
+                Ok(GetFileSystemNodeResponse {
+                    result: Some(worker::v1::get_file_system_node_response::Result::Success(
+                        ListFileSystemNodeResponse {
+                            nodes: vec![data.file.expect("File data should be present")],
+                        },
+                    )),
+                })
+            }
             Some(_) => Err(anyhow!(
                 "Unsupported response from golem-worker-executor list-directory call"
             )),
@@ -912,6 +942,7 @@ impl WorkerService for ForwardingWorkerService {
         request: GetFileContentsRequest,
     ) -> crate::Result<Bytes> {
         let account_id = self.cloud_service.get_account_id(token).await?;
+        let project_id = self.cloud_service.get_default_project(token).await?;
         let mut stream = self
             .worker_executor
             .client()
@@ -919,6 +950,7 @@ impl WorkerService for ForwardingWorkerService {
             .get_file_contents(workerexecutor::v1::GetFileContentsRequest {
                 worker_id: request.worker_id,
                 account_id: Some(account_id.into()),
+                project_id: Some(project_id.into()),
                 account_limits: Some(ResourceLimits {
                     available_fuel: i64::MAX,
                     max_memory_per_worker: i64::MAX,
@@ -964,6 +996,7 @@ impl WorkerService for ForwardingWorkerService {
     ) -> crate::Result<ForkWorkerResponse> {
         let mut retry_count = Self::RETRY_COUNT;
         let account_id = self.cloud_service.get_account_id(token).await?;
+        let project_id = self.cloud_service.get_default_project(token).await?;
         let result = loop {
             let account_id = account_id.clone();
             let result = self
@@ -974,6 +1007,7 @@ impl WorkerService for ForwardingWorkerService {
                     source_worker_id: fork_worker_request.source_worker_id.clone(),
                     target_worker_id: fork_worker_request.target_worker_id.clone(),
                     account_id: Some(account_id.into()),
+                    project_id: Some(project_id.clone().into()),
                     oplog_index_cutoff: fork_worker_request.oplog_index_cutoff,
                 })
                 .await;
@@ -1014,6 +1048,7 @@ impl WorkerService for ForwardingWorkerService {
         request: RevertWorkerRequest,
     ) -> crate::Result<RevertWorkerResponse> {
         let account_id = self.cloud_service.get_account_id(token).await?;
+        let project_id = self.cloud_service.get_default_project(token).await?;
         let result = self
             .worker_executor
             .client()
@@ -1021,6 +1056,7 @@ impl WorkerService for ForwardingWorkerService {
             .revert_worker(workerexecutor::v1::RevertWorkerRequest {
                 worker_id: request.worker_id.clone(),
                 account_id: Some(account_id.into()),
+                project_id: Some(project_id.clone().into()),
                 target: request.target,
             })
             .await;
@@ -1052,6 +1088,7 @@ impl WorkerService for ForwardingWorkerService {
         request: CancelInvocationRequest,
     ) -> crate::Result<CancelInvocationResponse> {
         let account_id = self.cloud_service.get_account_id(token).await?;
+        let project_id = self.cloud_service.get_default_project(token).await?;
         let result = self
             .worker_executor
             .client()
@@ -1060,6 +1097,7 @@ impl WorkerService for ForwardingWorkerService {
                 worker_id: request.worker_id.clone(),
                 idempotency_key: request.idempotency_key.clone(),
                 account_id: Some(account_id.into()),
+                project_id: Some(project_id.clone().into()),
             })
             .await;
 
diff --git a/golem-test-framework/src/components/worker_service/mod.rs b/golem-test-framework/src/components/worker_service/mod.rs
index 1015d36a..4228f6a5 100644
--- a/golem-test-framework/src/components/worker_service/mod.rs
+++ b/golem-test-framework/src/components/worker_service/mod.rs
@@ -27,53 +27,40 @@ use crate::config::GolemClientProtocol;
 use anyhow::{anyhow, Context as AnyhowContext};
 use async_trait::async_trait;
 use bytes::Bytes;
-use futures_util::future::join_all;
-use futures_util::stream::SplitStream;
-use futures_util::{SinkExt, StreamExt};
-use golem_api_grpc::proto::golem::apidefinition::api_definition::Definition;
-use golem_api_grpc::proto::golem::apidefinition::v1::{
-    api_definition_request, create_api_definition_request, update_api_definition_request,
-    ApiDefinitionRequest, CreateApiDefinitionRequest, DeleteApiDefinitionRequest,
-    GetApiDefinitionRequest, GetApiDefinitionVersionsRequest, UpdateApiDefinitionRequest,
-};
-use golem_api_grpc::proto::golem::apidefinition::{
-    static_binding, ApiDefinition, ApiDefinitionId, CorsPreflight, GatewayBinding,
-    GatewayBindingType, HttpApiDefinition, HttpMethod, HttpRoute, StaticBinding,
-};
+use futures::stream::SplitStream;
+use futures::{SinkExt, StreamExt};
 use golem_api_grpc::proto::golem::common::{
     AccountId, Empty, FilterComparator, PluginInstallationId, StringFilterComparator,
 };
-use golem_api_grpc::proto::golem::component as grpc_components;
 use golem_api_grpc::proto::golem::component::ComponentFilePermissions;
-use golem_api_grpc::proto::golem::rib::Expr;
 pub use golem_api_grpc::proto::golem::worker::v1::worker_service_client::WorkerServiceClient as WorkerServiceGrpcClient;
 use golem_api_grpc::proto::golem::worker::v1::{
     cancel_invocation_response, delete_worker_response, get_file_contents_response,
-    get_oplog_response, get_worker_metadata_response, get_workers_metadata_response,
-    interrupt_worker_response, invoke_and_await_json_response, invoke_and_await_response,
-    invoke_and_await_typed_response, invoke_response, launch_new_worker_response,
-    list_directory_response, resume_worker_response, revert_worker_response, search_oplog_response,
-    update_worker_response, CancelInvocationRequest, CancelInvocationResponse,
-    ConnectWorkerRequest, DeleteWorkerRequest, DeleteWorkerResponse, ForkWorkerRequest,
-    ForkWorkerResponse, GetFileContentsRequest, GetOplogRequest, GetOplogResponse,
-    GetOplogSuccessResponse, GetWorkerMetadataRequest, GetWorkerMetadataResponse,
-    GetWorkersMetadataRequest, GetWorkersMetadataResponse, GetWorkersMetadataSuccessResponse,
-    InterruptWorkerRequest, InterruptWorkerResponse, InvokeAndAwaitJsonRequest,
-    InvokeAndAwaitJsonResponse, InvokeAndAwaitRequest, InvokeAndAwaitResponse,
-    InvokeAndAwaitTypedResponse, InvokeJsonRequest, InvokeRequest, InvokeResponse,
-    LaunchNewWorkerRequest, LaunchNewWorkerResponse, LaunchNewWorkerSuccessResponse,
-    ListDirectoryRequest, ListDirectoryResponse, ListDirectorySuccessResponse, ResumeWorkerRequest,
+    get_file_system_node_response, get_oplog_response, get_worker_metadata_response,
+    get_workers_metadata_response, interrupt_worker_response, invoke_and_await_json_response,
+    invoke_and_await_response, invoke_and_await_typed_response, invoke_response,
+    launch_new_worker_response, resume_worker_response, revert_worker_response,
+    search_oplog_response, update_worker_response, CancelInvocationRequest,
+    CancelInvocationResponse, ConnectWorkerRequest, DeleteWorkerRequest, DeleteWorkerResponse,
+    ForkWorkerRequest, ForkWorkerResponse, GetFileContentsRequest, GetFileSystemNodeRequest,
+    GetFileSystemNodeResponse, GetOplogRequest, GetOplogResponse, GetOplogSuccessResponse,
+    GetWorkerMetadataRequest, GetWorkerMetadataResponse, GetWorkersMetadataRequest,
+    GetWorkersMetadataResponse, GetWorkersMetadataSuccessResponse, InterruptWorkerRequest,
+    InterruptWorkerResponse, InvokeAndAwaitJsonRequest, InvokeAndAwaitJsonResponse,
+    InvokeAndAwaitRequest, InvokeAndAwaitResponse, InvokeAndAwaitTypedResponse, InvokeJsonRequest,
+    InvokeRequest, InvokeResponse, LaunchNewWorkerRequest, LaunchNewWorkerResponse,
+    LaunchNewWorkerSuccessResponse, ListFileSystemNodeResponse, ResumeWorkerRequest,
     ResumeWorkerResponse, RevertWorkerRequest, RevertWorkerResponse, SearchOplogRequest,
     SearchOplogResponse, SearchOplogSuccessResponse, UpdateWorkerRequest, UpdateWorkerResponse,
 };
 use golem_api_grpc::proto::golem::worker::worker_filter::Filter;
 use golem_api_grpc::proto::golem::worker::{
     file_system_node, update_record, Cursor, DirectoryFileSystemNode, FailedUpdate,
-    FileFileSystemNode, FileSystemNode, IdempotencyKey, IndexedResourceMetadata, InvocationContext,
-    InvokeParameters, InvokeResult, InvokeResultTyped, LogEvent, OplogCursor, OplogEntry,
-    OplogEntryWithIndex, PendingUpdate, ResourceMetadata, SuccessfulUpdate, TargetWorkerId,
-    UpdateMode, UpdateRecord, WorkerCreatedAtFilter, WorkerEnvFilter, WorkerMetadata,
-    WorkerNameFilter, WorkerStatusFilter, WorkerVersionFilter,
+    FileFileSystemNode, FileSystemNode, IdempotencyKey, InvocationContext, InvokeParameters,
+    InvokeResult, InvokeResultTyped, LogEvent, OplogCursor, OplogEntry, OplogEntryWithIndex,
+    PendingUpdate, SuccessfulUpdate, UpdateMode, UpdateRecord, WorkerCreatedAtFilter,
+    WorkerEnvFilter, WorkerId, WorkerMetadata, WorkerNameFilter, WorkerStatusFilter,
+    WorkerVersionFilter, WorkerWasiConfigVarsFilter,
 };
 use golem_client::api::ApiDefinitionClient as ApiDefinitionServiceHttpClient;
 use golem_client::api::ApiDefinitionClientLive as ApiDefinitionServiceHttpClientLive;
@@ -84,16 +71,16 @@ use golem_client::api::ApiSecurityClientLive as ApiSecurityServiceHttpClientLive
 use golem_client::api::WorkerClient as WorkerServiceHttpClient;
 use golem_client::api::WorkerClientLive as WorkerServiceHttpClientLive;
 use golem_client::model::{
-    ApiDeployment, ApiDeploymentRequest, GatewayBindingComponent, SecuritySchemeData,
+    ApiDeployment, ApiDeploymentRequest, HttpApiDefinitionRequest, HttpApiDefinitionResponseData,
+    OpenApiHttpApiDefinitionResponse, SecuritySchemeData,
 };
 use golem_client::{Context, Security};
+use golem_common::model::worker::WasiConfigVars;
 use golem_common::model::ProjectId;
 use golem_common::model::WorkerEvent;
 use golem_service_base::clients::authorised_request;
-use golem_wasm_rpc::protobuf::TypeAnnotatedValue;
 use golem_wasm_rpc::{Value, ValueAndType};
 use std::collections::HashMap;
-use std::future::Future;
 use std::sync::Arc;
 use std::time::{Duration, SystemTime};
 use tokio::net::TcpStream;
@@ -185,6 +172,10 @@ pub trait WorkerService: Send + Sync {
                             name: request.name,
                             args: request.args,
                             env: request.env,
+                            wasi_config_vars: request
+                                .wasi_config_vars
+                                .expect("no wasi_config_vars field")
+                                .into(),
                         },
                     )
                     .await?;
@@ -327,7 +318,7 @@ pub trait WorkerService: Send + Sync {
     async fn invoke(
         &self,
         token: &Uuid,
-        worker_id: TargetWorkerId,
+        worker_id: WorkerId,
         idempotency_key: Option<IdempotencyKey>,
         function: String,
         invoke_parameters: Vec<ValueAndType>,
@@ -356,7 +347,7 @@ pub trait WorkerService: Send + Sync {
                 client
                     .invoke_function(
                         &worker_id.component_id.unwrap().value.unwrap().into(),
-                        &worker_id.name.unwrap(),
+                        &worker_id.name,
                         idempotency_key.map(|key| key.value).as_deref(),
                         &function,
                         &invoke_parameters_to_http(invoke_parameters),
@@ -394,7 +385,7 @@ pub trait WorkerService: Send + Sync {
                             .value
                             .unwrap()
                             .into(),
-                        &request.worker_id.unwrap().name.unwrap(),
+                        &request.worker_id.unwrap().name,
                         request.idempotency_key.map(|key| key.value).as_deref(),
                         &request.function,
                         &invoke_json_parameters_to_http(request.invoke_parameters),
@@ -410,7 +401,7 @@ pub trait WorkerService: Send + Sync {
     async fn invoke_and_await(
         &self,
         token: &Uuid,
-        worker_id: TargetWorkerId,
+        worker_id: WorkerId,
         idempotency_key: Option<IdempotencyKey>,
         function: String,
         invoke_parameters: Vec<ValueAndType>,
@@ -438,7 +429,7 @@ pub trait WorkerService: Send + Sync {
                 let result = client
                     .invoke_and_await_function(
                         &worker_id.component_id.unwrap().value.unwrap().into(),
-                        &worker_id.name.unwrap(),
+                        &worker_id.name,
                         idempotency_key.map(|key| key.value).as_deref(),
                         &function,
                         &invoke_parameters_to_http(invoke_parameters),
@@ -448,7 +439,7 @@ pub trait WorkerService: Send + Sync {
                 Ok(InvokeAndAwaitResponse {
                     result: Some(invoke_and_await_response::Result::Success(InvokeResult {
                         result: result.result.map(|result| {
-                            let value: Value = result.try_into().unwrap();
+                            let value: Value = result.into();
                             value.into()
                         }),
                     })),
@@ -460,7 +451,7 @@ pub trait WorkerService: Send + Sync {
     async fn invoke_and_await_typed(
         &self,
         token: &Uuid,
-        worker_id: TargetWorkerId,
+        worker_id: WorkerId,
         idempotency_key: Option<IdempotencyKey>,
         function: String,
         invoke_parameters: Vec<ValueAndType>,
@@ -487,7 +478,7 @@ pub trait WorkerService: Send + Sync {
                 let result = client
                     .invoke_and_await_function(
                         &worker_id.component_id.unwrap().value.unwrap().into(),
-                        &worker_id.name.unwrap(),
+                        &worker_id.name,
                         idempotency_key.map(|key| key.value).as_deref(),
                         &function,
                         &invoke_parameters_to_http(invoke_parameters),
@@ -497,9 +488,7 @@ pub trait WorkerService: Send + Sync {
                 Ok(InvokeAndAwaitTypedResponse {
                     result: Some(invoke_and_await_typed_response::Result::Success(
                         InvokeResultTyped {
-                            result: Some(TypeAnnotatedValue {
-                                type_annotated_value: result.result,
-                            }),
+                            result: result.result.map(|vnt| vnt.into()),
                         },
                     )),
                 })
@@ -531,7 +520,7 @@ pub trait WorkerService: Send + Sync {
                             .value
                             .unwrap()
                             .into(),
-                        &request.worker_id.unwrap().name.unwrap(),
+                        &request.worker_id.unwrap().name,
                         request.idempotency_key.map(|key| key.value).as_deref(),
                         &request.function,
                         &invoke_json_parameters_to_http(request.invoke_parameters),
@@ -805,16 +794,16 @@ pub trait WorkerService: Send + Sync {
         }
     }
 
-    async fn list_directory(
+    async fn get_file_system_node(
         &self,
         token: &Uuid,
-        request: ListDirectoryRequest,
-    ) -> crate::Result<ListDirectoryResponse> {
+        request: GetFileSystemNodeRequest,
+    ) -> crate::Result<GetFileSystemNodeResponse> {
         match self.client_protocol() {
             GolemClientProtocol::Grpc => {
                 let mut client = self.worker_grpc_client().await;
                 let request = authorised_request(request, token);
-                Ok(client.list_directory(request).await?.into_inner())
+                Ok(client.get_file_system_node(request).await?.into_inner())
             }
             GolemClientProtocol::Http => {
                 let client = self.worker_http_client(token).await;
@@ -830,14 +819,14 @@ pub trait WorkerService: Send + Sync {
                             .value
                             .unwrap()
                             .into(),
-                        &request.worker_id.unwrap().name.unwrap(),
+                        &request.worker_id.unwrap().name,
                         &request.path,
                     )
                     .await?;
 
-                Ok(ListDirectoryResponse {
-                    result: Some(list_directory_response::Result::Success(
-                        ListDirectorySuccessResponse {
+                Ok(GetFileSystemNodeResponse {
+                    result: Some(get_file_system_node_response::Result::Success(
+                        ListFileSystemNodeResponse {
                             nodes: result.nodes.into_iter().map(|node|
                                 FileSystemNode {
                                     value: Some(
@@ -914,7 +903,7 @@ pub trait WorkerService: Send + Sync {
                             .value
                             .unwrap()
                             .into(),
-                        &request.worker_id.unwrap().name.unwrap(),
+                        &request.worker_id.unwrap().name,
                         &request.file_path,
                     )
                     .await?;
@@ -1032,49 +1021,58 @@ pub trait WorkerService: Send + Sync {
         &self,
         token: &Uuid,
         project_id: &ProjectId,
-        request: CreateApiDefinitionRequest,
-    ) -> crate::Result<ApiDefinition> {
+        request: &HttpApiDefinitionRequest,
+    ) -> crate::Result<HttpApiDefinitionResponseData> {
         match self.client_protocol() {
             GolemClientProtocol::Grpc => not_available_on_grpc_api("create_api_definition"),
             GolemClientProtocol::Http => {
                 let client = self.api_definition_http_client(token).await;
 
-                match request.api_definition.unwrap() {
-                    create_api_definition_request::ApiDefinition::Definition(request) => {
-                        match client
-                            .create_definition_json(
-                                &project_id.0,
-                                &grpc_api_definition_request_to_http(
-                                    token,
-                                    request,
-                                    self.component_service(),
-                                )
-                                .await,
-                            )
-                            .await
-                        {
-                            Ok(result) => Ok(http_api_definition_to_grpc(
-                                token,
-                                result,
-                                self.component_service(),
-                            )
-                            .await),
-                            Err(error) => Err(anyhow!("{error:?}")),
-                        }
-                    }
-                    create_api_definition_request::ApiDefinition::Openapi(open_api) => match client
-                        .import_open_api_yaml(&project_id.0, &serde_yaml::from_str(&open_api)?)
-                        .await
-                    {
-                        Ok(result) => Ok(http_api_definition_to_grpc(
-                            token,
-                            result,
-                            self.component_service(),
-                        )
-                        .await),
-                        Err(error) => Err(anyhow!("{error:?}")),
-                    },
-                }
+                let result = client
+                    .create_definition_json(&project_id.0, request)
+                    .await?;
+
+                Ok(result)
+            }
+        }
+    }
+
+    async fn create_api_definition_from_yaml(
+        &self,
+        token: &Uuid,
+        project_id: &ProjectId,
+        open_api_yaml: &str,
+    ) -> crate::Result<HttpApiDefinitionResponseData> {
+        match self.client_protocol() {
+            GolemClientProtocol::Grpc => not_available_on_grpc_api("create_api_definition"),
+            GolemClientProtocol::Http => {
+                let client = self.api_definition_http_client(token).await;
+
+                let result = client
+                    .import_open_api_yaml(&project_id.0, &serde_yaml::from_str(open_api_yaml)?)
+                    .await?;
+
+                Ok(result)
+            }
+        }
+    }
+
+    async fn create_api_definition_from_json(
+        &self,
+        token: &Uuid,
+        project_id: &ProjectId,
+        open_api_json: &str,
+    ) -> crate::Result<HttpApiDefinitionResponseData> {
+        match self.client_protocol() {
+            GolemClientProtocol::Grpc => not_available_on_grpc_api("create_api_definition"),
+            GolemClientProtocol::Http => {
+                let client = self.api_definition_http_client(token).await;
+
+                let result = client
+                    .import_open_api_json(&project_id.0, &serde_json::from_str(open_api_json)?)
+                    .await?;
+
+                Ok(result)
             }
         }
     }
@@ -1083,47 +1081,18 @@ pub trait WorkerService: Send + Sync {
         &self,
         token: &Uuid,
         project_id: &ProjectId,
-        request: UpdateApiDefinitionRequest,
-    ) -> crate::Result<ApiDefinition> {
+        request: &HttpApiDefinitionRequest,
+    ) -> crate::Result<HttpApiDefinitionResponseData> {
         match self.client_protocol() {
             GolemClientProtocol::Grpc => not_available_on_grpc_api("update_api_definition"),
             GolemClientProtocol::Http => {
                 let client = self.api_definition_http_client(token).await;
 
-                match request.api_definition.unwrap() {
-                    update_api_definition_request::ApiDefinition::Definition(request) => {
-                        match client
-                            .update_definition_yaml(
-                                &project_id.0,
-                                &request.id.clone().unwrap().value,
-                                &request.clone().version,
-                                &grpc_api_definition_request_to_http(
-                                    token,
-                                    ApiDefinitionRequest {
-                                        id: request.id,
-                                        version: request.version,
-                                        draft: request.draft,
-                                        definition: request.definition,
-                                    },
-                                    self.component_service(),
-                                )
-                                .await,
-                            )
-                            .await
-                        {
-                            Ok(result) => Ok(http_api_definition_to_grpc(
-                                token,
-                                result,
-                                self.component_service(),
-                            )
-                            .await),
-                            Err(error) => Err(anyhow!("{error:?}")),
-                        }
-                    }
-                    update_api_definition_request::ApiDefinition::Openapi(_) => {
-                        todo!() // TODO: see worker-service-base for how this is interpreted
-                    }
-                }
+                let result = client
+                    .update_definition_json(&project_id.0, &request.id, &request.version, request)
+                    .await?;
+
+                Ok(result)
             }
         }
     }
@@ -1132,22 +1101,19 @@ pub trait WorkerService: Send + Sync {
         &self,
         token: &Uuid,
         project_id: &ProjectId,
-        request: GetApiDefinitionRequest,
-    ) -> crate::Result<ApiDefinition> {
+        api_definition_id: &str,
+        api_definition_version: &str,
+    ) -> crate::Result<HttpApiDefinitionResponseData> {
         match self.client_protocol() {
             GolemClientProtocol::Grpc => not_available_on_grpc_api("get_api_definition"),
             GolemClientProtocol::Http => {
                 let client = self.api_definition_http_client(token).await;
 
                 let result = client
-                    .get_definition(
-                        &project_id.0,
-                        &request.api_definition_id.unwrap().value,
-                        &request.version,
-                    )
+                    .get_definition(&project_id.0, api_definition_id, api_definition_version)
                     .await?;
 
-                Ok(http_api_definition_to_grpc(token, result, self.component_service()).await)
+                Ok(result)
             }
         }
     }
@@ -1156,24 +1122,18 @@ pub trait WorkerService: Send + Sync {
         &self,
         token: &Uuid,
         project_id: &ProjectId,
-        request: GetApiDefinitionVersionsRequest,
-    ) -> crate::Result<Vec<ApiDefinition>> {
+        api_definition_id: &str,
+    ) -> crate::Result<Vec<HttpApiDefinitionResponseData>> {
         match self.client_protocol() {
             GolemClientProtocol::Grpc => not_available_on_grpc_api("get_api_definition_versions"),
             GolemClientProtocol::Http => {
                 let client = self.api_definition_http_client(token).await;
 
                 let result = client
-                    .list_definitions(
-                        &project_id.0,
-                        request.api_definition_id.map(|id| id.value).as_deref(),
-                    )
+                    .list_definitions(&project_id.0, Some(api_definition_id))
                     .await?;
 
-                Ok(join_all(result.into_iter().map(async |def| {
-                    http_api_definition_to_grpc(token, def, self.component_service()).await
-                }))
-                .await)
+                Ok(result)
             }
         }
     }
@@ -1182,7 +1142,7 @@ pub trait WorkerService: Send + Sync {
         &self,
         token: &Uuid,
         project_id: &ProjectId,
-    ) -> crate::Result<Vec<ApiDefinition>> {
+    ) -> crate::Result<Vec<HttpApiDefinitionResponseData>> {
         match self.client_protocol() {
             GolemClientProtocol::Grpc => not_available_on_grpc_api("get_all_api_definitions"),
             GolemClientProtocol::Http => {
@@ -1190,10 +1150,7 @@ pub trait WorkerService: Send + Sync {
 
                 let result = client.list_definitions(&project_id.0, None).await?;
 
-                Ok(join_all(result.into_iter().map(async |def| {
-                    http_api_definition_to_grpc(token, def, self.component_service()).await
-                }))
-                .await)
+                Ok(result)
             }
         }
     }
@@ -1202,7 +1159,8 @@ pub trait WorkerService: Send + Sync {
         &self,
         token: &Uuid,
         project_id: &ProjectId,
-        request: DeleteApiDefinitionRequest,
+        api_definition_id: &str,
+        api_definition_version: &str,
     ) -> crate::Result<()> {
         match self.client_protocol() {
             GolemClientProtocol::Grpc => not_available_on_grpc_api("delete_api_definition"),
@@ -1210,11 +1168,7 @@ pub trait WorkerService: Send + Sync {
                 let client = self.api_definition_http_client(token).await;
 
                 client
-                    .delete_definition(
-                        &project_id.0,
-                        &request.api_definition_id.unwrap().value,
-                        &request.version,
-                    )
+                    .delete_definition(&project_id.0, api_definition_id, api_definition_version)
                     .await?;
 
                 Ok(())
@@ -1295,6 +1249,27 @@ pub trait WorkerService: Send + Sync {
         }
     }
 
+    async fn export_openapi_spec(
+        &self,
+        token: &Uuid,
+        project_id: &ProjectId,
+        api_definition_id: &str,
+        api_definition_version: &str,
+    ) -> crate::Result<OpenApiHttpApiDefinitionResponse> {
+        match self.client_protocol() {
+            GolemClientProtocol::Grpc => not_available_on_grpc_api("export_openapi_spec"),
+            GolemClientProtocol::Http => {
+                let client = self.api_definition_http_client(token).await;
+
+                let result = client
+                    .export_definition(&project_id.0, api_definition_id, api_definition_version)
+                    .await?;
+
+                Ok(result)
+            }
+        }
+    }
+
     async fn undeploy_api(
         &self,
         token: &Uuid,
@@ -1464,13 +1439,25 @@ async fn env_vars(
 fn http_worker_metadata_to_grpc(
     worker_metadata: golem_client::model::WorkerMetadata,
 ) -> WorkerMetadata {
+    let mut owned_resources = Vec::new();
+    for instance in worker_metadata.exported_resource_instances {
+        owned_resources.push(golem_api_grpc::proto::golem::worker::ResourceDescription {
+            resource_id: instance.key,
+            resource_name: instance.description.resource_name,
+            resource_owner: instance.description.resource_owner,
+            created_at: Some(instance.description.created_at.into()),
+        });
+    }
+
     WorkerMetadata {
         worker_id: Some(worker_metadata.worker_id.into()),
-        account_id: Some(AccountId {
+        created_by: Some(AccountId {
             name: "1".to_string(),
         }),
+        project_id: Some(ProjectId(worker_metadata.project_id).into()),
         args: worker_metadata.args,
         env: worker_metadata.env,
+        wasi_config_vars: Some(WasiConfigVars(worker_metadata.wasi_config_vars).into()),
         status: worker_metadata.status.into(),
         component_version: worker_metadata.component_version,
         retry_count: worker_metadata.retry_count,
@@ -1516,22 +1503,7 @@ fn http_worker_metadata_to_grpc(
         last_error: worker_metadata.last_error,
         component_size: worker_metadata.component_size,
         total_linear_memory_size: worker_metadata.total_linear_memory_size,
-        owned_resources: worker_metadata
-            .owned_resources
-            .into_iter()
-            .map(|(k, v)| {
-                (
-                    k.parse().unwrap(),
-                    ResourceMetadata {
-                        created_at: Some(SystemTime::from(v.created_at).into()),
-                        indexed: v.indexed.map(|indexed| IndexedResourceMetadata {
-                            resource_name: indexed.resource_name,
-                            resource_params: indexed.resource_params,
-                        }),
-                    },
-                )
-            })
-            .collect(),
+        owned_resources,
         active_plugins: worker_metadata
             .active_plugins
             .into_iter()
@@ -1615,6 +1587,18 @@ fn grpc_filter_to_http_filter(filter: Filter) -> Vec<String> {
                     value
                 )]
             }
+            Filter::WasiConfigVars(WorkerWasiConfigVarsFilter {
+                name,
+                comparator,
+                value,
+            }) => {
+                vec![format!(
+                    "config.{} {} {}",
+                    name,
+                    grpc_string_filter_comparator_to_http(comparator),
+                    value
+                )]
+            }
             Filter::And(and_filter) => {
                 if !allow_and {
                     panic!("'And' filters are only supported on the root level on the HTTP API")
@@ -1669,208 +1653,6 @@ fn invoke_parameters_to_grpc(parameters: Vec<ValueAndType>) -> Option<InvokePara
     })
 }
 
-async fn http_api_definition_to_grpc(
-    token: &Uuid,
-    response: golem_client::model::HttpApiDefinitionResponseData,
-    component_service: &Arc<dyn ComponentService>,
-) -> ApiDefinition {
-    ApiDefinition {
-        id: Some(ApiDefinitionId { value: response.id }),
-        version: response.version,
-        draft: response.draft,
-        created_at: response.created_at.map(|ts| SystemTime::from(ts).into()),
-        definition: Some(Definition::Http(HttpApiDefinition {
-            routes: join_all(response.routes.into_iter().map(async |route| {
-                HttpRoute {
-                    method: match route.method {
-                        golem_client::model::MethodPattern::Get => HttpMethod::Get,
-                        golem_client::model::MethodPattern::Connect => HttpMethod::Connect,
-                        golem_client::model::MethodPattern::Post => HttpMethod::Post,
-                        golem_client::model::MethodPattern::Delete => HttpMethod::Delete,
-                        golem_client::model::MethodPattern::Put => HttpMethod::Put,
-                        golem_client::model::MethodPattern::Patch => HttpMethod::Patch,
-                        golem_client::model::MethodPattern::Options => HttpMethod::Options,
-                        golem_client::model::MethodPattern::Trace => HttpMethod::Trace,
-                        golem_client::model::MethodPattern::Head => HttpMethod::Head,
-                    } as i32,
-                    path: route.path,
-                    binding: Some(GatewayBinding {
-                        component: join_option(route.binding.component.map(async |component| {
-                            let response = component_service
-                                .get_components(
-                                    token,
-                                    grpc_components::v1::GetComponentsRequest {
-                                        project_id: None,
-                                        component_name: Some(component.name),
-                                    },
-                                )
-                                .await
-                                .unwrap();
-                            let resolved_component = response.first().unwrap();
-
-                            grpc_components::VersionedComponentId {
-                                component_id: Some(
-                                    resolved_component
-                                        .versioned_component_id
-                                        .unwrap()
-                                        .component_id
-                                        .unwrap(),
-                                ),
-                                version: component.version,
-                            }
-                        }))
-                        .await,
-                        worker_name: route.binding.worker_name.as_deref().map(to_grpc_rib_expr),
-                        response: route.binding.response.as_deref().map(to_grpc_rib_expr),
-                        idempotency_key: route
-                            .binding
-                            .idempotency_key
-                            .as_deref()
-                            .map(to_grpc_rib_expr),
-                        binding_type: route.binding.binding_type.map(
-                            |binding_type| match binding_type {
-                                golem_client::model::GatewayBindingType::Default => {
-                                    GatewayBindingType::Default
-                                }
-                                golem_client::model::GatewayBindingType::FileServer => {
-                                    GatewayBindingType::FileServer
-                                }
-                                golem_client::model::GatewayBindingType::HttpHandler => {
-                                    GatewayBindingType::HttpHandler
-                                }
-                                golem_client::model::GatewayBindingType::CorsPreflight => {
-                                    GatewayBindingType::CorsPreflight
-                                }
-                            } as i32,
-                        ),
-                        static_binding: route.binding.cors_preflight.map(|cors_preflight| {
-                            // TODO: should there be AuthCallback in the HTTP API? and how this relates to middleware
-                            StaticBinding {
-                                static_binding: Some(
-                                    static_binding::StaticBinding::HttpCorsPreflight(
-                                        CorsPreflight {
-                                            allow_origin: Some(cors_preflight.allow_origin),
-                                            allow_methods: Some(cors_preflight.allow_methods),
-                                            allow_headers: Some(cors_preflight.allow_headers),
-                                            expose_headers: cors_preflight.expose_headers,
-                                            max_age: cors_preflight.max_age,
-                                            allow_credentials: cors_preflight.allow_credentials,
-                                        },
-                                    ),
-                                ),
-                            }
-                        }),
-                        invocation_context: None, // TODO
-                    }),
-                    middleware: None, // TODO
-                }
-            }))
-            .await,
-        })),
-    }
-}
-
-async fn join_option<F: Future>(value: Option<F>) -> Option<F::Output> {
-    match value {
-        Some(inner) => Some(inner.await),
-        None => None,
-    }
-}
-
-async fn grpc_api_definition_request_to_http(
-    token: &Uuid,
-    request: ApiDefinitionRequest,
-    component_service: &Arc<dyn ComponentService>,
-) -> golem_client::model::HttpApiDefinitionRequest {
-    golem_client::model::HttpApiDefinitionRequest {
-        id: request.id.unwrap().value,
-        version: request.version,
-        security: None, // TODO: is this missing in GRPC (or deprecated)?
-        routes: join_option(request.definition.map(async |definition| {
-            match definition {
-                api_definition_request::Definition::Http(definition) => {
-                    join_all(definition.routes.into_iter().map(async |route| {
-                        let binding = route.binding.unwrap();
-                        golem_client::model::RouteRequestData {
-                            method: match HttpMethod::try_from(route.method).unwrap() {
-                                HttpMethod::Get => golem_client::model::MethodPattern::Get,
-                                HttpMethod::Connect => golem_client::model::MethodPattern::Connect,
-                                HttpMethod::Post => golem_client::model::MethodPattern::Post,
-                                HttpMethod::Delete => golem_client::model::MethodPattern::Delete,
-                                HttpMethod::Put => golem_client::model::MethodPattern::Put,
-                                HttpMethod::Patch => golem_client::model::MethodPattern::Patch,
-                                HttpMethod::Options => golem_client::model::MethodPattern::Options,
-                                HttpMethod::Trace => golem_client::model::MethodPattern::Trace,
-                                HttpMethod::Head => golem_client::model::MethodPattern::Head,
-                            },
-                            path: route.path,
-                            binding: golem_client::model::GatewayBindingData {
-                                binding_type: binding.binding_type.map(|binding_type| {
-                                    match GatewayBindingType::try_from(binding_type).unwrap() {
-                                        GatewayBindingType::Default => {
-                                            golem_client::model::GatewayBindingType::Default
-                                        }
-                                        GatewayBindingType::FileServer => {
-                                            golem_client::model::GatewayBindingType::FileServer
-                                        }
-                                        GatewayBindingType::CorsPreflight => {
-                                            golem_client::model::GatewayBindingType::CorsPreflight
-                                        }
-                                        GatewayBindingType::AuthCallBack => {
-                                            panic!("auth callback is not supported on HTTP API")
-                                        }
-                                        GatewayBindingType::HttpHandler => {
-                                            golem_client::model::GatewayBindingType::HttpHandler
-                                        }
-                                    }
-                                }),
-                                component: join_option(binding.component.map(
-                                    async |versioned_component_id| {
-                                        let component = component_service
-                                            .get_latest_component_metadata(
-                                                token,
-                                                grpc_components::v1::GetLatestComponentRequest {
-                                                    component_id: versioned_component_id
-                                                        .component_id,
-                                                },
-                                            )
-                                            .await
-                                            .unwrap();
-                                        GatewayBindingComponent {
-                                            name: component.component_name,
-                                            version: Some(versioned_component_id.version),
-                                        }
-                                    },
-                                ))
-                                .await,
-                                worker_name: binding.worker_name.map(to_http_rib_expr),
-                                idempotency_key: binding.idempotency_key.map(to_http_rib_expr),
-                                invocation_context: binding
-                                    .invocation_context
-                                    .map(to_http_rib_expr),
-                                response: binding.response.map(to_http_rib_expr),
-                            },
-                            security: None,
-                        }
-                    }))
-                    .await
-                }
-            }
-        }))
-        .await
-        .unwrap_or_default(),
-        draft: request.draft,
-    }
-}
-
-fn to_grpc_rib_expr(expr: &str) -> Expr {
-    rib::Expr::from_text(expr).unwrap().into()
-}
-
-fn to_http_rib_expr(expr: Expr) -> String {
-    rib::Expr::try_from(expr).unwrap().to_string()
-}
-
 fn not_available_on_grpc_api<T>(endpoint: &str) -> crate::Result<T> {
     Err(anyhow!("not available on GRPC API: {endpoint}"))
 }
diff --git a/golem-test-framework/src/config/cli.rs b/golem-test-framework/src/config/cli.rs
index 723edc47..30e25375 100644
--- a/golem-test-framework/src/config/cli.rs
+++ b/golem-test-framework/src/config/cli.rs
@@ -417,7 +417,7 @@ impl CliTestDependencies {
             .await,
         );
 
-        let redis: Arc<dyn Redis + Send + Sync + 'static> =
+        let redis: Arc<dyn Redis> =
             Arc::new(DockerRedis::new(&unique_network_id, redis_prefix.to_string()).await);
 
         let redis_monitor: Arc<dyn RedisMonitor> = Arc::new(SpawnedRedisMonitor::new(
@@ -582,7 +582,7 @@ impl CliTestDependencies {
             .await,
         );
 
-        let redis: Arc<dyn Redis + Send + Sync + 'static> = Arc::new(SpawnedRedis::new(
+        let redis: Arc<dyn Redis> = Arc::new(SpawnedRedis::new(
             redis_port,
             redis_prefix.to_string(),
             out_level,
@@ -736,7 +736,7 @@ impl CliTestDependencies {
             .await,
         );
 
-        let redis: Arc<dyn Redis + Send + Sync + 'static> = Arc::new(
+        let redis: Arc<dyn Redis> = Arc::new(
             K8sRedis::new(
                 &namespace,
                 &routing_type,
@@ -899,7 +899,7 @@ impl CliTestDependencies {
             .await,
         );
 
-        let redis: Arc<dyn Redis + Send + Sync + 'static> = Arc::new(
+        let redis: Arc<dyn Redis> = Arc::new(
             K8sRedis::new(
                 &namespace,
                 &routing_type,
@@ -1020,7 +1020,7 @@ impl CliTestDependencies {
 
                 let rdb: Arc<dyn Rdb> = Arc::new(ProvidedPostgresRdb::new(postgres.clone()));
 
-                let redis: Arc<dyn Redis + Send + Sync + 'static> = Arc::new(ProvidedRedis::new(
+                let redis: Arc<dyn Redis> = Arc::new(ProvidedRedis::new(
                     redis_host.clone(),
                     *redis_port,
                     redis_prefix.clone(),
diff --git a/golem-test-framework/src/config/env.rs b/golem-test-framework/src/config/env.rs
index 03567fc0..6d2f1f81 100644
--- a/golem-test-framework/src/config/env.rs
+++ b/golem-test-framework/src/config/env.rs
@@ -12,7 +12,6 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use std::env;
 use crate::components::cloud_service::docker::DockerCloudService;
 use crate::components::cloud_service::spawned::SpawnedCloudService;
 use crate::components::cloud_service::CloudService;
@@ -29,7 +28,6 @@ use crate::components::redis::docker::DockerRedis;
 use crate::components::redis::provided::ProvidedRedis;
 use crate::components::redis::spawned::SpawnedRedis;
 use crate::components::redis::Redis;
-use crate::components::redis_monitor::docker::DockerRedisMonitor;
 use crate::components::redis_monitor::spawned::SpawnedRedisMonitor;
 use crate::components::redis_monitor::RedisMonitor;
 use crate::components::shard_manager::docker::DockerShardManager;
@@ -160,7 +158,7 @@ impl Default for EnvBasedTestDependenciesConfig {
             redis_host: "localhost".to_string(),
             redis_port: 6379,
             redis_key_prefix: "".to_string(),
-            golem_test_components: PathBuf::from_iter([env!("CARGO_MANIFEST_DIR"), "..", "test-components"]),
+            golem_test_components: Path::new("../test-components").to_path_buf(),
             golem_client_protocol: GolemClientProtocol::Grpc,
             unique_network_id: Uuid::new_v4().to_string(),
         }
@@ -202,9 +200,7 @@ impl EnvBasedTestDependencies {
         }
     }
 
-    async fn make_redis(
-        config: Arc<EnvBasedTestDependenciesConfig>,
-    ) -> Arc<dyn Redis + Send + Sync + 'static> {
+    async fn make_redis(config: Arc<EnvBasedTestDependenciesConfig>) -> Arc<dyn Redis> {
         let prefix = config.redis_key_prefix.clone();
         if config.golem_docker_services {
             Arc::new(DockerRedis::new(&config.unique_network_id, prefix).await)
@@ -227,21 +223,13 @@ impl EnvBasedTestDependencies {
 
     async fn make_redis_monitor(
         config: Arc<EnvBasedTestDependenciesConfig>,
-        redis: Arc<dyn Redis + Send + Sync + 'static>,
+        redis: Arc<dyn Redis>,
     ) -> Arc<dyn RedisMonitor> {
-        if config.golem_docker_services {
-            Arc::new(DockerRedisMonitor::new(
-                redis,
-                config.redis_monitor_stdout_level(),
-                config.redis_monitor_stderr_level(),
-            ))
-        } else {
-            Arc::new(SpawnedRedisMonitor::new(
-                redis,
-                config.redis_monitor_stdout_level(),
-                config.redis_monitor_stderr_level(),
-            ))
-        }
+        Arc::new(SpawnedRedisMonitor::new(
+            redis,
+            config.redis_monitor_stdout_level(),
+            config.redis_monitor_stderr_level(),
+        ))
     }
 
     async fn make_cloud_service(
@@ -252,7 +240,7 @@ impl EnvBasedTestDependencies {
             Arc::new(
                 DockerCloudService::new(
                     &config.unique_network_id,
-                    rdb.clone(),
+                    rdb,
                     config.golem_client_protocol,
                     config.default_verbosity(),
                 )
diff --git a/golem-test-framework/src/config/mod.rs b/golem-test-framework/src/config/mod.rs
index 25194a85..ed2f5bf6 100644
--- a/golem-test-framework/src/config/mod.rs
+++ b/golem-test-framework/src/config/mod.rs
@@ -28,7 +28,7 @@ pub use cli::{CliParams, CliTestDependencies, CliTestService};
 pub use env::EnvBasedTestDependencies;
 pub use env::EnvBasedTestDependenciesConfig;
 use golem_client::model::AccountData;
-use golem_common::model::AccountId;
+use golem_common::model::{AccountId, ProjectId};
 use golem_service_base::service::initial_component_files::InitialComponentFilesService;
 use golem_service_base::service::plugin_wasm_files::PluginWasmFilesService;
 use golem_service_base::storage::blob::BlobStorage;
@@ -63,27 +63,39 @@ pub trait TestDependencies: Send + Sync {
     fn plugin_wasm_files_service(&self) -> Arc<PluginWasmFilesService>;
     fn cloud_service(&self) -> Arc<dyn CloudService>;
 
-    fn admin(&self) -> TestDependenciesDsl<&Self> {
+    // TODO: this need to be cached, especially when using in benchmarks
+    async fn admin(&self) -> TestDependenciesDsl<&Self> {
         TestDependenciesDsl {
             deps: self,
             account_id: self.cloud_service().admin_account_id(),
             account_email: self.cloud_service().admin_email(),
+            default_project_id: self
+                .cloud_service()
+                .get_default_project(&self.cloud_service().admin_token())
+                .await
+                .expect("failed to get default project for admin"),
             token: self.cloud_service().admin_token(),
         }
     }
 
-    fn into_admin(self) -> TestDependenciesDsl<Self>
+    async fn into_admin(self) -> TestDependenciesDsl<Self>
     where
         Self: Sized,
     {
         let account_id = self.cloud_service().admin_account_id();
         let token = self.cloud_service().admin_token();
         let account_email = self.cloud_service().admin_email();
+        let default_project_id = self
+            .cloud_service()
+            .get_default_project(&token)
+            .await
+            .expect("failed to get default project for admin");
 
         TestDependenciesDsl {
             deps: self,
             account_id,
             account_email,
+            default_project_id,
             token,
         }
     }
@@ -100,12 +112,18 @@ pub trait TestDependencies: Send + Sync {
             .create_account(&self.cloud_service().admin_token(), &account_data)
             .await
             .expect("failed to create user");
+        let default_project_id = self
+            .cloud_service()
+            .get_default_project(&account.token)
+            .await
+            .expect("failed to get default project for user");
 
         TestDependenciesDsl {
             deps: self,
             account_id: account.id,
             account_email: account.email,
             token: account.token,
+            default_project_id,
         }
     }
 
@@ -124,12 +142,18 @@ pub trait TestDependencies: Send + Sync {
             .create_account(&self.cloud_service().admin_token(), &account_data)
             .await
             .expect("failed to create user");
+        let default_project_id = self
+            .cloud_service()
+            .get_default_project(&account.token)
+            .await
+            .expect("failed to get default project for user");
 
         TestDependenciesDsl {
             deps: self,
             account_id: account.id,
             account_email: account.email,
             token: account.token,
+            default_project_id,
         }
     }
 
@@ -195,18 +219,10 @@ pub struct TestDependenciesDsl<Deps> {
     pub deps: Deps,
     pub account_id: AccountId,
     pub account_email: String,
+    pub default_project_id: ProjectId,
     pub token: Uuid,
 }
 
-impl<Deps> std::fmt::Debug for TestDependenciesDsl<Deps> {
-    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
-        f.debug_struct("TestDependenciesDsl")
-            .field("account_id", &self.account_id)
-            .field("account_email", &self.account_email)
-            .finish_non_exhaustive()
-    }
-}
-
 #[derive(Debug, Clone)]
 pub enum DbType {
     Postgres,
diff --git a/golem-test-framework/src/dsl/debug_render.rs b/golem-test-framework/src/dsl/debug_render.rs
index cf173eae..c8a37b43 100644
--- a/golem-test-framework/src/dsl/debug_render.rs
+++ b/golem-test-framework/src/dsl/debug_render.rs
@@ -12,12 +12,12 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
+use golem_common::model::agent::{BinaryReference, DataValue, ElementValue, TextReference};
 use golem_common::model::public_oplog::{
     PluginInstallationDescription, PublicAttributeValue, PublicOplogEntry, PublicUpdateDescription,
     PublicWorkerInvocation, StringAttributeValue,
 };
-use golem_wasm_rpc::protobuf::type_annotated_value::TypeAnnotatedValue;
-use golem_wasm_rpc::{print_type_annotated_value, ValueAndType};
+use golem_wasm_rpc::{print_value_and_type, ValueAndType};
 use std::fmt::Write;
 
 // backported from golem-cli to help debugging worker executor issues
@@ -257,16 +257,6 @@ pub fn debug_render_oplog_entry(entry: &PublicOplogEntry) -> String {
             let _ = writeln!(result, "{pad}at:                {}", &params.timestamp);
             let _ = writeln!(result, "{pad}resource id:       {}", &params.id);
         }
-        PublicOplogEntry::DescribeResource(params) => {
-            let _ = writeln!(result, "DESCRIBE RESOURCE");
-            let _ = writeln!(result, "{pad}at:                {}", &params.timestamp);
-            let _ = writeln!(result, "{pad}resource id:       {}", &params.id);
-            let _ = writeln!(result, "{pad}resource name:     {}", &params.resource_name,);
-            let _ = writeln!(result, "{pad}resource parameters:");
-            for value in &params.resource_params {
-                let _ = writeln!(result, "{pad}  - {}", value_to_string(value));
-            }
-        }
         PublicOplogEntry::Log(params) => {
             let _ = writeln!(result, "LOG");
             let _ = writeln!(result, "{pad}at:                {}", &params.timestamp);
@@ -383,6 +373,52 @@ fn log_plugin_description(output: &mut String, pad: &str, value: &PluginInstalla
 }
 
 fn value_to_string(value: &ValueAndType) -> String {
-    let tav: TypeAnnotatedValue = value.try_into().expect("Failed to convert value to string");
-    print_type_annotated_value(&tav).expect("Failed to convert value to string")
+    print_value_and_type(value).unwrap_or_else(|_| format!("{value:?}"))
+}
+
+#[allow(dead_code)]
+fn log_data_value(output: &mut String, pad: &str, value: &DataValue) {
+    match value {
+        DataValue::Tuple(values) => {
+            let _ = writeln!(output, "{pad}  tuple:");
+            for value in &values.elements {
+                log_element_value(output, &format!("{pad}    "), value);
+            }
+        }
+        DataValue::Multimodal(values) => {
+            let _ = writeln!(output, "{pad}  multi-modal:");
+            for value in &values.elements {
+                log_element_value(output, &format!("{pad}    "), &value.value);
+            }
+        }
+    }
+}
+
+#[allow(dead_code)]
+fn log_element_value(output: &mut String, pad: &str, value: &ElementValue) {
+    match value {
+        ElementValue::ComponentModel(value) => {
+            let _ = writeln!(output, "{pad}- {}", value_to_string(value));
+        }
+        ElementValue::UnstructuredText(value) => match value {
+            TextReference::Url(url) => {
+                let _ = writeln!(output, "{pad}- URL: {}", url.value);
+            }
+            TextReference::Inline(inline) => {
+                let _ = writeln!(output, "{pad}- Inline: {}", inline.data);
+                if let Some(text_type) = &inline.text_type {
+                    let _ = writeln!(output, "{pad}  Language code: {}", text_type.language_code);
+                }
+            }
+        },
+        ElementValue::UnstructuredBinary(value) => match value {
+            BinaryReference::Url(url) => {
+                let _ = writeln!(output, "{pad}- URL: {}", url.value);
+            }
+            BinaryReference::Inline(inline) => {
+                let _ = writeln!(output, "{pad}- Inline: {} bytes", inline.data.len());
+                let _ = writeln!(output, "{pad}  MIME type: {}", inline.binary_type.mime_type);
+            }
+        },
+    }
 }
diff --git a/golem-test-framework/src/dsl/mod.rs b/golem-test-framework/src/dsl/mod.rs
index e3fb7de8..05702f1b 100644
--- a/golem-test-framework/src/dsl/mod.rs
+++ b/golem-test-framework/src/dsl/mod.rs
@@ -25,17 +25,18 @@ use golem_api_grpc::proto::golem::component::v1::GetLatestComponentRequest;
 use golem_api_grpc::proto::golem::worker::update_record::Update;
 use golem_api_grpc::proto::golem::worker::v1::worker_error::Error;
 use golem_api_grpc::proto::golem::worker::v1::{
-    cancel_invocation_response, fork_worker_response, get_oplog_response,
-    get_worker_metadata_response, get_workers_metadata_response, interrupt_worker_response,
-    invoke_and_await_json_response, invoke_and_await_response, invoke_and_await_typed_response,
-    invoke_response, launch_new_worker_response, list_directory_response, resume_worker_response,
-    revert_worker_response, search_oplog_response, update_worker_response, worker_execution_error,
-    CancelInvocationRequest, ConnectWorkerRequest, DeleteWorkerRequest, ForkWorkerRequest,
-    ForkWorkerResponse, GetFileContentsRequest, GetOplogRequest, GetWorkerMetadataRequest,
-    GetWorkersMetadataRequest, GetWorkersMetadataSuccessResponse, InterruptWorkerRequest,
-    InterruptWorkerResponse, InvokeAndAwaitJsonRequest, LaunchNewWorkerRequest,
-    ListDirectoryRequest, ResumeWorkerRequest, RevertWorkerRequest, SearchOplogRequest,
-    UpdateWorkerRequest, UpdateWorkerResponse, WorkerError, WorkerExecutionError,
+    cancel_invocation_response, fork_worker_response, get_file_system_node_response,
+    get_oplog_response, get_worker_metadata_response, get_workers_metadata_response,
+    interrupt_worker_response, invoke_and_await_json_response, invoke_and_await_response,
+    invoke_and_await_typed_response, invoke_response, launch_new_worker_response,
+    resume_worker_response, revert_worker_response, search_oplog_response, update_worker_response,
+    worker_execution_error, CancelInvocationRequest, ConnectWorkerRequest, DeleteWorkerRequest,
+    ForkWorkerRequest, ForkWorkerResponse, GetFileContentsRequest, GetFileSystemNodeRequest,
+    GetOplogRequest, GetWorkerMetadataRequest, GetWorkersMetadataRequest,
+    GetWorkersMetadataSuccessResponse, InterruptWorkerRequest, InterruptWorkerResponse,
+    InvokeAndAwaitJsonRequest, LaunchNewWorkerRequest, ResumeWorkerRequest, RevertWorkerRequest,
+    SearchOplogRequest, UpdateWorkerRequest, UpdateWorkerResponse, WorkerError,
+    WorkerExecutionError,
 };
 use golem_api_grpc::proto::golem::worker::{log_event, LogEvent, StdErrLog, StdOutLog, UpdateMode};
 use golem_client::model::Account;
@@ -49,20 +50,20 @@ use golem_common::model::plugin::PluginWasmFileKey;
 use golem_common::model::public_oplog::PublicOplogEntry;
 use golem_common::model::regions::DeletedRegions;
 use golem_common::model::{
-    AccountId, ComponentFilePermissions, PluginInstallationId, ProjectId, WorkerStatus,
+    AccountId, ComponentFilePermissions, PluginInstallationId, ProjectId,
+    WorkerResourceDescription, WorkerStatus,
 };
 use golem_common::model::{
     ComponentFileSystemNode, ComponentId, ComponentType, ComponentVersion, FailedUpdateRecord,
     IdempotencyKey, InitialComponentFile, InitialComponentFileKey, ScanCursor,
-    SuccessfulUpdateRecord, TargetWorkerId, WorkerFilter, WorkerId, WorkerMetadata,
-    WorkerResourceDescription, WorkerStatusRecord,
+    SuccessfulUpdateRecord, WorkerFilter, WorkerId, WorkerMetadata, WorkerStatusRecord,
 };
 use golem_common::widen_infallible;
 use golem_service_base::model::{ComponentName, PublicOplogEntryWithIndex, RevertWorkerTarget};
 use golem_service_base::replayable_stream::ReplayableStream;
 use golem_wasm_rpc::{Value, ValueAndType};
 use std::borrow::Borrow;
-use std::collections::{HashMap, HashSet};
+use std::collections::{BTreeMap, HashMap, HashSet};
 use std::path::{Path, PathBuf};
 use std::time::{Duration, Instant};
 use tempfile::Builder;
@@ -71,7 +72,7 @@ use tokio::sync::mpsc::UnboundedReceiver;
 use tokio::sync::oneshot::Sender;
 use tracing::{debug, info, Instrument};
 use uuid::Uuid;
-use wasm_metadata::AddMetadata;
+use wasm_metadata::{AddMetadata, AddMetadataField};
 
 pub struct StoreComponentBuilder<'a, DSL: TestDsl + ?Sized> {
     dsl: &'a DSL,
@@ -287,6 +288,7 @@ pub trait TestDsl {
         name: &str,
         args: Vec<String>,
         env: HashMap<String, String>,
+        wasi_config_vars: Vec<(String, String)>,
     ) -> crate::Result<WorkerId>;
 
     async fn try_start_worker_with(
@@ -295,6 +297,7 @@ pub trait TestDsl {
         name: &str,
         args: Vec<String>,
         env: HashMap<String, String>,
+        wasi_config_vars: Vec<(String, String)>,
     ) -> crate::Result<Result<WorkerId, Error>>;
 
     async fn get_worker_metadata(
@@ -328,72 +331,72 @@ pub trait TestDsl {
 
     async fn invoke(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> crate::Result<Result<(), Error>>;
     async fn invoke_with_key(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         idempotency_key: &IdempotencyKey,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> crate::Result<Result<(), Error>>;
     async fn invoke_and_await(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> crate::Result<Result<Vec<Value>, Error>>;
     async fn invoke_and_await_with_key(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         idempotency_key: &IdempotencyKey,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> crate::Result<Result<Vec<Value>, Error>>;
     async fn invoke_and_await_custom(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> crate::Result<Result<Vec<Value>, Error>>;
     async fn invoke_and_await_custom_with_key(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         idempotency_key: &IdempotencyKey,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> crate::Result<Result<Vec<Value>, Error>>;
     async fn invoke_and_await_typed(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> crate::Result<Result<Option<ValueAndType>, Error>>;
     async fn invoke_and_await_typed_custom(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> crate::Result<Result<Option<ValueAndType>, Error>>;
     async fn invoke_and_await_typed_with_key(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         idempotency_key: &IdempotencyKey,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> crate::Result<Result<Option<ValueAndType>, Error>>;
     async fn invoke_and_await_typed_custom_with_key(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         idempotency_key: &IdempotencyKey,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> crate::Result<Result<Option<ValueAndType>, Error>>;
     async fn invoke_and_await_json(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         function_name: &str,
         params: Vec<serde_json::Value>,
     ) -> crate::Result<Result<serde_json::Value, Error>>;
@@ -433,17 +436,13 @@ pub trait TestDsl {
 
     async fn check_oplog_is_queryable(&self, worker_id: &WorkerId) -> crate::Result<()>;
 
-    async fn list_directory(
+    async fn get_file_system_node(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         path: &str,
     ) -> crate::Result<Vec<ComponentFileSystemNode>>;
 
-    async fn get_file_contents(
-        &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
-        path: &str,
-    ) -> crate::Result<Bytes>;
+    async fn get_file_contents(&self, worker_id: &WorkerId, path: &str) -> crate::Result<Bytes>;
 
     async fn create_plugin(&self, definition: PluginDefinitionCreation) -> crate::Result<()>;
 
@@ -621,46 +620,6 @@ impl<Deps: TestDependencies> TestDsl for TestDependenciesDsl<Deps> {
             })
     }
 
-    async fn add_initial_component_file(&self, path: &Path) -> InitialComponentFileKey {
-        let source_path = self.deps.borrow().component_directory().join(path);
-        let data = tokio::fs::read(&source_path)
-            .await
-            .expect("Failed to read file");
-        let bytes = Bytes::from(data);
-
-        let stream = bytes
-            .map_item(|i| i.map_err(widen_infallible))
-            .map_error(widen_infallible);
-
-        self.deps
-            .initial_component_files_service()
-            .put_if_not_exists(&self.account_id, stream)
-            .await
-            .expect("Failed to add initial component file")
-    }
-
-    async fn add_plugin_wasm(&self, name: &str) -> crate::Result<PluginWasmFileKey> {
-        let source_path = self.deps.component_directory().join(format!("{name}.wasm"));
-        let data = tokio::fs::read(&source_path)
-            .await
-            .map_err(|e| anyhow!("Failed to read file: {e}"))?;
-
-        let bytes = Bytes::from(data);
-
-        let stream = bytes
-            .map_item(|i| i.map_err(widen_infallible))
-            .map_error(widen_infallible);
-
-        let key = self
-            .deps
-            .plugin_wasm_files_service()
-            .put_if_not_exists(&self.account_id, stream)
-            .await
-            .map_err(|e| anyhow!("Failed to store plugin wasm: {e}"))?;
-
-        Ok(key)
-    }
-
     async fn update_component(&self, component_id: &ComponentId, name: &str) -> ComponentVersion {
         let source_path = self.deps.component_directory().join(format!("{name}.wasm"));
         let component_env = HashMap::new();
@@ -725,12 +684,58 @@ impl<Deps: TestDependencies> TestDsl for TestDependenciesDsl<Deps> {
             .unwrap()
     }
 
+    async fn add_initial_component_file(&self, path: &Path) -> InitialComponentFileKey {
+        let source_path = self.deps.borrow().component_directory().join(path);
+        let data = tokio::fs::read(&source_path)
+            .await
+            .expect("Failed to read file");
+        let bytes = Bytes::from(data);
+
+        let stream = bytes
+            .map_item(|i| i.map_err(widen_infallible))
+            .map_error(widen_infallible);
+
+        let project_id = self
+            .deps
+            .cloud_service()
+            .get_default_project(&self.token)
+            .await
+            .expect("Failed to get default project");
+        self.deps
+            .initial_component_files_service()
+            .put_if_not_exists(&project_id, stream)
+            .await
+            .expect("Failed to add initial component file")
+    }
+
+    async fn add_plugin_wasm(&self, name: &str) -> crate::Result<PluginWasmFileKey> {
+        let source_path = self.deps.component_directory().join(format!("{name}.wasm"));
+        let data = tokio::fs::read(&source_path)
+            .await
+            .map_err(|e| anyhow!("Failed to read file: {e}"))?;
+
+        let bytes = Bytes::from(data);
+
+        let stream = bytes
+            .map_item(|i| i.map_err(widen_infallible))
+            .map_error(widen_infallible);
+
+        let key = self
+            .deps
+            .plugin_wasm_files_service()
+            .put_if_not_exists(&self.account_id, stream)
+            .await
+            .map_err(|e| anyhow!("Failed to store plugin wasm: {e}"))?;
+
+        Ok(key)
+    }
+
     async fn start_worker(
         &self,
         component_id: &ComponentId,
         name: &str,
     ) -> crate::Result<WorkerId> {
-        TestDsl::start_worker_with(self, component_id, name, vec![], HashMap::new()).await
+        TestDsl::start_worker_with(self, component_id, name, vec![], HashMap::new(), vec![]).await
     }
 
     async fn try_start_worker(
@@ -738,7 +743,8 @@ impl<Deps: TestDependencies> TestDsl for TestDependenciesDsl<Deps> {
         component_id: &ComponentId,
         name: &str,
     ) -> crate::Result<Result<WorkerId, Error>> {
-        TestDsl::try_start_worker_with(self, component_id, name, vec![], HashMap::new()).await
+        TestDsl::try_start_worker_with(self, component_id, name, vec![], HashMap::new(), vec![])
+            .await
     }
 
     async fn start_worker_with(
@@ -747,8 +753,11 @@ impl<Deps: TestDependencies> TestDsl for TestDependenciesDsl<Deps> {
         name: &str,
         args: Vec<String>,
         env: HashMap<String, String>,
+        wasi_config_vars: Vec<(String, String)>,
     ) -> crate::Result<WorkerId> {
-        let result = TestDsl::try_start_worker_with(self, component_id, name, args, env).await?;
+        let result =
+            TestDsl::try_start_worker_with(self, component_id, name, args, env, wasi_config_vars)
+                .await?;
         Ok(result.map_err(|err| anyhow!("Failed to start worker: {err:?}"))?)
     }
 
@@ -758,6 +767,7 @@ impl<Deps: TestDependencies> TestDsl for TestDependenciesDsl<Deps> {
         name: &str,
         args: Vec<String>,
         env: HashMap<String, String>,
+        wasi_config_vars: Vec<(String, String)>,
     ) -> crate::Result<Result<WorkerId, Error>> {
         let response = self
             .deps
@@ -769,6 +779,8 @@ impl<Deps: TestDependencies> TestDsl for TestDependenciesDsl<Deps> {
                     name: name.to_string(),
                     args,
                     env,
+                    wasi_config_vars: Some(BTreeMap::from_iter(wasi_config_vars).into()),
+                    ignore_already_existing: false,
                 },
             )
             .await?;
@@ -827,6 +839,48 @@ impl<Deps: TestDependencies> TestDsl for TestDependenciesDsl<Deps> {
         }
     }
 
+    async fn wait_for_status(
+        &self,
+        worker_id: &WorkerId,
+        status: WorkerStatus,
+        timeout: Duration,
+    ) -> crate::Result<WorkerMetadata> {
+        TestDsl::wait_for_statuses(self, worker_id, &[status], timeout).await
+    }
+
+    async fn wait_for_statuses(
+        &self,
+        worker_id: &WorkerId,
+        statuses: &[WorkerStatus],
+        timeout: Duration,
+    ) -> crate::Result<WorkerMetadata> {
+        let start = Instant::now();
+        let mut last_known = None;
+        while start.elapsed() < timeout {
+            let (metadata, _) = TestDsl::get_worker_metadata(self, worker_id)
+                .await?
+                .ok_or(anyhow!("Worker not found"))?;
+            if statuses
+                .iter()
+                .any(|s| s == &metadata.last_known_status.status)
+            {
+                return Ok(metadata);
+            }
+
+            last_known = Some(metadata.last_known_status.status.clone());
+            tokio::time::sleep(Duration::from_millis(50)).await;
+        }
+
+        Err(anyhow!(
+            "Timeout waiting for worker status {} (last known: {last_known:?})",
+            statuses
+                .iter()
+                .map(|s| format!("{s:?}"))
+                .collect::<Vec<_>>()
+                .join(", ")
+        ))
+    }
+
     async fn get_workers_metadata(
         &self,
         component_id: &ComponentId,
@@ -881,17 +935,16 @@ impl<Deps: TestDependencies> TestDsl for TestDependenciesDsl<Deps> {
 
     async fn invoke(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> crate::Result<Result<(), Error>> {
-        let target_worker_id: TargetWorkerId = worker_id.into();
         let invoke_response = self
             .deps
             .worker_service()
             .invoke(
                 &self.token,
-                target_worker_id.into(),
+                worker_id.clone().into(),
                 None,
                 function_name.to_string(),
                 params,
@@ -913,18 +966,17 @@ impl<Deps: TestDependencies> TestDsl for TestDependenciesDsl<Deps> {
 
     async fn invoke_with_key(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         idempotency_key: &IdempotencyKey,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> crate::Result<Result<(), Error>> {
-        let target_worker_id: TargetWorkerId = worker_id.into();
         let invoke_response = self
             .deps
             .worker_service()
             .invoke(
                 &self.token,
-                target_worker_id.into(),
+                worker_id.clone().into(),
                 Some(idempotency_key.clone().into()),
                 function_name.to_string(),
                 params,
@@ -946,7 +998,7 @@ impl<Deps: TestDependencies> TestDsl for TestDependenciesDsl<Deps> {
 
     async fn invoke_and_await(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> crate::Result<Result<Vec<Value>, Error>> {
@@ -955,7 +1007,7 @@ impl<Deps: TestDependencies> TestDsl for TestDependenciesDsl<Deps> {
 
     async fn invoke_and_await_with_key(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         idempotency_key: &IdempotencyKey,
         function_name: &str,
         params: Vec<ValueAndType>,
@@ -972,7 +1024,7 @@ impl<Deps: TestDependencies> TestDsl for TestDependenciesDsl<Deps> {
 
     async fn invoke_and_await_custom(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> crate::Result<Result<Vec<Value>, Error>> {
@@ -989,18 +1041,17 @@ impl<Deps: TestDependencies> TestDsl for TestDependenciesDsl<Deps> {
 
     async fn invoke_and_await_custom_with_key(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         idempotency_key: &IdempotencyKey,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> crate::Result<Result<Vec<Value>, Error>> {
-        let target_worker_id: TargetWorkerId = worker_id.into();
         let invoke_response = self
             .deps
             .worker_service()
             .invoke_and_await(
                 &self.token,
-                target_worker_id.into(),
+                worker_id.clone().into(),
                 Some(idempotency_key.clone().into()),
                 function_name.to_string(),
                 params,
@@ -1027,7 +1078,7 @@ impl<Deps: TestDependencies> TestDsl for TestDependenciesDsl<Deps> {
 
     async fn invoke_and_await_typed(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> crate::Result<Result<Option<ValueAndType>, Error>> {
@@ -1036,7 +1087,7 @@ impl<Deps: TestDependencies> TestDsl for TestDependenciesDsl<Deps> {
 
     async fn invoke_and_await_typed_custom(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> crate::Result<Result<Option<ValueAndType>, Error>> {
@@ -1053,7 +1104,7 @@ impl<Deps: TestDependencies> TestDsl for TestDependenciesDsl<Deps> {
 
     async fn invoke_and_await_typed_with_key(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         idempotency_key: &IdempotencyKey,
         function_name: &str,
         params: Vec<ValueAndType>,
@@ -1070,18 +1121,17 @@ impl<Deps: TestDependencies> TestDsl for TestDependenciesDsl<Deps> {
 
     async fn invoke_and_await_typed_custom_with_key(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         idempotency_key: &IdempotencyKey,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> crate::Result<Result<Option<ValueAndType>, Error>> {
-        let target_worker_id: TargetWorkerId = worker_id.into();
         let invoke_response = self
             .deps
             .worker_service()
             .invoke_and_await_typed(
                 &self.token,
-                target_worker_id.into(),
+                worker_id.clone().into(),
                 Some(idempotency_key.clone().into()),
                 function_name.to_string(),
                 params,
@@ -1094,15 +1144,12 @@ impl<Deps: TestDependencies> TestDsl for TestDependenciesDsl<Deps> {
             Some(invoke_and_await_typed_response::Result::Success(response)) => {
                 match response.result {
                     None => Ok(Ok(None)),
-                    Some(response) => match response.type_annotated_value {
-                        Some(response) => {
-                            let response: ValueAndType = response.try_into().map_err(|err| {
-                                anyhow!("Invocation result had unexpected format: {err}")
-                            })?;
-                            Ok(Ok(Some(response)))
-                        }
-                        None => Err(anyhow!("Missing type_annotated_value field")),
-                    },
+                    Some(response) => {
+                        let response: ValueAndType = response.try_into().map_err(|err| {
+                            anyhow!("Invocation result had unexpected format: {err}")
+                        })?;
+                        Ok(Ok(Some(response)))
+                    }
                 }
             }
             Some(invoke_and_await_typed_response::Result::Error(WorkerError {
@@ -1116,11 +1163,10 @@ impl<Deps: TestDependencies> TestDsl for TestDependenciesDsl<Deps> {
 
     async fn invoke_and_await_json(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         function_name: &str,
         params: Vec<serde_json::Value>,
     ) -> crate::Result<Result<serde_json::Value, Error>> {
-        let target_worker_id: TargetWorkerId = worker_id.into();
         let params = params.into_iter().map(|p| p.to_string()).collect();
         let invoke_response = self
             .deps
@@ -1128,7 +1174,7 @@ impl<Deps: TestDependencies> TestDsl for TestDependenciesDsl<Deps> {
             .invoke_and_await_json(
                 &self.token,
                 InvokeAndAwaitJsonRequest {
-                    worker_id: Some(target_worker_id.into()),
+                    worker_id: Some(worker_id.clone().into()),
                     idempotency_key: Some(IdempotencyKey::fresh().into()),
                     function: function_name.to_string(),
                     invoke_parameters: params,
@@ -1556,27 +1602,25 @@ impl<Deps: TestDependencies> TestDsl for TestDependenciesDsl<Deps> {
         Ok(())
     }
 
-    async fn list_directory(
+    async fn get_file_system_node(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         path: &str,
     ) -> crate::Result<Vec<ComponentFileSystemNode>> {
-        let target_worker_id: TargetWorkerId = worker_id.into();
-
         let response = self
             .deps
             .worker_service()
-            .list_directory(
+            .get_file_system_node(
                 &self.token,
-                ListDirectoryRequest {
-                    worker_id: Some(target_worker_id.into()),
+                GetFileSystemNodeRequest {
+                    worker_id: Some(worker_id.clone().into()),
                     path: path.to_string(),
                 },
             )
             .await?;
 
         match response.result {
-            Some(list_directory_response::Result::Success(response)) => {
+            Some(get_file_system_node_response::Result::Success(response)) => {
                 let converted = response
                     .nodes
                     .into_iter()
@@ -1589,18 +1633,13 @@ impl<Deps: TestDependencies> TestDsl for TestDependenciesDsl<Deps> {
         }
     }
 
-    async fn get_file_contents(
-        &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
-        path: &str,
-    ) -> crate::Result<Bytes> {
-        let target_worker_id: TargetWorkerId = worker_id.into();
+    async fn get_file_contents(&self, worker_id: &WorkerId, path: &str) -> crate::Result<Bytes> {
         self.deps
             .worker_service()
             .get_file_contents(
                 &self.token,
                 GetFileContentsRequest {
-                    worker_id: Some(target_worker_id.into()),
+                    worker_id: Some(worker_id.clone().into()),
                     file_path: path.to_string(),
                 },
             )
@@ -1647,48 +1686,6 @@ impl<Deps: TestDependencies> TestDsl for TestDependenciesDsl<Deps> {
             .await
     }
 
-    async fn wait_for_status(
-        &self,
-        worker_id: &WorkerId,
-        status: WorkerStatus,
-        timeout: Duration,
-    ) -> crate::Result<WorkerMetadata> {
-        TestDsl::wait_for_statuses(self, worker_id, &[status], timeout).await
-    }
-
-    async fn wait_for_statuses(
-        &self,
-        worker_id: &WorkerId,
-        statuses: &[WorkerStatus],
-        timeout: Duration,
-    ) -> crate::Result<WorkerMetadata> {
-        let start = Instant::now();
-        let mut last_known = None;
-        while start.elapsed() < timeout {
-            let (metadata, _) = TestDsl::get_worker_metadata(self, worker_id)
-                .await?
-                .ok_or(anyhow!("Worker not found"))?;
-            if statuses
-                .iter()
-                .any(|s| s == &metadata.last_known_status.status)
-            {
-                return Ok(metadata);
-            }
-
-            last_known = Some(metadata.last_known_status.status.clone());
-            tokio::time::sleep(Duration::from_millis(50)).await;
-        }
-
-        Err(anyhow!(
-            "Timeout waiting for worker status {} (last known: {last_known:?})",
-            statuses
-                .iter()
-                .map(|s| format!("{s:?}"))
-                .collect::<Vec<_>>()
-                .join(", ")
-        ))
-    }
-
     async fn fork_worker(
         &self,
         source_worker_id: &WorkerId,
@@ -2047,8 +2044,18 @@ pub fn to_worker_metadata(
                 .iter()
                 .map(|(k, v)| (k.clone(), v.clone()))
                 .collect::<Vec<_>>(),
-            account_id: metadata
-                .account_id
+            wasi_config_vars: metadata
+                .wasi_config_vars
+                .clone()
+                .expect("no wasi_config_vars_field")
+                .into(),
+            project_id: metadata
+                .project_id
+                .expect("no project_id")
+                .try_into()
+                .expect("invalid project_id"),
+            created_by: metadata
+                .created_by
                 .clone()
                 .expect("no account_id")
                 .clone()
@@ -2117,16 +2124,13 @@ pub fn to_worker_metadata(
                 owned_resources: metadata
                     .owned_resources
                     .iter()
-                    .map(|(k, v)| {
+                    .map(|desc| {
                         (
-                            WorkerResourceId(*k),
+                            WorkerResourceId(desc.resource_id),
                             WorkerResourceDescription {
-                                created_at: (*v
-                                    .created_at
-                                    .as_ref()
-                                    .expect("no timestamp on resource metadata"))
-                                .into(),
-                                indexed_resource_key: v.indexed.clone().map(|i| i.into()),
+                                created_at: desc.created_at.expect("Missing created_at").into(),
+                                resource_name: desc.resource_name.clone(),
+                                resource_owner: desc.resource_owner.clone(),
                             },
                         )
                     })
@@ -2206,6 +2210,7 @@ pub trait TestDslUnsafe {
         name: &str,
         args: Vec<String>,
         env: HashMap<String, String>,
+        wasi_config_vars: Vec<(String, String)>,
     ) -> WorkerId;
     async fn try_start_worker_with(
         &self,
@@ -2213,6 +2218,7 @@ pub trait TestDslUnsafe {
         name: &str,
         args: Vec<String>,
         env: HashMap<String, String>,
+        wasi_config_vars: Vec<(String, String)>,
     ) -> Result<WorkerId, Error>;
     async fn get_worker_metadata(
         &self,
@@ -2245,46 +2251,46 @@ pub trait TestDslUnsafe {
 
     async fn invoke(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> Result<(), Error>;
     async fn invoke_with_key(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         idempotency_key: &IdempotencyKey,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> Result<(), Error>;
     async fn invoke_and_await(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> Result<Vec<Value>, Error>;
     async fn invoke_and_await_with_key(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         idempotency_key: &IdempotencyKey,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> Result<Vec<Value>, Error>;
     async fn invoke_and_await_typed(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> Result<Option<ValueAndType>, Error>;
     async fn invoke_and_await_typed_with_key(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         idempotency_key: &IdempotencyKey,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> Result<Option<ValueAndType>, Error>;
     async fn invoke_and_await_json(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         function_name: &str,
         params: Vec<serde_json::Value>,
     ) -> Result<serde_json::Value, Error>;
@@ -2292,10 +2298,7 @@ pub trait TestDslUnsafe {
     async fn capture_output_forever(
         &self,
         worker_id: &WorkerId,
-    ) -> (
-        UnboundedReceiver<Option<LogEvent>>,
-        tokio::sync::oneshot::Sender<()>,
-    );
+    ) -> (UnboundedReceiver<Option<LogEvent>>, Sender<()>);
     async fn capture_output_with_termination(
         &self,
         worker_id: &WorkerId,
@@ -2319,16 +2322,12 @@ pub trait TestDslUnsafe {
 
     async fn check_oplog_is_queryable(&self, worker_id: &WorkerId);
 
-    async fn list_directory(
+    async fn get_file_system_node(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         path: &str,
     ) -> Vec<ComponentFileSystemNode>;
-    async fn get_file_contents(
-        &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
-        path: &str,
-    ) -> Bytes;
+    async fn get_file_contents(&self, worker_id: &WorkerId, path: &str) -> Bytes;
 
     async fn create_plugin(&self, definition: PluginDefinitionCreation);
 
@@ -2416,12 +2415,6 @@ impl<T: TestDsl + Sync> TestDslUnsafe for T {
             .expect("Failed to get latest component metadata")
     }
 
-    async fn add_plugin_wasm(&self, name: &str) -> PluginWasmFileKey {
-        <T as TestDsl>::add_plugin_wasm(self, name)
-            .await
-            .expect("Failed to add plugin wasm")
-    }
-
     async fn update_component(&self, component_id: &ComponentId, name: &str) -> ComponentVersion {
         <T as TestDsl>::update_component(self, component_id, name).await
     }
@@ -2455,6 +2448,12 @@ impl<T: TestDsl + Sync> TestDslUnsafe for T {
         <T as TestDsl>::add_initial_component_files(self, files).await
     }
 
+    async fn add_plugin_wasm(&self, name: &str) -> PluginWasmFileKey {
+        <T as TestDsl>::add_plugin_wasm(self, name)
+            .await
+            .expect("Failed to add plugin wasm")
+    }
+
     async fn start_worker(&self, component_id: &ComponentId, name: &str) -> WorkerId {
         <T as TestDsl>::start_worker(self, component_id, name)
             .await
@@ -2477,8 +2476,9 @@ impl<T: TestDsl + Sync> TestDslUnsafe for T {
         name: &str,
         args: Vec<String>,
         env: HashMap<String, String>,
+        wasi_config_vars: Vec<(String, String)>,
     ) -> WorkerId {
-        <T as TestDsl>::start_worker_with(self, component_id, name, args, env)
+        <T as TestDsl>::start_worker_with(self, component_id, name, args, env, wasi_config_vars)
             .await
             .expect("Failed to start worker")
     }
@@ -2489,8 +2489,9 @@ impl<T: TestDsl + Sync> TestDslUnsafe for T {
         name: &str,
         args: Vec<String>,
         env: HashMap<String, String>,
+        wasi_config_vars: Vec<(String, String)>,
     ) -> Result<WorkerId, Error> {
-        <T as TestDsl>::try_start_worker_with(self, component_id, name, args, env)
+        <T as TestDsl>::try_start_worker_with(self, component_id, name, args, env, wasi_config_vars)
             .await
             .expect("Failed to start worker")
     }
@@ -2504,6 +2505,28 @@ impl<T: TestDsl + Sync> TestDslUnsafe for T {
             .expect("Failed to get worker metadata")
     }
 
+    async fn wait_for_status(
+        &self,
+        worker_id: &WorkerId,
+        status: WorkerStatus,
+        timeout: Duration,
+    ) -> WorkerMetadata {
+        <T as TestDsl>::wait_for_status(self, worker_id, status, timeout)
+            .await
+            .expect("Failed to wait for status")
+    }
+
+    async fn wait_for_statuses(
+        &self,
+        worker_id: &WorkerId,
+        statuses: &[WorkerStatus],
+        timeout: Duration,
+    ) -> WorkerMetadata {
+        <T as TestDsl>::wait_for_statuses(self, worker_id, statuses, timeout)
+            .await
+            .expect("Failed to wait for status")
+    }
+
     async fn get_workers_metadata(
         &self,
         component_id: &ComponentId,
@@ -2525,7 +2548,7 @@ impl<T: TestDsl + Sync> TestDslUnsafe for T {
 
     async fn invoke(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> Result<(), Error> {
@@ -2536,7 +2559,7 @@ impl<T: TestDsl + Sync> TestDslUnsafe for T {
 
     async fn invoke_with_key(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         idempotency_key: &IdempotencyKey,
         function_name: &str,
         params: Vec<ValueAndType>,
@@ -2548,7 +2571,7 @@ impl<T: TestDsl + Sync> TestDslUnsafe for T {
 
     async fn invoke_and_await(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> Result<Vec<Value>, Error> {
@@ -2556,21 +2579,9 @@ impl<T: TestDsl + Sync> TestDslUnsafe for T {
             .await
             .expect("Failed to invoke function")
     }
-
-    async fn invoke_and_await_json(
-        &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
-        function_name: &str,
-        params: Vec<serde_json::Value>,
-    ) -> Result<serde_json::Value, Error> {
-        <T as TestDsl>::invoke_and_await_json(self, worker_id, function_name, params)
-            .await
-            .expect("Failed to invoke function")
-    }
-
     async fn invoke_and_await_with_key(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         idempotency_key: &IdempotencyKey,
         function_name: &str,
         params: Vec<ValueAndType>,
@@ -2587,7 +2598,7 @@ impl<T: TestDsl + Sync> TestDslUnsafe for T {
     }
     async fn invoke_and_await_typed(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         function_name: &str,
         params: Vec<ValueAndType>,
     ) -> Result<Option<ValueAndType>, Error> {
@@ -2597,7 +2608,7 @@ impl<T: TestDsl + Sync> TestDslUnsafe for T {
     }
     async fn invoke_and_await_typed_with_key(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         idempotency_key: &IdempotencyKey,
         function_name: &str,
         params: Vec<ValueAndType>,
@@ -2612,6 +2623,18 @@ impl<T: TestDsl + Sync> TestDslUnsafe for T {
         .await
         .expect("Failed to invoke function")
     }
+
+    async fn invoke_and_await_json(
+        &self,
+        worker_id: &WorkerId,
+        function_name: &str,
+        params: Vec<serde_json::Value>,
+    ) -> Result<serde_json::Value, Error> {
+        <T as TestDsl>::invoke_and_await_json(self, worker_id, function_name, params)
+            .await
+            .expect("Failed to invoke function")
+    }
+
     async fn capture_output(&self, worker_id: &WorkerId) -> UnboundedReceiver<LogEvent> {
         <T as TestDsl>::capture_output(self, worker_id).await
     }
@@ -2683,27 +2706,23 @@ impl<T: TestDsl + Sync> TestDslUnsafe for T {
             .await
             .expect("Failed to search oplog")
     }
-
     async fn check_oplog_is_queryable(&self, worker_id: &WorkerId) -> () {
         <T as TestDsl>::check_oplog_is_queryable(self, worker_id)
             .await
             .expect("Oplog check failed")
     }
 
-    async fn list_directory(
+    async fn get_file_system_node(
         &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
+        worker_id: &WorkerId,
         path: &str,
     ) -> Vec<ComponentFileSystemNode> {
-        <T as TestDsl>::list_directory(self, worker_id, path)
+        <T as TestDsl>::get_file_system_node(self, worker_id, path)
             .await
-            .expect("Failed to list directory")
+            .expect("Failed to get file system node")
     }
-    async fn get_file_contents(
-        &self,
-        worker_id: impl Into<TargetWorkerId> + Send + Sync,
-        path: &str,
-    ) -> Bytes {
+
+    async fn get_file_contents(&self, worker_id: &WorkerId, path: &str) -> Bytes {
         <T as TestDsl>::get_file_contents(self, worker_id, path)
             .await
             .expect("Failed to get file contents")
@@ -2741,28 +2760,6 @@ impl<T: TestDsl + Sync> TestDslUnsafe for T {
         .expect("Failed to install plugin")
     }
 
-    async fn wait_for_status(
-        &self,
-        worker_id: &WorkerId,
-        status: WorkerStatus,
-        timeout: Duration,
-    ) -> WorkerMetadata {
-        <T as TestDsl>::wait_for_status(self, worker_id, status, timeout)
-            .await
-            .expect("Failed to wait for status")
-    }
-
-    async fn wait_for_statuses(
-        &self,
-        worker_id: &WorkerId,
-        statuses: &[WorkerStatus],
-        timeout: Duration,
-    ) -> WorkerMetadata {
-        <T as TestDsl>::wait_for_statuses(self, worker_id, statuses, timeout)
-            .await
-            .expect("Failed to wait for status")
-    }
-
     async fn fork_worker(
         &self,
         source_worker_id: &WorkerId,
@@ -2836,12 +2833,12 @@ fn rename_component_if_needed(temp_dir: &Path, path: &Path, name: &str) -> anyho
         Ok(path.to_path_buf())
     } else {
         let new_path = Builder::new().disable_cleanup(true).tempfile_in(temp_dir)?;
-        let add_metadata = AddMetadata {
-            name: Some(name.to_string()),
-            version: metadata
-                .root_package_version
-                .map(|v| wasm_metadata::Version::new(v.to_string())),
-            ..Default::default()
+        let mut add_metadata = AddMetadata::default();
+        add_metadata.name = AddMetadataField::Set(name.to_string());
+        add_metadata.version = if let Some(v) = &metadata.root_package_version {
+            AddMetadataField::Set(wasm_metadata::Version::new(v.to_string()))
+        } else {
+            AddMetadataField::Clear
         };
 
         info!(
diff --git a/golem-worker-executor/Cargo.toml b/golem-worker-executor/Cargo.toml
index d8388c29..2c62bf91 100644
--- a/golem-worker-executor/Cargo.toml
+++ b/golem-worker-executor/Cargo.toml
@@ -24,38 +24,37 @@ test = false
 [features]
 
 [dependencies]
-golem-api-grpc = { path = "../golem-api-grpc", version = "=0.0.0" }
-golem-common = { path = "../golem-common", version = "=0.0.0" }
-golem-rib = { path = "../golem-rib", version = "=0.0.0" }
-golem-service-base = { path = "../golem-service-base", version = "=0.0.0", features = [ "worker-executor" ] }
-golem-wasm-ast = { path = "../wasm-ast", version = "=0.0.0" }
-golem-wasm-rpc = { path = "../wasm-rpc", version = "=0.0.0", default-features = false, features = ["host", "extra-bindings"] }
-golem-wasm-rpc-derive = { path = "../wasm-rpc-derive", version = "=0.0.0" }
+golem-api-grpc = { workspace = true }
+golem-common = { workspace = true, default-features = true }
+golem-rib = { workspace = true, default-features = true }
+golem-service-base = { workspace = true, features = ["worker-executor"] }
+golem-wasm-ast = { workspace = true, default-features = true }
+golem-wasm-rpc = { workspace = true, features = ["host", "extra-bindings"] }
+golem-wasm-rpc-derive = { workspace = true }
 
 anyhow = { workspace = true }
-applying = "1.0.1"
-async-lock = "3.4.0"
-async-mutex = "1.4.0"
-async-dropper-simple = { version = "0.2.6", features = ["no-default-bound", "tokio"] }
+applying = { workspace = true }
+async-lock = { workspace = true }
+async-mutex = { workspace = true }
+async-dropper-simple = { workspace = true, features = ["no-default-bound", "tokio"] }
 async-recursion = { workspace = true }
-async-scoped = { version = "0.9.0", features = ["use-tokio"] }
+async-scoped = { workspace = true, features = ["use-tokio"] }
 async-trait = { workspace = true }
 bincode = { workspace = true }
 bigdecimal = { workspace = true }
 bit-vec = { workspace = true }
 bytes = { workspace = true }
 cap-std = { workspace = true }
-cap-time-ext = "3.4.2"                              # keep in sync with wasmtime
+cap-time-ext = { workspace = true }                              # keep in sync with wasmtime
 chrono = { workspace = true }
 dashmap = { workspace = true }
 drop-stream = { workspace = true }
-evicting_cache_map = "0.4.0"
+evicting_cache_map = { workspace = true }
 figment = { workspace = true }
 fred = { workspace = true }
-fs-set-times = "0.20.3"
+fs-set-times = { workspace = true }
 futures = { workspace = true }
-futures-util = { workspace = true }
-gethostname = "1.0.0"
+gethostname = { workspace = true }
 hex = { workspace = true }
 http = { workspace = true }
 http-body = { workspace = true }
@@ -65,20 +64,20 @@ humantime-serde = { workspace = true }
 hyper = { workspace = true }
 itertools = { workspace = true }
 lazy_static = { workspace = true }
-log = "0.4.26"
-mac_address = { version = "1.1.8", features = ["serde"] }
-md5 = "0.7.0"
-metrohash = "1.0.7"
+log = { workspace = true }
+mac_address = { workspace = true, features = ["serde"] }
+md5 = { workspace = true }
+metrohash = { workspace = true }
 nonempty-collections = { workspace = true }
 prometheus = { workspace = true }
 prost = { workspace = true }
 rand = { workspace = true }
-ringbuf = "0.4.7"
+ringbuf = { workspace = true }
 serde = { workspace = true }
 serde_json = { workspace = true }
 sqlx = { workspace = true }
 sqlx-core = { workspace = true }
-sysinfo = "0.33.1"
+sysinfo = { workspace = true }
 tempfile = { workspace = true }
 tokio = { workspace = true }
 tokio-stream = { workspace = true }
@@ -87,20 +86,20 @@ tonic = { workspace = true }
 tonic-health = { workspace = true }
 tonic-reflection = { workspace = true }
 tracing = { workspace = true }
-try_match = "0.4.2"
+try_match = { workspace = true }
 url = { workspace = true }
 uuid = { workspace = true }
 wasmtime = { workspace = true }
 wasmtime-wasi = { workspace = true }
 wasmtime-wasi-http = { workspace = true }
-zstd = "0.13"
+zstd = { workspace = true }
 
 [dev-dependencies]
-golem-test-framework = { path = "../golem-test-framework", version = "=0.0.0" }
+golem-test-framework = { workspace = true }
 
 assert2 = { workspace = true }
 axum = { workspace = true }
-goldenfile = "1.8.0"
+goldenfile = { workspace = true }
 proptest = { workspace = true }
 rand = { workspace = true }
 redis = { workspace = true }
diff --git a/golem-worker-executor/config/worker-executor.sample.env b/golem-worker-executor/config/worker-executor.sample.env
index 860a053c..ec1a81b2 100644
--- a/golem-worker-executor/config/worker-executor.sample.env
+++ b/golem-worker-executor/config/worker-executor.sample.env
@@ -7,13 +7,23 @@ GOLEM__PORT=9000
 GOLEM__TRACING_FILE_NAME_WITH_PORT=true
 GOLEM__ACTIVE_WORKERS__DROP_WHEN_FULL=0.25
 GOLEM__ACTIVE_WORKERS__TTL="8h"
+GOLEM__AGENT_TYPES_SERVICE__TYPE="Grpc"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__ACCESS_TOKEN="2a354594-7a63-4091-a46b-cc58d379f677"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__CACHE_TIME_TO_IDLE="1m"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__CONNECT_TIMEOUT="30s"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__HOST="localhost"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__PORT=9092
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__RETRIES__MAX_ATTEMPTS=3
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__RETRIES__MAX_DELAY="1s"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__RETRIES__MAX_JITTER_FACTOR=0.15
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__RETRIES__MIN_DELAY="100ms"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__RETRIES__MULTIPLIER=3.0
 GOLEM__BLOB_STORAGE__TYPE="LocalFileSystem"
 GOLEM__BLOB_STORAGE__CONFIG__ROOT="../data/blob_storage"
 GOLEM__COMPILED_COMPONENT_SERVICE__TYPE="Enabled"
 GOLEM__COMPONENT_CACHE__MAX_CAPACITY=32
 GOLEM__COMPONENT_CACHE__MAX_METADATA_CAPACITY=16384
 GOLEM__COMPONENT_CACHE__MAX_RESOLVED_COMPONENT_CAPACITY=1024
-GOLEM__COMPONENT_CACHE__MAX_RESOLVED_PROJECT_CAPACITY=1024
 GOLEM__COMPONENT_CACHE__TIME_TO_IDLE="12h"
 GOLEM__COMPONENT_SERVICE__TYPE="Grpc"
 GOLEM__COMPONENT_SERVICE__CONFIG__ACCESS_TOKEN="2a354594-7a63-4091-a46b-cc58d379f677"
@@ -79,8 +89,10 @@ GOLEM__PLUGIN_SERVICE__CONFIG__RETRIES__MIN_DELAY="100ms"
 GOLEM__PLUGIN_SERVICE__CONFIG__RETRIES__MULTIPLIER=3.0
 GOLEM__PROJECT_SERVICE__TYPE="Grpc"
 GOLEM__PROJECT_SERVICE__CONFIG__ACCESS_TOKEN="2a354594-7a63-4091-a46b-cc58d379f677"
+GOLEM__PROJECT_SERVICE__CONFIG__CACHE_TIME_TO_IDLE="12h"
 GOLEM__PROJECT_SERVICE__CONFIG__CONNECT_TIMEOUT="30s"
 GOLEM__PROJECT_SERVICE__CONFIG__HOST="localhost"
+GOLEM__PROJECT_SERVICE__CONFIG__MAX_RESOLVED_PROJECT_CACHE_CAPACITY=1024
 GOLEM__PROJECT_SERVICE__CONFIG__PORT=9091
 GOLEM__PROJECT_SERVICE__CONFIG__RETRIES__MAX_ATTEMPTS=3
 GOLEM__PROJECT_SERVICE__CONFIG__RETRIES__MAX_DELAY="1s"
@@ -160,6 +172,17 @@ GOLEM__PORT=9000
 GOLEM__TRACING_FILE_NAME_WITH_PORT=true
 GOLEM__ACTIVE_WORKERS__DROP_WHEN_FULL=0.25
 GOLEM__ACTIVE_WORKERS__TTL="8h"
+GOLEM__AGENT_TYPES_SERVICE__TYPE="Grpc"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__ACCESS_TOKEN="2a354594-7a63-4091-a46b-cc58d379f677"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__CACHE_TIME_TO_IDLE="1m"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__CONNECT_TIMEOUT="30s"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__HOST="localhost"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__PORT=9092
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__RETRIES__MAX_ATTEMPTS=3
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__RETRIES__MAX_DELAY="1s"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__RETRIES__MAX_JITTER_FACTOR=0.15
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__RETRIES__MIN_DELAY="100ms"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__RETRIES__MULTIPLIER=3.0
 GOLEM__BLOB_STORAGE__TYPE="S3"
 #GOLEM__BLOB_STORAGE__CONFIG__AWS_ENDPOINT_URL=
 GOLEM__BLOB_STORAGE__CONFIG__COMPILATION_CACHE_BUCKET="golem-compiled-components"
@@ -181,7 +204,6 @@ GOLEM__COMPILED_COMPONENT_SERVICE__TYPE="Enabled"
 GOLEM__COMPONENT_CACHE__MAX_CAPACITY=32
 GOLEM__COMPONENT_CACHE__MAX_METADATA_CAPACITY=16384
 GOLEM__COMPONENT_CACHE__MAX_RESOLVED_COMPONENT_CAPACITY=1024
-GOLEM__COMPONENT_CACHE__MAX_RESOLVED_PROJECT_CAPACITY=1024
 GOLEM__COMPONENT_CACHE__TIME_TO_IDLE="12h"
 GOLEM__COMPONENT_SERVICE__TYPE="Grpc"
 GOLEM__COMPONENT_SERVICE__CONFIG__ACCESS_TOKEN="2a354594-7a63-4091-a46b-cc58d379f677"
@@ -247,8 +269,10 @@ GOLEM__PLUGIN_SERVICE__CONFIG__RETRIES__MIN_DELAY="100ms"
 GOLEM__PLUGIN_SERVICE__CONFIG__RETRIES__MULTIPLIER=3.0
 GOLEM__PROJECT_SERVICE__TYPE="Grpc"
 GOLEM__PROJECT_SERVICE__CONFIG__ACCESS_TOKEN="2a354594-7a63-4091-a46b-cc58d379f677"
+GOLEM__PROJECT_SERVICE__CONFIG__CACHE_TIME_TO_IDLE="12h"
 GOLEM__PROJECT_SERVICE__CONFIG__CONNECT_TIMEOUT="30s"
 GOLEM__PROJECT_SERVICE__CONFIG__HOST="localhost"
+GOLEM__PROJECT_SERVICE__CONFIG__MAX_RESOLVED_PROJECT_CACHE_CAPACITY=1024
 GOLEM__PROJECT_SERVICE__CONFIG__PORT=9091
 GOLEM__PROJECT_SERVICE__CONFIG__RETRIES__MAX_ATTEMPTS=3
 GOLEM__PROJECT_SERVICE__CONFIG__RETRIES__MAX_DELAY="1s"
@@ -321,12 +345,22 @@ GOLEM__PORT=9000
 GOLEM__TRACING_FILE_NAME_WITH_PORT=true
 GOLEM__ACTIVE_WORKERS__DROP_WHEN_FULL=0.25
 GOLEM__ACTIVE_WORKERS__TTL="8h"
+GOLEM__AGENT_TYPES_SERVICE__TYPE="Grpc"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__ACCESS_TOKEN="2a354594-7a63-4091-a46b-cc58d379f677"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__CACHE_TIME_TO_IDLE="1m"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__CONNECT_TIMEOUT="30s"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__HOST="localhost"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__PORT=9092
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__RETRIES__MAX_ATTEMPTS=3
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__RETRIES__MAX_DELAY="1s"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__RETRIES__MAX_JITTER_FACTOR=0.15
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__RETRIES__MIN_DELAY="100ms"
+GOLEM__AGENT_TYPES_SERVICE__CONFIG__RETRIES__MULTIPLIER=3.0
 GOLEM__BLOB_STORAGE__TYPE="InMemory"
 GOLEM__COMPILED_COMPONENT_SERVICE__TYPE="Enabled"
 GOLEM__COMPONENT_CACHE__MAX_CAPACITY=32
 GOLEM__COMPONENT_CACHE__MAX_METADATA_CAPACITY=16384
 GOLEM__COMPONENT_CACHE__MAX_RESOLVED_COMPONENT_CAPACITY=1024
-GOLEM__COMPONENT_CACHE__MAX_RESOLVED_PROJECT_CAPACITY=1024
 GOLEM__COMPONENT_CACHE__TIME_TO_IDLE="12h"
 GOLEM__COMPONENT_SERVICE__TYPE="Grpc"
 GOLEM__COMPONENT_SERVICE__CONFIG__ACCESS_TOKEN="2a354594-7a63-4091-a46b-cc58d379f677"
@@ -379,8 +413,10 @@ GOLEM__PLUGIN_SERVICE__CONFIG__RETRIES__MIN_DELAY="100ms"
 GOLEM__PLUGIN_SERVICE__CONFIG__RETRIES__MULTIPLIER=3.0
 GOLEM__PROJECT_SERVICE__TYPE="Grpc"
 GOLEM__PROJECT_SERVICE__CONFIG__ACCESS_TOKEN="2a354594-7a63-4091-a46b-cc58d379f677"
+GOLEM__PROJECT_SERVICE__CONFIG__CACHE_TIME_TO_IDLE="12h"
 GOLEM__PROJECT_SERVICE__CONFIG__CONNECT_TIMEOUT="30s"
 GOLEM__PROJECT_SERVICE__CONFIG__HOST="localhost"
+GOLEM__PROJECT_SERVICE__CONFIG__MAX_RESOLVED_PROJECT_CACHE_CAPACITY=1024
 GOLEM__PROJECT_SERVICE__CONFIG__PORT=9091
 GOLEM__PROJECT_SERVICE__CONFIG__RETRIES__MAX_ATTEMPTS=3
 GOLEM__PROJECT_SERVICE__CONFIG__RETRIES__MAX_DELAY="1s"
diff --git a/golem-worker-executor/config/worker-executor.toml b/golem-worker-executor/config/worker-executor.toml
index 0f55043f..a50d7b75 100644
--- a/golem-worker-executor/config/worker-executor.toml
+++ b/golem-worker-executor/config/worker-executor.toml
@@ -9,6 +9,23 @@ tracing_file_name_with_port = true
 drop_when_full = 0.25
 ttl = "8h"
 
+[agent_types_service]
+type = "Grpc"
+
+[agent_types_service.config]
+access_token = "2a354594-7a63-4091-a46b-cc58d379f677"
+cache_time_to_idle = "1m"
+connect_timeout = "30s"
+host = "localhost"
+port = 9092
+
+[agent_types_service.config.retries]
+max_attempts = 3
+max_delay = "1s"
+max_jitter_factor = 0.15
+min_delay = "100ms"
+multiplier = 3.0
+
 [blob_storage]
 type = "LocalFileSystem"
 
@@ -24,7 +41,6 @@ type = "Enabled"
 max_capacity = 32
 max_metadata_capacity = 16384
 max_resolved_component_capacity = 1024
-max_resolved_project_capacity = 1024
 time_to_idle = "12h"
 
 [component_service]
@@ -120,8 +136,10 @@ type = "Grpc"
 
 [project_service.config]
 access_token = "2a354594-7a63-4091-a46b-cc58d379f677"
+cache_time_to_idle = "12h"
 connect_timeout = "30s"
 host = "localhost"
+max_resolved_project_cache_capacity = 1024
 port = 9091
 
 [project_service.config.retries]
@@ -237,6 +255,23 @@ without_time = false
 # drop_when_full = 0.25
 # ttl = "8h"
 # 
+# [agent_types_service]
+# type = "Grpc"
+# 
+# [agent_types_service.config]
+# access_token = "2a354594-7a63-4091-a46b-cc58d379f677"
+# cache_time_to_idle = "1m"
+# connect_timeout = "30s"
+# host = "localhost"
+# port = 9092
+# 
+# [agent_types_service.config.retries]
+# max_attempts = 3
+# max_delay = "1s"
+# max_jitter_factor = 0.15
+# min_delay = "100ms"
+# multiplier = 3.0
+# 
 # [blob_storage]
 # type = "S3"
 # 
@@ -268,7 +303,6 @@ without_time = false
 # max_capacity = 32
 # max_metadata_capacity = 16384
 # max_resolved_component_capacity = 1024
-# max_resolved_project_capacity = 1024
 # time_to_idle = "12h"
 # 
 # [component_service]
@@ -364,8 +398,10 @@ without_time = false
 # 
 # [project_service.config]
 # access_token = "2a354594-7a63-4091-a46b-cc58d379f677"
+# cache_time_to_idle = "12h"
 # connect_timeout = "30s"
 # host = "localhost"
+# max_resolved_project_cache_capacity = 1024
 # port = 9091
 # 
 # [project_service.config.retries]
@@ -471,6 +507,23 @@ without_time = false
 # drop_when_full = 0.25
 # ttl = "8h"
 # 
+# [agent_types_service]
+# type = "Grpc"
+# 
+# [agent_types_service.config]
+# access_token = "2a354594-7a63-4091-a46b-cc58d379f677"
+# cache_time_to_idle = "1m"
+# connect_timeout = "30s"
+# host = "localhost"
+# port = 9092
+# 
+# [agent_types_service.config.retries]
+# max_attempts = 3
+# max_delay = "1s"
+# max_jitter_factor = 0.15
+# min_delay = "100ms"
+# multiplier = 3.0
+# 
 # [blob_storage]
 # type = "InMemory"
 # 
@@ -485,7 +538,6 @@ without_time = false
 # max_capacity = 32
 # max_metadata_capacity = 16384
 # max_resolved_component_capacity = 1024
-# max_resolved_project_capacity = 1024
 # time_to_idle = "12h"
 # 
 # [component_service]
@@ -568,8 +620,10 @@ without_time = false
 # 
 # [project_service.config]
 # access_token = "2a354594-7a63-4091-a46b-cc58d379f677"
+# cache_time_to_idle = "12h"
 # connect_timeout = "30s"
 # host = "localhost"
+# max_resolved_project_cache_capacity = 1024
 # port = 9091
 # 
 # [project_service.config.retries]
diff --git a/golem-worker-executor/src/bootstrap.rs b/golem-worker-executor/src/bootstrap.rs
index 3051691e..c850ecbe 100644
--- a/golem-worker-executor/src/bootstrap.rs
+++ b/golem-worker-executor/src/bootstrap.rs
@@ -13,8 +13,9 @@
 // limitations under the License.
 
 use crate::durable_host::DurableWorkerCtx;
-use crate::preview2::{golem_api_1_x, golem_durability};
+use crate::preview2::{golem_agent, golem_api_1_x, golem_durability};
 use crate::services::active_workers::ActiveWorkers;
+use crate::services::agent_types::AgentTypesService;
 use crate::services::blob_store::BlobStoreService;
 use crate::services::component::ComponentService;
 use crate::services::events::Events;
@@ -24,6 +25,7 @@ use crate::services::key_value::KeyValueService;
 use crate::services::oplog::plugin::OplogProcessorPlugin;
 use crate::services::oplog::OplogService;
 use crate::services::plugins::{Plugins, PluginsObservations};
+use crate::services::projects::ProjectService;
 use crate::services::promise::PromiseService;
 use crate::services::rpc::{DirectWorkerInvocationRpc, RemoteInvocationRpc};
 use crate::services::scheduler::SchedulerService;
@@ -38,7 +40,7 @@ use crate::services::worker_fork::DefaultWorkerFork;
 use crate::services::worker_proxy::WorkerProxy;
 use crate::services::{rdbms, resource_limits, All, NoAdditionalDeps};
 use crate::wasi_host::create_linker;
-use crate::workerctx::cloud::Context;
+use crate::workerctx::default::Context;
 use crate::{Bootstrap, RunDetails};
 use async_trait::async_trait;
 use golem_service_base::storage::blob::BlobStorage;
@@ -73,14 +75,15 @@ impl Bootstrap<Context> for ServerBootstrap {
         golem_config: &GolemConfig,
         blob_storage: Arc<dyn BlobStorage>,
         plugin_observations: Arc<dyn PluginsObservations>,
+        project_service: Arc<dyn ProjectService>,
     ) -> Arc<dyn ComponentService> {
         crate::services::component::configured(
             &golem_config.component_service,
-            &golem_config.project_service,
             &golem_config.component_cache,
             &golem_config.compiled_component_service,
             blob_storage,
             plugin_observations,
+            project_service,
         )
     }
 
@@ -109,6 +112,8 @@ impl Bootstrap<Context> for ServerBootstrap {
         file_loader: Arc<FileLoader>,
         plugins: Arc<dyn Plugins>,
         oplog_processor_plugin: Arc<dyn OplogProcessorPlugin>,
+        project_service: Arc<dyn ProjectService>,
+        agent_type_service: Arc<dyn AgentTypesService>,
     ) -> anyhow::Result<All<Context>> {
         let resource_limits = resource_limits::configured(&golem_config.resource_limits);
 
@@ -143,6 +148,8 @@ impl Bootstrap<Context> for ServerBootstrap {
             plugins.clone(),
             oplog_processor_plugin.clone(),
             resource_limits.clone(),
+            project_service.clone(),
+            agent_type_service.clone(),
             additional_deps.clone(),
         ));
 
@@ -175,11 +182,14 @@ impl Bootstrap<Context> for ServerBootstrap {
             plugins.clone(),
             oplog_processor_plugin.clone(),
             resource_limits.clone(),
+            project_service.clone(),
+            agent_type_service.clone(),
             additional_deps.clone(),
         ));
 
         Ok(All::new(
             active_workers,
+            agent_type_service,
             engine,
             linker,
             runtime.clone(),
@@ -205,6 +215,7 @@ impl Bootstrap<Context> for ServerBootstrap {
             plugins.clone(),
             oplog_processor_plugin.clone(),
             resource_limits,
+            project_service,
             additional_deps,
         ))
     }
@@ -215,6 +226,7 @@ impl Bootstrap<Context> for ServerBootstrap {
         golem_api_1_x::oplog::add_to_linker_get_host(&mut linker, get_durable_ctx)?;
         golem_api_1_x::context::add_to_linker_get_host(&mut linker, get_durable_ctx)?;
         golem_durability::durability::add_to_linker_get_host(&mut linker, get_durable_ctx)?;
+        golem_agent::host::add_to_linker_get_host(&mut linker, get_durable_ctx)?;
         golem_wasm_rpc::golem_rpc_0_2_x::types::add_to_linker_get_host(
             &mut linker,
             get_durable_ctx,
diff --git a/golem-worker-executor/src/config.rs b/golem-worker-executor/src/config.rs
index 57820266..a66e2f0b 100644
--- a/golem-worker-executor/src/config.rs
+++ b/golem-worker-executor/src/config.rs
@@ -14,17 +14,12 @@
 
 #[cfg(test)]
 mod tests {
-    use std::env;
-    use std::path::PathBuf;
     use test_r::test;
 
     use crate::services::golem_config::make_config_loader;
 
     #[test]
     pub fn config_is_loadable() {
-        env::set_current_dir(PathBuf::from(env!("CARGO_MANIFEST_DIR")))
-            .expect("Failed to set current directory");
-
         make_config_loader()
             .load()
             .expect("Failed to load base config");
diff --git a/golem-worker-executor/src/durable_host/blobstore/container.rs b/golem-worker-executor/src/durable_host/blobstore/container.rs
index 17261163..695d4502 100644
--- a/golem-worker-executor/src/durable_host/blobstore/container.rs
+++ b/golem-worker-executor/src/durable_host/blobstore/container.rs
@@ -72,7 +72,7 @@ impl<Ctx: WorkerCtx> HostContainer for DurableWorkerCtx<Ctx> {
         )
         .await?;
 
-        let account_id = self.state.owned_worker_id.account_id();
+        let project_id = self.state.owned_worker_id.project_id();
         let container_name = self
             .as_wasi_view()
             .table()
@@ -83,7 +83,7 @@ impl<Ctx: WorkerCtx> HostContainer for DurableWorkerCtx<Ctx> {
             let result = self
                 .state
                 .blob_store_service
-                .get_data(account_id, container_name.clone(), name.clone(), start, end)
+                .get_data(project_id, container_name.clone(), name.clone(), start, end)
                 .await;
             durability
                 .persist(self, (container_name, name, start, end), result)
@@ -117,7 +117,7 @@ impl<Ctx: WorkerCtx> HostContainer for DurableWorkerCtx<Ctx> {
         )
         .await?;
 
-        let account_id = self.state.owned_worker_id.account_id();
+        let project_id = self.state.owned_worker_id.project_id();
         let container_name = self
             .as_wasi_view()
             .table()
@@ -134,7 +134,7 @@ impl<Ctx: WorkerCtx> HostContainer for DurableWorkerCtx<Ctx> {
             let result = self
                 .state
                 .blob_store_service
-                .write_data(account_id, container_name.clone(), name.clone(), data)
+                .write_data(project_id, container_name.clone(), name.clone(), data)
                 .await;
             durability
                 .persist(self, (container_name, name, len), result)
@@ -161,7 +161,7 @@ impl<Ctx: WorkerCtx> HostContainer for DurableWorkerCtx<Ctx> {
         )
         .await?;
 
-        let account_id = self.state.owned_worker_id.account_id();
+        let project_id = self.state.owned_worker_id.project_id();
         let container_name = self
             .as_wasi_view()
             .table()
@@ -172,7 +172,7 @@ impl<Ctx: WorkerCtx> HostContainer for DurableWorkerCtx<Ctx> {
             let result = self
                 .state
                 .blob_store_service
-                .list_objects(account_id, container_name.clone())
+                .list_objects(project_id, container_name.clone())
                 .await;
             durability.persist(self, container_name, result).await
         } else {
@@ -204,7 +204,7 @@ impl<Ctx: WorkerCtx> HostContainer for DurableWorkerCtx<Ctx> {
         )
         .await?;
 
-        let account_id = self.state.owned_worker_id.account_id();
+        let project_id = self.state.owned_worker_id.project_id();
         let container_name = self
             .as_wasi_view()
             .table()
@@ -215,7 +215,7 @@ impl<Ctx: WorkerCtx> HostContainer for DurableWorkerCtx<Ctx> {
             let result = self
                 .state
                 .blob_store_service
-                .delete_object(account_id, container_name.clone(), name.clone())
+                .delete_object(project_id, container_name.clone(), name.clone())
                 .await;
             durability
                 .persist(self, (container_name, name), result)
@@ -243,7 +243,7 @@ impl<Ctx: WorkerCtx> HostContainer for DurableWorkerCtx<Ctx> {
         )
         .await?;
 
-        let account_id = self.state.owned_worker_id.account_id();
+        let project_id = self.state.owned_worker_id.project_id();
         let container_name = self
             .as_wasi_view()
             .table()
@@ -254,7 +254,7 @@ impl<Ctx: WorkerCtx> HostContainer for DurableWorkerCtx<Ctx> {
             let result = self
                 .state
                 .blob_store_service
-                .delete_objects(account_id, container_name.clone(), names.clone())
+                .delete_objects(project_id, container_name.clone(), names.clone())
                 .await;
             durability
                 .persist(self, (container_name, names), result)
@@ -282,7 +282,7 @@ impl<Ctx: WorkerCtx> HostContainer for DurableWorkerCtx<Ctx> {
         )
         .await?;
 
-        let account_id = self.state.owned_worker_id.account_id();
+        let project_id = self.state.owned_worker_id.project_id();
         let container_name = self
             .as_wasi_view()
             .table()
@@ -293,7 +293,7 @@ impl<Ctx: WorkerCtx> HostContainer for DurableWorkerCtx<Ctx> {
             let result = self
                 .state
                 .blob_store_service
-                .has_object(account_id, container_name.clone(), name.clone())
+                .has_object(project_id, container_name.clone(), name.clone())
                 .await;
             durability
                 .persist(self, (container_name, name), result)
@@ -322,7 +322,7 @@ impl<Ctx: WorkerCtx> HostContainer for DurableWorkerCtx<Ctx> {
             )
             .await?;
 
-        let account_id = self.state.owned_worker_id.account_id();
+        let project_id = self.state.owned_worker_id.project_id();
         let container_name = self
             .as_wasi_view()
             .table()
@@ -333,7 +333,7 @@ impl<Ctx: WorkerCtx> HostContainer for DurableWorkerCtx<Ctx> {
             let result = self
                 .state
                 .blob_store_service
-                .object_info(account_id, container_name.clone(), name.clone())
+                .object_info(project_id, container_name.clone(), name.clone())
                 .await;
             durability
                 .persist(self, (container_name, name), result)
@@ -365,7 +365,7 @@ impl<Ctx: WorkerCtx> HostContainer for DurableWorkerCtx<Ctx> {
         )
         .await?;
 
-        let account_id = self.state.owned_worker_id.account_id();
+        let project_id = self.state.owned_worker_id.project_id();
         let container_name = self
             .as_wasi_view()
             .table()
@@ -376,7 +376,7 @@ impl<Ctx: WorkerCtx> HostContainer for DurableWorkerCtx<Ctx> {
             let result = self
                 .state
                 .blob_store_service
-                .clear(account_id, container_name.clone())
+                .clear(project_id, container_name.clone())
                 .await;
             durability.persist(self, container_name, result).await
         } else {
diff --git a/golem-worker-executor/src/durable_host/blobstore/mod.rs b/golem-worker-executor/src/durable_host/blobstore/mod.rs
index 6207e2b2..c31bc16b 100644
--- a/golem-worker-executor/src/durable_host/blobstore/mod.rs
+++ b/golem-worker-executor/src/durable_host/blobstore/mod.rs
@@ -15,7 +15,7 @@
 pub mod container;
 pub mod types;
 
-use futures_util::TryFutureExt;
+use futures::TryFutureExt;
 use golem_common::model::oplog::DurableFunctionType;
 use wasmtime::component::Resource;
 use wasmtime_wasi::IoView;
@@ -33,7 +33,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
         &mut self,
         name: ContainerName,
     ) -> anyhow::Result<Result<Resource<Container>, Error>> {
-        let account_id = self.state.owned_worker_id.account_id();
+        let account_id = self.state.owned_worker_id.project_id();
         let durability = Durability::<u64, SerializableError>::new(
             self,
             "golem blobstore::blobstore",
@@ -69,7 +69,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
         &mut self,
         name: ContainerName,
     ) -> anyhow::Result<Result<Resource<Container>, Error>> {
-        let account_id = self.state.owned_worker_id.account_id();
+        let account_id = self.state.owned_worker_id.project_id();
         let durability = Durability::<Option<u64>, SerializableError>::new(
             self,
             "golem blobstore::blobstore",
@@ -102,7 +102,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
     }
 
     async fn delete_container(&mut self, name: ContainerName) -> anyhow::Result<Result<(), Error>> {
-        let account_id = self.state.owned_worker_id.account_id();
+        let account_id = self.state.owned_worker_id.project_id();
         let durability = Durability::<(), SerializableError>::new(
             self,
             "golem blobstore::blobstore",
@@ -131,7 +131,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
         &mut self,
         name: ContainerName,
     ) -> anyhow::Result<Result<bool, Error>> {
-        let account_id = self.state.owned_worker_id.account_id();
+        let account_id = self.state.owned_worker_id.project_id();
         let durability = Durability::<bool, SerializableError>::new(
             self,
             "golem blobstore::blobstore",
@@ -161,7 +161,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
         src: ObjectId,
         dest: ObjectId,
     ) -> anyhow::Result<Result<(), Error>> {
-        let account_id = self.state.owned_worker_id.account_id();
+        let account_id = self.state.owned_worker_id.project_id();
         let durability = Durability::<(), SerializableError>::new(
             self,
             "golem blobstore::blobstore",
@@ -203,7 +203,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
         src: ObjectId,
         dest: ObjectId,
     ) -> anyhow::Result<Result<(), Error>> {
-        let account_id = self.state.owned_worker_id.account_id();
+        let account_id = self.state.owned_worker_id.project_id();
         let durability = Durability::<(), SerializableError>::new(
             self,
             "golem blobstore::blobstore",
diff --git a/golem-worker-executor/src/durable_host/durability.rs b/golem-worker-executor/src/durable_host/durability.rs
index 62f20de3..b6e50e38 100644
--- a/golem-worker-executor/src/durable_host/durability.rs
+++ b/golem-worker-executor/src/durable_host/durability.rs
@@ -410,8 +410,7 @@ impl<Ctx: WorkerCtx> DurabilityHost for DurableWorkerCtx<Ctx> {
         } else {
             let (_, oplog_entry) = crate::get_oplog_entry!(
                 self.state.replay_state,
-                OplogEntry::ImportedFunctionInvoked,
-                OplogEntry::ImportedFunctionInvokedV1
+                OplogEntry::ImportedFunctionInvoked
             )?;
 
             let bytes = self
@@ -431,27 +430,15 @@ impl<Ctx: WorkerCtx> DurabilityHost for DurableWorkerCtx<Ctx> {
                 OplogEntry::ImportedFunctionInvoked {
                     timestamp,
                     function_name,
-                    wrapped_function_type,
+                    durable_function_type,
                     ..
                 } => Ok(PersistedDurableFunctionInvocation {
                     timestamp,
                     function_name,
                     response: bytes.to_vec(),
-                    function_type: wrapped_function_type,
+                    function_type: durable_function_type,
                     oplog_entry_version: OplogEntryVersion::V2,
                 }),
-                OplogEntry::ImportedFunctionInvokedV1 {
-                    timestamp,
-                    function_name,
-                    wrapped_function_type,
-                    ..
-                } => Ok(PersistedDurableFunctionInvocation {
-                    timestamp,
-                    function_name,
-                    response: bytes.to_vec(),
-                    function_type: wrapped_function_type,
-                    oplog_entry_version: OplogEntryVersion::V1,
-                }),
                 _ => Err(WorkerExecutorError::unexpected_oplog_entry(
                     "ImportedFunctionInvoked",
                     format!("{oplog_entry:?}"),
diff --git a/golem-worker-executor/src/durable_host/golem/v1x.rs b/golem-worker-executor/src/durable_host/golem/v1x.rs
index 1d8934c7..0eedccb4 100644
--- a/golem-worker-executor/src/durable_host/golem/v1x.rs
+++ b/golem-worker-executor/src/durable_host/golem/v1x.rs
@@ -26,7 +26,7 @@ use crate::preview2::golem_api_1_x::oplog::{
     Host as OplogHost, HostGetOplog, HostSearchOplog, SearchOplog,
 };
 use crate::services::oplog::CommitLevel;
-use crate::services::{HasOplogService, HasPlugins, HasWorker};
+use crate::services::{HasOplogService, HasPlugins, HasProjectService, HasWorker};
 use crate::workerctx::{InvocationManagement, StatusManagement, WorkerCtx};
 use anyhow::anyhow;
 use bincode::de::Decoder;
@@ -102,8 +102,6 @@ impl<Ctx: WorkerCtx> HostGetWorkers for DurableWorkerCtx<Ctx> {
 
 impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
     async fn create_promise(&mut self) -> anyhow::Result<golem_api_1_x::host::PromiseId> {
-        self.observe_function_call("golem::api", "create_promise");
-
         let durability = Durability::<PromiseId, SerializableError>::new(
             self,
             "golem::api",
@@ -523,7 +521,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
         .await?;
 
         let worker_id: WorkerId = worker_id.into();
-        let owned_worker_id = OwnedWorkerId::new(&self.owned_worker_id.account_id, &worker_id);
+        let owned_worker_id = OwnedWorkerId::new(&self.owned_worker_id.project_id, &worker_id);
 
         let mode = match mode {
             golem_api_1_x::host::UpdateMode::Automatic => {
@@ -562,7 +560,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
     ) -> anyhow::Result<Option<golem_api_1_x::host::WorkerMetadata>> {
         self.observe_function_call("golem::api", "get_worker_metadata");
         let worker_id: WorkerId = worker_id.into();
-        let owned_worker_id = OwnedWorkerId::new(&self.owned_worker_id.account_id, &worker_id);
+        let owned_worker_id = OwnedWorkerId::new(&self.owned_worker_id.project_id, &worker_id);
         let metadata = self.state.worker_service.get(&owned_worker_id).await;
 
         match metadata {
@@ -593,7 +591,6 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
         .await?;
 
         let source_worker_id: WorkerId = source_worker_id.into();
-
         let target_worker_id: WorkerId = target_worker_id.into();
 
         let oplog_index_cut_off: OplogIndex = OplogIndex::from_u64(oplog_idx_cut_off);
@@ -637,7 +634,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
 
             let result = self
                 .worker_proxy()
-                .revert(worker_id.clone(), revert_target.clone())
+                .revert(&worker_id, revert_target.clone())
                 .await;
             durability
                 .persist(self, (worker_id, revert_target), result)
@@ -667,7 +664,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
                 .component_service
                 .resolve_component(
                     component_slug.clone(),
-                    self.state.component_metadata.component_owner.clone(),
+                    self.state.component_metadata.owner.clone(),
                 )
                 .await;
             durability.persist(self, component_slug, result).await
@@ -712,7 +709,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
                     .component_service
                     .resolve_component(
                         component_slug.clone(),
-                        self.state.component_metadata.component_owner.clone(),
+                        self.state.component_metadata.owner.clone(),
                     )
                     .await?;
                 let worker_id = component_id.map(|component_id| WorkerId {
@@ -722,7 +719,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
 
                 if let Some(worker_id) = worker_id.clone() {
                     let owned_id = OwnedWorkerId {
-                        account_id: self.state.owned_worker_id.account_id(),
+                        project_id: self.state.owned_worker_id.project_id(),
                         worker_id,
                     };
 
@@ -762,10 +759,17 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
             };
             let oplog_index_cut_off = self.state.current_oplog_index().await.previous();
 
+            let metadata = self
+                .state
+                .worker_service
+                .get(&self.owned_worker_id)
+                .await
+                .ok_or_else(|| anyhow::anyhow!("Worker does not exist"))?;
             let fork_result = self
                 .state
                 .worker_fork
                 .fork_and_write_fork_result(
+                    &metadata.created_by,
                     &self.owned_worker_id,
                     &target_worker_id,
                     oplog_index_cut_off,
@@ -788,7 +792,7 @@ impl<Ctx: WorkerCtx> HostGetOplog for DurableWorkerCtx<Ctx> {
     ) -> anyhow::Result<Resource<GetOplogEntry>> {
         self.observe_function_call("golem::api::get-oplog", "new");
 
-        let account_id = self.owned_worker_id.account_id();
+        let account_id = self.owned_worker_id.project_id();
         let worker_id: WorkerId = worker_id.into();
         let owned_worker_id = OwnedWorkerId::new(&account_id, &worker_id);
 
@@ -810,6 +814,7 @@ impl<Ctx: WorkerCtx> HostGetOplog for DurableWorkerCtx<Ctx> {
         let component_service = self.state.component_service.clone();
         let oplog_service = self.state.oplog_service();
         let plugins = self.state.plugins();
+        let project_service = self.state.project_service();
 
         let entry = self.as_wasi_view().table().get(&self_)?.clone();
 
@@ -817,6 +822,7 @@ impl<Ctx: WorkerCtx> HostGetOplog for DurableWorkerCtx<Ctx> {
             component_service,
             oplog_service,
             plugins,
+            project_service,
             &entry.owned_worker_id,
             entry.current_component_version,
             entry.next_oplog_index,
@@ -890,7 +896,7 @@ impl<Ctx: WorkerCtx> HostSearchOplog for DurableWorkerCtx<Ctx> {
     ) -> anyhow::Result<Resource<SearchOplog>> {
         self.observe_function_call("golem::api::search-oplog", "new");
 
-        let account_id = self.owned_worker_id.account_id();
+        let account_id = self.owned_worker_id.project_id();
         let worker_id: WorkerId = worker_id.into();
         let owned_worker_id = OwnedWorkerId::new(&account_id, &worker_id);
 
@@ -920,6 +926,7 @@ impl<Ctx: WorkerCtx> HostSearchOplog for DurableWorkerCtx<Ctx> {
         let component_service = self.state.component_service.clone();
         let oplog_service = self.state.oplog_service();
         let plugins = self.state.plugins();
+        let project_service = self.state.project_service();
 
         let entry = self.as_wasi_view().table().get(&self_)?.clone();
 
@@ -927,6 +934,7 @@ impl<Ctx: WorkerCtx> HostSearchOplog for DurableWorkerCtx<Ctx> {
             component_service,
             oplog_service,
             plugins,
+            project_service,
             &entry.owned_worker_id,
             entry.current_component_version,
             entry.next_oplog_index,
@@ -1188,6 +1196,13 @@ impl From<golem_api_1_x::host::WorkerPropertyFilter> for golem_common::model::Wo
                     filter.value.into(),
                 )
             }
+            golem_api_1_x::host::WorkerPropertyFilter::WasiConfigVars(filter) => {
+                golem_common::model::WorkerFilter::new_wasi_config_vars(
+                    filter.name,
+                    filter.comparator.into(),
+                    filter.value,
+                )
+            }
         }
     }
 }
@@ -1212,6 +1227,7 @@ impl From<golem_common::model::WorkerMetadata> for golem_api_1_x::host::WorkerMe
             worker_id: value.worker_id.into(),
             args: value.args,
             env: value.env,
+            wasi_config_vars: value.wasi_config_vars.into_iter().collect(),
             status: value.last_known_status.status.into(),
             component_version: value.last_known_status.component_version,
             retry_count: 0,
diff --git a/golem-worker-executor/src/durable_host/http/types.rs b/golem-worker-executor/src/durable_host/http/types.rs
index e3ca0553..a24f1a9c 100644
--- a/golem-worker-executor/src/durable_host/http/types.rs
+++ b/golem-worker-executor/src/durable_host/http/types.rs
@@ -654,7 +654,7 @@ impl<Ctx: WorkerCtx> HostFutureIncomingResponse for DurableWorkerCtx<Ctx> {
             )
             .into())
         } else {
-            let (_, oplog_entry) = get_oplog_entry!(self.state.replay_state, OplogEntry::ImportedFunctionInvoked, OplogEntry::ImportedFunctionInvokedV1).map_err(|golem_err| anyhow!("failed to get http::types::future_incoming_response::get oplog entry: {golem_err}"))?;
+            let (_, oplog_entry) = get_oplog_entry!(self.state.replay_state, OplogEntry::ImportedFunctionInvoked).map_err(|golem_err| anyhow!("failed to get http::types::future_incoming_response::get oplog entry: {golem_err}"))?;
 
             let serialized_response = self
                 .state
diff --git a/golem-worker-executor/src/durable_host/keyvalue/eventual.rs b/golem-worker-executor/src/durable_host/keyvalue/eventual.rs
index 142b4da7..42e77910 100644
--- a/golem-worker-executor/src/durable_host/keyvalue/eventual.rs
+++ b/golem-worker-executor/src/durable_host/keyvalue/eventual.rs
@@ -31,7 +31,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
         bucket: Resource<Bucket>,
         key: Key,
     ) -> anyhow::Result<Result<Option<Resource<IncomingValue>>, Resource<Error>>> {
-        let account_id = self.owned_worker_id.account_id();
+        let project_id = self.owned_worker_id.project_id();
         let bucket = self
             .as_wasi_view()
             .table()
@@ -51,7 +51,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
             let result = self
                 .state
                 .key_value_service
-                .get(account_id, bucket.clone(), key.clone())
+                .get(project_id, bucket.clone(), key.clone())
                 .await;
             durability.persist(self, (bucket, key), result).await
         } else {
@@ -83,7 +83,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
         key: Key,
         outgoing_value: Resource<OutgoingValue>,
     ) -> anyhow::Result<Result<(), Resource<Error>>> {
-        let account_id = self.owned_worker_id.account_id();
+        let project_id = self.owned_worker_id.project_id();
         let bucket = self
             .as_wasi_view()
             .table()
@@ -112,7 +112,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
             let result = self
                 .state
                 .key_value_service
-                .set(account_id, bucket, key, outgoing_value)
+                .set(project_id, bucket, key, outgoing_value)
                 .await;
             durability.persist(self, input, result).await
         } else {
@@ -136,7 +136,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
         bucket: Resource<Bucket>,
         key: Key,
     ) -> anyhow::Result<Result<(), Resource<Error>>> {
-        let account_id = self.owned_worker_id.account_id();
+        let project_id = self.owned_worker_id.project_id();
         let bucket = self
             .as_wasi_view()
             .table()
@@ -157,7 +157,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
             let result = self
                 .state
                 .key_value_service
-                .delete(account_id, bucket, key)
+                .delete(project_id, bucket, key)
                 .await;
             durability.persist(self, input, result).await
         } else {
@@ -181,7 +181,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
         bucket: Resource<Bucket>,
         key: Key,
     ) -> anyhow::Result<Result<bool, Resource<Error>>> {
-        let account_id = self.owned_worker_id.account_id();
+        let project_id = self.owned_worker_id.project_id();
         let bucket = self
             .as_wasi_view()
             .table()
@@ -202,7 +202,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
             let result = self
                 .state
                 .key_value_service
-                .exists(account_id, bucket, key)
+                .exists(project_id, bucket, key)
                 .await;
             durability.persist(self, input, result).await
         } else {
diff --git a/golem-worker-executor/src/durable_host/keyvalue/eventual_batch.rs b/golem-worker-executor/src/durable_host/keyvalue/eventual_batch.rs
index 69065ef4..64ac9702 100644
--- a/golem-worker-executor/src/durable_host/keyvalue/eventual_batch.rs
+++ b/golem-worker-executor/src/durable_host/keyvalue/eventual_batch.rs
@@ -31,7 +31,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
         bucket: Resource<Bucket>,
         keys: Vec<Key>,
     ) -> anyhow::Result<Result<Vec<Option<Resource<IncomingValue>>>, Resource<Error>>> {
-        let account_id = self.owned_worker_id.account_id();
+        let project_id = self.owned_worker_id.project_id();
         let bucket = self
             .as_wasi_view()
             .table()
@@ -51,7 +51,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
             let result = self
                 .state
                 .key_value_service
-                .get_many(account_id, bucket, keys)
+                .get_many(project_id, bucket, keys)
                 .await;
             durability.persist(self, input, result).await
         } else {
@@ -91,7 +91,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
         &mut self,
         bucket: Resource<Bucket>,
     ) -> anyhow::Result<Result<Vec<Key>, Resource<Error>>> {
-        let account_id = self.owned_worker_id.account_id();
+        let project_id = self.owned_worker_id.project_id();
         let bucket = self
             .as_wasi_view()
             .table()
@@ -110,7 +110,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
             let result = self
                 .state
                 .key_value_service
-                .get_keys(account_id, bucket.clone())
+                .get_keys(project_id, bucket.clone())
                 .await;
             durability.persist(self, bucket, result).await
         } else {
@@ -125,7 +125,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
         bucket: Resource<Bucket>,
         key_values: Vec<(Key, Resource<OutgoingValue>)>,
     ) -> anyhow::Result<Result<(), Resource<Error>>> {
-        let account_id = self.owned_worker_id.account_id();
+        let project_id = self.owned_worker_id.project_id();
         let bucket = self
             .as_wasi_view()
             .table()
@@ -166,7 +166,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
             let result = self
                 .state
                 .key_value_service
-                .set_many(account_id, bucket, key_values)
+                .set_many(project_id, bucket, key_values)
                 .await;
             durability.persist(self, input, result).await
         } else {
@@ -190,7 +190,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
         bucket: Resource<Bucket>,
         keys: Vec<Key>,
     ) -> anyhow::Result<Result<(), Resource<Error>>> {
-        let account_id = self.owned_worker_id.account_id();
+        let project_id = self.owned_worker_id.project_id();
         let bucket = self
             .as_wasi_view()
             .table()
@@ -211,7 +211,7 @@ impl<Ctx: WorkerCtx> Host for DurableWorkerCtx<Ctx> {
             let result = self
                 .state
                 .key_value_service
-                .delete_many(account_id, bucket, keys)
+                .delete_many(project_id, bucket, keys)
                 .await;
             durability.persist(self, input, result).await
         } else {
diff --git a/golem-worker-executor/src/durable_host/mod.rs b/golem-worker-executor/src/durable_host/mod.rs
index 711cb552..635ea552 100644
--- a/golem-worker-executor/src/durable_host/mod.rs
+++ b/golem-worker-executor/src/durable_host/mod.rs
@@ -15,23 +15,43 @@
 // WASI Host implementation for Golem, delegating to the core WASI implementation (wasmtime_wasi)
 // implementing the Golem specific instrumentation on top of it.
 
+pub mod blobstore;
+mod cli;
+mod clocks;
+mod config;
+pub mod durability;
+mod dynamic_linking;
+mod filesystem;
+pub mod golem;
+pub mod http;
+pub mod io;
+pub mod keyvalue;
+mod logging;
+mod random;
+pub mod rdbms;
+mod replay_state;
+pub mod serialized;
+mod sockets;
+pub mod wasm_rpc;
+
 use crate::durable_host::http::serialized::SerializableHttpRequest;
 use crate::durable_host::io::{ManagedStdErr, ManagedStdIn, ManagedStdOut};
 use crate::durable_host::replay_state::ReplayState;
-use crate::durable_host::serialized::SerializableError;
 use crate::metrics::wasm::{record_number_of_replayed_functions, record_resume_worker};
 use crate::model::event::InternalWorkerEvent;
 use crate::model::{
-    CurrentResourceLimits, ExecutionStatus, InvocationContext, LastError, ListDirectoryResult,
-    ReadFileResult, TrapType, WorkerConfig,
+    CurrentResourceLimits, ExecutionStatus, InvocationContext, LastError, ReadFileResult, TrapType,
+    WorkerConfig,
 };
+use crate::services::agent_types::AgentTypesService;
 use crate::services::blob_store::BlobStoreService;
-use crate::services::component::{ComponentMetadata, ComponentService};
+use crate::services::component::ComponentService;
 use crate::services::file_loader::{FileLoader, FileUseToken};
 use crate::services::golem_config::GolemConfig;
 use crate::services::key_value::KeyValueService;
 use crate::services::oplog::{CommitLevel, Oplog, OplogOps, OplogService};
 use crate::services::plugins::Plugins;
+use crate::services::projects::ProjectService;
 use crate::services::promise::PromiseService;
 use crate::services::rdbms::RdbmsService;
 use crate::services::rpc::Rpc;
@@ -40,18 +60,18 @@ use crate::services::worker::WorkerService;
 use crate::services::worker_event::WorkerEventService;
 use crate::services::worker_fork::WorkerForkService;
 use crate::services::worker_proxy::WorkerProxy;
-use crate::services::{worker_enumeration, HasAll, HasConfig, HasOplog, HasWorker};
+use crate::services::{
+    worker_enumeration, HasAll, HasConfig, HasOplog, HasProjectService, HasWorker,
+};
 use crate::services::{HasOplogService, HasPlugins};
 use crate::wasi_host;
-use crate::worker::invocation::{
-    find_first_available_function, invoke_observed_and_traced, InvokeResult,
-};
+use crate::worker::invocation::{invoke_observed_and_traced, InvokeResult};
 use crate::worker::status::calculate_last_known_status;
 use crate::worker::{interpret_function_result, is_worker_error_retriable, RetryDecision, Worker};
 use crate::workerctx::{
-    ExternalOperations, FileSystemReading, IndexedResourceStore, InvocationContextManagement,
-    InvocationHooks, InvocationManagement, PublicWorkerIo, StatusManagement, UpdateManagement,
-    WorkerCtx,
+    ExternalOperations, FileSystemReading, HasWasiConfigVars, InvocationContextManagement,
+    InvocationHooks, InvocationManagement, LogEventEmitBehaviour, PublicWorkerIo, StatusManagement,
+    UpdateManagement, WorkerCtx,
 };
 use anyhow::anyhow;
 use async_trait::async_trait;
@@ -59,31 +79,31 @@ use bytes::BytesMut;
 use chrono::{DateTime, Utc};
 pub use durability::*;
 use futures::future::try_join_all;
-use futures_util::TryFutureExt;
-use futures_util::TryStreamExt;
+use futures::TryFutureExt;
+use futures::TryStreamExt;
 use golem_common::model::invocation_context::{
     AttributeValue, InvocationContextSpan, InvocationContextStack, SpanId,
 };
 use golem_common::model::oplog::{
-    DurableFunctionType, IndexedResourceKey, LogLevel, OplogEntry, OplogIndex, PersistenceLevel,
+    DurableFunctionType, LogLevel, OplogEntry, OplogIndex, PersistenceLevel,
     TimestampedUpdateDescription, UpdateDescription, WorkerError, WorkerResourceId,
 };
 use golem_common::model::regions::{DeletedRegions, OplogRegion};
-use golem_common::model::{exports, PluginInstallationId};
+use golem_common::model::RetryConfig;
+use golem_common::model::{AccountId, PluginInstallationId, ProjectId};
 use golem_common::model::{
-    AccountId, ComponentFilePath, ComponentFilePermissions, ComponentFileSystemNode,
+    ComponentFilePath, ComponentFilePermissions, ComponentFileSystemNode,
     ComponentFileSystemNodeDetails, ComponentId, ComponentType, ComponentVersion,
-    FailedUpdateRecord, IdempotencyKey, InitialComponentFile, OwnedWorkerId, ScanCursor,
-    ScheduledAction, SuccessfulUpdateRecord, Timestamp, WorkerFilter, WorkerId, WorkerMetadata,
-    WorkerResourceDescription, WorkerStatus, WorkerStatusRecord,
+    FailedUpdateRecord, GetFileSystemNodeResult, IdempotencyKey, InitialComponentFile,
+    OwnedWorkerId, ScanCursor, ScheduledAction, SuccessfulUpdateRecord, Timestamp, WorkerFilter,
+    WorkerId, WorkerMetadata, WorkerResourceDescription, WorkerStatus, WorkerStatusRecord,
 };
-use golem_common::model::{RetryConfig, TargetWorkerId};
 use golem_common::retries::get_delay;
 use golem_service_base::error::worker_executor::{InterruptKind, WorkerExecutorError};
-use golem_wasm_rpc::wasmtime::ResourceStore;
+use golem_wasm_rpc::wasmtime::{ResourceStore, ResourceTypeId};
 use golem_wasm_rpc::{Uri, Value, ValueAndType};
 use replay_state::ReplayEvent;
-use std::collections::{HashMap, HashSet};
+use std::collections::{BTreeMap, HashMap, HashSet};
 use std::error::Error;
 use std::fmt::{Debug, Display, Formatter};
 use std::ops::Add;
@@ -106,24 +126,6 @@ use wasmtime_wasi_http::types::{
 };
 use wasmtime_wasi_http::{HttpResult, WasiHttpCtx, WasiHttpImpl, WasiHttpView};
 
-pub mod blobstore;
-mod cli;
-mod clocks;
-pub mod durability;
-mod dynamic_linking;
-mod filesystem;
-pub mod golem;
-pub mod http;
-pub mod io;
-pub mod keyvalue;
-mod logging;
-mod random;
-pub mod rdbms;
-mod replay_state;
-pub mod serialized;
-mod sockets;
-pub mod wasm_rpc;
-
 /// Partial implementation of the WorkerCtx interfaces for adding durable execution to workers.
 pub struct DurableWorkerCtx<Ctx: WorkerCtx> {
     table: Arc<Mutex<ResourceTable>>, // Required because of the dropped Sync constraints in https://github.com/bytecodealliance/wasmtime/pull/7802
@@ -146,7 +148,7 @@ impl<Ctx: WorkerCtx> DurableWorkerCtx<Ctx> {
         worker_enumeration_service: Arc<dyn worker_enumeration::WorkerEnumerationService>,
         key_value_service: Arc<dyn KeyValueService>,
         blob_store_service: Arc<dyn BlobStoreService>,
-        rdbms_service: Arc<dyn crate::services::rdbms::RdbmsService>,
+        rdbms_service: Arc<dyn RdbmsService>,
         event_service: Arc<dyn WorkerEventService + Send + Sync>,
         oplog_service: Arc<dyn OplogService>,
         oplog: Arc<dyn Oplog>,
@@ -161,6 +163,8 @@ impl<Ctx: WorkerCtx> DurableWorkerCtx<Ctx> {
         file_loader: Arc<FileLoader>,
         plugins: Arc<dyn Plugins>,
         worker_fork: Arc<dyn WorkerForkService>,
+        project_service: Arc<dyn ProjectService>,
+        agent_types_service: Arc<dyn AgentTypesService>,
     ) -> Result<Self, WorkerExecutorError> {
         let temp_dir = Arc::new(tempfile::Builder::new().prefix("golem").tempdir().map_err(
             |e| WorkerExecutorError::runtime(format!("Failed to create temporary directory: {e}")),
@@ -182,7 +186,7 @@ impl<Ctx: WorkerCtx> DurableWorkerCtx<Ctx> {
 
         let component_metadata = component_service
             .get_metadata(
-                &owned_worker_id.account_id,
+                &owned_worker_id.project_id,
                 &owned_worker_id.component_id(),
                 Some(worker_config.component_version_for_replay),
             )
@@ -190,12 +194,18 @@ impl<Ctx: WorkerCtx> DurableWorkerCtx<Ctx> {
 
         let files = prepare_filesystem(
             &file_loader,
-            &owned_worker_id.account_id,
+            &owned_worker_id.project_id,
             temp_dir.path(),
             &component_metadata.files,
         )
         .await?;
 
+        // TODO: pass config vars from component metadata
+        let wasi_config_vars = effective_wasi_config_vars(
+            worker_config.initial_wasi_config_vars.clone(),
+            BTreeMap::new(),
+        );
+
         let stdin = ManagedStdIn::disabled();
         let stdout = ManagedStdOut::from_stdout(Stdout);
         let stderr = ManagedStdErr::from_stderr(Stderr);
@@ -237,6 +247,7 @@ impl<Ctx: WorkerCtx> DurableWorkerCtx<Ctx> {
                 blob_store_service,
                 rdbms_service,
                 component_service,
+                agent_types_service,
                 plugins,
                 config.clone(),
                 owned_worker_id.clone(),
@@ -250,6 +261,10 @@ impl<Ctx: WorkerCtx> DurableWorkerCtx<Ctx> {
                 RwLock::new(compute_read_only_paths(&files)),
                 TRwLock::new(files),
                 file_loader,
+                project_service,
+                worker_config.created_by.clone(),
+                worker_config.initial_wasi_config_vars,
+                wasi_config_vars,
             )
             .await,
             temp_dir,
@@ -264,7 +279,10 @@ impl<Ctx: WorkerCtx> DurableWorkerCtx<Ctx> {
             .expect("ResourceTable mutex must never fail")
     }
 
-    fn is_read_only(&mut self, fd: &Resource<Descriptor>) -> Result<bool, ResourceTableError> {
+    fn check_if_file_is_readonly(
+        &mut self,
+        fd: &Resource<Descriptor>,
+    ) -> Result<bool, ResourceTableError> {
         let table = Arc::get_mut(&mut self.table)
             .expect("ResourceTable is shared and cannot be borrowed mutably")
             .get_mut()
@@ -281,7 +299,7 @@ impl<Ctx: WorkerCtx> DurableWorkerCtx<Ctx> {
     }
 
     fn fail_if_read_only(&mut self, fd: &Resource<Descriptor>) -> FsResult<()> {
-        if self.is_read_only(fd)? {
+        if self.check_if_file_is_readonly(fd)? {
             Err(wasmtime_wasi::p2::bindings::filesystem::types::ErrorCode::NotPermitted.into())
         } else {
             Ok(())
@@ -310,7 +328,11 @@ impl<Ctx: WorkerCtx> DurableWorkerCtx<Ctx> {
         &self.owned_worker_id
     }
 
-    pub fn component_metadata(&self) -> &ComponentMetadata {
+    pub fn created_by(&self) -> &AccountId {
+        &self.state.created_by
+    }
+
+    pub fn component_metadata(&self) -> &golem_service_base::model::Component {
         &self.state.component_metadata
     }
 
@@ -373,6 +395,10 @@ impl<Ctx: WorkerCtx> DurableWorkerCtx<Ctx> {
         self.state.component_service.clone()
     }
 
+    pub fn agent_types_service(&self) -> Arc<dyn AgentTypesService> {
+        self.state.agent_types_service.clone()
+    }
+
     pub fn worker_fork(&self) -> Arc<dyn WorkerForkService> {
         self.state.worker_fork.clone()
     }
@@ -463,70 +489,60 @@ impl<Ctx: WorkerCtx> DurableWorkerCtx<Ctx> {
                 ..
             } = &entry
             {
-                // Stdout and stderr writes are persistent and overwritten by sending the data to the event
-                // service instead of the real output stream
-
-                if self.state.is_live()
-                // If the worker is still in replay mode we never emit events.
-                {
-                    if !self
-                        .state
-                        .replay_state
-                        .seen_log(*level, context, message)
-                        .await
-                    {
-                        // haven't seen this log before
+                match Ctx::LOG_EVENT_EMIT_BEHAVIOUR {
+                    LogEventEmitBehaviour::LiveOnly => {
+                        // Stdout and stderr writes are persistent and overwritten by sending the data to the event
+                        // service instead of the real output stream
+
+                        if self.state.is_live()
+                        // If the worker is in live mode we always emit events
+                        {
+                            if !self
+                                .state
+                                .replay_state
+                                .seen_log(*level, context, message)
+                                .await
+                            {
+                                // haven't seen this log before
+                                self.public_state
+                                    .event_service
+                                    .emit_event(event.clone(), true);
+                                self.state.oplog.add(entry).await;
+                            } else {
+                                // we have persisted emitting this log before, so we mark it as non-live and
+                                // remove the entry from the seen log set.
+                                // note that we still call emit_event because we need replayed log events for
+                                // improved error reporting in case of invocation failures
+                                self.public_state
+                                    .event_service
+                                    .emit_event(event.clone(), false);
+                                self.state
+                                    .replay_state
+                                    .remove_seen_log(*level, context, message)
+                                    .await;
+                            }
+                        }
+                    }
+                    LogEventEmitBehaviour::Always => {
                         self.public_state
                             .event_service
                             .emit_event(event.clone(), true);
-                        self.state.oplog.add(entry).await;
-                    } else {
-                        // we have persisted emitting this log before, so we mark it as non-live and
-                        // remove the entry from the seen log set.
-                        // note that we still call emit_event because we need replayed log events for
-                        // improved error reporting in case of invocation failures
-                        self.public_state
-                            .event_service
-                            .emit_event(event.clone(), false);
-                        self.state
-                            .replay_state
-                            .remove_seen_log(*level, context, message)
-                            .await;
+
+                        if self.state.is_live()
+                            && !self
+                                .state
+                                .replay_state
+                                .seen_log(*level, context, message)
+                                .await
+                        {
+                            self.state.oplog.add(entry).await;
+                        }
                     }
                 }
             }
         }
     }
 
-    pub async fn generate_unique_local_worker_id(
-        &mut self,
-        remote_worker_id: TargetWorkerId,
-    ) -> Result<WorkerId, WorkerExecutorError> {
-        match remote_worker_id.clone().try_into_worker_id() {
-            Some(worker_id) => Ok(worker_id),
-            None => {
-                let durability = Durability::<WorkerId, SerializableError>::new(
-                    self,
-                    "golem::rpc::wasm-rpc",
-                    "generate_unique_local_worker_id",
-                    DurableFunctionType::ReadLocal,
-                )
-                .await?;
-                let worker_id = if durability.is_live() {
-                    let result = self
-                        .rpc()
-                        .generate_unique_local_worker_id(remote_worker_id)
-                        .await;
-                    durability.persist(self, (), result).await
-                } else {
-                    durability.replay(self).await
-                }?;
-
-                Ok(worker_id)
-            }
-        }
-    }
-
     /// Counts the number of Error entries that are at the end of the oplog. This equals to the number of retries that have been attempted.
     /// It also returns the last error stored in these entries.
     pub async fn trailing_error_count(&self) -> u64 {
@@ -538,6 +554,12 @@ impl<Ctx: WorkerCtx> DurableWorkerCtx<Ctx> {
     }
 }
 
+impl<Ctx: WorkerCtx> HasWasiConfigVars for DurableWorkerCtx<Ctx> {
+    fn wasi_config_vars(&self) -> BTreeMap<String, String> {
+        self.state.wasi_config_vars.read().unwrap().clone()
+    }
+}
+
 impl<Ctx: WorkerCtx + DurableWorkerCtxView<Ctx>> DurableWorkerCtx<Ctx> {
     pub async fn finalize_pending_snapshot_update(
         instance: &Instance,
@@ -567,73 +589,82 @@ impl<Ctx: WorkerCtx + DurableWorkerCtxView<Ctx>> DurableWorkerCtx<Ctx> {
                     .await
                 {
                     Ok(Some(data)) => {
-                        let failed = if let Some(load_snapshot) = find_first_available_function(
-                            store,
-                            instance,
-                            vec![
-                                "golem:api/load-snapshot@1.1.0.{load}".to_string(),
-                                "golem:api/load-snapshot@0.2.0.{load}".to_string(),
-                            ],
-                        ) {
-                            let idempotency_key = IdempotencyKey::fresh();
-                            store
-                                .as_context_mut()
-                                .data_mut()
-                                .durable_ctx_mut()
-                                .set_current_idempotency_key(idempotency_key.clone())
+                        let component_metadata = store
+                            .as_context()
+                            .data()
+                            .component_metadata()
+                            .metadata
+                            .clone();
+
+                        let failed = match component_metadata.load_snapshot().await {
+                            Ok(Some(load_snapshot)) => {
+                                let idempotency_key = IdempotencyKey::fresh();
+                                store
+                                    .as_context_mut()
+                                    .data_mut()
+                                    .durable_ctx_mut()
+                                    .set_current_idempotency_key(idempotency_key.clone())
+                                    .await;
+
+                                store
+                                    .as_context_mut()
+                                    .data_mut()
+                                    .begin_call_snapshotting_function();
+                                let load_result = invoke_observed_and_traced(
+                                    load_snapshot.name.to_string(),
+                                    vec![Value::List(data.iter().map(|b| Value::U8(*b)).collect())],
+                                    store,
+                                    instance,
+                                    &component_metadata,
+                                )
                                 .await;
-
-                            store
-                                .as_context_mut()
-                                .data_mut()
-                                .begin_call_snapshotting_function();
-                            let load_result = invoke_observed_and_traced(
-                                load_snapshot,
-                                vec![Value::List(data.iter().map(|b| Value::U8(*b)).collect())],
-                                store,
-                                instance,
-                            )
-                            .await;
-                            store
-                                .as_context_mut()
-                                .data_mut()
-                                .end_call_snapshotting_function();
-
-                            match load_result {
-                                Err(error) => {
-                                    Some(format!("Manual update failed to load snapshot: {error}"))
-                                }
-                                Ok(InvokeResult::Failed { error, .. }) => {
-                                    let stderr = store
-                                        .as_context()
-                                        .data()
-                                        .get_public_state()
-                                        .event_service()
-                                        .get_last_invocation_errors();
-                                    let error = error.to_string(&stderr);
-                                    Some(format!("Manual update failed to load snapshot: {error}"))
-                                }
-                                Ok(InvokeResult::Succeeded { output, .. }) => {
-                                    if let Some(output) = output {
-                                        match output {
-                                            Value::Result(Err(Some(boxed_error_value))) => {
-                                                match &*boxed_error_value {
-                                                    Value::String(error) =>
-                                                        Some(format!("Manual update failed to load snapshot: {error}")),
-                                                    _ =>
-                                                        Some("Unexpected result value from the snapshot load function".to_string())
+                                store
+                                    .as_context_mut()
+                                    .data_mut()
+                                    .end_call_snapshotting_function();
+
+                                match load_result {
+                                    Err(error) => Some(format!(
+                                        "Manual update failed to load snapshot: {error}"
+                                    )),
+                                    Ok(InvokeResult::Failed { error, .. }) => {
+                                        let stderr = store
+                                            .as_context()
+                                            .data()
+                                            .get_public_state()
+                                            .event_service()
+                                            .get_last_invocation_errors();
+                                        let error = error.to_string(&stderr);
+                                        Some(format!(
+                                            "Manual update failed to load snapshot: {error}"
+                                        ))
+                                    }
+                                    Ok(InvokeResult::Succeeded { output, .. }) => {
+                                        if let Some(output) = output {
+                                            match output {
+                                                Value::Result(Err(Some(boxed_error_value))) => {
+                                                    match &*boxed_error_value {
+                                                        Value::String(error) =>
+                                                            Some(format!("Manual update failed to load snapshot: {error}")),
+                                                        _ =>
+                                                            Some("Unexpected result value from the snapshot load function".to_string())
+                                                    }
                                                 }
+                                                _ => None
                                             }
-                                            _ => None
+                                        } else {
+                                            Some("Unexpected result value from the snapshot load function".to_string())
                                         }
-                                    } else {
-                                        Some("Unexpected result value from the snapshot load function".to_string())
                                     }
+                                    _ => None,
                                 }
-                                _ => None,
                             }
-                        } else {
-                            Some("Failed to find exported load-snapshot function".to_string())
+                            Ok(None) => {
+                                Some("Failed to find exported load-snapshot function".to_string())
+                            }
+                            Err(err) => Some(format!(
+                                "Failed to find exported load-snapshot function: {err}"
+                            )),
                         };
 
                         if let Some(error) = failed {
@@ -651,10 +682,10 @@ impl<Ctx: WorkerCtx + DurableWorkerCtxView<Ctx>> DurableWorkerCtx<Ctx> {
                                 .data_mut()
                                 .on_worker_update_succeeded(
                                     &description,
-                                    component_metadata.size,
+                                    component_metadata.component_size,
                                     HashSet::from_iter(
                                         component_metadata
-                                            .plugin_installations
+                                            .installed_plugins
                                             .into_iter()
                                             .map(|installation| installation.id),
                                     ),
@@ -739,10 +770,10 @@ impl<Ctx: WorkerCtx> DurableWorkerCtx<Ctx> {
 
                             self.on_worker_update_succeeded(
                                 &pending_update.description,
-                                component_metadata.size,
+                                component_metadata.component_size,
                                 HashSet::from_iter(
                                     component_metadata
-                                        .plugin_installations
+                                        .installed_plugins
                                         .into_iter()
                                         .map(|installation| installation.id),
                                 ),
@@ -768,7 +799,7 @@ impl<Ctx: WorkerCtx> DurableWorkerCtx<Ctx> {
     ) -> Result<(), WorkerExecutorError> {
         let current_metadata = &self.state.component_metadata;
 
-        if new_version <= current_metadata.version {
+        if new_version <= current_metadata.versioned_component_id.version {
             debug!("Update {new_version} was already applied, skipping");
             return Ok(());
         };
@@ -776,7 +807,7 @@ impl<Ctx: WorkerCtx> DurableWorkerCtx<Ctx> {
         let new_metadata = self
             .component_service()
             .get_metadata(
-                &self.owned_worker_id.account_id,
+                &self.owned_worker_id.project_id,
                 &self.owned_worker_id.component_id(),
                 Some(new_version),
             )
@@ -786,13 +817,21 @@ impl<Ctx: WorkerCtx> DurableWorkerCtx<Ctx> {
         update_filesystem(
             &mut current_files,
             &self.state.file_loader,
-            &self.owned_worker_id.account_id,
+            &self.owned_worker_id.project_id,
             self.temp_dir.path(),
             &new_metadata.files,
         )
         .await?;
 
-        (*self.state.read_only_paths.write().unwrap()) = compute_read_only_paths(&current_files);
+        let mut read_only_paths = self.state.read_only_paths.write().unwrap();
+        *read_only_paths = compute_read_only_paths(&current_files);
+
+        // TODO: take config vars from component metadata
+        let mut wasi_config_vars = self.state.wasi_config_vars.write().unwrap();
+        *wasi_config_vars = effective_wasi_config_vars(
+            self.state.initial_wasi_config_vars.clone(),
+            BTreeMap::new(),
+        );
 
         self.state.component_metadata = new_metadata;
 
@@ -947,6 +986,7 @@ impl<Ctx: WorkerCtx> StatusManagement for DurableWorkerCtx<Ctx> {
                 .schedule(
                     at,
                     ScheduledAction::ArchiveOplog {
+                        account_id: self.state.created_by.clone(),
                         owned_worker_id: self.owned_worker_id.clone(),
                         last_oplog_index: self.public_state.oplog.current_oplog_index().await,
                         next_after: self.state.config.oplog.archive_interval,
@@ -1130,18 +1170,19 @@ impl<Ctx: WorkerCtx> ResourceStore for DurableWorkerCtx<Ctx> {
         self.state.self_uri()
     }
 
-    async fn add(&mut self, resource: ResourceAny) -> u64 {
-        let id = self.state.add(resource).await;
+    async fn add(&mut self, resource: ResourceAny, name: ResourceTypeId) -> u64 {
+        let id = self.state.add(resource, name.clone()).await;
         let resource_id = WorkerResourceId(id);
         if self.state.is_live() {
-            let entry = OplogEntry::create_resource(resource_id);
+            let entry = OplogEntry::create_resource(resource_id, name.clone());
             self.state.oplog.add(entry.clone()).await;
             self.update_worker_status(move |status| {
                 status.owned_resources.insert(
                     resource_id,
                     WorkerResourceDescription {
                         created_at: entry.timestamp(),
-                        indexed_resource_key: None,
+                        resource_owner: name.owner,
+                        resource_name: name.name,
                     },
                 );
             })
@@ -1150,12 +1191,15 @@ impl<Ctx: WorkerCtx> ResourceStore for DurableWorkerCtx<Ctx> {
         id
     }
 
-    async fn get(&mut self, resource_id: u64) -> Option<ResourceAny> {
+    async fn get(&mut self, resource_id: u64) -> Option<(ResourceTypeId, ResourceAny)> {
         let result = self.state.borrow(resource_id).await;
-        if result.is_some() {
+        if let Some((resource_type_id, _)) = &result {
             let id = WorkerResourceId(resource_id);
             if self.state.is_live() {
-                self.state.oplog.add(OplogEntry::drop_resource(id)).await;
+                self.state
+                    .oplog
+                    .add(OplogEntry::drop_resource(id, resource_type_id.clone()))
+                    .await;
                 self.update_worker_status(move |status| {
                     status.owned_resources.remove(&id);
                 })
@@ -1165,7 +1209,7 @@ impl<Ctx: WorkerCtx> ResourceStore for DurableWorkerCtx<Ctx> {
         result
     }
 
-    async fn borrow(&self, resource_id: u64) -> Option<ResourceAny> {
+    async fn borrow(&self, resource_id: u64) -> Option<(ResourceTypeId, ResourceAny)> {
         self.state.borrow(resource_id).await
     }
 }
@@ -1269,54 +1313,6 @@ impl<Ctx: WorkerCtx> UpdateManagement for DurableWorkerCtx<Ctx> {
     }
 }
 
-#[async_trait]
-impl<Ctx: WorkerCtx> IndexedResourceStore for DurableWorkerCtx<Ctx> {
-    fn get_indexed_resource(
-        &self,
-        resource_name: &str,
-        resource_params: &[String],
-    ) -> Option<WorkerResourceId> {
-        let key = IndexedResourceKey {
-            resource_name: resource_name.to_string(),
-            resource_params: resource_params.to_vec(),
-        };
-        self.state.indexed_resources.get(&key).copied()
-    }
-
-    async fn store_indexed_resource(
-        &mut self,
-        resource_name: &str,
-        resource_params: &[String],
-        resource: WorkerResourceId,
-    ) {
-        let key = IndexedResourceKey {
-            resource_name: resource_name.to_string(),
-            resource_params: resource_params.to_vec(),
-        };
-        self.state.indexed_resources.insert(key.clone(), resource);
-        if self.state.is_live() {
-            self.state
-                .oplog
-                .add(OplogEntry::describe_resource(resource, key.clone()))
-                .await;
-            self.update_worker_status(|status| {
-                if let Some(description) = status.owned_resources.get_mut(&resource) {
-                    description.indexed_resource_key = Some(key);
-                }
-            })
-            .await;
-        }
-    }
-
-    fn drop_indexed_resource(&mut self, resource_name: &str, resource_params: &[String]) {
-        let key = IndexedResourceKey {
-            resource_name: resource_name.to_string(),
-            resource_params: resource_params.to_vec(),
-        };
-        self.state.indexed_resources.remove(&key);
-    }
-}
-
 #[async_trait]
 impl<Ctx: WorkerCtx> InvocationContextManagement for DurableWorkerCtx<Ctx> {
     async fn start_span(
@@ -1488,6 +1484,12 @@ impl<Ctx: WorkerCtx> InvocationContextManagement for DurableWorkerCtx<Ctx> {
         }
         Ok(())
     }
+
+    fn clone_as_inherited_stack(&self, current_span_id: &SpanId) -> InvocationContextStack {
+        self.state
+            .invocation_context
+            .clone_as_inherited_stack(current_span_id)
+    }
 }
 
 pub trait DurableWorkerCtxView<Ctx: WorkerCtx> {
@@ -1518,9 +1520,28 @@ impl<Ctx: WorkerCtx + DurableWorkerCtxView<Ctx>> ExternalOperations<Ctx> for Dur
     async fn resume_replay(
         store: &mut (impl AsContextMut<Data = Ctx> + Send),
         instance: &Instance,
+        refresh_replay_target: bool,
     ) -> Result<RetryDecision, WorkerExecutorError> {
         let mut number_of_replayed_functions = 0;
 
+        if refresh_replay_target {
+            let new_target = store
+                .as_context()
+                .data()
+                .durable_ctx()
+                .state
+                .oplog
+                .current_oplog_index()
+                .await;
+            store
+                .as_context_mut()
+                .data_mut()
+                .durable_ctx_mut()
+                .state
+                .replay_state
+                .set_replay_target(new_target);
+        }
+
         let resume_result = loop {
             let cont = store.as_context().data().durable_ctx().state.is_replay();
 
@@ -1572,18 +1593,26 @@ impl<Ctx: WorkerCtx + DurableWorkerCtxView<Ctx>> ExternalOperations<Ctx> for Dur
                             .set_current_invocation_context(invocation_context)
                             .await?;
 
+                        let component_metadata = store
+                            .as_context()
+                            .data()
+                            .component_metadata()
+                            .metadata
+                            .clone();
+
                         let full_function_name = function_name.to_string();
                         let invoke_result = invoke_observed_and_traced(
                             full_function_name.clone(),
                             function_input.clone(),
                             store,
                             instance,
+                            &component_metadata,
                         )
                         .instrument(span)
                         .await;
 
                         // We are removing the spans introduced by the invocation. Not calling `finish_span` here,
-                        // as it would add FinishSpan oplog entries without corersponding StartSpan ones. Instead,
+                        // as it would add FinishSpan oplog entries without corresponding StartSpan ones. Instead,
                         // the oplog processor should assume that spans implicitly created by ExportedFunctionInvoked
                         // are finished at ExportedFunctionCompleted.
                         for span_id in local_span_ids {
@@ -1601,19 +1630,20 @@ impl<Ctx: WorkerCtx + DurableWorkerCtxView<Ctx>> ExternalOperations<Ctx> for Dur
                                 let component_metadata =
                                     store.as_context().data().component_metadata();
 
-                                match exports::function_by_name(
-                                    &component_metadata.exports,
-                                    &full_function_name,
-                                ) {
+                                match component_metadata
+                                    .metadata
+                                    .find_function(&full_function_name)
+                                    .await
+                                {
                                     Ok(value) => {
                                         if let Some(value) = value {
-                                            let result =
-                                                interpret_function_result(output, value.result)
-                                                    .map_err(|e| {
-                                                        WorkerExecutorError::ValueMismatch {
-                                                            details: e.join(", "),
-                                                        }
-                                                    })?;
+                                            let result = interpret_function_result(
+                                                output,
+                                                value.analysed_export.result,
+                                            )
+                                            .map_err(|e| WorkerExecutorError::ValueMismatch {
+                                                details: e.join(", "),
+                                            })?;
                                             if let Err(err) = store
                                                 .as_context_mut()
                                                 .data_mut()
@@ -1798,7 +1828,7 @@ impl<Ctx: WorkerCtx + DurableWorkerCtxView<Ctx>> ExternalOperations<Ctx> for Dur
                         }
                         UpdateDescription::Automatic { target_version, .. } => {
                             // snapshot update will be succeeded as part of the replay.
-                            let result = Self::resume_replay(store, instance).await;
+                            let result = Self::resume_replay(store, instance, false).await;
                             record_resume_worker(start.elapsed());
 
                             match result {
@@ -1857,7 +1887,7 @@ impl<Ctx: WorkerCtx + DurableWorkerCtxView<Ctx>> ExternalOperations<Ctx> for Dur
                     }
                 }
                 None => {
-                    let result = Self::resume_replay(store, instance).await;
+                    let result = Self::resume_replay(store, instance, false).await;
                     record_resume_worker(start.elapsed());
 
                     result
@@ -1879,7 +1909,7 @@ impl<Ctx: WorkerCtx + DurableWorkerCtxView<Ctx>> ExternalOperations<Ctx> for Dur
 
     async fn record_last_known_limits<T: HasAll<Ctx> + Send + Sync>(
         _this: &T,
-        _account_id: &AccountId,
+        _project_id: &ProjectId,
         _last_known_limits: &CurrentResourceLimits,
     ) -> Result<(), WorkerExecutorError> {
         Ok(())
@@ -1908,6 +1938,7 @@ impl<Ctx: WorkerCtx + DurableWorkerCtxView<Ctx>> ExternalOperations<Ctx> for Dur
         let default_retry_config = &this.config().retry;
         for worker in workers {
             let owned_worker_id = worker.owned_worker_id();
+            let created_by = worker.created_by.clone();
             let latest_worker_status =
                 calculate_last_known_status(this, &owned_worker_id, &Some(worker)).await?;
             let last_error =
@@ -1929,11 +1960,14 @@ impl<Ctx: WorkerCtx + DurableWorkerCtxView<Ctx>> ExternalOperations<Ctx> for Dur
                 RetryDecision::Immediate | RetryDecision::ReacquirePermits => {
                     let _ = Worker::get_or_create_running(
                         this,
+                        &created_by,
                         &owned_worker_id,
                         None,
                         None,
                         None,
                         None,
+                        None,
+                        &InvocationContextStack::fresh(),
                     )
                     .await?;
                 }
@@ -1950,13 +1984,23 @@ impl<Ctx: WorkerCtx + DurableWorkerCtxView<Ctx>> ExternalOperations<Ctx> for Dur
 
     async fn on_worker_update_failed_to_start<T: HasAll<Ctx> + Send + Sync>(
         this: &T,
+        account_id: &AccountId,
         owned_worker_id: &OwnedWorkerId,
         target_version: ComponentVersion,
         details: Option<String>,
     ) -> Result<(), WorkerExecutorError> {
         let worker = this
             .worker_activator()
-            .get_or_create_suspended(owned_worker_id, None, None, None, None)
+            .get_or_create_suspended(
+                account_id,
+                owned_worker_id,
+                None,
+                None,
+                None,
+                None,
+                None,
+                &InvocationContextStack::fresh(),
+            )
             .await?;
 
         let entry = OplogEntry::failed_update(target_version, details.clone());
@@ -1984,10 +2028,10 @@ impl<Ctx: WorkerCtx + DurableWorkerCtxView<Ctx>> ExternalOperations<Ctx> for Dur
 
 #[async_trait]
 impl<Ctx: WorkerCtx + DurableWorkerCtxView<Ctx>> FileSystemReading for DurableWorkerCtx<Ctx> {
-    async fn list_directory(
+    async fn get_file_system_node(
         &self,
         path: &ComponentFilePath,
-    ) -> Result<ListDirectoryResult, WorkerExecutorError> {
+    ) -> Result<GetFileSystemNodeResult, WorkerExecutorError> {
         let root = self.temp_dir.path();
         let target = root.join(PathBuf::from(path.to_rel_string()));
 
@@ -1999,20 +2043,43 @@ impl<Ctx: WorkerCtx + DurableWorkerCtxView<Ctx>> FileSystemReading for DurableWo
                 }
             })?;
             if !exists {
-                return Ok(ListDirectoryResult::NotFound);
+                return Ok(GetFileSystemNodeResult::NotFound);
             };
         }
 
-        {
-            let metadata = tokio::fs::metadata(&target).await.map_err(|e| {
-                WorkerExecutorError::FileSystemError {
-                    path: path.to_string(),
-                    reason: format!("Failed to get metadata: {e}"),
-                }
-            })?;
-            if !metadata.is_dir() {
-                return Ok(ListDirectoryResult::NotADirectory);
+        let metadata = tokio::fs::metadata(&target).await.map_err(|e| {
+            WorkerExecutorError::FileSystemError {
+                path: path.to_string(),
+                reason: format!("Failed to get metadata: {e}"),
+            }
+        })?;
+
+        if metadata.is_file() {
+            let is_readonly_by_host = metadata.permissions().readonly();
+            let is_readonly_by_us = self.state.read_only_paths.read().unwrap().contains(&target);
+
+            let permissions = if is_readonly_by_host || is_readonly_by_us {
+                ComponentFilePermissions::ReadOnly
+            } else {
+                ComponentFilePermissions::ReadWrite
+            };
+
+            let last_modified = metadata.modified().ok().unwrap_or(SystemTime::UNIX_EPOCH);
+            let file_name = target
+                .file_name()
+                .map(|name| name.to_string_lossy().to_string())
+                .unwrap_or_else(|| "unknown".to_string());
+
+            let file_node = ComponentFileSystemNode {
+                name: file_name,
+                last_modified,
+                details: ComponentFileSystemNodeDetails::File {
+                    size: metadata.len(),
+                    permissions,
+                },
             };
+
+            return Ok(GetFileSystemNodeResult::File(file_node));
         }
 
         let mut entries = tokio::fs::read_dir(target).await.map_err(|e| {
@@ -2069,7 +2136,7 @@ impl<Ctx: WorkerCtx + DurableWorkerCtxView<Ctx>> FileSystemReading for DurableWo
                 });
             };
         }
-        Ok(ListDirectoryResult::Ok(result))
+        Ok(GetFileSystemNodeResult::Ok(result))
     }
 
     async fn read_file(
@@ -2211,7 +2278,6 @@ pub(crate) async fn recover_stderr_logs<T: HasOplogService + HasConfig>(
                     break;
                 }
             }
-            Some((_, OplogEntry::ExportedFunctionInvokedV1 { .. })) => break,
             Some((_, OplogEntry::ExportedFunctionInvoked { .. })) => break,
             _ => {}
         }
@@ -2259,13 +2325,15 @@ struct PrivateDurableWorkerState {
     blob_store_service: Arc<dyn BlobStoreService>,
     rdbms_service: Arc<dyn RdbmsService>,
     component_service: Arc<dyn ComponentService>,
+    agent_types_service: Arc<dyn AgentTypesService>,
     plugins: Arc<dyn Plugins>,
     config: Arc<GolemConfig>,
     owned_worker_id: OwnedWorkerId,
+    created_by: AccountId,
     current_idempotency_key: Option<IdempotencyKey>,
     rpc: Arc<dyn Rpc>,
     worker_proxy: Arc<dyn WorkerProxy>,
-    resources: HashMap<WorkerResourceId, ResourceAny>,
+    resources: HashMap<WorkerResourceId, (ResourceTypeId, ResourceAny)>,
     last_resource_id: WorkerResourceId,
     replay_state: ReplayState,
     overridden_retry_policy: Option<RetryConfig>,
@@ -2277,8 +2345,7 @@ struct PrivateDurableWorkerState {
 
     snapshotting_mode: Option<PersistenceLevel>,
 
-    indexed_resources: HashMap<IndexedResourceKey, WorkerResourceId>,
-    component_metadata: ComponentMetadata,
+    component_metadata: golem_service_base::model::Component,
 
     total_linear_memory_size: u64,
 
@@ -2292,6 +2359,12 @@ struct PrivateDurableWorkerState {
     read_only_paths: RwLock<HashSet<PathBuf>>,
     files: TRwLock<HashMap<PathBuf, IFSWorkerFile>>,
     file_loader: Arc<FileLoader>,
+
+    project_service: Arc<dyn ProjectService>,
+    /// The initial config vars that the worker was configured with
+    initial_wasi_config_vars: BTreeMap<String, String>,
+    /// The current config vars of the worker, taking into account component version, etc.
+    wasi_config_vars: RwLock<BTreeMap<String, String>>,
 }
 
 impl PrivateDurableWorkerState {
@@ -2307,6 +2380,7 @@ impl PrivateDurableWorkerState {
         blob_store_service: Arc<dyn BlobStoreService>,
         rdbms_service: Arc<dyn RdbmsService>,
         component_service: Arc<dyn ComponentService>,
+        agent_types_service: Arc<dyn AgentTypesService>,
         plugins: Arc<dyn Plugins>,
         config: Arc<GolemConfig>,
         owned_worker_id: OwnedWorkerId,
@@ -2314,12 +2388,16 @@ impl PrivateDurableWorkerState {
         worker_proxy: Arc<dyn WorkerProxy>,
         deleted_regions: DeletedRegions,
         last_oplog_index: OplogIndex,
-        component_metadata: ComponentMetadata,
+        component_metadata: golem_service_base::model::Component,
         total_linear_memory_size: u64,
         worker_fork: Arc<dyn WorkerForkService>,
         read_only_paths: RwLock<HashSet<PathBuf>>,
         files: TRwLock<HashMap<PathBuf, IFSWorkerFile>>,
         file_loader: Arc<FileLoader>,
+        project_service: Arc<dyn ProjectService>,
+        created_by: AccountId,
+        initial_wasi_config_vars: BTreeMap<String, String>,
+        wasi_config_vars: BTreeMap<String, String>,
     ) -> Self {
         let replay_state = ReplayState::new(
             owned_worker_id.clone(),
@@ -2342,6 +2420,7 @@ impl PrivateDurableWorkerState {
             blob_store_service,
             rdbms_service,
             component_service,
+            agent_types_service,
             plugins,
             config,
             owned_worker_id,
@@ -2355,7 +2434,6 @@ impl PrivateDurableWorkerState {
             assume_idempotence: true,
             open_http_requests: HashMap::new(),
             snapshotting_mode: None,
-            indexed_resources: HashMap::new(),
             component_metadata,
             total_linear_memory_size,
             replay_state,
@@ -2367,6 +2445,10 @@ impl PrivateDurableWorkerState {
             read_only_paths,
             files,
             file_loader,
+            project_service,
+            created_by,
+            initial_wasi_config_vars,
+            wasi_config_vars: RwLock::new(wasi_config_vars),
         }
     }
 
@@ -2505,7 +2587,8 @@ impl PrivateDurableWorkerState {
             .schedule(
                 when,
                 ScheduledAction::CompletePromise {
-                    account_id: self.owned_worker_id.account_id(),
+                    account_id: self.created_by.clone(),
+                    project_id: self.owned_worker_id.project_id(),
                     promise_id,
                 },
             )
@@ -2537,7 +2620,7 @@ impl PrivateDurableWorkerState {
     ) -> Result<(Option<ScanCursor>, Vec<WorkerMetadata>), WorkerExecutorError> {
         self.worker_enumeration_service
             .get(
-                &self.owned_worker_id.account_id,
+                &self.owned_worker_id.project_id,
                 component_id,
                 filter,
                 cursor,
@@ -2556,19 +2639,19 @@ impl ResourceStore for PrivateDurableWorkerState {
         }
     }
 
-    async fn add(&mut self, resource: ResourceAny) -> u64 {
+    async fn add(&mut self, resource: ResourceAny, name: ResourceTypeId) -> u64 {
         let id = self.last_resource_id;
         self.last_resource_id = self.last_resource_id.next();
-        self.resources.insert(id, resource);
+        self.resources.insert(id, (name, resource));
         id.0
     }
 
-    async fn get(&mut self, resource_id: u64) -> Option<ResourceAny> {
+    async fn get(&mut self, resource_id: u64) -> Option<(ResourceTypeId, ResourceAny)> {
         let resource_id = WorkerResourceId(resource_id);
         self.resources.remove(&resource_id)
     }
 
-    async fn borrow(&self, resource_id: u64) -> Option<ResourceAny> {
+    async fn borrow(&self, resource_id: u64) -> Option<(ResourceTypeId, ResourceAny)> {
         self.resources.get(&WorkerResourceId(resource_id)).cloned()
     }
 }
@@ -2597,6 +2680,12 @@ impl HasPlugins for PrivateDurableWorkerState {
     }
 }
 
+impl HasProjectService for PrivateDurableWorkerState {
+    fn project_service(&self) -> Arc<dyn ProjectService> {
+        self.project_service.clone()
+    }
+}
+
 pub struct PublicDurableWorkerState<Ctx: WorkerCtx> {
     promise_service: Arc<dyn PromiseService>,
     event_service: Arc<dyn WorkerEventService + Send + Sync>,
@@ -2726,7 +2815,7 @@ enum IFSWorkerFile {
 
 async fn prepare_filesystem(
     file_loader: &Arc<FileLoader>,
-    account_id: &AccountId,
+    project_id: &ProjectId,
     root: &Path,
     files: &[InitialComponentFile],
 ) -> Result<HashMap<PathBuf, IFSWorkerFile>, WorkerExecutorError> {
@@ -2740,7 +2829,7 @@ async fn prepare_filesystem(
                 ComponentFilePermissions::ReadOnly => {
                     debug!("Loading read-only file {}", path.display());
                     let token = file_loader
-                        .get_read_only_to(account_id, &file.key, &path)
+                        .get_read_only_to(project_id, &file.key, &path)
                         .await?;
                     Ok::<_, WorkerExecutorError>((
                         path,
@@ -2753,7 +2842,7 @@ async fn prepare_filesystem(
                 ComponentFilePermissions::ReadWrite => {
                     debug!("Loading read-write file {}", path.display());
                     file_loader
-                        .get_read_write_to(account_id, &file.key, &path)
+                        .get_read_write_to(project_id, &file.key, &path)
                         .await?;
                     Ok((path, IFSWorkerFile::Rw))
                 }
@@ -2766,7 +2855,7 @@ async fn prepare_filesystem(
 async fn update_filesystem(
     current_state: &mut HashMap<PathBuf, IFSWorkerFile>,
     file_loader: &Arc<FileLoader>,
-    account_id: &AccountId,
+    project_id: &ProjectId,
     root: &Path,
     files: &[InitialComponentFile],
 ) -> Result<(), WorkerExecutorError> {
@@ -2782,7 +2871,7 @@ async fn update_filesystem(
             .map(|f| root.join(PathBuf::from(f.path.to_rel_string()))),
     );
 
-    // We do this in two phases to make errors less likely. First delete all files that are no longer needed and then create
+    // We do this in two phases to make errors less likely. First, delete all files that are no longer needed and then create
     // new ones.
     let futures_phase_1 = current_state.iter().map(|(path, file)| {
         let path = path.clone();
@@ -2819,21 +2908,21 @@ async fn update_filesystem(
                     let exists = tokio::fs::try_exists(&path).map_err(|e| WorkerExecutorError::FileSystemError { path: file.path.to_rel_string(), reason: format!("Failed checking whether path exists: {e}") }).await?;
 
                     if exists {
-                        // Try removing it if it's an empty directory, this will fail otherwise and we can report the error.
+                        // Try removing it if it's an empty directory; this will fail otherwise, and we can report the error.
                         tokio::fs::remove_dir(&path).await.map_err(|e|
                             WorkerExecutorError::FileSystemError {
                                 path: file.path.to_rel_string(),
-                                reason: format!("Tried replacing an existing non-empty path with ro file during update: {e}")
+                                reason: format!("Tried replacing an existing non-empty path with ro file during update: {e}"),
                             }
                         )?;
                     };
 
                     let token = file_loader
-                        .get_read_only_to(account_id, &file.key, &path)
+                        .get_read_only_to(project_id, &file.key, &path)
                         .await?;
 
                     Ok::<_, WorkerExecutorError>(UpdateFileSystemResult::Replace { path, value: IFSWorkerFile::Ro { file, _token: token } })
-                },
+                }
                 (ComponentFilePermissions::ReadOnly, Some(IFSWorkerFile::Ro { file: existing_file, .. })) => {
                     if existing_file.key == file.key {
                         Ok(UpdateFileSystemResult::NoChanges)
@@ -2842,11 +2931,11 @@ async fn update_filesystem(
                         tokio::fs::remove_file(&path).await.map_err(|e|
                             WorkerExecutorError::FileSystemError {
                                 path: file.path.to_rel_string(),
-                                reason: format!("Failed deleting file during update: {e}")
+                                reason: format!("Failed deleting file during update: {e}"),
                             }
                         )?;
                         let token = file_loader
-                            .get_read_only_to(account_id, &file.key, &path)
+                            .get_read_only_to(project_id, &file.key, &path)
                             .await?;
                         Ok::<_, WorkerExecutorError>(UpdateFileSystemResult::Replace { path, value: IFSWorkerFile::Ro { file, _token: token } })
                     }
@@ -2854,7 +2943,7 @@ async fn update_filesystem(
                 (ComponentFilePermissions::ReadOnly, Some(IFSWorkerFile::Rw)) => {
                     Err(WorkerExecutorError::FileSystemError {
                         path: file.path.to_rel_string(),
-                        reason: "Tried updating rw file to ro during update".to_string()
+                        reason: "Tried updating rw file to ro during update".to_string(),
                     })
                 }
                 (ComponentFilePermissions::ReadWrite, None) => {
@@ -2866,45 +2955,45 @@ async fn update_filesystem(
                         let metadata = tokio::fs::metadata(&path).await.map_err(|e|
                             WorkerExecutorError::FileSystemError {
                                 path: file.path.to_rel_string(),
-                                reason: format!("Failed getting metadata of path: {e}")
+                                reason: format!("Failed getting metadata of path: {e}"),
                             }
                         )?;
 
                         if metadata.is_file() {
-                            return Ok(UpdateFileSystemResult::NoChanges)
+                            return Ok(UpdateFileSystemResult::NoChanges);
                         }
 
-                        // Try removing it if it's an empty directory, this will fail otherwise and we can report the error.
+                        // Try removing it if it's an empty directory, this will fail otherwise, and we can report the error.
                         tokio::fs::remove_dir(&path).await.map_err(|e|
                             WorkerExecutorError::FileSystemError {
                                 path: file.path.to_rel_string(),
-                                reason: format!("Tried replacing an existing non-empty path with rw file during update: {e}")
+                                reason: format!("Tried replacing an existing non-empty path with rw file during update: {e}"),
                             }
                         )?;
                     }
 
                     file_loader
-                        .get_read_write_to(account_id, &file.key, &path)
+                        .get_read_write_to(project_id, &file.key, &path)
                         .await?;
-                    Ok::<_, WorkerExecutorError>(UpdateFileSystemResult::Replace { path, value: IFSWorkerFile::Rw})
-                },
+                    Ok::<_, WorkerExecutorError>(UpdateFileSystemResult::Replace { path, value: IFSWorkerFile::Rw })
+                }
                 (ComponentFilePermissions::ReadWrite, Some(IFSWorkerFile::Ro { .. })) => {
                     debug!("Updating ro file to rw {}", path.display());
                     tokio::fs::remove_file(&path).await.map_err(|e|
                         WorkerExecutorError::FileSystemError {
                             path: file.path.to_rel_string(),
-                            reason: format!("Failed deleting file during update: {e}")
+                            reason: format!("Failed deleting file during update: {e}"),
                         }
                     )?;
                     file_loader
-                        .get_read_write_to(account_id, &file.key, &path)
+                        .get_read_write_to(project_id, &file.key, &path)
                         .await?;
-                    Ok::<_, WorkerExecutorError>(UpdateFileSystemResult::Replace { path, value: IFSWorkerFile::Rw})
-                },
+                    Ok::<_, WorkerExecutorError>(UpdateFileSystemResult::Replace { path, value: IFSWorkerFile::Rw })
+                }
                 (ComponentFilePermissions::ReadWrite, Some(IFSWorkerFile::Rw)) => {
                     debug!("Updating rw file {}", path.display());
                     Ok(UpdateFileSystemResult::NoChanges)
-                },
+                }
             }
         }
     });
@@ -2935,6 +3024,23 @@ fn compute_read_only_paths(files: &HashMap<PathBuf, IFSWorkerFile>) -> HashSet<P
     HashSet::from_iter(ro_paths)
 }
 
+fn effective_wasi_config_vars(
+    worker_wasi_config_vars: BTreeMap<String, String>,
+    component_wasi_config_vars: BTreeMap<String, String>,
+) -> BTreeMap<String, String> {
+    let mut result = BTreeMap::new();
+
+    for (k, v) in component_wasi_config_vars {
+        result.insert(k, v);
+    }
+
+    for (k, v) in worker_wasi_config_vars {
+        result.insert(k, v);
+    }
+
+    result
+}
+
 /// Helper macro for expecting a given type of OplogEntry as the next entry in the oplog during
 /// replay, while skipping hint entries.
 /// The macro expression's type is `Result<OplogEntry, GolemError>` and it fails if the next non-hint
diff --git a/golem-worker-executor/src/durable_host/replay_state.rs b/golem-worker-executor/src/durable_host/replay_state.rs
index 80888e3e..33bba069 100644
--- a/golem-worker-executor/src/durable_host/replay_state.rs
+++ b/golem-worker-executor/src/durable_host/replay_state.rs
@@ -108,6 +108,10 @@ impl ReplayState {
         self.replay_target.get()
     }
 
+    pub fn set_replay_target(&mut self, new_target: OplogIndex) {
+        self.replay_target.set(new_target)
+    }
+
     pub async fn skipped_regions(&self) -> DeletedRegions {
         let internal = self.internal.read().await;
         internal.skipped_regions.clone()
@@ -317,20 +321,11 @@ impl ReplayState {
         let oplog_entry = oplog_entries.into_iter().next().unwrap();
 
         // record side effects that need to be applied at the next opportunity
-        match oplog_entry {
-            OplogEntry::SuccessfulUpdate { target_version, .. } => {
-                self.record_replay_event(ReplayEvent::UpdateReplayed {
-                    new_version: target_version,
-                })
-                .await
-            }
-            OplogEntry::SuccessfulUpdateV1 { target_version, .. } => {
-                self.record_replay_event(ReplayEvent::UpdateReplayed {
-                    new_version: target_version,
-                })
-                .await
-            }
-            _ => {}
+        if let OplogEntry::SuccessfulUpdate { target_version, .. } = oplog_entry {
+            self.record_replay_event(ReplayEvent::UpdateReplayed {
+                new_version: target_version,
+            })
+            .await
         }
 
         if read_idx == self.replay_target.get() {
@@ -416,31 +411,6 @@ impl ReplayState {
             if self.is_replay() {
                 let (_, oplog_entry) = self.get_oplog_entry().await;
                 match &oplog_entry {
-                    OplogEntry::ExportedFunctionInvokedV1 {
-                        function_name,
-                        idempotency_key,
-                        ..
-                    } => {
-                        let request: Vec<golem_wasm_rpc::protobuf::Val> = self
-                            .oplog
-                            .get_payload_of_entry(&oplog_entry)
-                            .await
-                            .expect("failed to deserialize function request payload")
-                            .unwrap();
-                        let request = request
-                            .into_iter()
-                            .map(|val| {
-                                val.try_into()
-                                    .expect("failed to decode serialized protobuf value")
-                            })
-                            .collect::<Vec<Value>>();
-                        break Ok(Some(ExportedFunctionInvoked {
-                            function_name: function_name.to_string(),
-                            function_input: request,
-                            idempotency_key: idempotency_key.clone(),
-                            invocation_context: InvocationContextStack::fresh(),
-                        }));
-                    }
                     OplogEntry::ExportedFunctionInvoked {
                         function_name,
                         idempotency_key,
diff --git a/golem-worker-executor/src/durable_host/wasm_rpc/mod.rs b/golem-worker-executor/src/durable_host/wasm_rpc/mod.rs
index 1f0cba0e..bd1686e2 100644
--- a/golem-worker-executor/src/durable_host/wasm_rpc/mod.rs
+++ b/golem-worker-executor/src/durable_host/wasm_rpc/mod.rs
@@ -25,16 +25,17 @@ use crate::get_oplog_entry;
 use crate::services::component::ComponentService;
 use crate::services::oplog::{CommitLevel, OplogOps};
 use crate::services::rpc::{RpcDemand, RpcError};
-use crate::workerctx::{InvocationContextManagement, InvocationManagement, WorkerCtx};
+use crate::workerctx::{
+    HasWasiConfigVars, InvocationContextManagement, InvocationManagement, WorkerCtx,
+};
 use anyhow::anyhow;
 use async_trait::async_trait;
 use chrono::{DateTime, Utc};
-use golem_common::model::exports::function_by_name;
 use golem_common::model::invocation_context::{AttributeValue, InvocationContextSpan, SpanId};
 use golem_common::model::oplog::{DurableFunctionType, OplogEntry, PersistenceLevel};
 use golem_common::model::{
-    AccountId, ComponentId, IdempotencyKey, OplogIndex, OwnedWorkerId, ScheduledAction,
-    TargetWorkerId, WorkerId,
+    AccountId, ComponentId, IdempotencyKey, OplogIndex, OwnedWorkerId, ProjectId, ScheduledAction,
+    WorkerId,
 };
 use golem_common::serialization::try_deserialize;
 use golem_service_base::error::worker_executor::WorkerExecutorError;
@@ -48,6 +49,7 @@ use golem_wasm_rpc::{
     ValueAndType, WasmRpcEntry, WitType, WitValue,
 };
 use std::any::Any;
+use std::collections::BTreeMap;
 use std::fmt::{Debug, Formatter};
 use std::sync::Arc;
 use tracing::{error, Instrument};
@@ -64,25 +66,13 @@ impl<Ctx: WorkerCtx> HostWasmRpc for DurableWorkerCtx<Ctx> {
     ) -> anyhow::Result<Resource<WasmRpcEntry>> {
         self.observe_function_call("golem::rpc::wasm-rpc", "new");
 
-        let worker_id: WorkerId = worker_id.into();
-        let remote_worker_id = worker_id.into_target_worker_id();
-
-        construct_wasm_rpc_resource(self, remote_worker_id).await
-    }
-
-    async fn ephemeral(
-        &mut self,
-        component_id: golem_wasm_rpc::golem_rpc_0_2_x::types::ComponentId,
-    ) -> anyhow::Result<Resource<WasmRpcEntry>> {
-        self.observe_function_call("golem::rpc::wasm-rpc", "ephemeral");
+        let args = self.get_arguments().await?;
+        let env = self.get_environment().await?;
+        let wasi_config_vars = self.wasi_config_vars();
 
-        let component_id: ComponentId = component_id.into();
-        let remote_worker_id = TargetWorkerId {
-            component_id,
-            worker_name: None,
-        };
+        let remote_worker_id: WorkerId = worker_id.into();
 
-        construct_wasm_rpc_resource(self, remote_worker_id).await
+        construct_wasm_rpc_resource(self, remote_worker_id, &args, &env, wasi_config_vars).await
     }
 
     async fn invoke_and_await(
@@ -93,6 +83,7 @@ impl<Ctx: WorkerCtx> HostWasmRpc for DurableWorkerCtx<Ctx> {
     ) -> anyhow::Result<Result<WitValue, golem_wasm_rpc::RpcError>> {
         let args = self.get_arguments().await?;
         let env = self.get_environment().await?;
+        let wasi_config_vars = self.wasi_config_vars();
 
         let entry = self.table().get(&self_)?;
         let payload = entry.payload.downcast_ref::<WasmRpcEntryPayload>().unwrap();
@@ -147,7 +138,7 @@ impl<Ctx: WorkerCtx> HostWasmRpc for DurableWorkerCtx<Ctx> {
                 function_name: function_name.clone(),
                 function_params: try_get_typed_parameters(
                     self.state.component_service.clone(),
-                    &remote_worker_id.account_id,
+                    &remote_worker_id.project_id,
                     &remote_worker_id.worker_id.component_id,
                     &function_name,
                     &function_params,
@@ -165,9 +156,11 @@ impl<Ctx: WorkerCtx> HostWasmRpc for DurableWorkerCtx<Ctx> {
                     Some(idempotency_key),
                     function_name,
                     function_params,
+                    self.created_by(),
                     self.worker_id(),
                     &args,
                     &env,
+                    wasi_config_vars,
                     stack,
                 )
                 .await;
@@ -227,6 +220,7 @@ impl<Ctx: WorkerCtx> HostWasmRpc for DurableWorkerCtx<Ctx> {
     ) -> anyhow::Result<Result<(), golem_wasm_rpc::RpcError>> {
         let args = self.get_arguments().await?;
         let env = self.get_environment().await?;
+        let wasi_config_vars = self.wasi_config_vars();
 
         let entry = self.table().get(&self_)?;
         let payload = entry.payload.downcast_ref::<WasmRpcEntryPayload>().unwrap();
@@ -282,7 +276,7 @@ impl<Ctx: WorkerCtx> HostWasmRpc for DurableWorkerCtx<Ctx> {
                 function_name: function_name.clone(),
                 function_params: try_get_typed_parameters(
                     self.state.component_service.clone(),
-                    &remote_worker_id.account_id,
+                    &remote_worker_id.project_id,
                     &remote_worker_id.worker_id.component_id,
                     &function_name,
                     &function_params,
@@ -300,9 +294,11 @@ impl<Ctx: WorkerCtx> HostWasmRpc for DurableWorkerCtx<Ctx> {
                     Some(idempotency_key),
                     function_name,
                     function_params,
+                    self.created_by(),
                     self.worker_id(),
                     &args,
                     &env,
+                    wasi_config_vars,
                     stack,
                 )
                 .await;
@@ -330,6 +326,7 @@ impl<Ctx: WorkerCtx> HostWasmRpc for DurableWorkerCtx<Ctx> {
     ) -> anyhow::Result<Resource<FutureInvokeResult>> {
         let args = self.get_arguments().await?;
         let env = self.get_environment().await?;
+        let wasi_config_vars = self.wasi_config_vars();
 
         let begin_index = self
             .state
@@ -376,13 +373,14 @@ impl<Ctx: WorkerCtx> HostWasmRpc for DurableWorkerCtx<Ctx> {
                 .await?;
 
         let worker_id = self.worker_id().clone();
+        let created_by = self.created_by().clone();
         let request = SerializableInvokeRequest {
             remote_worker_id: remote_worker_id.worker_id(),
             idempotency_key: idempotency_key.clone(),
             function_name: function_name.clone(),
             function_params: try_get_typed_parameters(
                 self.state.component_service.clone(),
-                &remote_worker_id.account_id,
+                &remote_worker_id.project_id,
                 &remote_worker_id.worker_id.component_id,
                 &function_name,
                 &function_params,
@@ -404,9 +402,11 @@ impl<Ctx: WorkerCtx> HostWasmRpc for DurableWorkerCtx<Ctx> {
                             Some(idempotency_key),
                             function_name,
                             function_params,
+                            &created_by,
                             &worker_id,
                             &args,
                             &env,
+                            wasi_config_vars,
                             stack,
                         )
                         .await)
@@ -428,8 +428,10 @@ impl<Ctx: WorkerCtx> HostWasmRpc for DurableWorkerCtx<Ctx> {
                 payload: Box::new(FutureInvokeResultState::Deferred {
                     remote_worker_id,
                     self_worker_id: worker_id,
+                    self_created_by: created_by,
                     args,
                     env,
+                    wasi_config_vars,
                     function_name,
                     function_params,
                     idempotency_key,
@@ -500,7 +502,7 @@ impl<Ctx: WorkerCtx> HostWasmRpc for DurableWorkerCtx<Ctx> {
                 function_name: function_name.clone(),
                 function_params: try_get_typed_parameters(
                     self.state.component_service.clone(),
-                    &remote_worker_id.account_id,
+                    &remote_worker_id.project_id,
                     &remote_worker_id.worker_id.component_id,
                     &function_name,
                     &function_params,
@@ -514,6 +516,7 @@ impl<Ctx: WorkerCtx> HostWasmRpc for DurableWorkerCtx<Ctx> {
                 .invocation_context
                 .clone_as_inherited_stack(&self.state.current_span_id);
             let action = ScheduledAction::Invoke {
+                account_id: self.created_by().clone(),
                 owned_worker_id: remote_worker_id,
                 idempotency_key,
                 full_function_name: function_name,
@@ -619,8 +622,10 @@ enum FutureInvokeResultState {
     Deferred {
         remote_worker_id: OwnedWorkerId,
         self_worker_id: WorkerId,
+        self_created_by: AccountId,
         args: Vec<String>,
         env: Vec<(String, String)>,
+        wasi_config_vars: BTreeMap<String, String>,
         function_name: String,
         function_params: Vec<WitValue>,
         idempotency_key: IdempotencyKey,
@@ -807,8 +812,10 @@ impl<Ctx: WorkerCtx> HostFutureInvokeResult for DurableWorkerCtx<Ctx> {
                                 let FutureInvokeResultState::Deferred {
                                     remote_worker_id,
                                     self_worker_id,
+                                    self_created_by,
                                     args,
                                     env,
+                                    wasi_config_vars,
                                     function_name,
                                     function_params,
                                     idempotency_key,
@@ -825,9 +832,11 @@ impl<Ctx: WorkerCtx> HostFutureInvokeResult for DurableWorkerCtx<Ctx> {
                                         Some(idempotency_key),
                                         function_name,
                                         function_params,
+                                        &self_created_by,
                                         &self_worker_id,
                                         &args,
                                         &env,
+                                        wasi_config_vars,
                                         stack,
                                     )
                                     .await)
@@ -851,7 +860,7 @@ impl<Ctx: WorkerCtx> HostFutureInvokeResult for DurableWorkerCtx<Ctx> {
                             function_name: function_name.clone(),
                             function_params: try_get_typed_parameters(
                                 component_service,
-                                &remote_worker_id.account_id,
+                                &remote_worker_id.project_id,
                                 &remote_worker_id.worker_id.component_id,
                                 function_name,
                                 function_params,
@@ -1106,18 +1115,32 @@ impl<Ctx: WorkerCtx> golem_wasm_rpc::Host for DurableWorkerCtx<Ctx> {
     }
 }
 
-async fn construct_wasm_rpc_resource<Ctx: WorkerCtx>(
+pub async fn construct_wasm_rpc_resource<Ctx: WorkerCtx>(
     ctx: &mut DurableWorkerCtx<Ctx>,
-    remote_worker_id: TargetWorkerId,
+    remote_worker_id: WorkerId,
+    args: &[String],
+    env: &[(String, String)],
+    config: BTreeMap<String, String>,
 ) -> anyhow::Result<Resource<WasmRpcEntry>> {
-    let remote_worker_id = ctx
-        .generate_unique_local_worker_id(remote_worker_id)
-        .await?;
-
     let span = create_rpc_connection_span(ctx, &remote_worker_id).await?;
-
-    let remote_worker_id = OwnedWorkerId::new(&ctx.owned_worker_id.account_id, &remote_worker_id);
-    let demand = ctx.rpc().create_demand(&remote_worker_id).await;
+    let stack = ctx
+        .state
+        .invocation_context
+        .clone_as_inherited_stack(span.span_id());
+
+    let remote_worker_id = OwnedWorkerId::new(&ctx.owned_worker_id.project_id, &remote_worker_id);
+    let demand = ctx
+        .rpc()
+        .create_demand(
+            &remote_worker_id,
+            ctx.created_by(),
+            ctx.worker_id(),
+            args,
+            env,
+            config,
+            stack,
+        )
+        .await?;
     let entry = ctx.table().push(WasmRpcEntry {
         payload: Box::new(WasmRpcEntryPayload::Interface {
             demand,
@@ -1136,20 +1159,20 @@ async fn construct_wasm_rpc_resource<Ctx: WorkerCtx>(
 /// This should only be used for generating "debug information" for the stored oplog entries.
 async fn try_get_typed_parameters(
     components: Arc<dyn ComponentService>,
-    account_id: &AccountId,
+    project_id: &ProjectId,
     component_id: &ComponentId,
     function_name: &str,
     params: &[WitValue],
 ) -> Vec<ValueAndType> {
-    if let Ok(metadata) = components
-        .get_metadata(account_id, component_id, None)
+    if let Ok(component) = components
+        .get_metadata(project_id, component_id, None)
         .await
     {
-        if let Ok(Some(function)) = function_by_name(&metadata.exports, function_name) {
-            if function.parameters.len() == params.len() {
+        if let Ok(Some(function)) = component.metadata.find_function(function_name).await {
+            if function.analysed_export.parameters.len() == params.len() {
                 return params
                     .iter()
-                    .zip(function.parameters)
+                    .zip(function.analysed_export.parameters)
                     .map(|(value, def)| ValueAndType::new(value.clone().into(), def.typ.clone()))
                     .collect();
             }
diff --git a/golem-worker-executor/src/grpc/invocation.rs b/golem-worker-executor/src/grpc/invocation.rs
index 69b9b3c2..ad099226 100644
--- a/golem-worker-executor/src/grpc/invocation.rs
+++ b/golem-worker-executor/src/grpc/invocation.rs
@@ -12,31 +12,36 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use crate::services::component::ComponentMetadata;
 use crate::services::HasComponentService;
 use crate::worker::Worker;
 use crate::workerctx::WorkerCtx;
 use golem_api_grpc::proto::golem::common::ResourceLimits as GrpcResourceLimits;
-use golem_common::base_model::{TargetWorkerId, WorkerId};
+use golem_common::base_model::WorkerId;
 use golem_common::model::invocation_context::InvocationContextStack;
-use golem_common::model::{AccountId, ComponentVersion, IdempotencyKey, WorkerMetadata};
+use golem_common::model::{AccountId, ComponentVersion, IdempotencyKey, ProjectId, WorkerMetadata};
 use golem_service_base::error::worker_executor::WorkerExecutorError;
+use golem_service_base::model::Component;
 use golem_wasm_ast::analysis::{AnalysedExport, AnalysedFunction, AnalysedFunctionParameter};
-use golem_wasm_rpc::json::TypeAnnotatedValueJsonExtensions;
-use golem_wasm_rpc::protobuf::type_annotated_value::TypeAnnotatedValue;
+use golem_wasm_rpc::json::ValueAndTypeJsonExtensions;
 use golem_wasm_rpc::protobuf::Val;
-use golem_wasm_rpc::Value;
+use golem_wasm_rpc::{Value, ValueAndType};
 use rib::{ParsedFunctionName, ParsedFunctionSite};
+use std::collections::BTreeMap;
 use std::sync::Arc;
 use tracing::warn;
 
 pub trait CanStartWorker {
     fn account_id(&self) -> Result<AccountId, WorkerExecutorError>;
     fn account_limits(&self) -> Option<GrpcResourceLimits>;
-    fn worker_id(&self) -> Result<TargetWorkerId, WorkerExecutorError>;
+    fn project_id(&self) -> Result<ProjectId, WorkerExecutorError>;
+    fn worker_id(&self) -> Result<WorkerId, WorkerExecutorError>;
     fn args(&self) -> Option<Vec<String>>;
     fn env(&self) -> Option<Vec<(String, String)>>;
+    fn wasi_config_vars(&self) -> Result<Option<BTreeMap<String, String>>, WorkerExecutorError>;
     fn parent(&self) -> Option<WorkerId>;
+    fn maybe_invocation_context(&self) -> Option<InvocationContextStack> {
+        None
+    }
 }
 
 pub trait GrpcInvokeRequest: CanStartWorker {
@@ -53,7 +58,8 @@ trait ProtobufInvocationDetails {
     fn proto_account_id(&self) -> &Option<golem_api_grpc::proto::golem::common::AccountId>;
     fn proto_account_limits(&self)
         -> &Option<golem_api_grpc::proto::golem::common::ResourceLimits>;
-    fn proto_worker_id(&self) -> &Option<golem_api_grpc::proto::golem::worker::TargetWorkerId>;
+    fn proto_worker_id(&self) -> &Option<golem_api_grpc::proto::golem::worker::WorkerId>;
+    fn proto_project_id(&self) -> &Option<golem_api_grpc::proto::golem::common::ProjectId>;
     fn proto_invocation_context(
         &self,
     ) -> &Option<golem_api_grpc::proto::golem::worker::InvocationContext>;
@@ -72,7 +78,14 @@ impl<T: ProtobufInvocationDetails> CanStartWorker for T {
         *self.proto_account_limits()
     }
 
-    fn worker_id(&self) -> Result<TargetWorkerId, WorkerExecutorError> {
+    fn project_id(&self) -> Result<ProjectId, WorkerExecutorError> {
+        (*self.proto_project_id())
+            .ok_or(WorkerExecutorError::invalid_request("project_id not found"))?
+            .try_into()
+            .map_err(WorkerExecutorError::invalid_request)
+    }
+
+    fn worker_id(&self) -> Result<WorkerId, WorkerExecutorError> {
         self.proto_worker_id()
             .clone()
             .ok_or(WorkerExecutorError::invalid_request("worker_id not found"))?
@@ -92,6 +105,20 @@ impl<T: ProtobufInvocationDetails> CanStartWorker for T {
             .map(|ctx| ctx.env.clone().into_iter().collect::<Vec<_>>())
     }
 
+    fn wasi_config_vars(&self) -> Result<Option<BTreeMap<String, String>>, WorkerExecutorError> {
+        match self.proto_invocation_context() {
+            Some(ctx) => Ok(Some(
+                ctx.wasi_config_vars
+                    .clone()
+                    .ok_or(WorkerExecutorError::invalid_request(
+                        "wasi_config_vars not found",
+                    ))?
+                    .into(),
+            )),
+            None => Ok(None),
+        }
+    }
+
     fn parent(&self) -> Option<WorkerId> {
         self.proto_invocation_context().as_ref().and_then(|ctx| {
             ctx.parent
@@ -102,7 +129,7 @@ impl<T: ProtobufInvocationDetails> CanStartWorker for T {
 }
 
 impl ProtobufInvocationDetails
-    for golem_api_grpc::proto::golem::workerexecutor::v1::ListDirectoryRequest
+    for golem_api_grpc::proto::golem::workerexecutor::v1::GetFileSystemNodeRequest
 {
     fn proto_account_id(&self) -> &Option<golem_api_grpc::proto::golem::common::AccountId> {
         &self.account_id
@@ -114,10 +141,14 @@ impl ProtobufInvocationDetails
         &self.account_limits
     }
 
-    fn proto_worker_id(&self) -> &Option<golem_api_grpc::proto::golem::worker::TargetWorkerId> {
+    fn proto_worker_id(&self) -> &Option<golem_api_grpc::proto::golem::worker::WorkerId> {
         &self.worker_id
     }
 
+    fn proto_project_id(&self) -> &Option<golem_api_grpc::proto::golem::common::ProjectId> {
+        &self.project_id
+    }
+
     fn proto_invocation_context(
         &self,
     ) -> &Option<golem_api_grpc::proto::golem::worker::InvocationContext> {
@@ -138,10 +169,14 @@ impl ProtobufInvocationDetails
         &self.account_limits
     }
 
-    fn proto_worker_id(&self) -> &Option<golem_api_grpc::proto::golem::worker::TargetWorkerId> {
+    fn proto_worker_id(&self) -> &Option<golem_api_grpc::proto::golem::worker::WorkerId> {
         &self.worker_id
     }
 
+    fn proto_project_id(&self) -> &Option<golem_api_grpc::proto::golem::common::ProjectId> {
+        &self.project_id
+    }
+
     fn proto_invocation_context(
         &self,
     ) -> &Option<golem_api_grpc::proto::golem::worker::InvocationContext> {
@@ -162,10 +197,14 @@ impl ProtobufInvocationDetails
         &self.account_limits
     }
 
-    fn proto_worker_id(&self) -> &Option<golem_api_grpc::proto::golem::worker::TargetWorkerId> {
+    fn proto_worker_id(&self) -> &Option<golem_api_grpc::proto::golem::worker::WorkerId> {
         &self.worker_id
     }
 
+    fn proto_project_id(&self) -> &Option<golem_api_grpc::proto::golem::common::ProjectId> {
+        &self.project_id
+    }
+
     fn proto_invocation_context(
         &self,
     ) -> &Option<golem_api_grpc::proto::golem::worker::InvocationContext> {
@@ -186,10 +225,14 @@ impl ProtobufInvocationDetails
         &self.account_limits
     }
 
-    fn proto_worker_id(&self) -> &Option<golem_api_grpc::proto::golem::worker::TargetWorkerId> {
+    fn proto_worker_id(&self) -> &Option<golem_api_grpc::proto::golem::worker::WorkerId> {
         &self.worker_id
     }
 
+    fn proto_project_id(&self) -> &Option<golem_api_grpc::proto::golem::common::ProjectId> {
+        &self.project_id
+    }
+
     fn proto_invocation_context(
         &self,
     ) -> &Option<golem_api_grpc::proto::golem::worker::InvocationContext> {
@@ -210,10 +253,14 @@ impl ProtobufInvocationDetails
         &self.account_limits
     }
 
-    fn proto_worker_id(&self) -> &Option<golem_api_grpc::proto::golem::worker::TargetWorkerId> {
+    fn proto_worker_id(&self) -> &Option<golem_api_grpc::proto::golem::worker::WorkerId> {
         &self.worker_id
     }
 
+    fn proto_project_id(&self) -> &Option<golem_api_grpc::proto::golem::common::ProjectId> {
+        &self.project_id
+    }
+
     fn proto_invocation_context(
         &self,
     ) -> &Option<golem_api_grpc::proto::golem::worker::InvocationContext> {
@@ -255,10 +302,14 @@ impl ProtobufInvocationDetails
         &self.account_limits
     }
 
-    fn proto_worker_id(&self) -> &Option<golem_api_grpc::proto::golem::worker::TargetWorkerId> {
+    fn proto_worker_id(&self) -> &Option<golem_api_grpc::proto::golem::worker::WorkerId> {
         &self.worker_id
     }
 
+    fn proto_project_id(&self) -> &Option<golem_api_grpc::proto::golem::common::ProjectId> {
+        &self.project_id
+    }
+
     fn proto_invocation_context(
         &self,
     ) -> &Option<golem_api_grpc::proto::golem::worker::InvocationContext> {
@@ -346,14 +397,14 @@ fn assume_future_component_version(metadata: &WorkerMetadata) -> ComponentVersio
 }
 
 fn resolve_function<'t>(
-    component: &'t ComponentMetadata,
+    component: &'t Component,
     function: &str,
 ) -> Result<(&'t AnalysedFunction, ParsedFunctionName), WorkerExecutorError> {
     let parsed =
         ParsedFunctionName::parse(function).map_err(WorkerExecutorError::invalid_request)?;
     let mut functions = Vec::new();
 
-    for export in &component.exports {
+    for export in component.metadata.exports() {
         match export {
             AnalysedExport::Instance(interface) => {
                 if matches!(parsed.site().interface_name(), Some(name) if name == interface.name) {
@@ -397,19 +448,14 @@ async fn interpret_json_input<Ctx: WorkerCtx>(
     let component_metadata = worker
         .component_service()
         .get_metadata(
-            &metadata.account_id,
+            &metadata.project_id,
             &metadata.worker_id.component_id,
             Some(assumed_component_version),
         )
         .await?;
-    let (function, parsed) = resolve_function(&component_metadata, function_name)?;
+    let (function, _parsed) = resolve_function(&component_metadata, function_name)?;
 
-    let expected_params: Vec<&AnalysedFunctionParameter> =
-        if parsed.function().is_indexed_resource() {
-            function.parameters.iter().skip(1).collect()
-        } else {
-            function.parameters.iter().collect()
-        };
+    let expected_params: Vec<&AnalysedFunctionParameter> = function.parameters.iter().collect();
 
     let mut input = Vec::new();
     for (json_string, param) in input_json_strings.iter().zip(expected_params) {
@@ -419,20 +465,15 @@ async fn interpret_json_input<Ctx: WorkerCtx>(
                 param.name
             ))
         })?;
-        let type_annotated_value =
-            TypeAnnotatedValue::parse_with_type(&json, &param.typ).map_err(|errors| {
+        let value_and_type =
+            ValueAndType::parse_with_type(&json, &param.typ).map_err(|errors| {
                 WorkerExecutorError::invalid_request(format!(
                     "Parameter {} has unexpected type: {}",
                     param.name,
                     errors.join(", ")
                 ))
             })?;
-        let val: Value = type_annotated_value.try_into().map_err(|err| {
-            WorkerExecutorError::invalid_request(format!(
-                "Invalid parameter value for {}: {err}",
-                param.name
-            ))
-        })?;
+        let val: Value = value_and_type.value;
         input.push(val.into());
     }
 
diff --git a/golem-worker-executor/src/grpc/mod.rs b/golem-worker-executor/src/grpc/mod.rs
index 0d0220c1..60d9232b 100644
--- a/golem-worker-executor/src/grpc/mod.rs
+++ b/golem-worker-executor/src/grpc/mod.rs
@@ -19,51 +19,54 @@ use crate::model::event::InternalWorkerEvent;
 use crate::model::public_oplog::{
     find_component_version_at, get_public_oplog_chunk, search_public_oplog,
 };
-use crate::model::{LastError, ListDirectoryResult, ReadFileResult};
+use crate::model::{LastError, ReadFileResult};
 use crate::services::events::Event;
 use crate::services::worker_activator::{DefaultWorkerActivator, LazyWorkerActivator};
 use crate::services::worker_event::WorkerEventReceiver;
 use crate::services::{
     All, HasActiveWorkers, HasAll, HasComponentService, HasEvents, HasOplogService, HasPlugins,
-    HasPromiseService, HasRunningWorkerEnumerationService, HasShardManagerService, HasShardService,
-    HasWorkerEnumerationService, HasWorkerService, UsesAllDeps,
+    HasProjectService, HasPromiseService, HasRunningWorkerEnumerationService,
+    HasShardManagerService, HasShardService, HasWorkerEnumerationService, HasWorkerService,
+    UsesAllDeps,
 };
 use crate::worker::Worker;
 use crate::workerctx::WorkerCtx;
-use futures_util::Stream;
-use futures_util::StreamExt;
+use futures::Stream;
+use futures::StreamExt;
 use gethostname::gethostname;
 use golem_api_grpc::proto::golem;
-use golem_api_grpc::proto::golem::worker::{Cursor, ResourceMetadata, UpdateMode};
+use golem_api_grpc::proto::golem::worker::{Cursor, UpdateMode};
 use golem_api_grpc::proto::golem::workerexecutor::v1::worker_executor_server::WorkerExecutor;
 use golem_api_grpc::proto::golem::workerexecutor::v1::{
     ActivatePluginRequest, ActivatePluginResponse, CancelInvocationRequest,
     CancelInvocationResponse, ConnectWorkerRequest, DeactivatePluginRequest,
     DeactivatePluginResponse, DeleteWorkerRequest, ForkWorkerRequest, ForkWorkerResponse,
-    GetFileContentsRequest, GetFileContentsResponse, GetOplogRequest, GetOplogResponse,
-    GetRunningWorkersMetadataRequest, GetRunningWorkersMetadataResponse, GetWorkersMetadataRequest,
-    GetWorkersMetadataResponse, InvokeAndAwaitWorkerJsonRequest, InvokeAndAwaitWorkerRequest,
+    GetFileContentsRequest, GetFileContentsResponse, GetFileSystemNodeRequest,
+    GetFileSystemNodeResponse, GetOplogRequest, GetOplogResponse, GetRunningWorkersMetadataRequest,
+    GetRunningWorkersMetadataResponse, GetWorkersMetadataRequest, GetWorkersMetadataResponse,
+    InvokeAndAwaitWorkerJsonRequest, InvokeAndAwaitWorkerRequest,
     InvokeAndAwaitWorkerResponseTyped, InvokeAndAwaitWorkerSuccess, InvokeJsonWorkerRequest,
-    InvokeWorkerResponse, ListDirectoryRequest, ListDirectoryResponse, RevertWorkerRequest,
-    RevertWorkerResponse, SearchOplogRequest, SearchOplogResponse, UpdateWorkerRequest,
-    UpdateWorkerResponse,
+    InvokeWorkerResponse, RevertWorkerRequest, RevertWorkerResponse, SearchOplogRequest,
+    SearchOplogResponse, UpdateWorkerRequest, UpdateWorkerResponse,
 };
 use golem_common::grpc::{
     proto_account_id_string, proto_component_id_string, proto_idempotency_key_string,
-    proto_plugin_installation_id_string, proto_promise_id_string, proto_target_worker_id_string,
-    proto_worker_id_string,
+    proto_plugin_installation_id_string, proto_promise_id_string, proto_worker_id_string,
 };
 use golem_common::metrics::api::record_new_grpc_api_active_stream;
+use golem_common::model::invocation_context::InvocationContextStack;
 use golem_common::model::oplog::{OplogIndex, UpdateDescription};
+use golem_common::model::protobuf::to_protobuf_resource_description;
 use golem_common::model::{
-    AccountId, ComponentFilePath, ComponentId, ComponentType, IdempotencyKey, OwnedWorkerId,
-    PluginInstallationId, ScanCursor, ShardId, TimestampedWorkerInvocation, WorkerEvent,
-    WorkerFilter, WorkerId, WorkerInvocation, WorkerMetadata, WorkerStatus,
+    AccountId, ComponentFilePath, ComponentId, ComponentType, GetFileSystemNodeResult,
+    IdempotencyKey, OwnedWorkerId, PluginInstallationId, ProjectId, ScanCursor, ShardId,
+    TimestampedWorkerInvocation, WorkerEvent, WorkerFilter, WorkerId, WorkerInvocation,
+    WorkerMetadata, WorkerStatus,
 };
 use golem_common::{model as common_model, recorded_grpc_api_request};
 use golem_service_base::error::worker_executor::*;
-use golem_wasm_rpc::protobuf::type_annotated_value::TypeAnnotatedValue;
 use golem_wasm_rpc::protobuf::Val;
+use golem_wasm_rpc::ValueAndType;
 use std::cmp::min;
 use std::collections::HashMap;
 use std::fmt::{Debug, Display, Formatter};
@@ -257,18 +260,20 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         request: golem::workerexecutor::v1::CreateWorkerRequest,
     ) -> Result<(), WorkerExecutorError> {
         let owned_worker_id =
-            extract_owned_worker_id(&request, |r| &r.worker_id, |r| &r.account_id)?;
+            extract_owned_worker_id(&request, |r| &r.worker_id, |r| &r.project_id)?;
+        let account_id = extract_account_id(&request, |r| &r.account_id)?;
+
         self.ensure_worker_belongs_to_this_executor(&owned_worker_id)?;
 
         if let Some(limits) = request.account_limits {
-            Ctx::record_last_known_limits(self, &owned_worker_id.account_id, &limits.into())
+            Ctx::record_last_known_limits(self, &owned_worker_id.project_id, &limits.into())
                 .await?;
         }
 
         let component_version = request.component_version;
 
         let existing_worker = self.worker_service().get(&owned_worker_id).await;
-        if existing_worker.is_some() {
+        if existing_worker.is_some() && !request.ignore_already_existing {
             return Err(WorkerExecutorError::worker_already_exists(
                 owned_worker_id.worker_id(),
             ));
@@ -283,11 +288,21 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
 
         let worker = Worker::get_or_create_suspended(
             self,
+            &account_id,
             &owned_worker_id,
             Some(args),
             Some(env),
+            Some(
+                request
+                    .wasi_config_vars
+                    .ok_or(WorkerExecutorError::invalid_request(
+                        "no wasi_config_vars field",
+                    ))?
+                    .into(),
+            ),
             Some(component_version),
             None,
+            &InvocationContextStack::fresh(),
         )
         .await?;
 
@@ -330,8 +345,9 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         let owned_worker_id = extract_owned_worker_id(
             &(&request, promise_id.clone()),
             |(_, r)| &r.worker_id,
-            |(r, _)| &r.account_id,
+            |(r, _)| &r.project_id,
         )?;
+        let account_id = extract_account_id(&request, |r| &r.account_id)?;
         self.ensure_worker_belongs_to_this_executor(&owned_worker_id)?;
 
         let data = request.data;
@@ -360,8 +376,18 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
             // By making sure the worker is in memory. If it was suspended because of waiting
             // for a promise, replaying that call will now not suspend as the promise has been
             // completed, and the worker will continue running.
-            Worker::get_or_create_running(&self.services, &owned_worker_id, None, None, None, None)
-                .await?;
+            Worker::get_or_create_running(
+                &self.services,
+                &account_id,
+                &owned_worker_id,
+                None,
+                None,
+                None,
+                None,
+                None,
+                &InvocationContextStack::fresh(),
+            )
+            .await?;
         }
 
         let success = golem::workerexecutor::v1::CompletePromiseSuccess { completed };
@@ -374,7 +400,8 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         request: DeleteWorkerRequest,
     ) -> Result<(), WorkerExecutorError> {
         let owned_worker_id =
-            extract_owned_worker_id(&request, |r| &r.worker_id, |r| &r.account_id)?;
+            extract_owned_worker_id(&request, |r| &r.worker_id, |r| &r.project_id)?;
+        let account_id = extract_account_id(&request, |r| &r.account_id)?;
         self.ensure_worker_belongs_to_this_executor(&owned_worker_id)?;
 
         if let Some(metadata) =
@@ -389,9 +416,18 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
             };
 
             if should_interrupt {
-                let worker =
-                    Worker::get_or_create_suspended(self, &owned_worker_id, None, None, None, None)
-                        .await?;
+                let worker = Worker::get_or_create_suspended(
+                    self,
+                    &account_id,
+                    &owned_worker_id,
+                    None,
+                    None,
+                    None,
+                    None,
+                    None,
+                    &InvocationContextStack::fresh(),
+                )
+                .await?;
 
                 if let Some(mut await_interrupted) =
                     worker.set_interrupting(InterruptKind::Interrupt).await
@@ -419,7 +455,14 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
             .clone()
             .ok_or(WorkerExecutorError::invalid_request("account_id not found"))?;
 
-        let account_id = account_id_proto.into();
+        let account_id: AccountId = account_id_proto.into();
+
+        let project_id_proto = request
+            .project_id
+            .ok_or(WorkerExecutorError::invalid_request("project_id not found"))?;
+        let project_id: ProjectId = project_id_proto
+            .try_into()
+            .map_err(WorkerExecutorError::invalid_request)?;
 
         let target_worker_id_proto = request
             .target_worker_id
@@ -430,7 +473,7 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
             .try_into()
             .map_err(WorkerExecutorError::invalid_request)?;
 
-        let owned_target_worker_id = OwnedWorkerId::new(&account_id, &target_worker_id);
+        let owned_target_worker_id = OwnedWorkerId::new(&project_id, &target_worker_id);
 
         let source_worker_id_proto = request
             .source_worker_id
@@ -441,11 +484,12 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
             .try_into()
             .map_err(WorkerExecutorError::invalid_request)?;
 
-        let owned_source_worker_id = OwnedWorkerId::new(&account_id, &source_worker_id);
+        let owned_source_worker_id = OwnedWorkerId::new(&project_id, &source_worker_id);
 
         self.services
             .worker_fork_service()
             .fork(
+                &account_id,
                 &owned_source_worker_id,
                 &owned_target_worker_id.worker_id,
                 OplogIndex::from_u64(request.oplog_index_cutoff),
@@ -466,7 +510,8 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         request: RevertWorkerRequest,
     ) -> Result<(), WorkerExecutorError> {
         let owned_worker_id =
-            extract_owned_worker_id(&request, |r| &r.worker_id, |r| &r.account_id)?;
+            extract_owned_worker_id(&request, |r| &r.worker_id, |r| &r.project_id)?;
+        let account_id = extract_account_id(&request, |r| &r.account_id)?;
         self.ensure_worker_belongs_to_this_executor(&owned_worker_id)?;
 
         let target = request
@@ -480,9 +525,18 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
 
         match metadata {
             Some(_) => {
-                let worker =
-                    Worker::get_or_create_suspended(self, &owned_worker_id, None, None, None, None)
-                        .await?;
+                let worker = Worker::get_or_create_suspended(
+                    self,
+                    &account_id,
+                    &owned_worker_id,
+                    None,
+                    None,
+                    None,
+                    None,
+                    None,
+                    &InvocationContextStack::fresh(),
+                )
+                .await?;
                 worker.revert(target).await?;
                 Ok(())
             }
@@ -497,7 +551,8 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         request: CancelInvocationRequest,
     ) -> Result<bool, WorkerExecutorError> {
         let owned_worker_id =
-            extract_owned_worker_id(&request, |r| &r.worker_id, |r| &r.account_id)?;
+            extract_owned_worker_id(&request, |r| &r.worker_id, |r| &r.project_id)?;
+        let account_id = extract_account_id(&request, |r| &r.account_id)?;
         self.ensure_worker_belongs_to_this_executor(&owned_worker_id)?;
 
         let idempotency_key = request
@@ -521,11 +576,14 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
                 {
                     let worker = Worker::get_or_create_suspended(
                         self,
+                        &account_id,
                         &owned_worker_id,
                         None,
                         None,
                         None,
                         None,
+                        None,
+                        &InvocationContextStack::fresh(),
                     )
                     .await?;
                     worker.cancel_invocation(idempotency_key).await?;
@@ -551,7 +609,8 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         request: golem::workerexecutor::v1::InterruptWorkerRequest,
     ) -> Result<(), WorkerExecutorError> {
         let owned_worker_id =
-            extract_owned_worker_id(&request, |r| &r.worker_id, |r| &r.account_id)?;
+            extract_owned_worker_id(&request, |r| &r.worker_id, |r| &r.project_id)?;
+        let account_id = extract_account_id(&request, |r| &r.account_id)?;
         self.ensure_worker_belongs_to_this_executor(&owned_worker_id)?;
 
         let metadata = Worker::<Ctx>::get_latest_metadata(&self.services, &owned_worker_id).await?;
@@ -591,11 +650,14 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
                     debug!("Marking suspended worker as interrupted");
                     let worker = Worker::get_or_create_suspended(
                         self,
+                        &account_id,
                         &owned_worker_id,
                         None,
                         None,
                         None,
                         None,
+                        None,
+                        &InvocationContextStack::fresh(),
                     )
                     .await?;
                     worker.set_interrupting(InterruptKind::Interrupt).await;
@@ -606,11 +668,14 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
                     debug!("Marking worker scheduled to be retried as interrupted");
                     let worker = Worker::get_or_create_suspended(
                         self,
+                        &account_id,
                         &owned_worker_id,
                         None,
                         None,
                         None,
                         None,
+                        None,
+                        &InvocationContextStack::fresh(),
                     )
                     .await?;
                     worker.set_interrupting(InterruptKind::Interrupt).await;
@@ -620,11 +685,14 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
                 WorkerStatus::Running => {
                     let worker = Worker::get_or_create_suspended(
                         self,
+                        &account_id,
                         &owned_worker_id,
                         None,
                         None,
                         None,
                         None,
+                        None,
+                        &InvocationContextStack::fresh(),
                     )
                     .await?;
                     worker
@@ -649,7 +717,8 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         request: golem::workerexecutor::v1::ResumeWorkerRequest,
     ) -> Result<(), WorkerExecutorError> {
         let owned_worker_id =
-            extract_owned_worker_id(&request, |r| &r.worker_id, |r| &r.account_id)?;
+            extract_owned_worker_id(&request, |r| &r.worker_id, |r| &r.project_id)?;
+        let account_id = extract_account_id(&request, |r| &r.account_id)?;
         self.ensure_worker_belongs_to_this_executor(&owned_worker_id)?;
 
         let force_resume = request.force.unwrap_or(false);
@@ -670,11 +739,14 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
                 );
                 let _ = Worker::get_or_create_running(
                     &self.services,
+                    &account_id,
                     &owned_worker_id,
                     None,
                     None,
                     None,
                     None,
+                    None,
+                    &InvocationContextStack::fresh(),
                 )
                 .await?;
                 Ok(())
@@ -686,11 +758,14 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
                 );
                 let _ = Worker::get_or_create_running(
                     &self.services,
+                    &account_id,
                     &owned_worker_id,
                     None,
                     None,
                     None,
                     None,
+                    None,
+                    &InvocationContextStack::fresh(),
                 )
                 .await?;
                 Ok(())
@@ -718,7 +793,7 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
     async fn invoke_and_await_worker_internal_typed<Req: GrpcInvokeRequest>(
         &self,
         request: &Req,
-    ) -> Result<Option<TypeAnnotatedValue>, WorkerExecutorError> {
+    ) -> Result<Option<ValueAndType>, WorkerExecutorError> {
         let full_function_name = request.name();
 
         let worker = self.get_or_create(request).await?;
@@ -744,18 +819,7 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
             )
             .await?;
 
-        let tav =
-            value
-                .map(|value| value.try_into())
-                .transpose()
-                .map_err(|msgs: Vec<String>| {
-                    WorkerExecutorError::runtime(format!(
-                        "Failed to encode result: {}",
-                        msgs.join(", ")
-                    ))
-                })?;
-
-        Ok(tav)
+        Ok(value)
     }
 
     async fn get_or_create<Req: CanStartWorker>(
@@ -771,25 +835,11 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         &self,
         request: &Req,
     ) -> Result<Arc<Worker<Ctx>>, WorkerExecutorError> {
-        let target_worker_id = request.worker_id()?;
-
-        let current_assignment = self.shard_service().current_assignment()?;
-
-        let unspecified_name = target_worker_id.worker_name.is_none();
-        let worker_id = target_worker_id.into_worker_id(
-            &current_assignment.shard_ids,
-            current_assignment.number_of_shards,
-        );
-
-        if unspecified_name {
-            info!(
-                worker_id = worker_id.to_string(),
-                "Generated new unique worker id"
-            );
-        }
+        let worker_id = request.worker_id()?;
+        let project_id = request.project_id()?;
 
         let account_id: AccountId = request.account_id()?;
-        let owned_worker_id = OwnedWorkerId::new(&account_id, &worker_id);
+        let owned_worker_id = OwnedWorkerId::new(&project_id, &worker_id);
         self.ensure_worker_belongs_to_this_executor(&worker_id)?;
 
         let metadata = self.worker_service().get(&owned_worker_id).await;
@@ -799,16 +849,22 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         }
 
         if let Some(limits) = request.account_limits() {
-            Ctx::record_last_known_limits(self, &account_id, &limits.into()).await?;
+            Ctx::record_last_known_limits(self, &project_id, &limits.into()).await?;
         }
 
+        let invocation_context = request
+            .maybe_invocation_context()
+            .unwrap_or_else(InvocationContextStack::fresh);
         Worker::get_or_create_suspended(
             self,
+            &account_id,
             &owned_worker_id,
             request.args(),
             request.env(),
+            request.wasi_config_vars()?,
             None,
             request.parent(),
+            &invocation_context,
         )
         .await
     }
@@ -888,7 +944,7 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         request: golem::workerexecutor::v1::GetWorkerMetadataRequest,
     ) -> Result<golem::worker::WorkerMetadata, WorkerExecutorError> {
         let owned_worker_id =
-            extract_owned_worker_id(&request, |r| &r.worker_id, |r| &r.account_id)?;
+            extract_owned_worker_id(&request, |r| &r.worker_id, |r| &r.project_id)?;
         self.ensure_worker_belongs_to_this_executor(&owned_worker_id)?;
 
         let metadata = Worker::<Ctx>::get_latest_metadata(&self.services, &owned_worker_id)
@@ -904,10 +960,7 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         )
         .await;
 
-        Ok(Self::create_proto_metadata(
-            metadata,
-            last_error_and_retry_count,
-        ))
+        Self::create_proto_metadata(metadata, last_error_and_retry_count)
     }
 
     async fn get_running_workers_metadata_internal(
@@ -932,7 +985,7 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         let result: Vec<golem::worker::WorkerMetadata> = workers
             .into_iter()
             .map(|worker_metadata| Self::create_proto_metadata(worker_metadata, None))
-            .collect();
+            .collect::<Result<Vec<_>, _>>()?;
 
         Ok(result)
     }
@@ -946,10 +999,10 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
             .and_then(|t| t.try_into().ok())
             .ok_or(WorkerExecutorError::invalid_request("Invalid component id"))?;
 
-        let account_id: AccountId = request
-            .account_id
-            .map(|t| t.into())
-            .ok_or(WorkerExecutorError::invalid_request("Invalid account id"))?;
+        let project_id: ProjectId = request
+            .project_id
+            .and_then(|t| t.try_into().ok())
+            .ok_or(WorkerExecutorError::invalid_request("Invalid project id"))?;
 
         let filter: Option<WorkerFilter> = match request.filter {
             Some(f) => Some(f.try_into().map_err(WorkerExecutorError::invalid_request)?),
@@ -959,7 +1012,7 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         let (new_cursor, workers) = self
             .worker_enumeration_service()
             .get(
-                &account_id,
+                &project_id,
                 &component_id,
                 filter,
                 request
@@ -984,7 +1037,8 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
                 &worker_metadata.last_known_status,
             )
             .await;
-            let metadata = Self::create_proto_metadata(worker_metadata, last_error_and_retry_count);
+            let metadata =
+                Self::create_proto_metadata(worker_metadata, last_error_and_retry_count)?;
             result.push(metadata);
         }
 
@@ -1002,7 +1056,8 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         request: UpdateWorkerRequest,
     ) -> Result<(), WorkerExecutorError> {
         let owned_worker_id =
-            extract_owned_worker_id(&request, |r| &r.worker_id, |r| &r.account_id)?;
+            extract_owned_worker_id(&request, |r| &r.worker_id, |r| &r.project_id)?;
+        let account_id = extract_account_id(&request, |r| &r.account_id)?;
         self.ensure_worker_belongs_to_this_executor(&owned_worker_id)?;
 
         let mut metadata = Worker::<Ctx>::get_latest_metadata(&self.services, &owned_worker_id)
@@ -1020,7 +1075,7 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         let component_metadata = self
             .component_service()
             .get_metadata(
-                &owned_worker_id.account_id,
+                &owned_worker_id.project_id,
                 &owned_worker_id.worker_id.component_id,
                 Some(metadata.last_known_status.component_version),
             )
@@ -1066,11 +1121,14 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
                         debug!("Activating worker for update",);
                         let worker = Worker::get_or_create_suspended(
                             self,
+                            &account_id,
                             &owned_worker_id,
                             None,
                             None,
+                            None,
                             Some(metadata.last_known_status.component_version),
                             None,
+                            &InvocationContextStack::fresh(),
                         )
                         .await?;
 
@@ -1101,11 +1159,14 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
                         // to begin the update.
                         let worker = Worker::get_or_create_suspended(
                             self,
+                            &account_id,
                             &owned_worker_id,
                             None,
                             None,
                             None,
                             None,
+                            None,
+                            &InvocationContextStack::fresh(),
                         )
                         .await?;
 
@@ -1133,9 +1194,18 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
                 // This is in a race condition with other worker invocations, so the whole update
                 // process need to be initiated through the worker's invocation queue.
 
-                let worker =
-                    Worker::get_or_create_suspended(self, &owned_worker_id, None, None, None, None)
-                        .await?;
+                let worker = Worker::get_or_create_suspended(
+                    self,
+                    &account_id,
+                    &owned_worker_id,
+                    None,
+                    None,
+                    None,
+                    None,
+                    None,
+                    &InvocationContextStack::fresh(),
+                )
+                .await?;
                 worker.enqueue_manual_update(request.target_version).await;
             }
         }
@@ -1147,17 +1217,10 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         &self,
         request: ConnectWorkerRequest,
     ) -> ResponseResult<<Self as WorkerExecutor>::ConnectWorkerStream> {
-        let worker_id: WorkerId = request
-            .worker_id
-            .ok_or(WorkerExecutorError::invalid_request("missing worker_id"))?
-            .try_into()
-            .map_err(WorkerExecutorError::invalid_request)?;
-        let account_id: AccountId = request
-            .account_id
-            .ok_or(WorkerExecutorError::invalid_request("missing account_id"))?
-            .into();
-        let owned_worker_id = OwnedWorkerId::new(&account_id, &worker_id);
-        self.ensure_worker_belongs_to_this_executor(&worker_id)?;
+        let owned_worker_id =
+            extract_owned_worker_id(&request, |r| &r.worker_id, |r| &r.project_id)?;
+        let account_id = extract_account_id(&request, |r| &r.account_id)?;
+        self.ensure_worker_belongs_to_this_executor(&owned_worker_id)?;
 
         let metadata = Worker::<Ctx>::get_latest_metadata(self, &owned_worker_id)
             .await?
@@ -1168,10 +1231,19 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         self.ensure_not_failed(&owned_worker_id, &metadata).await?;
 
         if metadata.last_known_status.status != WorkerStatus::Interrupted {
-            let event_service =
-                Worker::get_or_create_suspended(self, &owned_worker_id, None, None, None, None)
-                    .await?
-                    .event_service();
+            let event_service = Worker::get_or_create_suspended(
+                self,
+                &account_id,
+                &owned_worker_id,
+                None,
+                None,
+                None,
+                None,
+                None,
+                &InvocationContextStack::fresh(),
+            )
+            .await?
+            .event_service();
 
             let receiver = event_service.receiver();
 
@@ -1193,7 +1265,7 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         request: GetOplogRequest,
     ) -> Result<GetOplogResponse, WorkerExecutorError> {
         let owned_worker_id =
-            extract_owned_worker_id(&request, |r| &r.worker_id, |r| &r.account_id)?;
+            extract_owned_worker_id(&request, |r| &r.worker_id, |r| &r.project_id)?;
         self.ensure_worker_belongs_to_this_executor(&owned_worker_id)?;
 
         let chunk = match request.cursor {
@@ -1201,6 +1273,7 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
                 self.component_service(),
                 self.oplog_service(),
                 self.plugins(),
+                self.project_service(),
                 &owned_worker_id,
                 cursor.current_component_version,
                 OplogIndex::from_u64(cursor.next_oplog_index),
@@ -1221,6 +1294,7 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
                     self.component_service(),
                     self.oplog_service(),
                     self.plugins(),
+                    self.project_service(),
                     &owned_worker_id,
                     initial_component_version,
                     start,
@@ -1267,7 +1341,7 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         request: SearchOplogRequest,
     ) -> Result<SearchOplogResponse, WorkerExecutorError> {
         let owned_worker_id =
-            extract_owned_worker_id(&request, |r| &r.worker_id, |r| &r.account_id)?;
+            extract_owned_worker_id(&request, |r| &r.worker_id, |r| &r.project_id)?;
         self.ensure_worker_belongs_to_this_executor(&owned_worker_id)?;
 
         let chunk = match request.cursor {
@@ -1275,6 +1349,7 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
                 self.component_service(),
                 self.oplog_service(),
                 self.plugins(),
+                self.project_service(),
                 &owned_worker_id,
                 cursor.current_component_version,
                 OplogIndex::from_u64(cursor.next_oplog_index),
@@ -1295,6 +1370,7 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
                     self.component_service(),
                     self.oplog_service(),
                     self.plugins(),
+                    self.project_service(),
                     &owned_worker_id,
                     initial_component_version,
                     start,
@@ -1343,38 +1419,40 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         })
     }
 
-    async fn list_directory_internal(
+    async fn get_file_system_node_internal(
         &self,
-        request: ListDirectoryRequest,
-    ) -> Result<ListDirectoryResponse, WorkerExecutorError> {
+        request: GetFileSystemNodeRequest,
+    ) -> Result<GetFileSystemNodeResponse, WorkerExecutorError> {
         let path = ComponentFilePath::from_abs_str(&request.path)
             .map_err(|e| WorkerExecutorError::invalid_request(format!("Invalid path: {e}")))?;
 
         let worker = self.get_or_create(&request).await?;
 
-        let result = worker.list_directory(path).await?;
+        let result = worker.get_file_system_node(path).await?;
 
         let response = match result {
-            ListDirectoryResult::Ok(entries) => ListDirectoryResponse {
+            GetFileSystemNodeResult::Ok(entries) => GetFileSystemNodeResponse {
                 result: Some(
-                    golem::workerexecutor::v1::list_directory_response::Result::Success(
+                    golem::workerexecutor::v1::get_file_system_node_response::Result::DirSuccess(
                         golem::workerexecutor::v1::ListDirectorySuccessResponse {
                             nodes: entries.into_iter().map(|entry| entry.into()).collect(),
                         },
                     ),
                 ),
             },
-            ListDirectoryResult::NotFound => ListDirectoryResponse {
+            GetFileSystemNodeResult::NotFound => GetFileSystemNodeResponse {
                 result: Some(
-                    golem::workerexecutor::v1::list_directory_response::Result::NotFound(
+                    golem::workerexecutor::v1::get_file_system_node_response::Result::NotFound(
                         golem::common::Empty {},
                     ),
                 ),
             },
-            ListDirectoryResult::NotADirectory => ListDirectoryResponse {
+            GetFileSystemNodeResult::File(file_node) => GetFileSystemNodeResponse {
                 result: Some(
-                    golem::workerexecutor::v1::list_directory_response::Result::NotADirectory(
-                        golem::common::Empty {},
+                    golem::workerexecutor::v1::get_file_system_node_response::Result::FileSuccess(
+                        golem::workerexecutor::v1::ListFileDataSuccessResponse {
+                            file: Some(file_node.into()),
+                        },
                     ),
                 ),
             },
@@ -1465,7 +1543,8 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         request: ActivatePluginRequest,
     ) -> Result<(), WorkerExecutorError> {
         let owned_worker_id =
-            extract_owned_worker_id(&request, |r| &r.worker_id, |r| &r.account_id)?;
+            extract_owned_worker_id(&request, |r| &r.worker_id, |r| &r.project_id)?;
+        let account_id = extract_account_id(&request, |r| &r.account_id)?;
         self.ensure_worker_belongs_to_this_executor(&owned_worker_id)?;
 
         let plugin_installation_id =
@@ -1496,24 +1575,27 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
                     let component_metadata = self
                         .component_service()
                         .get_metadata(
-                            &owned_worker_id.account_id,
+                            &owned_worker_id.project_id,
                             &owned_worker_id.worker_id.component_id,
                             Some(metadata.last_known_status.component_version),
                         )
                         .await?;
 
                     if component_metadata
-                        .plugin_installations
+                        .installed_plugins
                         .iter()
                         .any(|installation| installation.id == plugin_installation_id)
                     {
                         let worker = Worker::get_or_create_suspended(
                             self,
+                            &account_id,
                             &owned_worker_id,
                             None,
                             None,
                             None,
                             None,
+                            None,
+                            &InvocationContextStack::fresh(),
                         )
                         .await?;
                         worker.activate_plugin(plugin_installation_id).await?;
@@ -1536,7 +1618,8 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         request: DeactivatePluginRequest,
     ) -> Result<(), WorkerExecutorError> {
         let owned_worker_id =
-            extract_owned_worker_id(&request, |r| &r.worker_id, |r| &r.account_id)?;
+            extract_owned_worker_id(&request, |r| &r.worker_id, |r| &r.project_id)?;
+        let account_id = extract_account_id(&request, |r| &r.account_id)?;
         self.ensure_worker_belongs_to_this_executor(&owned_worker_id)?;
 
         let plugin_installation_id =
@@ -1567,24 +1650,27 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
                     let component_metadata = self
                         .component_service()
                         .get_metadata(
-                            &owned_worker_id.account_id,
+                            &owned_worker_id.project_id,
                             &owned_worker_id.worker_id.component_id,
                             Some(metadata.last_known_status.component_version),
                         )
                         .await?;
 
                     if component_metadata
-                        .plugin_installations
+                        .installed_plugins
                         .iter()
                         .any(|installation| installation.id == plugin_installation_id)
                     {
                         let worker = Worker::get_or_create_suspended(
                             self,
+                            &account_id,
                             &owned_worker_id,
                             None,
                             None,
                             None,
                             None,
+                            None,
+                            &InvocationContextStack::fresh(),
                         )
                         .await?;
                         worker.deactivate_plugin(plugin_installation_id).await?;
@@ -1605,7 +1691,7 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
     fn create_proto_metadata(
         metadata: WorkerMetadata,
         last_error_and_retry_count: Option<LastError>,
-    ) -> golem::worker::WorkerMetadata {
+    ) -> Result<golem::worker::WorkerMetadata, WorkerExecutorError> {
         let mut updates = Vec::new();
 
         let latest_status = metadata.last_known_status;
@@ -1658,24 +1744,20 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
                 + record.timestamp.as_ref().unwrap().nanos as i64
         });
 
-        let mut owned_resources = HashMap::new();
+        let mut owned_resources = Vec::new();
         for (resource_id, resource) in latest_status.owned_resources {
-            owned_resources.insert(
-                resource_id.0,
-                ResourceMetadata {
-                    created_at: Some(resource.created_at.into()),
-                    indexed: resource.indexed_resource_key.map(|t| t.into()),
-                },
-            );
+            owned_resources.push(to_protobuf_resource_description(resource_id, resource));
         }
 
         let active_plugins = latest_status.active_plugins;
 
-        golem::worker::WorkerMetadata {
+        Ok(golem::worker::WorkerMetadata {
             worker_id: Some(metadata.worker_id.into()),
+            project_id: Some(metadata.project_id.into()),
             args: metadata.args.clone(),
             env: HashMap::from_iter(metadata.env.iter().cloned()),
-            account_id: Some(metadata.account_id.into()),
+            created_by: Some(metadata.created_by.into()),
+            wasi_config_vars: Some(metadata.wasi_config_vars.into()),
             component_version: latest_status.component_version,
             status: Into::<golem::worker::WorkerStatus>::into(latest_status.status.clone()).into(),
             retry_count: last_error_and_retry_count
@@ -1702,7 +1784,7 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
                 .into_regions()
                 .map(|region| region.into())
                 .collect(),
-        }
+        })
     }
 }
 
@@ -1768,7 +1850,7 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         let request = request.into_inner();
         let record = recorded_grpc_api_request!(
             "invoke_and_await_worker",
-            worker_id = proto_target_worker_id_string(&request.worker_id),
+            worker_id = proto_worker_id_string(&request.worker_id),
             idempotency_key = proto_idempotency_key_string(&request.idempotency_key),
             account_id = proto_account_id_string(&request.account_id),
         );
@@ -1807,17 +1889,15 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         let request = request.into_inner();
         let record = recorded_grpc_api_request!(
             "invoke_and_await_worker_typed",
-            worker_id = proto_target_worker_id_string(&request.worker_id),
+            worker_id = proto_worker_id_string(&request.worker_id),
             idempotency_key = proto_idempotency_key_string(&request.idempotency_key),
             account_id = proto_account_id_string(&request.account_id),
         );
 
         match self.invoke_and_await_worker_internal_typed(&request).instrument(record.span.clone()).await {
-            Ok(type_annotated_value) => {
+            Ok(value_and_type) => {
                 let result = golem::workerexecutor::v1::InvokeAndAwaitWorkerSuccessTyped {
-                    output: type_annotated_value.map(|tav| golem_wasm_rpc::protobuf::TypeAnnotatedValue {
-                        type_annotated_value: Some(tav),
-                    })
+                    output: value_and_type.map(|vnt| vnt.into())
                 };
 
                 record.succeed(Ok(Response::new(
@@ -1850,7 +1930,7 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         let request = request.into_inner();
         let record = recorded_grpc_api_request!(
             "invoke_worker",
-            worker_id = proto_target_worker_id_string(&request.worker_id),
+            worker_id = proto_worker_id_string(&request.worker_id),
             function = request.name,
             account_id = proto_account_id_string(&request.account_id),
             idempotency_key = proto_idempotency_key_string(&request.idempotency_key),
@@ -1892,21 +1972,19 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         let request = request.into_inner();
         let record = recorded_grpc_api_request!(
             "invoke_and_await_worker_json",
-            worker_id = proto_target_worker_id_string(&request.worker_id),
+            worker_id = proto_worker_id_string(&request.worker_id),
             idempotency_key = proto_idempotency_key_string(&request.idempotency_key),
             account_id = proto_account_id_string(&request.account_id),
         );
 
         match self.invoke_and_await_worker_internal_typed(&request).instrument(record.span.clone()).await {
-            Ok(type_annotated_value) => {
+            Ok(value_and_type) => {
                 let result = golem::workerexecutor::v1::InvokeAndAwaitWorkerSuccessTyped {
-                    output: type_annotated_value.map(|tav| golem_wasm_rpc::protobuf::TypeAnnotatedValue {
-                        type_annotated_value: Some(tav),
-                    })
+                    output: value_and_type.map(|vnt| vnt.into())
                 };
 
                 record.succeed(Ok(Response::new(
-                    golem::workerexecutor::v1::InvokeAndAwaitWorkerResponseTyped {
+                    InvokeAndAwaitWorkerResponseTyped {
                         result: Some(
                             golem::workerexecutor::v1::invoke_and_await_worker_response_typed::Result::Success(result),
                         ),
@@ -1935,7 +2013,7 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         let request = request.into_inner();
         let record = recorded_grpc_api_request!(
             "invoke_worker_json",
-            worker_id = proto_target_worker_id_string(&request.worker_id),
+            worker_id = proto_worker_id_string(&request.worker_id),
             function = request.name,
             account_id = proto_account_id_string(&request.account_id),
             idempotency_key = proto_idempotency_key_string(&request.idempotency_key),
@@ -2553,27 +2631,27 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         }
     }
 
-    async fn list_directory(
+    async fn get_file_system_node(
         &self,
-        request: Request<ListDirectoryRequest>,
-    ) -> ResponseResult<ListDirectoryResponse> {
+        request: Request<GetFileSystemNodeRequest>,
+    ) -> ResponseResult<GetFileSystemNodeResponse> {
         let request = request.into_inner();
         let record = recorded_grpc_api_request!(
-            "list_directory",
-            worker_id = proto_target_worker_id_string(&request.worker_id),
+            "get_file_system_node",
+            worker_id = proto_worker_id_string(&request.worker_id),
             path = request.path,
         );
 
         let result = self
-            .list_directory_internal(request)
+            .get_file_system_node_internal(request)
             .instrument(record.span.clone())
             .await;
         match result {
             Ok(response) => record.succeed(Ok(Response::new(response))),
             Err(err) => record.fail(
-                Ok(Response::new(ListDirectoryResponse {
+                Ok(Response::new(GetFileSystemNodeResponse {
                     result: Some(
-                        golem::workerexecutor::v1::list_directory_response::Result::Failure(
+                        golem::workerexecutor::v1::get_file_system_node_response::Result::Failure(
                             err.clone().into(),
                         ),
                     ),
@@ -2593,7 +2671,7 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + UsesAllDeps<Ctx = Ctx> + Send + Sync +
         let request = request.into_inner();
         let record = recorded_grpc_api_request!(
             "get_file_contents",
-            worker_id = proto_target_worker_id_string(&request.worker_id),
+            worker_id = proto_worker_id_string(&request.worker_id),
             path = request.file_path,
         );
 
@@ -2750,7 +2828,7 @@ impl Stream for WorkerEventStream {
 fn extract_owned_worker_id<T>(
     request: &T,
     get_worker_id: impl FnOnce(&T) -> &Option<golem::worker::WorkerId>,
-    get_account_id: impl FnOnce(&T) -> &Option<golem::common::AccountId>,
+    get_project_id: impl FnOnce(&T) -> &Option<golem::common::ProjectId>,
 ) -> Result<OwnedWorkerId, WorkerExecutorError> {
     let worker_id = get_worker_id(request)
         .as_ref()
@@ -2760,10 +2838,22 @@ fn extract_owned_worker_id<T>(
         .try_into()
         .map_err(WorkerExecutorError::invalid_request)?;
 
+    let project_id = get_project_id(request)
+        .as_ref()
+        .ok_or(WorkerExecutorError::invalid_request("project_id not found"))?;
+    let project_id: ProjectId = (*project_id)
+        .try_into()
+        .map_err(WorkerExecutorError::invalid_request)?;
+
+    Ok(OwnedWorkerId::new(&project_id, &worker_id))
+}
+
+fn extract_account_id<T>(
+    request: &T,
+    get_account_id: impl FnOnce(&T) -> &Option<golem::common::AccountId>,
+) -> Result<AccountId, WorkerExecutorError> {
     let account_id = get_account_id(request)
         .as_ref()
         .ok_or(WorkerExecutorError::invalid_request("account_id not found"))?;
-    let account_id: AccountId = account_id.clone().into();
-
-    Ok(OwnedWorkerId::new(&account_id, &worker_id))
+    Ok(account_id.clone().into())
 }
diff --git a/golem-worker-executor/src/lib.rs b/golem-worker-executor/src/lib.rs
index d76e0352..83ff07e1 100644
--- a/golem-worker-executor/src/lib.rs
+++ b/golem-worker-executor/src/lib.rs
@@ -31,6 +31,7 @@ test_r::enable!();
 
 use crate::grpc::WorkerExecutorImpl;
 use crate::services::active_workers::ActiveWorkers;
+use crate::services::agent_types::AgentTypesService;
 use crate::services::blob_store::{BlobStoreService, DefaultBlobStoreService};
 use crate::services::component::ComponentService;
 use crate::services::events::Events;
@@ -44,6 +45,7 @@ use crate::services::oplog::{
     OplogArchiveService, OplogService, PrimaryOplogService,
 };
 use crate::services::plugins::{Plugins, PluginsObservations};
+use crate::services::projects::ProjectService;
 use crate::services::promise::{DefaultPromiseService, PromiseService};
 use crate::services::scheduler::{SchedulerService, SchedulerServiceDefault};
 use crate::services::shard::{ShardService, ShardServiceDefault};
@@ -100,7 +102,7 @@ pub struct RunDetails {
 
 /// The Bootstrap trait should be implemented by all Worker Executors to customize the initialization
 /// of its services.
-/// With a valid `Bootstrap` implementation the service can be started with the `run` method.
+/// With a valid `Bootstrap` implementation, the service can be started with the `run` method.
 #[async_trait]
 #[allow(clippy::too_many_arguments)]
 pub trait Bootstrap<Ctx: WorkerCtx> {
@@ -114,7 +116,7 @@ pub trait Bootstrap<Ctx: WorkerCtx> {
         join_set: &mut JoinSet<Result<(), anyhow::Error>>,
     ) -> anyhow::Result<u16> {
         let golem_config = service_dependencies.config();
-        let (mut health_reporter, health_service) = tonic_health::server::health_reporter();
+        let (health_reporter, health_service) = tonic_health::server::health_reporter();
         health_reporter
             .set_serving::<WorkerExecutorServer<WorkerExecutorImpl<Ctx, All<Ctx>>>>()
             .await;
@@ -169,6 +171,7 @@ pub trait Bootstrap<Ctx: WorkerCtx> {
         golem_config: &GolemConfig,
         blob_storage: Arc<dyn BlobStorage>,
         plugin_observations: Arc<dyn PluginsObservations>,
+        project_service: Arc<dyn ProjectService>,
     ) -> Arc<dyn ComponentService>;
 
     /// Allows customizing the `All` service.
@@ -200,6 +203,8 @@ pub trait Bootstrap<Ctx: WorkerCtx> {
         file_loader: Arc<FileLoader>,
         plugins: Arc<dyn Plugins>,
         oplog_processor_plugin: Arc<dyn OplogProcessorPlugin>,
+        project_service: Arc<dyn ProjectService>,
+        agent_type_service: Arc<dyn AgentTypesService>,
     ) -> anyhow::Result<All<Ctx>>;
 
     /// Can be overridden to customize the wasmtime configuration
@@ -282,7 +287,6 @@ pub async fn create_worker_executor_impl<Ctx: WorkerCtx, A: Bootstrap<Ctx> + ?Si
         Arc<dyn KeyValueStorage + Send + Sync>,
     ) = match &golem_config.key_value_storage {
         KeyValueStorageConfig::Redis(redis) => {
-            info!("Using Redis for key-value storage at {}", redis.url());
             let pool = RedisPool::configured(redis)
                 .await
                 .map_err(|err| anyhow!(err))?;
@@ -291,11 +295,9 @@ pub async fn create_worker_executor_impl<Ctx: WorkerCtx, A: Bootstrap<Ctx> + ?Si
             (Some(pool), None, key_value_storage)
         }
         KeyValueStorageConfig::InMemory(_) => {
-            info!("Using in-memory key-value storage");
             (None, None, Arc::new(InMemoryKeyValueStorage::new()))
         }
         KeyValueStorageConfig::Sqlite(sqlite) => {
-            info!("Using Sqlite for key-value storage at {}", sqlite.database);
             let pool = SqlitePool::configured(sqlite)
                 .await
                 .map_err(|err| anyhow!(err))?;
@@ -311,18 +313,15 @@ pub async fn create_worker_executor_impl<Ctx: WorkerCtx, A: Bootstrap<Ctx> + ?Si
     let indexed_storage: Arc<dyn IndexedStorage + Send + Sync> = match &golem_config.indexed_storage
     {
         IndexedStorageConfig::KVStoreRedis(_) => {
-            info!("Using the same Redis for indexed-storage");
             let redis = redis
                 .expect("Redis must be configured as key-value storage when using KVStoreRedis");
             Arc::new(RedisIndexedStorage::new(redis.clone()))
         }
         IndexedStorageConfig::Redis(redis) => {
-            info!("Using Redis for indexed-storage at {}", redis.url());
             let pool = RedisPool::configured(redis).await?;
             Arc::new(RedisIndexedStorage::new(pool.clone()))
         }
         IndexedStorageConfig::KVStoreSqlite(_) => {
-            info!("Using the same Sqlite for indexed-storage");
             let sqlite = sqlite
                 .clone()
                 .expect("Sqlite must be configured as key-value storage when using KVStoreSqlite");
@@ -333,7 +332,6 @@ pub async fn create_worker_executor_impl<Ctx: WorkerCtx, A: Bootstrap<Ctx> + ?Si
             )
         }
         IndexedStorageConfig::Sqlite(sqlite) => {
-            info!("Using Sqlite for indexed storage at {}", sqlite.database);
             let pool = SqlitePool::configured(sqlite)
                 .await
                 .map_err(|err| anyhow!(err))?;
@@ -344,28 +342,17 @@ pub async fn create_worker_executor_impl<Ctx: WorkerCtx, A: Bootstrap<Ctx> + ?Si
             )
         }
         IndexedStorageConfig::InMemory(_) => {
-            info!("Using in-memory indexed storage");
             Arc::new(storage::indexed::memory::InMemoryIndexedStorage::new())
         }
     };
     let blob_storage: Arc<dyn BlobStorage + Send + Sync> = match &golem_config.blob_storage {
-        BlobStorageConfig::S3(config) => {
-            info!("Using S3 for blob storage");
-            Arc::new(S3BlobStorage::new(config.clone()).await)
-        }
-        BlobStorageConfig::LocalFileSystem(config) => {
-            info!(
-                "Using local file system for blob storage at {:?}",
-                config.root
-            );
-            Arc::new(
-                golem_service_base::storage::blob::fs::FileSystemBlobStorage::new(&config.root)
-                    .await
-                    .map_err(|err| anyhow!(err))?,
-            )
-        }
+        BlobStorageConfig::S3(config) => Arc::new(S3BlobStorage::new(config.clone()).await),
+        BlobStorageConfig::LocalFileSystem(config) => Arc::new(
+            golem_service_base::storage::blob::fs::FileSystemBlobStorage::new(&config.root)
+                .await
+                .map_err(|err| anyhow!(err))?,
+        ),
         BlobStorageConfig::KVStoreSqlite(_) => {
-            info!("Using the same Sqlite for blob-storage");
             let sqlite = sqlite
                 .expect("Sqlite must be configured as key-value storage when using KVStoreSqlite");
             Arc::new(
@@ -375,7 +362,6 @@ pub async fn create_worker_executor_impl<Ctx: WorkerCtx, A: Bootstrap<Ctx> + ?Si
             )
         }
         BlobStorageConfig::Sqlite(sqlite) => {
-            info!("Using Sqlite for blob storage at {}", sqlite.database);
             let pool = SqlitePool::configured(sqlite)
                 .await
                 .map_err(|err| anyhow!(err))?;
@@ -386,7 +372,6 @@ pub async fn create_worker_executor_impl<Ctx: WorkerCtx, A: Bootstrap<Ctx> + ?Si
             )
         }
         BlobStorageConfig::InMemory(_) => {
-            info!("Using in-memory blob storage");
             Arc::new(golem_service_base::storage::blob::memory::InMemoryBlobStorage::new())
         }
     };
@@ -396,10 +381,18 @@ pub async fn create_worker_executor_impl<Ctx: WorkerCtx, A: Bootstrap<Ctx> + ?Si
     let file_loader = Arc::new(FileLoader::new(initial_files_service.clone())?);
     let (plugins, plugins_observations) = bootstrap.create_plugins(&golem_config);
 
+    let project_service = services::projects::configured(&golem_config.project_service);
+
     let component_service = bootstrap.create_component_service(
         &golem_config,
         blob_storage.clone(),
         plugins_observations,
+        project_service.clone(),
+    );
+
+    let agent_type_service = services::agent_types::configured(
+        &golem_config.agent_types_service,
+        component_service.clone(),
     );
 
     let golem_config = Arc::new(golem_config.clone());
@@ -501,6 +494,7 @@ pub async fn create_worker_executor_impl<Ctx: WorkerCtx, A: Bootstrap<Ctx> + ?Si
         shard_service.clone(),
         lazy_worker_activator.clone(),
         plugins.clone(),
+        project_service.clone(),
     ));
 
     let oplog_service: Arc<dyn OplogService> = Arc::new(ForwardingOplogService::new(
@@ -508,6 +502,7 @@ pub async fn create_worker_executor_impl<Ctx: WorkerCtx, A: Bootstrap<Ctx> + ?Si
         oplog_processor_plugin.clone(),
         component_service.clone(),
         plugins.clone(),
+        project_service.clone(),
     ));
 
     let worker_service = Arc::new(DefaultWorkerService::new(
@@ -557,6 +552,8 @@ pub async fn create_worker_executor_impl<Ctx: WorkerCtx, A: Bootstrap<Ctx> + ?Si
             file_loader,
             plugins,
             oplog_processor_plugin,
+            project_service,
+            agent_type_service,
         )
         .await?;
 
diff --git a/golem-worker-executor/src/model/mod.rs b/golem-worker-executor/src/model/mod.rs
index cdff0fc5..1614af31 100644
--- a/golem-worker-executor/src/model/mod.rs
+++ b/golem-worker-executor/src/model/mod.rs
@@ -21,15 +21,14 @@ use golem_common::model::invocation_context::{
 use golem_common::model::oplog::{PersistenceLevel, WorkerError};
 use golem_common::model::regions::DeletedRegions;
 use golem_common::model::{
-    ComponentFileSystemNode, ComponentType, ShardAssignment, ShardId, Timestamp, WorkerId,
-    WorkerStatusRecord,
+    AccountId, ComponentType, ShardAssignment, ShardId, Timestamp, WorkerId, WorkerStatusRecord,
 };
 use golem_service_base::error::worker_executor::{
     InterruptKind, WorkerExecutorError, WorkerOutOfMemory,
 };
 use golem_wasm_rpc::ValueAndType;
 use nonempty_collections::NEVec;
-use std::collections::{HashMap, HashSet};
+use std::collections::{BTreeMap, HashMap, HashSet};
 use std::fmt::{Debug, Display, Formatter};
 use std::pin::Pin;
 use std::sync::Arc;
@@ -65,21 +64,25 @@ pub struct WorkerConfig {
     pub deleted_regions: DeletedRegions,
     pub total_linear_memory_size: u64,
     pub component_version_for_replay: u64,
+    pub created_by: AccountId,
+    pub initial_wasi_config_vars: BTreeMap<String, String>,
 }
 
 impl WorkerConfig {
     pub fn new(
         worker_id: WorkerId,
-        component_version: u64,
+        target_component_version: u64,
         worker_args: Vec<String>,
         mut worker_env: Vec<(String, String)>,
         deleted_regions: DeletedRegions,
         total_linear_memory_size: u64,
         component_version_for_replay: u64,
+        created_by: AccountId,
+        initial_wasi_config_vars: BTreeMap<String, String>,
     ) -> WorkerConfig {
         let worker_name = worker_id.worker_name.clone();
         let component_id = worker_id.component_id;
-        let component_version = component_version.to_string();
+        let component_version = target_component_version.to_string();
         worker_env.retain(|(key, _)| {
             key != "GOLEM_WORKER_NAME"
                 && key != "GOLEM_COMPONENT_ID"
@@ -94,6 +97,8 @@ impl WorkerConfig {
             deleted_regions,
             total_linear_memory_size,
             component_version_for_replay,
+            created_by,
+            initial_wasi_config_vars,
         }
     }
 }
@@ -244,10 +249,7 @@ impl TrapType {
                             Some(WorkerExecutorError::ValueMismatch { details }) => {
                                 TrapType::Error(WorkerError::InvalidRequest(details.clone()))
                             }
-                            _ => {
-                                println!("boom3: {error:?}");
-                                TrapType::Error(WorkerError::Unknown(format!("{error:#}")))
-                            }
+                            _ => TrapType::Error(WorkerError::Unknown(format!("{error:#}"))),
                         },
                     },
                 },
@@ -337,13 +339,6 @@ pub enum LookupResult {
     Complete(Result<Option<ValueAndType>, WorkerExecutorError>),
 }
 
-#[derive(Clone, Debug)]
-pub enum ListDirectoryResult {
-    Ok(Vec<ComponentFileSystemNode>),
-    NotFound,
-    NotADirectory,
-}
-
 pub enum ReadFileResult {
     Ok(Pin<Box<dyn Stream<Item = Result<Bytes, WorkerExecutorError>> + Send + 'static>>),
     NotFound,
diff --git a/golem-worker-executor/src/model/public_oplog/mod.rs b/golem-worker-executor/src/model/public_oplog/mod.rs
index 04af9d64..70edae90 100644
--- a/golem-worker-executor/src/model/public_oplog/mod.rs
+++ b/golem-worker-executor/src/model/public_oplog/mod.rs
@@ -29,6 +29,7 @@ use crate::durable_host::wasm_rpc::serialized::{
 use crate::services::component::ComponentService;
 use crate::services::oplog::OplogService;
 use crate::services::plugins::Plugins;
+use crate::services::projects::ProjectService;
 use crate::services::rdbms::mysql::types as mysql_types;
 use crate::services::rdbms::mysql::MysqlType;
 use crate::services::rdbms::postgres::types as postgres_types;
@@ -38,15 +39,12 @@ use crate::services::rpc::RpcError;
 use async_trait::async_trait;
 use bincode::Decode;
 use golem_api_grpc::proto::golem::worker::UpdateMode;
-use golem_common::model::exports::{find_resource_site, function_by_name};
-use golem_common::model::invocation_context::TraceId;
 use golem_common::model::lucene::Query;
 use golem_common::model::oplog::{OplogEntry, OplogIndex, SpanData, UpdateDescription};
 use golem_common::model::public_oplog::{
     ActivatePluginParameters, CancelInvocationParameters, ChangePersistenceLevelParameters,
-    ChangeRetryPolicyParameters, CreateParameters, DeactivatePluginParameters,
-    DescribeResourceParameters, EndRegionParameters, ErrorParameters,
-    ExportedFunctionCompletedParameters, ExportedFunctionInvokedParameters,
+    ChangeRetryPolicyParameters, CreateParameters, DeactivatePluginParameters, EndRegionParameters,
+    ErrorParameters, ExportedFunctionCompletedParameters, ExportedFunctionInvokedParameters,
     ExportedFunctionParameters, FailedUpdateParameters, FinishSpanParameters, GrowMemoryParameters,
     ImportedFunctionInvokedParameters, JumpParameters, LogParameters, ManualUpdateParameters,
     PendingUpdateParameters, PendingWorkerInvocationParameters, PluginInstallationDescription,
@@ -65,10 +63,7 @@ use golem_wasm_ast::analysis::analysed_type::{
     case, field, list, option, record, result, result_err, str, u64, unit_case, variant,
 };
 use golem_wasm_ast::analysis::{AnalysedFunctionParameter, AnalysedType};
-use golem_wasm_rpc::{
-    parse_value_and_type, IntoValue, IntoValueAndType, Value, ValueAndType, WitValue,
-};
-use rib::{ParsedFunctionName, ParsedFunctionReference};
+use golem_wasm_rpc::{IntoValue, IntoValueAndType, Value, ValueAndType, WitValue};
 use std::collections::{BTreeSet, HashMap};
 use std::net::IpAddr;
 use std::sync::Arc;
@@ -86,6 +81,7 @@ pub async fn get_public_oplog_chunk(
     component_service: Arc<dyn ComponentService>,
     oplog_service: Arc<dyn OplogService>,
     plugins: Arc<dyn Plugins>,
+    projects: Arc<dyn ProjectService>,
     owned_worker_id: &OwnedWorkerId,
     initial_component_version: ComponentVersion,
     initial_oplog_index: OplogIndex,
@@ -115,6 +111,7 @@ pub async fn get_public_oplog_chunk(
             oplog_service.clone(),
             component_service.clone(),
             plugins.clone(),
+            projects.clone(),
             owned_worker_id,
             current_component_version,
         )
@@ -143,6 +140,7 @@ pub async fn search_public_oplog(
     component_service: Arc<dyn ComponentService>,
     oplog_service: Arc<dyn OplogService>,
     plugin_service: Arc<dyn Plugins>,
+    project_service: Arc<dyn ProjectService>,
     owned_worker_id: &OwnedWorkerId,
     initial_component_version: ComponentVersion,
     initial_oplog_index: OplogIndex,
@@ -161,6 +159,7 @@ pub async fn search_public_oplog(
             component_service.clone(),
             oplog_service.clone(),
             plugin_service.clone(),
+            project_service.clone(),
             owned_worker_id,
             current_component_version,
             current_index,
@@ -228,6 +227,7 @@ pub trait PublicOplogEntryOps: Sized {
         oplog_service: Arc<dyn OplogService>,
         components: Arc<dyn ComponentService>,
         plugins: Arc<dyn Plugins>,
+        projects: Arc<dyn ProjectService>,
         owned_worker_id: &OwnedWorkerId,
         component_version: ComponentVersion,
     ) -> Result<Self, String>;
@@ -240,49 +240,34 @@ impl PublicOplogEntryOps for PublicOplogEntry {
         oplog_service: Arc<dyn OplogService>,
         components: Arc<dyn ComponentService>,
         plugins: Arc<dyn Plugins>,
+        projects: Arc<dyn ProjectService>,
         owned_worker_id: &OwnedWorkerId,
         component_version: ComponentVersion,
     ) -> Result<Self, String> {
         match value {
-            OplogEntry::CreateV1 {
-                timestamp,
-                worker_id,
-                component_version,
-                args,
-                env,
-                account_id,
-                parent,
-                component_size,
-                initial_total_linear_memory_size,
-            } => Ok(PublicOplogEntry::Create(CreateParameters {
-                timestamp,
-                worker_id,
-                component_version,
-                args,
-                env: env.into_iter().collect(),
-                account_id,
-                parent,
-                component_size,
-                initial_total_linear_memory_size,
-                initial_active_plugins: BTreeSet::new(),
-            })),
             OplogEntry::Create {
                 timestamp,
                 worker_id,
                 component_version,
                 args,
                 env,
-                account_id,
+                project_id,
+                created_by,
                 parent,
                 component_size,
                 initial_total_linear_memory_size,
                 initial_active_plugins,
+                wasi_config_vars,
             } => {
+                let project_owner = projects
+                    .get_project_owner(&project_id)
+                    .await
+                    .map_err(|err| err.to_string())?;
                 let mut initial_plugins = BTreeSet::new();
                 for installation_id in initial_active_plugins {
                     let (installation, definition) = plugins
                         .get(
-                            &account_id,
+                            &project_owner,
                             &worker_id.component_id,
                             component_version,
                             &installation_id,
@@ -301,39 +286,21 @@ impl PublicOplogEntryOps for PublicOplogEntry {
                     component_version,
                     args,
                     env: env.into_iter().collect(),
-                    account_id,
+                    project_id,
+                    created_by,
                     parent,
                     component_size,
                     initial_total_linear_memory_size,
                     initial_active_plugins: initial_plugins,
+                    wasi_config_vars: wasi_config_vars.into(),
                 }))
             }
-            OplogEntry::ImportedFunctionInvokedV1 {
-                timestamp,
-                function_name,
-                response,
-                wrapped_function_type,
-            } => {
-                let payload_bytes = oplog_service
-                    .download_payload(owned_worker_id, &response)
-                    .await?;
-                let value = encode_host_function_response_as_value(&function_name, &payload_bytes)?;
-                Ok(PublicOplogEntry::ImportedFunctionInvoked(
-                    ImportedFunctionInvokedParameters {
-                        timestamp,
-                        function_name,
-                        request: no_payload()?,
-                        response: value,
-                        wrapped_function_type: wrapped_function_type.into(),
-                    },
-                ))
-            }
             OplogEntry::ImportedFunctionInvoked {
                 timestamp,
                 function_name,
                 request,
                 response,
-                wrapped_function_type,
+                durable_function_type,
             } => {
                 let request_bytes = oplog_service
                     .download_payload(owned_worker_id, &request)
@@ -351,60 +318,7 @@ impl PublicOplogEntryOps for PublicOplogEntry {
                         function_name,
                         request,
                         response,
-                        wrapped_function_type: wrapped_function_type.into(),
-                    },
-                ))
-            }
-            OplogEntry::ExportedFunctionInvokedV1 {
-                timestamp,
-                function_name,
-                request,
-                idempotency_key,
-            } => {
-                let payload_bytes = oplog_service
-                    .download_payload(owned_worker_id, &request)
-                    .await?;
-                let proto_params: Vec<golem_wasm_rpc::protobuf::Val> =
-                    core_try_deserialize(&payload_bytes)?.unwrap_or_default();
-                let params = proto_params
-                    .into_iter()
-                    .map(Value::try_from)
-                    .collect::<Result<Vec<_>, _>>()?;
-
-                let metadata = components
-                    .get_metadata(
-                        &owned_worker_id.account_id,
-                        &owned_worker_id.worker_id.component_id,
-                        Some(component_version),
-                    )
-                    .await
-                    .map_err(|err| err.to_string())?;
-                let function = function_by_name(&metadata.exports, &function_name)?.ok_or(
-                        format!("Exported function {function_name} not found in component {} version {component_version}", owned_worker_id.component_id())
-                    )?;
-
-                let parsed = ParsedFunctionName::parse(&function_name)?;
-                let param_types: Box<dyn Iterator<Item = &AnalysedFunctionParameter>> =
-                    if parsed.function().is_indexed_resource() {
-                        Box::new(function.parameters.iter().skip(1))
-                    } else {
-                        Box::new(function.parameters.iter())
-                    };
-
-                let request = param_types
-                    .zip(params)
-                    .map(|(param, value)| ValueAndType::new(value, param.typ.clone()))
-                    .collect();
-
-                Ok(PublicOplogEntry::ExportedFunctionInvoked(
-                    ExportedFunctionInvokedParameters {
-                        timestamp,
-                        function_name,
-                        request,
-                        idempotency_key,
-                        trace_id: TraceId::generate(),
-                        trace_states: vec![],
-                        invocation_context: vec![],
+                        durable_function_type: durable_function_type.into(),
                     },
                 ))
             }
@@ -429,23 +343,18 @@ impl PublicOplogEntryOps for PublicOplogEntry {
 
                 let metadata = components
                     .get_metadata(
-                        &owned_worker_id.account_id,
+                        &owned_worker_id.project_id,
                         &owned_worker_id.worker_id.component_id,
                         Some(component_version),
                     )
                     .await
                     .map_err(|err| err.to_string())?;
-                let function = function_by_name(&metadata.exports, &function_name)?.ok_or(
+                let function = metadata.metadata.find_function(&function_name).await?.ok_or(
                     format!("Exported function {function_name} not found in component {} version {component_version}", owned_worker_id.component_id())
                 )?;
 
-                let parsed = ParsedFunctionName::parse(&function_name)?;
                 let param_types: Box<dyn Iterator<Item = &AnalysedFunctionParameter>> =
-                    if parsed.function().is_indexed_resource() {
-                        Box::new(function.parameters.iter().skip(1))
-                    } else {
-                        Box::new(function.parameters.iter())
-                    };
+                    Box::new(function.analysed_export.parameters.iter());
 
                 let request = param_types
                     .zip(params)
@@ -550,14 +459,14 @@ impl PublicOplogEntryOps for PublicOplogEntry {
                     } => {
                         let metadata = components
                             .get_metadata(
-                                &owned_worker_id.account_id,
+                                &owned_worker_id.project_id,
                                 &owned_worker_id.worker_id.component_id,
                                 Some(component_version),
                             )
                             .await
                             .map_err(|err| err.to_string())?;
 
-                        let function = function_by_name(&metadata.exports, &full_function_name)?;
+                        let function = metadata.metadata.find_function(&full_function_name).await?;
 
                         // It is not guaranteed that we can resolve the enqueued invocation's parameter types because
                         // we only know the current component version. If the client enqueued an update earlier and assumes
@@ -566,9 +475,10 @@ impl PublicOplogEntryOps for PublicOplogEntry {
                         // If we cannot resolve the type, we leave the `function_input` field empty in the public oplog.
                         let mut params = None;
                         if let Some(function) = function {
-                            if function.parameters.len() == function_input.len() {
+                            if function.analysed_export.parameters.len() == function_input.len() {
                                 params = Some(
                                     function
+                                        .analysed_export
                                         .parameters
                                         .iter()
                                         .zip(function_input)
@@ -628,29 +538,21 @@ impl PublicOplogEntryOps for PublicOplogEntry {
                     description: public_description,
                 }))
             }
-            OplogEntry::SuccessfulUpdateV1 {
-                timestamp,
-                target_version,
-                new_component_size,
-            } => Ok(PublicOplogEntry::SuccessfulUpdate(
-                SuccessfulUpdateParameters {
-                    timestamp,
-                    target_version,
-                    new_component_size,
-                    new_active_plugins: BTreeSet::new(),
-                },
-            )),
             OplogEntry::SuccessfulUpdate {
                 timestamp,
                 target_version,
                 new_component_size,
                 new_active_plugins,
             } => {
+                let project_owner = projects
+                    .get_project_owner(&owned_worker_id.project_id)
+                    .await
+                    .map_err(|err| err.to_string())?;
                 let mut new_plugins = BTreeSet::new();
                 for installation_id in new_active_plugins {
                     let (installation, definition) = plugins
                         .get(
-                            &owned_worker_id.account_id,
+                            &project_owner,
                             &owned_worker_id.worker_id.component_id,
                             target_version,
                             &installation_id,
@@ -688,66 +590,27 @@ impl PublicOplogEntryOps for PublicOplogEntry {
                     delta,
                 }))
             }
-            OplogEntry::CreateResource { timestamp, id } => {
-                Ok(PublicOplogEntry::CreateResource(ResourceParameters {
-                    timestamp,
-                    id,
-                }))
-            }
-            OplogEntry::DropResource { timestamp, id } => {
-                Ok(PublicOplogEntry::DropResource(ResourceParameters {
-                    timestamp,
-                    id,
-                }))
-            }
-            OplogEntry::DescribeResource {
+            OplogEntry::CreateResource {
                 timestamp,
                 id,
-                indexed_resource,
-            } => {
-                let metadata = components
-                    .get_metadata(
-                        &owned_worker_id.account_id,
-                        &owned_worker_id.worker_id.component_id,
-                        Some(component_version),
-                    )
-                    .await
-                    .map_err(|err| err.to_string())?;
-
-                let resource_name = indexed_resource.resource_name.clone();
-                let resource_constructor_name = ParsedFunctionName::new(
-                    find_resource_site(&metadata.exports, &resource_name).ok_or(format!(
-                        "Resource site for resource {} not found in component {} version {}",
-                        resource_name,
-                        owned_worker_id.component_id(),
-                        component_version
-                    ))?,
-                    ParsedFunctionReference::RawResourceConstructor {
-                        resource: resource_name.clone(),
-                    },
-                );
-                let constructor_def = function_by_name(&metadata.exports, &resource_constructor_name.to_string())?.ok_or(
-                        format!("Resource constructor {resource_constructor_name} not found in component {} version {component_version}", owned_worker_id.component_id())
-                    )?;
+                resource_type_id,
+            } => Ok(PublicOplogEntry::CreateResource(ResourceParameters {
+                timestamp,
+                id,
+                name: resource_type_id.name,
+                owner: resource_type_id.owner,
+            })),
+            OplogEntry::DropResource {
+                timestamp,
+                id,
+                resource_type_id,
+            } => Ok(PublicOplogEntry::DropResource(ResourceParameters {
+                timestamp,
+                id,
+                name: resource_type_id.name,
+                owner: resource_type_id.owner,
+            })),
 
-                let mut resource_params = Vec::new();
-                for (value_str, param) in indexed_resource
-                    .resource_params
-                    .iter()
-                    .zip(constructor_def.parameters)
-                {
-                    let value_and_type = parse_value_and_type(&param.typ, value_str)?;
-                    resource_params.push(value_and_type);
-                }
-                Ok(PublicOplogEntry::DescribeResource(
-                    DescribeResourceParameters {
-                        timestamp,
-                        id,
-                        resource_name,
-                        resource_params,
-                    },
-                ))
-            }
             OplogEntry::Log {
                 timestamp,
                 level,
@@ -763,9 +626,13 @@ impl PublicOplogEntryOps for PublicOplogEntry {
                 Ok(PublicOplogEntry::Restart(TimestampParameter { timestamp }))
             }
             OplogEntry::ActivatePlugin { timestamp, plugin } => {
+                let project_owner = projects
+                    .get_project_owner(&owned_worker_id.project_id)
+                    .await
+                    .map_err(|err| err.to_string())?;
                 let (installation, definition) = plugins
                     .get(
-                        &owned_worker_id.account_id,
+                        &project_owner,
                         &owned_worker_id.worker_id.component_id,
                         component_version,
                         &plugin,
@@ -782,9 +649,13 @@ impl PublicOplogEntryOps for PublicOplogEntry {
                 }))
             }
             OplogEntry::DeactivatePlugin { timestamp, plugin } => {
+                let project_owner = projects
+                    .get_project_owner(&owned_worker_id.project_id)
+                    .await
+                    .map_err(|err| err.to_string())?;
                 let (installation, definition) = plugins
                     .get(
-                        &owned_worker_id.account_id,
+                        &project_owner,
                         &owned_worker_id.worker_id.component_id,
                         component_version,
                         &plugin,
diff --git a/golem-worker-executor/src/services/active_workers.rs b/golem-worker-executor/src/services/active_workers.rs
index f09a009a..680429dd 100644
--- a/golem-worker-executor/src/services/active_workers.rs
+++ b/golem-worker-executor/src/services/active_workers.rs
@@ -12,17 +12,21 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
+use std::collections::BTreeMap;
+use std::sync::Arc;
+use std::time::Duration;
+use tokio::sync::{Mutex, OwnedSemaphorePermit, Semaphore, TryAcquireError};
+
+use tracing::{debug, Instrument};
+
 use crate::services::golem_config::MemoryConfig;
 use crate::services::HasAll;
 use crate::worker::Worker;
 use crate::workerctx::WorkerCtx;
 use golem_common::cache::{BackgroundEvictionMode, Cache, FullCacheEvictionMode, SimpleCache};
-use golem_common::model::{OwnedWorkerId, WorkerId};
+use golem_common::model::invocation_context::InvocationContextStack;
+use golem_common::model::{AccountId, OwnedWorkerId, WorkerId};
 use golem_service_base::error::worker_executor::WorkerExecutorError;
-use std::sync::Arc;
-use std::time::Duration;
-use tokio::sync::{Mutex, OwnedSemaphorePermit, Semaphore, TryAcquireError};
-use tracing::{debug, Instrument};
 
 /// Holds the metadata and wasmtime structures of currently active Golem workers
 pub struct ActiveWorkers<Ctx: WorkerCtx> {
@@ -52,10 +56,13 @@ impl<Ctx: WorkerCtx> ActiveWorkers<Ctx> {
         &self,
         deps: &T,
         owned_worker_id: &OwnedWorkerId,
+        account_id: &AccountId,
         worker_args: Option<Vec<String>>,
         worker_env: Option<Vec<(String, String)>>,
+        worker_wasi_config_vars: Option<BTreeMap<String, String>>,
         component_version: Option<u64>,
         parent: Option<WorkerId>,
+        invocation_context_stack: &InvocationContextStack,
     ) -> Result<Arc<Worker<Ctx>>, WorkerExecutorError>
     where
         T: HasAll<Ctx> + Clone + Send + Sync + 'static,
@@ -63,18 +70,23 @@ impl<Ctx: WorkerCtx> ActiveWorkers<Ctx> {
         let worker_id = owned_worker_id.worker_id();
 
         let owned_worker_id = owned_worker_id.clone();
+        let account_id = account_id.clone();
         let deps = deps.clone();
+        let invocation_context_stack = invocation_context_stack.clone();
         self.workers
             .get_or_insert_simple(&worker_id, || {
                 Box::pin(async move {
                     Ok(Arc::new(
                         Worker::new(
                             &deps,
+                            &account_id,
                             owned_worker_id,
                             worker_args,
                             worker_env,
+                            worker_wasi_config_vars,
                             component_version,
                             parent,
+                            &invocation_context_stack,
                         )
                         .in_current_span()
                         .await?,
diff --git a/golem-worker-executor/src/services/compiled_component.rs b/golem-worker-executor/src/services/compiled_component.rs
index 49af52c7..da958fb9 100644
--- a/golem-worker-executor/src/services/compiled_component.rs
+++ b/golem-worker-executor/src/services/compiled_component.rs
@@ -15,7 +15,7 @@
 use crate::services::golem_config::CompiledComponentServiceConfig;
 use crate::Engine;
 use async_trait::async_trait;
-use golem_common::model::ComponentId;
+use golem_common::model::{ComponentId, ProjectId};
 use golem_service_base::error::worker_executor::WorkerExecutorError;
 use golem_service_base::storage::blob::{BlobStorage, BlobStorageNamespace};
 use std::path::{Path, PathBuf};
@@ -29,12 +29,14 @@ use wasmtime::component::Component;
 pub trait CompiledComponentService: Send + Sync {
     async fn get(
         &self,
+        project_id: &ProjectId,
         component_id: &ComponentId,
         component_version: u64,
         engine: &Engine,
     ) -> Result<Option<Component>, WorkerExecutorError>;
     async fn put(
         &self,
+        project_id: &ProjectId,
         component_id: &ComponentId,
         component_version: u64,
         component: &Component,
@@ -59,6 +61,7 @@ impl DefaultCompiledComponentService {
 impl CompiledComponentService for DefaultCompiledComponentService {
     async fn get(
         &self,
+        project_id: &ProjectId,
         component_id: &ComponentId,
         component_version: u64,
         engine: &Engine,
@@ -68,7 +71,9 @@ impl CompiledComponentService for DefaultCompiledComponentService {
             .get_raw(
                 "compiled_component",
                 "get",
-                BlobStorageNamespace::CompilationCache,
+                BlobStorageNamespace::CompilationCache {
+                    project_id: project_id.clone(),
+                },
                 &Self::key(component_id, component_version),
             )
             .await
@@ -106,6 +111,7 @@ impl CompiledComponentService for DefaultCompiledComponentService {
 
     async fn put(
         &self,
+        project_id: &ProjectId,
         component_id: &ComponentId,
         component_version: u64,
         component: &Component,
@@ -117,7 +123,9 @@ impl CompiledComponentService for DefaultCompiledComponentService {
             .put_raw(
                 "compiled_component",
                 "put",
-                BlobStorageNamespace::CompilationCache,
+                BlobStorageNamespace::CompilationCache {
+                    project_id: project_id.clone(),
+                },
                 &Self::key(component_id, component_version),
                 &bytes,
             )
@@ -164,6 +172,7 @@ impl CompiledComponentServiceDisabled {
 impl CompiledComponentService for CompiledComponentServiceDisabled {
     async fn get(
         &self,
+        _project_id: &ProjectId,
         _component_id: &ComponentId,
         _component_version: u64,
         _engine: &Engine,
@@ -173,6 +182,7 @@ impl CompiledComponentService for CompiledComponentServiceDisabled {
 
     async fn put(
         &self,
+        _project_id: &ProjectId,
         _component_id: &ComponentId,
         _component_version: u64,
         _component: &Component,
diff --git a/golem-worker-executor/src/services/component.rs b/golem-worker-executor/src/services/component.rs
index bb3e44de..e2c47c07 100644
--- a/golem-worker-executor/src/services/component.rs
+++ b/golem-worker-executor/src/services/component.rs
@@ -14,23 +14,16 @@
 
 use super::golem_config::{
     CompiledComponentServiceConfig, ComponentCacheConfig, ComponentServiceConfig,
-    ProjectServiceConfig,
 };
 use super::plugins::PluginsObservations;
 use crate::metrics::component::record_compilation_time;
+use crate::services::projects::ProjectService;
 use async_trait::async_trait;
 use golem_common::cache::{BackgroundEvictionMode, Cache, FullCacheEvictionMode};
 use golem_common::model::component::ComponentOwner;
-use golem_common::model::component_metadata::{DynamicLinkedInstance, LinearMemory};
-use golem_common::model::plugin::PluginInstallation;
-use golem_common::model::{
-    AccountId, ComponentId, ComponentType, ComponentVersion, InitialComponentFile,
-};
+use golem_common::model::{ComponentId, ComponentVersion, ProjectId};
 use golem_service_base::error::worker_executor::WorkerExecutorError;
 use golem_service_base::storage::blob::BlobStorage;
-use golem_service_base::testing::LocalFileSystemComponentMetadata;
-use golem_wasm_ast::analysis::AnalysedExport;
-use std::collections::HashMap;
 use std::sync::Arc;
 use std::time::Duration;
 use tracing::info;
@@ -38,83 +31,52 @@ use uuid::Uuid;
 use wasmtime::component::Component;
 use wasmtime::Engine;
 
-#[derive(Debug, Clone)]
-pub struct ComponentMetadata {
-    pub version: ComponentVersion,
-    pub size: u64,
-    pub memories: Vec<LinearMemory>,
-    pub exports: Vec<AnalysedExport>,
-    pub component_type: ComponentType,
-    pub files: Vec<InitialComponentFile>,
-    pub plugin_installations: Vec<PluginInstallation>,
-    pub component_owner: ComponentOwner,
-    pub dynamic_linking: HashMap<String, DynamicLinkedInstance>,
-    pub env: HashMap<String, String>,
-}
-
-impl From<LocalFileSystemComponentMetadata> for ComponentMetadata {
-    fn from(value: LocalFileSystemComponentMetadata) -> Self {
-        Self {
-            version: value.version,
-            size: value.size,
-            memories: value.memories,
-            exports: value.exports,
-            component_type: value.component_type,
-            files: value.files,
-            plugin_installations: vec![],
-            component_owner: ComponentOwner {
-                account_id: value.account_id,
-                project_id: value.project_id,
-            },
-            dynamic_linking: value.dynamic_linking,
-            env: value.env,
-        }
-    }
-}
-
 /// Service for downloading a specific Golem component from the Golem Component API
 #[async_trait]
 pub trait ComponentService: Send + Sync {
     async fn get(
         &self,
         engine: &Engine,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         component_id: &ComponentId,
         component_version: ComponentVersion,
-    ) -> Result<(Component, ComponentMetadata), WorkerExecutorError>;
+    ) -> Result<(Component, golem_service_base::model::Component), WorkerExecutorError>;
 
     async fn get_metadata(
         &self,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         component_id: &ComponentId,
         forced_version: Option<ComponentVersion>,
-    ) -> Result<ComponentMetadata, WorkerExecutorError>;
+    ) -> Result<golem_service_base::model::Component, WorkerExecutorError>;
 
-    /// Resolve a component given a user provided string. The syntax of the provided string is allowed to vary between implementations.
-    /// Resolving component is the component in whoose context the resolution is being performed
+    /// Resolve a component given a user-provided string. The syntax of the provided string is allowed to vary between implementations.
+    /// Resolving component is the component in whose context the resolution is being performed
     async fn resolve_component(
         &self,
         component_reference: String,
         resolving_component: ComponentOwner,
     ) -> Result<Option<ComponentId>, WorkerExecutorError>;
+
+    /// Returns all the component metadata the implementation has cached.
+    /// This is useful for some mock/local implementations.
+    async fn all_cached_metadata(&self) -> Vec<golem_service_base::model::Component>;
 }
 
 pub fn configured(
     config: &ComponentServiceConfig,
-    project_service_config: &ProjectServiceConfig,
     cache_config: &ComponentCacheConfig,
     compiled_config: &CompiledComponentServiceConfig,
     blob_storage: Arc<dyn BlobStorage>,
     plugin_observations: Arc<dyn PluginsObservations>,
+    project_service: Arc<dyn ProjectService>,
 ) -> Arc<dyn ComponentService> {
     let compiled_component_service =
         super::compiled_component::configured(compiled_config, blob_storage);
-    match (config, project_service_config) {
-        (ComponentServiceConfig::Grpc(config), ProjectServiceConfig::Grpc(project_config)) => {
+    match config {
+        ComponentServiceConfig::Grpc(config) => {
             info!("Using component API at {}", config.url());
-            Arc::new(self::grpc::ComponentServiceGrpc::new(
+            Arc::new(grpc::ComponentServiceGrpc::new(
                 config.uri(),
-                project_config.uri(),
                 config
                     .access_token
                     .parse::<Uuid>()
@@ -122,25 +84,24 @@ pub fn configured(
                 cache_config.max_capacity,
                 cache_config.max_metadata_capacity,
                 cache_config.max_resolved_component_capacity,
-                cache_config.max_resolved_project_capacity,
                 cache_config.time_to_idle,
                 config.retries.clone(),
                 config.connect_timeout,
                 compiled_component_service,
                 config.max_component_size,
                 plugin_observations,
+                project_service,
             ))
         }
-        (ComponentServiceConfig::Local(config), ProjectServiceConfig::Disabled(_)) => {
+        ComponentServiceConfig::Local(config) => {
             info!("Using local component server at {:?}", config.root);
-            Arc::new(self::filesystem::ComponentServiceLocalFileSystem::new(
+            Arc::new(filesystem::ComponentServiceLocalFileSystem::new(
                 &config.root,
                 cache_config.max_capacity,
                 cache_config.time_to_idle,
                 compiled_component_service,
             ))
         }
-        _ => panic!("Unsupported cloud component and project service configuration"),
     }
 }
 
@@ -168,15 +129,15 @@ fn create_component_cache(
 mod filesystem {
     use super::create_component_cache;
     use super::record_compilation_time;
+    use super::ComponentKey;
     use super::ComponentService;
-    use super::{ComponentKey, ComponentMetadata};
     use crate::services::compiled_component::CompiledComponentService;
     use async_lock::{RwLock, Semaphore};
     use async_trait::async_trait;
     use golem_common::cache::Cache;
     use golem_common::cache::SimpleCache;
     use golem_common::model::component::ComponentOwner;
-    use golem_common::model::{AccountId, ComponentId, ComponentVersion};
+    use golem_common::model::{ComponentId, ComponentVersion, ProjectId};
     use golem_service_base::error::worker_executor::WorkerExecutorError;
     use golem_service_base::testing::LocalFileSystemComponentMetadata;
     use std::collections::{HashMap, HashSet};
@@ -292,6 +253,7 @@ mod filesystem {
             &self,
             wasm_path: &Path,
             engine: &Engine,
+            project_id: &ProjectId,
             component_id: &ComponentId,
             component_version: ComponentVersion,
         ) -> Result<Component, WorkerExecutorError> {
@@ -308,7 +270,7 @@ mod filesystem {
                 .get_or_insert_simple(&key.clone(), || {
                     Box::pin(async move {
                         let result = compiled_component_service
-                            .get(&component_id, component_version, &engine)
+                            .get(project_id, &component_id, component_version, &engine)
                             .await;
 
                         let component = match result {
@@ -353,7 +315,7 @@ mod filesystem {
                                 );
 
                                 let result = compiled_component_service
-                                    .put(&component_id, component_version, &component)
+                                    .put(project_id, &component_id, component_version, &component)
                                     .await;
 
                                 match result {
@@ -377,7 +339,7 @@ mod filesystem {
             &self,
             component_id: &ComponentId,
             component_version: ComponentVersion,
-        ) -> Result<ComponentMetadata, WorkerExecutorError> {
+        ) -> Result<golem_service_base::model::Component, WorkerExecutorError> {
             let key = ComponentKey {
                 component_id: component_id.clone(),
                 component_version,
@@ -400,7 +362,7 @@ mod filesystem {
         async fn get_latest_metadata(
             &self,
             component_id: &ComponentId,
-        ) -> Result<ComponentMetadata, WorkerExecutorError> {
+        ) -> Result<golem_service_base::model::Component, WorkerExecutorError> {
             self.refresh_index().await?;
 
             let index = self.index.read().await;
@@ -432,10 +394,11 @@ mod filesystem {
         async fn get(
             &self,
             engine: &Engine,
-            _account_id: &AccountId,
+            project_id: &ProjectId,
             component_id: &ComponentId,
             component_version: ComponentVersion,
-        ) -> Result<(Component, ComponentMetadata), WorkerExecutorError> {
+        ) -> Result<(Component, golem_service_base::model::Component), WorkerExecutorError>
+        {
             let key = ComponentKey {
                 component_id: component_id.clone(),
                 component_version,
@@ -455,7 +418,13 @@ mod filesystem {
             let wasm_path = self.root.join(metadata.wasm_filename.clone());
 
             let component = self
-                .get_component_from_path(&wasm_path, engine, component_id, component_version)
+                .get_component_from_path(
+                    &wasm_path,
+                    engine,
+                    project_id,
+                    component_id,
+                    component_version,
+                )
                 .await?;
 
             Ok((component, metadata.into()))
@@ -463,10 +432,10 @@ mod filesystem {
 
         async fn get_metadata(
             &self,
-            _account_id: &AccountId,
+            _project_id: &ProjectId,
             component_id: &ComponentId,
             forced_version: Option<ComponentVersion>,
-        ) -> Result<ComponentMetadata, WorkerExecutorError> {
+        ) -> Result<golem_service_base::model::Component, WorkerExecutorError> {
             match forced_version {
                 Some(version) => self.get_metadata_for_version(component_id, version).await,
                 None => self.get_latest_metadata(component_id).await,
@@ -486,6 +455,18 @@ mod filesystem {
                 .get(&component_reference)
                 .cloned())
         }
+
+        async fn all_cached_metadata(&self) -> Vec<golem_service_base::model::Component> {
+            self.index
+                .read()
+                .await
+                .metadata
+                .values()
+                .map(|local_metadata| {
+                    golem_service_base::model::Component::from(local_metadata.clone())
+                })
+                .collect()
+        }
     }
 
     struct ComponentMetadataIndex {
@@ -508,20 +489,20 @@ mod filesystem {
 }
 
 mod grpc {
-    use super::{create_component_cache, ComponentKey, ComponentMetadata, ComponentService};
+    use super::{create_component_cache, ComponentKey, ComponentService};
     use crate::grpc::{authorised_grpc_request, is_grpc_retriable, GrpcError};
     use crate::metrics::component::record_compilation_time;
     use crate::services::compiled_component::CompiledComponentService;
     use crate::services::plugins::PluginsObservations;
+    use crate::services::projects::ProjectService;
     use async_trait::async_trait;
-    use futures_util::TryStreamExt;
+    use futures::TryStreamExt;
     use golem_api_grpc::proto::golem::component::v1::component_service_client::ComponentServiceClient;
     use golem_api_grpc::proto::golem::component::v1::{
         download_component_response, get_component_metadata_response, ComponentError,
         DownloadComponentRequest, GetComponentsRequest, GetLatestComponentRequest,
         GetVersionedComponentRequest,
     };
-    use golem_api_grpc::proto::golem::project::v1::cloud_project_service_client::CloudProjectServiceClient;
     use golem_common::cache::{BackgroundEvictionMode, Cache, FullCacheEvictionMode, SimpleCache};
     use golem_common::client::{GrpcClient, GrpcClientConfig};
     use golem_common::metrics::external_calls::record_external_call_response_size_bytes;
@@ -530,10 +511,10 @@ mod grpc {
     use golem_common::model::{ProjectId, RetryConfig};
     use golem_common::retries::with_retries;
     use golem_service_base::error::worker_executor::WorkerExecutorError;
-    use golem_wasm_ast::analysis::AnalysedExport;
+
     use http::Uri;
     use prost::Message;
-    use std::collections::HashMap;
+
     use std::future::Future;
     use std::sync::Arc;
     use std::time::{Duration, Instant};
@@ -547,34 +528,32 @@ mod grpc {
 
     pub struct ComponentServiceGrpc {
         component_cache: Cache<ComponentKey, (), Component, WorkerExecutorError>,
-        component_metadata_cache: Cache<ComponentKey, (), ComponentMetadata, WorkerExecutorError>,
+        component_metadata_cache:
+            Cache<ComponentKey, (), golem_service_base::model::Component, WorkerExecutorError>,
         resolved_component_cache:
             Cache<(ProjectId, String), (), Option<ComponentId>, WorkerExecutorError>,
         access_token: Uuid,
         retry_config: RetryConfig,
-        compiled_component_service: Arc<dyn CompiledComponentService + Send + Sync>,
+        compiled_component_service: Arc<dyn CompiledComponentService>,
         component_client: GrpcClient<ComponentServiceClient<Channel>>,
-        project_client: GrpcClient<CloudProjectServiceClient<Channel>>,
         plugin_observations: Arc<dyn PluginsObservations>,
-        resolved_project_cache:
-            Cache<(AccountId, String), (), Option<ProjectId>, WorkerExecutorError>,
+        project_service: Arc<dyn ProjectService>,
     }
 
     impl ComponentServiceGrpc {
         pub fn new(
             component_endpoint: Uri,
-            project_endpoint: Uri,
             access_token: Uuid,
             max_component_capacity: usize,
             max_metadata_capacity: usize,
             max_resolved_component_capacity: usize,
-            max_resolved_project_capacity: usize,
             time_to_idle: Duration,
             retry_config: RetryConfig,
             connect_timeout: Duration,
-            compiled_component_service: Arc<dyn CompiledComponentService + Send + Sync>,
+            compiled_component_service: Arc<dyn CompiledComponentService>,
             max_component_size: usize,
             plugin_observations: Arc<dyn PluginsObservations>,
+            project_service: Arc<dyn ProjectService>,
         ) -> Self {
             Self {
                 component_cache: create_component_cache(max_component_capacity, time_to_idle),
@@ -603,110 +582,8 @@ mod grpc {
                         connect_timeout,
                     },
                 ),
-                project_client: GrpcClient::new(
-                    "project_service",
-                    move |channel| {
-                        CloudProjectServiceClient::new(channel)
-                            .max_decoding_message_size(max_component_size)
-                            .send_compressed(CompressionEncoding::Gzip)
-                            .accept_compressed(CompressionEncoding::Gzip)
-                    },
-                    project_endpoint,
-                    GrpcClientConfig {
-                        retries_on_unavailable: retry_config.clone(),
-                        connect_timeout,
-                    },
-                ),
-                resolved_project_cache: create_resolved_project_cache(
-                    max_resolved_project_capacity,
-                    time_to_idle,
-                ),
                 plugin_observations,
-            }
-        }
-
-        fn resolve_project_remotely(
-            &self,
-            account_id: &AccountId,
-            project_name: &str,
-        ) -> impl Future<Output = Result<Option<ProjectId>, WorkerExecutorError>> + 'static
-        {
-            use golem_api_grpc::proto::golem::project::v1::{
-                get_projects_response, GetProjectsRequest, ProjectError,
-            };
-            use golem_api_grpc::proto::golem::project::Project as GrpcProject;
-
-            let client = self.project_client.clone();
-            let retry_config = self.retry_config.clone();
-            let access_token = self.access_token;
-
-            fn get_account(project: &GrpcProject) -> AccountId {
-                project
-                    .data
-                    .clone()
-                    .expect("did not receive account data")
-                    .owner_account_id
-                    .expect("failed to receive project owner_account_id")
-                    .into()
-            }
-
-            let account_id = account_id.clone();
-            let project_name = project_name.to_string();
-
-            async move {
-                with_retries(
-                    "component",
-                    "resolve_project_remotely",
-                    Some(format!("{account_id}/{project_name}").to_string()),
-                    &retry_config,
-                    &(
-                        client,
-                        account_id.clone(),
-                        project_name.to_string(),
-                        access_token,
-                    ),
-                    |(client, account_id, project_name, access_token)| {
-                        Box::pin(async move {
-                            let response = client
-                                .call("lookup_project_by_name", move |client| {
-                                    let request = authorised_grpc_request(
-                                        GetProjectsRequest {
-                                            project_name: Some(project_name.to_string()),
-                                        },
-                                        access_token,
-                                    );
-                                    Box::pin(client.get_projects(request))
-                                })
-                                .await?
-                                .into_inner();
-
-                            match response
-                                .result
-                                .expect("Didn't receive expected field result")
-                            {
-                                get_projects_response::Result::Success(payload) => {
-                                    let project_id = payload
-                                        .data
-                                        .into_iter()
-                                        // TODO: Push account filter to the server
-                                        .find(|p| get_account(p) == *account_id)
-                                        .map(|c| c.id.expect("didn't receive expected project_id"));
-                                    Ok(project_id.map(|c| {
-                                        c.try_into().expect("failed to convert project_id")
-                                    }))
-                                }
-                                get_projects_response::Result::Error(err) => {
-                                    Err(GrpcError::Domain(err))?
-                                }
-                            }
-                        })
-                    },
-                    is_grpc_retriable::<ProjectError>,
-                )
-                .await
-                .map_err(|err| {
-                    WorkerExecutorError::unknown(format!("Failed to get project: {err}"))
-                })
+                project_service,
             }
         }
 
@@ -789,15 +666,17 @@ mod grpc {
         async fn get(
             &self,
             engine: &Engine,
-            account_id: &AccountId,
+            project_id: &ProjectId,
             component_id: &ComponentId,
             component_version: ComponentVersion,
-        ) -> Result<(Component, ComponentMetadata), WorkerExecutorError> {
+        ) -> Result<(Component, golem_service_base::model::Component), WorkerExecutorError>
+        {
             let key = ComponentKey {
                 component_id: component_id.clone(),
                 component_version,
             };
             let client_clone = self.component_client.clone();
+            let project_id_clone = project_id.clone();
             let component_id_clone = component_id.clone();
             let engine = engine.clone();
             let access_token = self.access_token;
@@ -808,7 +687,12 @@ mod grpc {
                 .get_or_insert_simple(&key.clone(), || {
                     Box::pin(async move {
                         let result = compiled_component_service
-                            .get(&component_id_clone, component_version, &engine)
+                            .get(
+                                &project_id_clone,
+                                &component_id_clone,
+                                component_version,
+                                &engine,
+                            )
                             .await;
 
                         let component = match result {
@@ -857,7 +741,12 @@ mod grpc {
                                 );
 
                                 let result = compiled_component_service
-                                    .put(&component_id_clone, component_version, &component)
+                                    .put(
+                                        &project_id_clone,
+                                        &component_id_clone,
+                                        component_version,
+                                        &component,
+                                    )
                                     .await;
 
                                 match result {
@@ -876,7 +765,7 @@ mod grpc {
                 })
                 .await?;
             let metadata = self
-                .get_metadata(account_id, component_id, Some(component_version))
+                .get_metadata(project_id, component_id, Some(component_version))
                 .await?;
 
             Ok((component, metadata))
@@ -884,10 +773,10 @@ mod grpc {
 
         async fn get_metadata(
             &self,
-            account_id: &AccountId,
+            project_id: &ProjectId,
             component_id: &ComponentId,
             forced_version: Option<ComponentVersion>,
-        ) -> Result<ComponentMetadata, WorkerExecutorError> {
+        ) -> Result<golem_service_base::model::Component, WorkerExecutorError> {
             match forced_version {
                 Some(version) => {
                     let client = self.component_client.clone();
@@ -895,7 +784,7 @@ mod grpc {
                     let retry_config = self.retry_config.clone();
                     let component_id = component_id.clone();
                     let plugin_observations = self.plugin_observations.clone();
-                    let account_id = account_id.clone();
+                    let account_id = self.project_service.get_project_owner(project_id).await?;
                     self.component_metadata_cache
                         .get_or_insert_simple(
                             &ComponentKey {
@@ -912,12 +801,12 @@ mod grpc {
                                         forced_version,
                                     )
                                     .await?;
-                                    for installation in &metadata.plugin_installations {
+                                    for installation in &metadata.installed_plugins {
                                         plugin_observations
                                             .observe_plugin_installation(
                                                 &account_id,
                                                 &component_id,
-                                                metadata.version,
+                                                metadata.versioned_component_id.version,
                                                 installation,
                                             )
                                             .await?;
@@ -943,7 +832,7 @@ mod grpc {
                         .get_or_insert_simple(
                             &ComponentKey {
                                 component_id: component_id.clone(),
-                                component_version: metadata.version,
+                                component_version: metadata.versioned_component_id.version,
                             },
                             || Box::pin(async move { Ok(metadata) }),
                         )
@@ -969,10 +858,8 @@ mod grpc {
                 .unwrap_or(resolving_component.account_id);
 
             let project_id = if let Some(project_name) = component_slug.project_name {
-                self.resolved_project_cache
-                    .get_or_insert_simple(&(account_id.clone(), project_name.clone()), || {
-                        Box::pin(self.resolve_project_remotely(&account_id, &project_name))
-                    })
+                self.project_service
+                    .resolve_project(&account_id, &project_name)
                     .await?
                     .ok_or(WorkerExecutorError::invalid_request(format!(
                         "Failed to resolve project: {project_name}"
@@ -989,6 +876,13 @@ mod grpc {
                 })
                 .await
         }
+
+        async fn all_cached_metadata(&self) -> Vec<golem_service_base::model::Component> {
+            self.component_metadata_cache
+                .iter()
+                .map(|(_, v)| v)
+                .collect()
+        }
     }
 
     async fn download_via_grpc(
@@ -1057,7 +951,7 @@ mod grpc {
         retry_config: &RetryConfig,
         component_id: &ComponentId,
         component_version: Option<ComponentVersion>,
-    ) -> Result<ComponentMetadata, WorkerExecutorError> {
+    ) -> Result<golem_service_base::model::Component, WorkerExecutorError> {
         let desc = format!("Getting component metadata of {component_id}");
         debug!("{}", &desc);
         with_retries(
@@ -1112,92 +1006,7 @@ mod grpc {
                         }
                     }?;
 
-                    let result = ComponentMetadata {
-                        version: component
-                            .versioned_component_id
-                            .as_ref()
-                            .map(|id| id.version)
-                            .ok_or(GrpcError::Unexpected(
-                                "Undefined component version".to_string(),
-                            ))?,
-                        size: component.component_size,
-                        component_type: component.component_type().into(),
-                        memories: component
-                            .metadata
-                            .as_ref()
-                            .map(|metadata| metadata.memories.iter().map(|m| (*m).into()).collect())
-                            .unwrap_or_default(),
-                        exports: component
-                            .metadata
-                            .as_ref()
-                            .map(|metadata| {
-                                let export = &metadata.exports;
-                                let vec: Vec<Result<AnalysedExport, String>> = export
-                                    .iter()
-                                    .cloned()
-                                    .map(AnalysedExport::try_from)
-                                    .collect();
-                                vec.into_iter().collect()
-                            })
-                            .unwrap_or_else(|| Ok(Vec::new()))
-                            .map_err(|err| {
-                                GrpcError::Unexpected(format!("Failed to get the exports: {err}"))
-                            })?,
-                        files: component
-                            .files
-                            .into_iter()
-                            .map(|file| file.try_into())
-                            .collect::<Result<Vec<_>, _>>()
-                            .map_err(|err| {
-                                GrpcError::Unexpected(format!("Failed to get the files: {err}"))
-                            })?,
-                        plugin_installations: component
-                            .installed_plugins
-                            .into_iter()
-                            .map(|plugin| plugin.try_into())
-                            .collect::<Result<Vec<_>, _>>()
-                            .map_err(|err| {
-                                GrpcError::Unexpected(format!(
-                                    "Failed to get the plugin installations: {err}"
-                                ))
-                            })?,
-                        dynamic_linking: HashMap::from_iter(
-                            component
-                                .metadata
-                                .map(|metadata| {
-                                    metadata
-                                        .dynamic_linking
-                                        .into_iter()
-                                        .map(|(k, v)| v.try_into().map(|v| (k.clone(), v)))
-                                        .collect::<Result<Vec<_>, String>>()
-                                })
-                                .unwrap_or_else(|| Ok(Vec::new()))
-                                .map_err(|err| {
-                                    GrpcError::Unexpected(format!(
-                                        "Failed to get the dynamic linking information: {err}"
-                                    ))
-                                })?,
-                        ),
-                        component_owner: ComponentOwner {
-                            account_id: component
-                                .account_id
-                                .ok_or(GrpcError::Unexpected(
-                                    "Missing account_id for component".to_string(),
-                                ))?
-                                .into(),
-                            project_id: ProjectId(
-                                component
-                                    .project_id
-                                    .and_then(|p| p.value)
-                                    .ok_or(GrpcError::Unexpected(
-                                        "Missing project_id for component".to_string(),
-                                    ))?
-                                    .into(),
-                            ),
-                        },
-                        env: component.env,
-                    };
-
+                    let result = component.try_into()?;
                     record_external_call_response_size_bytes("components", "get_metadata", len);
 
                     Ok(result)
@@ -1234,7 +1043,7 @@ mod grpc {
     fn create_component_metadata_cache(
         max_capacity: usize,
         time_to_idle: Duration,
-    ) -> Cache<ComponentKey, (), ComponentMetadata, WorkerExecutorError> {
+    ) -> Cache<ComponentKey, (), golem_service_base::model::Component, WorkerExecutorError> {
         Cache::new(
             Some(max_capacity),
             FullCacheEvictionMode::LeastRecentlyUsed(1),
@@ -1246,21 +1055,6 @@ mod grpc {
         )
     }
 
-    fn create_resolved_project_cache(
-        max_capacity: usize,
-        time_to_idle: Duration,
-    ) -> Cache<(AccountId, String), (), Option<ProjectId>, WorkerExecutorError> {
-        Cache::new(
-            Some(max_capacity),
-            FullCacheEvictionMode::LeastRecentlyUsed(1),
-            BackgroundEvictionMode::OlderThan {
-                ttl: time_to_idle,
-                period: Duration::from_secs(60),
-            },
-            "resolved_project",
-        )
-    }
-
     fn create_resolved_component_cache(
         max_capacity: usize,
         time_to_idle: Duration,
diff --git a/golem-worker-executor/src/services/file_loader.rs b/golem-worker-executor/src/services/file_loader.rs
index ea30182c..9c845abd 100644
--- a/golem-worker-executor/src/services/file_loader.rs
+++ b/golem-worker-executor/src/services/file_loader.rs
@@ -15,7 +15,7 @@
 use anyhow::anyhow;
 use async_lock::Mutex;
 use futures::TryStreamExt;
-use golem_common::model::{AccountId, InitialComponentFileKey};
+use golem_common::model::{InitialComponentFileKey, ProjectId};
 use golem_service_base::error::worker_executor::WorkerExecutorError;
 use golem_service_base::service::initial_component_files::InitialComponentFilesService;
 use std::collections::HashMap;
@@ -69,11 +69,11 @@ impl FileLoader {
     /// The file will only be valid until the token is dropped.
     pub async fn get_read_only_to(
         &self,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         key: &InitialComponentFileKey,
         target: &PathBuf,
     ) -> Result<FileUseToken, WorkerExecutorError> {
-        self.get_read_only_to_impl(account_id, key, target)
+        self.get_read_only_to_impl(project_id, key, target)
             .await
             .map_err(|e| {
                 WorkerExecutorError::initial_file_download_failed(
@@ -86,11 +86,11 @@ impl FileLoader {
     /// Read-write files are copied to target.
     pub async fn get_read_write_to(
         &self,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         key: &InitialComponentFileKey,
         target: &PathBuf,
     ) -> Result<(), WorkerExecutorError> {
-        self.get_read_write_to_impl(account_id, key, target)
+        self.get_read_write_to_impl(project_id, key, target)
             .await
             .map_err(|e| {
                 WorkerExecutorError::initial_file_download_failed(
@@ -102,7 +102,7 @@ impl FileLoader {
 
     async fn get_read_only_to_impl(
         &self,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         key: &InitialComponentFileKey,
         target: &PathBuf,
     ) -> Result<FileUseToken, anyhow::Error> {
@@ -110,7 +110,7 @@ impl FileLoader {
             tokio::fs::create_dir_all(parent).await?;
         };
 
-        let cache_entry = self.get_or_add_cache_entry(account_id, key).await?;
+        let cache_entry = self.get_or_add_cache_entry(project_id, key).await?;
 
         // peek at the cache entry. It's fine to not hold the lock here.
         // as long as we keep a ref to the cache entry, the file will not be deleted
@@ -137,7 +137,7 @@ impl FileLoader {
 
     async fn get_read_write_to_impl(
         &self,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         key: &InitialComponentFileKey,
         target: &PathBuf,
     ) -> Result<(), anyhow::Error> {
@@ -176,13 +176,13 @@ impl FileLoader {
         }
 
         // alternative, download the file directly to the target
-        self.download_file_to_path(account_id, target, key).await?;
+        self.download_file_to_path(project_id, target, key).await?;
         Ok(())
     }
 
     async fn get_or_add_cache_entry(
         &self,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         key: &InitialComponentFileKey,
     ) -> Result<Arc<CacheEntry>, anyhow::Error> {
         let cache_entry;
@@ -219,7 +219,7 @@ impl FileLoader {
                 let path = self.cache_dir.path().join(counter.to_string());
 
                 match self
-                    .download_file_to_path_as_read_only(account_id, &path, key)
+                    .download_file_to_path_as_read_only(project_id, &path, key)
                     .await
                 {
                     Ok(()) => {
@@ -242,18 +242,18 @@ impl FileLoader {
 
     async fn download_file_to_path_as_read_only(
         &self,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         path: &Path,
         key: &InitialComponentFileKey,
     ) -> Result<(), anyhow::Error> {
-        self.download_file_to_path(account_id, path, key).await?;
+        self.download_file_to_path(project_id, path, key).await?;
         self.set_path_read_only(path).await?;
         Ok(())
     }
 
     async fn download_file_to_path(
         &self,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         path: &Path,
         key: &InitialComponentFileKey,
     ) -> Result<(), anyhow::Error> {
@@ -261,7 +261,7 @@ impl FileLoader {
 
         let mut data = self
             .initial_component_files_service
-            .get(account_id, key)
+            .get(project_id, key)
             .await
             .map_err(|e| anyhow!(e))?
             .ok_or_else(|| anyhow!("File not found"))?;
@@ -303,7 +303,7 @@ struct InitializedCacheEntry {
 
 impl Drop for InitializedCacheEntry {
     fn drop(&mut self) {
-        tracing::debug!("Removing file {}", self.path.display());
+        debug!("Removing file {}", self.path.display());
         if let Err(e) = std::fs::remove_file(&self.path) {
             tracing::error!("Failed to remove file {}: {}", self.path.display(), e);
         }
diff --git a/golem-worker-executor/src/services/golem_config.rs b/golem-worker-executor/src/services/golem_config.rs
index 8930d8d4..27355794 100644
--- a/golem-worker-executor/src/services/golem_config.rs
+++ b/golem-worker-executor/src/services/golem_config.rs
@@ -12,21 +12,22 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use std::net::{Ipv4Addr, SocketAddr, SocketAddrV4};
-use std::path::{Path, PathBuf};
-use std::time::Duration;
-
 use anyhow::Context;
 use figment::providers::{Format, Toml};
 use figment::Figment;
 use golem_common::config::{
     ConfigExample, ConfigLoader, DbSqliteConfig, HasConfigExamples, RedisConfig,
 };
-use golem_common::model::RetryConfig;
+use golem_common::model::{AccountId, ProjectId, RetryConfig};
 use golem_common::tracing::TracingConfig;
+use golem_common::SafeDisplay;
 use golem_service_base::config::BlobStorageConfig;
 use http::Uri;
 use serde::{Deserialize, Serialize};
+use std::fmt::Write;
+use std::net::{Ipv4Addr, SocketAddr, SocketAddrV4};
+use std::path::{Path, PathBuf};
+use std::time::Duration;
 use url::Url;
 
 /// The shared global Golem executor configuration
@@ -53,12 +54,127 @@ pub struct GolemConfig {
     pub component_service: ComponentServiceConfig,
     pub component_cache: ComponentCacheConfig,
     pub project_service: ProjectServiceConfig,
+    pub agent_types_service: AgentTypesServiceConfig,
     pub grpc_address: String,
     pub port: u16,
     pub http_address: String,
     pub http_port: u16,
 }
 
+impl SafeDisplay for GolemConfig {
+    fn to_safe_string(&self) -> String {
+        use std::fmt::Write;
+
+        let mut result = String::new();
+
+        let _ = writeln!(&mut result, "tracing:");
+        let _ = writeln!(&mut result, "{}", self.tracing.to_safe_string_indented());
+        let _ = writeln!(
+            &mut result,
+            "tracing file name with port: {}",
+            self.tracing_file_name_with_port
+        );
+        let _ = writeln!(&mut result, "key-value storage:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.key_value_storage.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "indexed storage:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.indexed_storage.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "blob storage:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.blob_storage.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "limits:");
+        let _ = writeln!(&mut result, "{}", self.limits.to_safe_string_indented());
+        let _ = writeln!(&mut result, "retry:");
+        let _ = writeln!(&mut result, "{}", self.retry.to_safe_string_indented());
+        let _ = writeln!(&mut result, "compiled component service:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.compiled_component_service.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "shard manager service:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.shard_manager_service.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "plugin service:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.plugin_service.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "oplog:");
+        let _ = writeln!(&mut result, "{}", self.oplog.to_safe_string_indented());
+        let _ = writeln!(&mut result, "suspend:");
+        let _ = writeln!(&mut result, "{}", self.suspend.to_safe_string_indented());
+        let _ = writeln!(&mut result, "active_workers:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.active_workers.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "scheduler:");
+        let _ = writeln!(&mut result, "{}", self.scheduler.to_safe_string_indented());
+        let _ = writeln!(&mut result, "public worker api:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.public_worker_api.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "memory:");
+        let _ = writeln!(&mut result, "{}", self.memory.to_safe_string_indented());
+        let _ = writeln!(&mut result, "rdbms:");
+        let _ = writeln!(&mut result, "{}", self.rdbms.to_safe_string_indented());
+        let _ = writeln!(&mut result, "resource limits:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.resource_limits.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "component service:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.component_service.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "component cache:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.component_cache.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "project service:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.project_service.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "agent types service:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.agent_types_service.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "gRPC address: {}", self.grpc_address);
+        let _ = writeln!(&mut result, "gRPC port: {}", self.port);
+        let _ = writeln!(&mut result, "HTTP address: {}", self.http_address);
+        let _ = writeln!(&mut result, "HTTP port: {}", self.http_port);
+
+        result
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct Limits {
     pub max_active_workers: usize,
@@ -73,6 +189,52 @@ pub struct Limits {
     pub max_oplog_query_pages_size: usize,
 }
 
+impl SafeDisplay for Limits {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+
+        let _ = writeln!(
+            &mut result,
+            "max active workers: {}",
+            self.max_active_workers
+        );
+        let _ = writeln!(
+            &mut result,
+            "invocation result broadcast capacity: {}",
+            self.invocation_result_broadcast_capacity
+        );
+        let _ = writeln!(
+            &mut result,
+            "max concurrent streams: {}",
+            self.max_concurrent_streams
+        );
+        let _ = writeln!(
+            &mut result,
+            "event broadcast capacity: {}",
+            self.event_broadcast_capacity
+        );
+        let _ = writeln!(
+            &mut result,
+            "event history size: {}",
+            self.event_history_size
+        );
+        let _ = writeln!(&mut result, "fuel to borrow: {}", self.fuel_to_borrow);
+        let _ = writeln!(
+            &mut result,
+            "epoch interval: {}",
+            self.epoch_interval.as_secs()
+        );
+        let _ = writeln!(&mut result, "epoch ticks: {}", self.epoch_ticks);
+        let _ = writeln!(
+            &mut result,
+            "max oplog query pages: {}",
+            self.max_oplog_query_pages_size
+        );
+
+        result
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 #[serde(tag = "type", content = "config")]
 pub enum PluginServiceConfig {
@@ -80,6 +242,23 @@ pub enum PluginServiceConfig {
     Local(PluginServiceLocalConfig),
 }
 
+impl SafeDisplay for PluginServiceConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        match self {
+            PluginServiceConfig::Grpc(grpc) => {
+                let _ = writeln!(&mut result, "grpc:");
+                let _ = writeln!(&mut result, "{}", grpc.to_safe_string_indented());
+            }
+            PluginServiceConfig::Local(local) => {
+                let _ = writeln!(&mut result, "local:");
+                let _ = writeln!(&mut result, "{}", local.to_safe_string_indented());
+            }
+        }
+        result
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct PluginServiceGrpcConfig {
     pub host: String,
@@ -91,11 +270,31 @@ pub struct PluginServiceGrpcConfig {
     pub connect_timeout: Duration,
 }
 
+impl SafeDisplay for PluginServiceGrpcConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "host: {}", self.host);
+        let _ = writeln!(&mut result, "port: {}", self.port);
+        let _ = writeln!(&mut result, "access token: ****");
+        let _ = writeln!(&mut result, "connect timeout: {:?}", self.connect_timeout);
+        let _ = writeln!(&mut result, "plugin cache size: {}", self.plugin_cache_size);
+        let _ = writeln!(&mut result, "retries:");
+        let _ = writeln!(&mut result, "{}", self.retries.to_safe_string_indented());
+        result
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct PluginServiceLocalConfig {
     pub root: PathBuf,
 }
 
+impl SafeDisplay for PluginServiceLocalConfig {
+    fn to_safe_string(&self) -> String {
+        format!("root: {:?}", self.root)
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 #[serde(tag = "type", content = "config")]
 pub enum CompiledComponentServiceConfig {
@@ -103,6 +302,15 @@ pub enum CompiledComponentServiceConfig {
     Disabled(CompiledComponentServiceDisabledConfig),
 }
 
+impl SafeDisplay for CompiledComponentServiceConfig {
+    fn to_safe_string(&self) -> String {
+        match self {
+            CompiledComponentServiceConfig::Enabled(_) => "enabled".to_string(),
+            CompiledComponentServiceConfig::Disabled(_) => "disabled".to_string(),
+        }
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct CompiledComponentServiceEnabledConfig {}
 
@@ -116,6 +324,22 @@ pub enum ShardManagerServiceConfig {
     SingleShard(ShardManagerServiceSingleShardConfig),
 }
 
+impl SafeDisplay for ShardManagerServiceConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        match self {
+            ShardManagerServiceConfig::Grpc(grpc) => {
+                let _ = writeln!(&mut result, "grpc:");
+                let _ = writeln!(&mut result, "{}", grpc.to_safe_string_indented());
+            }
+            ShardManagerServiceConfig::SingleShard(_) => {
+                let _ = writeln!(&mut result, "single shard");
+            }
+        }
+        result
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct ShardManagerServiceGrpcConfig {
     pub host: String,
@@ -123,6 +347,17 @@ pub struct ShardManagerServiceGrpcConfig {
     pub retries: RetryConfig,
 }
 
+impl SafeDisplay for ShardManagerServiceGrpcConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "host: {}", self.host);
+        let _ = writeln!(&mut result, "port: {}", self.port);
+        let _ = writeln!(&mut result, "retries:",);
+        let _ = writeln!(&mut result, "{}", self.retries.to_safe_string_indented());
+        result
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct ShardManagerServiceSingleShardConfig {}
 
@@ -136,6 +371,19 @@ pub struct WorkerServiceGrpcConfig {
     pub connect_timeout: Duration,
 }
 
+impl SafeDisplay for WorkerServiceGrpcConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "host: {}", self.host);
+        let _ = writeln!(&mut result, "port: {}", self.port);
+        let _ = writeln!(&mut result, "access token: ****");
+        let _ = writeln!(&mut result, "connect timeout: {:?}", self.connect_timeout);
+        let _ = writeln!(&mut result, "retries:");
+        let _ = writeln!(&mut result, "{}", self.retries.to_safe_string_indented());
+        result
+    }
+}
+
 impl GolemConfig {
     pub fn from_file(path: &str) -> Self {
         Figment::new()
@@ -211,6 +459,12 @@ pub struct SuspendConfig {
     pub suspend_after: Duration,
 }
 
+impl SafeDisplay for SuspendConfig {
+    fn to_safe_string(&self) -> String {
+        format!("suspend after: {:?}", self.suspend_after)
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct ActiveWorkersConfig {
     pub drop_when_full: f64,
@@ -218,12 +472,29 @@ pub struct ActiveWorkersConfig {
     pub ttl: Duration,
 }
 
+impl SafeDisplay for ActiveWorkersConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "drop when full: {}", self.drop_when_full);
+        let _ = writeln!(&mut result, "ttl: {:?}", self.ttl);
+        result
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct SchedulerConfig {
     #[serde(with = "humantime_serde")]
     pub refresh_interval: Duration,
 }
 
+impl SafeDisplay for SchedulerConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "refresh interval: {:?}", self.refresh_interval);
+        result
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct OplogConfig {
     pub max_operations_before_commit: u64,
@@ -236,6 +507,36 @@ pub struct OplogConfig {
     pub archive_interval: Duration,
 }
 
+impl SafeDisplay for OplogConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(
+            &mut result,
+            "max operations before commit: {}",
+            self.max_operations_before_commit
+        );
+        let _ = writeln!(
+            &mut result,
+            "max operations before commit for ephemerals: {}",
+            self.max_operations_before_commit_ephemeral
+        );
+        let _ = writeln!(&mut result, "max payload size: {}", self.max_payload_size);
+        let _ = writeln!(
+            &mut result,
+            "indexed storage layers: {}",
+            self.indexed_storage_layers
+        );
+        let _ = writeln!(
+            &mut result,
+            "blob storage layers: {}",
+            self.blob_storage_layers
+        );
+        let _ = writeln!(&mut result, "entry count limit: {}", self.entry_count_limit);
+        let _ = writeln!(&mut result, "archive interval: {:?}", self.archive_interval);
+        result
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 #[serde(tag = "type", content = "config")]
 pub enum KeyValueStorageConfig {
@@ -244,9 +545,36 @@ pub enum KeyValueStorageConfig {
     InMemory(KeyValueStorageInMemoryConfig),
 }
 
+impl SafeDisplay for KeyValueStorageConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        match self {
+            KeyValueStorageConfig::Redis(inner) => {
+                let _ = writeln!(&mut result, "redis:");
+                let _ = writeln!(&mut result, "{}", inner.to_safe_string_indented());
+            }
+            KeyValueStorageConfig::Sqlite(inner) => {
+                let _ = writeln!(&mut result, "sqlite:");
+                let _ = writeln!(&mut result, "{}", inner.to_safe_string_indented());
+            }
+            KeyValueStorageConfig::InMemory(inner) => {
+                let _ = writeln!(&mut result, "in-memory:");
+                let _ = writeln!(&mut result, "{}", inner.to_safe_string_indented());
+            }
+        }
+        result
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct KeyValueStorageInMemoryConfig {}
 
+impl SafeDisplay for KeyValueStorageInMemoryConfig {
+    fn to_safe_string(&self) -> String {
+        "".to_string()
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 #[serde(tag = "type", content = "config")]
 pub enum IndexedStorageConfig {
@@ -257,15 +585,62 @@ pub enum IndexedStorageConfig {
     InMemory(IndexedStorageInMemoryConfig),
 }
 
+impl SafeDisplay for IndexedStorageConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        match self {
+            IndexedStorageConfig::KVStoreRedis(inner) => {
+                let _ = writeln!(&mut result, "redis kv-store:");
+                let _ = writeln!(&mut result, "{}", inner.to_safe_string_indented());
+            }
+            IndexedStorageConfig::Redis(inner) => {
+                let _ = writeln!(&mut result, "redis:");
+                let _ = writeln!(&mut result, "{}", inner.to_safe_string_indented());
+            }
+            IndexedStorageConfig::KVStoreSqlite(inner) => {
+                let _ = writeln!(&mut result, "sqlite kv-store:");
+                let _ = writeln!(&mut result, "{}", inner.to_safe_string_indented());
+            }
+            IndexedStorageConfig::Sqlite(inner) => {
+                let _ = writeln!(&mut result, "sqlite:");
+                let _ = writeln!(&mut result, "{}", inner.to_safe_string_indented());
+            }
+            IndexedStorageConfig::InMemory(inner) => {
+                let _ = writeln!(&mut result, "in-memory:");
+                let _ = writeln!(&mut result, "{}", inner.to_safe_string_indented());
+            }
+        }
+        result
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct IndexedStorageKVStoreRedisConfig {}
 
+impl SafeDisplay for IndexedStorageKVStoreRedisConfig {
+    fn to_safe_string(&self) -> String {
+        "".to_string()
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct IndexedStorageKVStoreSqliteConfig {}
 
+impl SafeDisplay for IndexedStorageKVStoreSqliteConfig {
+    fn to_safe_string(&self) -> String {
+        "".to_string()
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct IndexedStorageInMemoryConfig {}
 
+impl SafeDisplay for IndexedStorageInMemoryConfig {
+    fn to_safe_string(&self) -> String {
+        "".to_string()
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct MemoryConfig {
     pub system_memory_override: Option<u64>,
@@ -296,17 +671,68 @@ impl MemoryConfig {
     }
 }
 
+impl SafeDisplay for MemoryConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        if let Some(ovrd) = &self.system_memory_override {
+            let _ = writeln!(&mut result, "system memory override: {ovrd}");
+        }
+        let _ = writeln!(
+            &mut result,
+            "worker memory ratio: {}",
+            self.worker_memory_ratio
+        );
+        let _ = writeln!(
+            &mut result,
+            "worker estimate coefficient: {}",
+            self.worker_estimate_coefficient
+        );
+        let _ = writeln!(
+            &mut result,
+            "acquire retry delay: {:?}",
+            self.acquire_retry_delay
+        );
+        let _ = writeln!(&mut result, "oom retry config:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.oom_retry_config.to_safe_string_indented()
+        );
+
+        result
+    }
+}
+
 #[derive(Clone, Copy, Debug, Default, Serialize, Deserialize)]
 pub struct RdbmsConfig {
     pub pool: RdbmsPoolConfig,
     pub query: RdbmsQueryConfig,
 }
 
+impl SafeDisplay for RdbmsConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "pool:");
+        let _ = writeln!(&mut result, "{}", self.pool.to_safe_string_indented());
+        let _ = writeln!(&mut result, "query:");
+        let _ = writeln!(&mut result, "{}", self.query.to_safe_string_indented());
+        result
+    }
+}
+
 #[derive(Clone, Copy, Debug, Serialize, Deserialize)]
 pub struct RdbmsQueryConfig {
     pub query_batch: usize,
 }
 
+impl SafeDisplay for RdbmsQueryConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "batch size: {}", self.query_batch);
+        result
+    }
+}
+
 #[derive(Clone, Copy, Debug, Serialize, Deserialize)]
 pub struct RdbmsPoolConfig {
     pub max_connections: u32,
@@ -316,6 +742,16 @@ pub struct RdbmsPoolConfig {
     pub eviction_period: Duration,
 }
 
+impl SafeDisplay for RdbmsPoolConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "max connections: {}", self.max_connections);
+        let _ = writeln!(&mut result, "eviction ttl: {:?}", self.eviction_ttl);
+        let _ = writeln!(&mut result, "eviction period: {:?}", self.eviction_period);
+        result
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 #[serde(tag = "type", content = "config")]
 pub enum ResourceLimitsConfig {
@@ -323,6 +759,22 @@ pub enum ResourceLimitsConfig {
     Disabled(ResourceLimitsDisabledConfig),
 }
 
+impl SafeDisplay for ResourceLimitsConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        match self {
+            ResourceLimitsConfig::Grpc(grpc) => {
+                let _ = writeln!(&mut result, "grpc:");
+                let _ = writeln!(&mut result, "{}", grpc.to_safe_string_indented());
+            }
+            ResourceLimitsConfig::Disabled(_) => {
+                let _ = writeln!(&mut result, "disabled");
+            }
+        }
+        result
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct ResourceLimitsGrpcConfig {
     pub host: String,
@@ -333,6 +785,23 @@ pub struct ResourceLimitsGrpcConfig {
     pub batch_update_interval: Duration,
 }
 
+impl SafeDisplay for ResourceLimitsGrpcConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "host: {}", self.host);
+        let _ = writeln!(&mut result, "port: {}", self.port);
+        let _ = writeln!(&mut result, "access token: ****");
+        let _ = writeln!(
+            &mut result,
+            "batch update interval: {:?}",
+            self.batch_update_interval
+        );
+        let _ = writeln!(&mut result, "retries:");
+        let _ = writeln!(&mut result, "{}", self.retries.to_safe_string_indented());
+        result
+    }
+}
+
 impl ResourceLimitsGrpcConfig {
     pub fn url(&self) -> Url {
         build_url("resource limits", &self.host, self.port)
@@ -351,11 +820,29 @@ pub struct ComponentCacheConfig {
     pub max_capacity: usize,
     pub max_metadata_capacity: usize,
     pub max_resolved_component_capacity: usize,
-    pub max_resolved_project_capacity: usize,
     #[serde(with = "humantime_serde")]
     pub time_to_idle: Duration,
 }
 
+impl SafeDisplay for ComponentCacheConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "max capacity: {}", self.max_capacity);
+        let _ = writeln!(
+            &mut result,
+            "max metadata capacity: {}",
+            self.max_metadata_capacity
+        );
+        let _ = writeln!(
+            &mut result,
+            "max resolved component capacity: {}",
+            self.max_resolved_component_capacity
+        );
+        let _ = writeln!(&mut result, "time to idle: {:?}", self.time_to_idle);
+        result
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 #[serde(tag = "type", content = "config")]
 pub enum ProjectServiceConfig {
@@ -363,6 +850,23 @@ pub enum ProjectServiceConfig {
     Disabled(ProjectServiceDisabledConfig),
 }
 
+impl SafeDisplay for ProjectServiceConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        match self {
+            ProjectServiceConfig::Grpc(grpc) => {
+                let _ = writeln!(&mut result, "grpc:");
+                let _ = writeln!(&mut result, "{}", grpc.to_safe_string_indented());
+            }
+            ProjectServiceConfig::Disabled(disabled) => {
+                let _ = writeln!(&mut result, "disabled:");
+                let _ = writeln!(&mut result, "{}", disabled.to_safe_string_indented());
+            }
+        }
+        result
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct ProjectServiceGrpcConfig {
     pub host: String,
@@ -371,6 +875,9 @@ pub struct ProjectServiceGrpcConfig {
     pub retries: RetryConfig,
     #[serde(with = "humantime_serde")]
     pub connect_timeout: Duration,
+    pub max_resolved_project_cache_capacity: usize,
+    #[serde(with = "humantime_serde")]
+    pub cache_time_to_idle: Duration,
 }
 
 impl ProjectServiceGrpcConfig {
@@ -383,8 +890,111 @@ impl ProjectServiceGrpcConfig {
     }
 }
 
+impl SafeDisplay for ProjectServiceGrpcConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "host: {}", self.host);
+        let _ = writeln!(&mut result, "port: {}", self.port);
+        let _ = writeln!(&mut result, "access token: ****");
+        let _ = writeln!(&mut result, "connect timeout: {:?}", self.connect_timeout);
+        let _ = writeln!(
+            &mut result,
+            "max resolved project cache capacity: {}",
+            self.max_resolved_project_cache_capacity
+        );
+        let _ = writeln!(
+            &mut result,
+            "cache time to idle: {:?}",
+            self.cache_time_to_idle
+        );
+        let _ = writeln!(&mut result, "retries:");
+        let _ = writeln!(&mut result, "{}", self.retries.to_safe_string_indented());
+        result
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
-pub struct ProjectServiceDisabledConfig {}
+pub struct ProjectServiceDisabledConfig {
+    pub account_id: AccountId,
+    pub project_id: ProjectId,
+    pub project_name: String,
+}
+
+impl SafeDisplay for ProjectServiceDisabledConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "account_id: {}", self.account_id);
+        let _ = writeln!(&mut result, "project id: {}", self.project_id);
+        let _ = writeln!(&mut result, "project name: {}", self.project_name);
+        result
+    }
+}
+
+#[derive(Clone, Debug, Serialize, Deserialize)]
+#[serde(tag = "type", content = "config")]
+pub enum AgentTypesServiceConfig {
+    Grpc(AgentTypesServiceGrpcConfig),
+    Local(AgentTypesServiceLocalConfig),
+}
+
+impl SafeDisplay for AgentTypesServiceConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        match self {
+            AgentTypesServiceConfig::Grpc(grpc) => {
+                let _ = writeln!(&mut result, "grpc:");
+                let _ = writeln!(&mut result, "{}", grpc.to_safe_string_indented());
+            }
+            AgentTypesServiceConfig::Local(_) => {
+                let _ = writeln!(&mut result, "local");
+            }
+        }
+        result
+    }
+}
+
+#[derive(Clone, Debug, Serialize, Deserialize)]
+pub struct AgentTypesServiceGrpcConfig {
+    pub host: String,
+    pub port: u16,
+    pub access_token: String,
+    pub retries: RetryConfig,
+    #[serde(with = "humantime_serde")]
+    pub connect_timeout: Duration,
+    #[serde(with = "humantime_serde")]
+    pub cache_time_to_idle: Duration,
+}
+
+impl AgentTypesServiceGrpcConfig {
+    pub fn url(&self) -> Url {
+        build_url("agent_types", &self.host, self.port)
+    }
+
+    pub fn uri(&self) -> Uri {
+        build_uri("agent_types", &self.host, self.port)
+    }
+}
+
+impl SafeDisplay for AgentTypesServiceGrpcConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "host: {}", self.host);
+        let _ = writeln!(&mut result, "port: {}", self.port);
+        let _ = writeln!(&mut result, "access token: ****");
+        let _ = writeln!(&mut result, "connect timeout: {:?}", self.connect_timeout);
+        let _ = writeln!(
+            &mut result,
+            "cache time to idle: {:?}",
+            self.cache_time_to_idle
+        );
+        let _ = writeln!(&mut result, "retries:");
+        let _ = writeln!(&mut result, "{}", self.retries.to_safe_string_indented());
+        result
+    }
+}
+
+#[derive(Clone, Debug, Serialize, Deserialize)]
+pub struct AgentTypesServiceLocalConfig {}
 
 #[derive(Clone, Debug, Serialize, Deserialize)]
 #[serde(tag = "type", content = "config")]
@@ -393,11 +1003,36 @@ pub enum ComponentServiceConfig {
     Grpc(ComponentServiceGrpcConfig),
 }
 
+impl SafeDisplay for ComponentServiceConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        match self {
+            ComponentServiceConfig::Local(local) => {
+                let _ = writeln!(&mut result, "local:");
+                let _ = writeln!(&mut result, "{}", local.to_safe_string_indented());
+            }
+            ComponentServiceConfig::Grpc(grpc) => {
+                let _ = writeln!(&mut result, "grpc:");
+                let _ = writeln!(&mut result, "{}", grpc.to_safe_string_indented());
+            }
+        }
+        result
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct ComponentServiceLocalConfig {
     pub root: PathBuf,
 }
 
+impl SafeDisplay for ComponentServiceLocalConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "root: {:?}", self.root);
+        result
+    }
+}
+
 #[derive(Clone, Debug, Serialize, Deserialize)]
 pub struct ComponentServiceGrpcConfig {
     pub host: String,
@@ -419,6 +1054,23 @@ impl ComponentServiceGrpcConfig {
     }
 }
 
+impl SafeDisplay for ComponentServiceGrpcConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "host: {}", self.host);
+        let _ = writeln!(&mut result, "port: {}", self.port);
+        let _ = writeln!(&mut result, "access token: ****");
+        let _ = writeln!(
+            &mut result,
+            "max component size: {}",
+            self.max_component_size
+        );
+        let _ = writeln!(&mut result, "retries:");
+        let _ = writeln!(&mut result, "{}", self.retries.to_safe_string_indented());
+        result
+    }
+}
+
 impl Default for GolemConfig {
     fn default() -> Self {
         Self {
@@ -443,6 +1095,7 @@ impl Default for GolemConfig {
             component_service: ComponentServiceConfig::default(),
             component_cache: ComponentCacheConfig::default(),
             project_service: ProjectServiceConfig::default(),
+            agent_types_service: AgentTypesServiceConfig::default(),
             grpc_address: "0.0.0.0".to_string(),
             port: 9000,
             http_address: "0.0.0.0".to_string(),
@@ -673,7 +1326,6 @@ impl Default for ComponentCacheConfig {
             max_capacity: 32,
             max_metadata_capacity: 16384,
             max_resolved_component_capacity: 1024,
-            max_resolved_project_capacity: 1024,
             time_to_idle: Duration::from_secs(12 * 60 * 60),
         }
     }
@@ -712,6 +1364,27 @@ impl Default for ProjectServiceGrpcConfig {
             access_token: "2a354594-7a63-4091-a46b-cc58d379f677".to_string(),
             retries: RetryConfig::max_attempts_3(),
             connect_timeout: Duration::from_secs(30),
+            max_resolved_project_cache_capacity: 1024,
+            cache_time_to_idle: Duration::from_secs(12 * 60 * 60),
+        }
+    }
+}
+
+impl Default for AgentTypesServiceConfig {
+    fn default() -> Self {
+        Self::Grpc(AgentTypesServiceGrpcConfig::default())
+    }
+}
+
+impl Default for AgentTypesServiceGrpcConfig {
+    fn default() -> Self {
+        Self {
+            host: "localhost".to_string(),
+            port: 9092,
+            access_token: "2a354594-7a63-4091-a46b-cc58d379f677".to_string(),
+            retries: RetryConfig::max_attempts_3(),
+            connect_timeout: Duration::from_secs(30),
+            cache_time_to_idle: Duration::from_secs(60),
         }
     }
 }
diff --git a/golem-worker-executor/src/services/oplog/blob.rs b/golem-worker-executor/src/services/oplog/blob.rs
index af82226b..a68e4d61 100644
--- a/golem-worker-executor/src/services/oplog/blob.rs
+++ b/golem-worker-executor/src/services/oplog/blob.rs
@@ -18,7 +18,7 @@ use async_lock::RwLockUpgradableReadGuard;
 use async_trait::async_trait;
 use evicting_cache_map::EvictingCacheMap;
 use golem_common::model::oplog::{OplogEntry, OplogIndex};
-use golem_common::model::{AccountId, ComponentId, OwnedWorkerId, ScanCursor, WorkerId};
+use golem_common::model::{ComponentId, OwnedWorkerId, ProjectId, ScanCursor, WorkerId};
 use golem_service_base::error::worker_executor::WorkerExecutorError;
 use golem_service_base::storage::blob::{
     BlobStorage, BlobStorageLabelledApi, BlobStorageNamespace, ExistsResult,
@@ -67,7 +67,7 @@ impl OplogArchiveService for BlobOplogArchiveService {
                 "blob_oplog",
                 "delete",
                 BlobStorageNamespace::CompressedOplog {
-                    account_id: owned_worker_id.account_id(),
+                    project_id: owned_worker_id.project_id(),
                     component_id: owned_worker_id.component_id(),
                     level: self.level,
                 },
@@ -97,7 +97,7 @@ impl OplogArchiveService for BlobOplogArchiveService {
             .with("blob_oplog", "exists")
             .exists(
                 BlobStorageNamespace::CompressedOplog {
-                    account_id: owned_worker_id.account_id(),
+                    project_id: owned_worker_id.project_id(),
                     component_id: owned_worker_id.component_id(),
                     level: self.level,
                 },
@@ -115,7 +115,7 @@ impl OplogArchiveService for BlobOplogArchiveService {
 
     async fn scan_for_component(
         &self,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         component_id: &ComponentId,
         cursor: ScanCursor,
         _count: u64,
@@ -124,7 +124,7 @@ impl OplogArchiveService for BlobOplogArchiveService {
             let blob_storage = self.blob_storage.with("blob_oplog", "scan_for_component");
             let owned_worker_ids = if blob_storage.exists(
                 BlobStorageNamespace::CompressedOplog {
-                    account_id: account_id.clone(),
+                    project_id: project_id.clone(),
                     component_id: component_id.clone(),
                     level: self.level,
                 },
@@ -136,7 +136,7 @@ impl OplogArchiveService for BlobOplogArchiveService {
                 let paths = blob_storage
                     .list_dir(
                     BlobStorageNamespace::CompressedOplog {
-                    account_id: account_id.clone(),
+                    project_id: project_id.clone(),
                     component_id: component_id.clone(),
                     level: self.level,
                 },
@@ -150,7 +150,7 @@ impl OplogArchiveService for BlobOplogArchiveService {
                     .map(|path| {
                         let worker_name = path.file_name().unwrap().to_str().unwrap();
                         OwnedWorkerId {
-                            account_id: account_id.clone(),
+                            project_id: project_id.clone(),
                             worker_id: WorkerId {
                                 component_id: component_id.clone(),
                                 worker_name: worker_name.to_string(),
@@ -247,7 +247,7 @@ impl BlobOplogArchive {
                 .with("blob_oplog", "new")
                 .create_dir(
                     BlobStorageNamespace::CompressedOplog {
-                        account_id: self.owned_worker_id.account_id(),
+                        project_id: self.owned_worker_id.project_id(),
                         component_id: self.owned_worker_id.component_id(),
                         level: self.level,
                     },
@@ -274,7 +274,7 @@ impl BlobOplogArchive {
             .with("blob_oplog", "exists")
             .exists(
                 BlobStorageNamespace::CompressedOplog {
-                    account_id: owned_worker_id.account_id(),
+                    project_id: owned_worker_id.project_id(),
                     component_id: owned_worker_id.component_id(),
                     level,
                 },
@@ -299,7 +299,7 @@ impl BlobOplogArchive {
             .with("blob_oplog", "new")
             .list_dir(
                 BlobStorageNamespace::CompressedOplog {
-                    account_id: owned_worker_id.account_id(),
+                    project_id: owned_worker_id.project_id(),
                     component_id: owned_worker_id.component_id(),
                     level,
                 },
@@ -346,7 +346,7 @@ impl BlobOplogArchive {
                 .with("blob_oplog", "read")
                 .get(
                     BlobStorageNamespace::CompressedOplog {
-                        account_id: self.owned_worker_id.account_id(),
+                        project_id: self.owned_worker_id.project_id(),
                         component_id: self.owned_worker_id.component_id(),
                         level: self.level,
                     },
@@ -446,7 +446,7 @@ impl OplogArchive for BlobOplogArchive {
                 "blob_oplog",
                 "append").put(
                 BlobStorageNamespace::CompressedOplog {
-                    account_id: self.owned_worker_id.account_id(),
+                    project_id: self.owned_worker_id.project_id(),
                     component_id: self.owned_worker_id.component_id(),
                     level: self.level
                 },
@@ -503,7 +503,7 @@ impl OplogArchive for BlobOplogArchive {
             .collect::<Vec<_>>();
 
         let ns = BlobStorageNamespace::CompressedOplog {
-            account_id: self.owned_worker_id.account_id(),
+            project_id: self.owned_worker_id.project_id(),
             component_id: self.owned_worker_id.component_id(),
             level: self.level,
         };
@@ -529,7 +529,7 @@ impl OplogArchive for BlobOplogArchive {
                 self.blob_storage
                 .with("blob_oplog", "drop_prefix")
                 .delete_dir(BlobStorageNamespace::CompressedOplog {
-                    account_id: self.owned_worker_id.account_id(),
+                    project_id: self.owned_worker_id.project_id(),
                     component_id: self.owned_worker_id.component_id(),
                     level: self.level,
                 },
diff --git a/golem-worker-executor/src/services/oplog/compressed.rs b/golem-worker-executor/src/services/oplog/compressed.rs
index 5ac8122e..8bf1a216 100644
--- a/golem-worker-executor/src/services/oplog/compressed.rs
+++ b/golem-worker-executor/src/services/oplog/compressed.rs
@@ -19,7 +19,7 @@ use async_trait::async_trait;
 use bincode::{Decode, Encode};
 use evicting_cache_map::EvictingCacheMap;
 use golem_common::model::oplog::{OplogEntry, OplogIndex};
-use golem_common::model::{AccountId, ComponentId, OwnedWorkerId, ScanCursor, WorkerId};
+use golem_common::model::{ComponentId, OwnedWorkerId, ProjectId, ScanCursor, WorkerId};
 use golem_common::serialization::{deserialize, serialize};
 use golem_service_base::error::worker_executor::WorkerExecutorError;
 use std::cmp::min;
@@ -94,7 +94,7 @@ impl OplogArchiveService for CompressedOplogArchiveService {
 
     async fn scan_for_component(
         &self,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         component_id: &ComponentId,
         cursor: ScanCursor,
         count: u64,
@@ -119,7 +119,7 @@ impl OplogArchiveService for CompressedOplogArchiveService {
             keys.into_iter()
                 .map(|key| OwnedWorkerId {
                     worker_id: PrimaryOplogService::get_worker_id_from_key(&key, component_id),
-                    account_id: account_id.clone(),
+                    project_id: project_id.clone(),
                 })
                 .collect(),
         ))
diff --git a/golem-worker-executor/src/services/oplog/mod.rs b/golem-worker-executor/src/services/oplog/mod.rs
index 82f2be57..5f24993f 100644
--- a/golem-worker-executor/src/services/oplog/mod.rs
+++ b/golem-worker-executor/src/services/oplog/mod.rs
@@ -24,7 +24,7 @@ use golem_common::model::oplog::{
     DurableFunctionType, OplogEntry, OplogIndex, OplogPayload, UpdateDescription,
 };
 use golem_common::model::{
-    AccountId, ComponentId, ComponentVersion, IdempotencyKey, OwnedWorkerId, ScanCursor, Timestamp,
+    ComponentId, ComponentVersion, IdempotencyKey, OwnedWorkerId, ProjectId, ScanCursor, Timestamp,
     WorkerId, WorkerMetadata,
 };
 use golem_common::serialization::{serialize, try_deserialize};
@@ -71,14 +71,14 @@ pub trait OplogService: Debug + Send + Sync {
         initial_entry: OplogEntry,
         initial_worker_metadata: WorkerMetadata,
         execution_status: Arc<std::sync::RwLock<ExecutionStatus>>,
-    ) -> Arc<dyn Oplog + 'static>;
+    ) -> Arc<dyn Oplog>;
     async fn open(
         &self,
         owned_worker_id: &OwnedWorkerId,
         last_oplog_index: OplogIndex,
         initial_worker_metadata: WorkerMetadata,
         execution_status: Arc<std::sync::RwLock<ExecutionStatus>>,
-    ) -> Arc<dyn Oplog + 'static>;
+    ) -> Arc<dyn Oplog>;
 
     async fn get_last_index(&self, owned_worker_id: &OwnedWorkerId) -> OplogIndex;
 
@@ -100,9 +100,7 @@ pub trait OplogService: Debug + Send + Sync {
     ) -> BTreeMap<OplogIndex, OplogEntry> {
         assert!(
             start_idx <= last_idx,
-            "Invalid range passed to OplogService::read_range: start_idx = {}, last_idx = {}",
-            start_idx,
-            last_idx
+            "Invalid range passed to OplogService::read_range: start_idx = {start_idx}, last_idx = {last_idx}"
         );
 
         self.read(
@@ -130,7 +128,7 @@ pub trait OplogService: Debug + Send + Sync {
     /// Pages can be empty. This operation is slow and is not locking the oplog.
     async fn scan_for_component(
         &self,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         component_id: &ComponentId,
         cursor: ScanCursor,
         count: u64,
@@ -250,7 +248,7 @@ pub trait OplogOps: Oplog {
             function_name,
             request: request_payload,
             response: response_payload,
-            wrapped_function_type: function_type,
+            durable_function_type: function_type,
         };
         self.add(entry.clone()).await;
         Ok(entry)
@@ -311,9 +309,6 @@ pub trait OplogOps: Oplog {
 
     async fn get_raw_payload_of_entry(&self, entry: &OplogEntry) -> Result<Option<Bytes>, String> {
         match entry {
-            OplogEntry::ImportedFunctionInvokedV1 { response, .. } => {
-                Ok(Some(self.download_payload(response).await?))
-            }
             OplogEntry::ImportedFunctionInvoked { response, .. } => {
                 Ok(Some(self.download_payload(response).await?))
             }
diff --git a/golem-worker-executor/src/services/oplog/multilayer.rs b/golem-worker-executor/src/services/oplog/multilayer.rs
index e777404b..0b16d6cc 100644
--- a/golem-worker-executor/src/services/oplog/multilayer.rs
+++ b/golem-worker-executor/src/services/oplog/multilayer.rs
@@ -24,7 +24,7 @@ use async_trait::async_trait;
 use bytes::Bytes;
 use golem_common::model::oplog::{OplogEntry, OplogIndex, OplogPayload};
 use golem_common::model::{
-    AccountId, ComponentId, ComponentType, OwnedWorkerId, ScanCursor, WorkerMetadata,
+    ComponentId, ComponentType, OwnedWorkerId, ProjectId, ScanCursor, WorkerMetadata,
 };
 use golem_service_base::error::worker_executor::WorkerExecutorError;
 use nonempty_collections::NEVec;
@@ -59,7 +59,7 @@ pub trait OplogArchiveService: Debug + Send + Sync {
 
     async fn scan_for_component(
         &self,
-        account_id: &AccountId,
+        account_id: &ProjectId,
         component_id: &ComponentId,
         cursor: ScanCursor,
         count: u64,
@@ -363,7 +363,7 @@ impl OplogService for MultiLayerOplogService {
                 }
             };
 
-            result.extend(partial_result.into_iter());
+            result.extend(partial_result);
 
             if !full_match {
                 for layer in &self.lower {
@@ -404,7 +404,7 @@ impl OplogService for MultiLayerOplogService {
 
     async fn scan_for_component(
         &self,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         component_id: &ComponentId,
         cursor: ScanCursor,
         count: u64,
@@ -413,7 +413,7 @@ impl OplogService for MultiLayerOplogService {
             0 => {
                 let (new_cursor, unfiltered_ids) = self
                     .primary
-                    .scan_for_component(account_id, component_id, cursor, count)
+                    .scan_for_component(project_id, component_id, cursor, count)
                     .await?;
 
                 let ids = self
@@ -436,7 +436,7 @@ impl OplogService for MultiLayerOplogService {
             }
             layer if layer <= self.lower.len().get() => {
                 let (new_cursor, unfiltered_ids) = self.lower[layer - 1]
-                    .scan_for_component(account_id, component_id, cursor, count)
+                    .scan_for_component(project_id, component_id, cursor, count)
                     .await?;
                 let ids = self
                     .filter_ids_existing_on_lower_layers(unfiltered_ids, layer)
diff --git a/golem-worker-executor/src/services/oplog/plugin.rs b/golem-worker-executor/src/services/oplog/plugin.rs
index ccea96ec..dd482218 100644
--- a/golem-worker-executor/src/services/oplog/plugin.rs
+++ b/golem-worker-executor/src/services/oplog/plugin.rs
@@ -17,6 +17,7 @@ use crate::model::ExecutionStatus;
 use crate::services::component::ComponentService;
 use crate::services::oplog::{CommitLevel, OpenOplogs, Oplog, OplogConstructor, OplogService};
 use crate::services::plugins::Plugins;
+use crate::services::projects::ProjectService;
 use crate::services::shard::ShardService;
 use crate::services::worker_activator::WorkerActivator;
 use crate::services::{
@@ -35,18 +36,19 @@ use golem_common::model::plugin::{
 use golem_common::model::public_oplog::PublicOplogEntry;
 use golem_common::model::{
     AccountId, ComponentId, ComponentVersion, IdempotencyKey, OwnedWorkerId, PluginInstallationId,
-    ScanCursor, ShardId, TargetWorkerId, WorkerId, WorkerMetadata,
+    ProjectId, ScanCursor, ShardId, WorkerId, WorkerMetadata,
 };
 use golem_service_base::error::worker_executor::WorkerExecutorError;
 use golem_wasm_rpc::{IntoValue, Value};
 use std::collections::hash_map::Entry;
-use std::collections::{BTreeMap, HashMap, VecDeque};
+use std::collections::{BTreeMap, HashMap, HashSet, VecDeque};
 use std::fmt::{Debug, Formatter};
 use std::sync::Arc;
 use std::time::Duration;
 use tokio::task::JoinHandle;
 use tokio::time::Instant;
 use tracing::Instrument;
+use uuid::Uuid;
 
 #[async_trait]
 pub trait OplogProcessorPlugin: Send + Sync {
@@ -70,12 +72,14 @@ pub struct PerExecutorOplogProcessorPlugin<Ctx: WorkerCtx> {
     shard_service: Arc<dyn ShardService>,
     worker_activator: Arc<dyn WorkerActivator<Ctx>>,
     plugins: Arc<dyn Plugins>,
+    project_service: Arc<dyn ProjectService>,
 }
 
-type WorkerKey = (AccountId, String, String);
+type WorkerKey = (ProjectId, String, String);
 
 #[derive(Debug, Clone)]
 struct RunningPlugin {
+    pub account_id: AccountId,
     pub owned_worker_id: OwnedWorkerId,
     pub configuration: HashMap<String, String>,
     pub component_version: ComponentVersion,
@@ -87,6 +91,7 @@ impl<Ctx: WorkerCtx> PerExecutorOplogProcessorPlugin<Ctx> {
         shard_service: Arc<dyn ShardService>,
         worker_activator: Arc<dyn WorkerActivator<Ctx>>,
         plugins: Arc<dyn Plugins>,
+        project_service: Arc<dyn ProjectService>,
     ) -> Self {
         Self {
             workers: Arc::new(RwLock::new(HashMap::new())),
@@ -94,20 +99,22 @@ impl<Ctx: WorkerCtx> PerExecutorOplogProcessorPlugin<Ctx> {
             shard_service,
             worker_activator,
             plugins,
+            project_service,
         }
     }
 
     async fn resolve_plugin_worker(
         &self,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         component_id: &ComponentId,
         component_version: ComponentVersion,
         plugin_installation_id: &PluginInstallationId,
     ) -> Result<RunningPlugin, WorkerExecutorError> {
+        let project_owner = self.project_service.get_project_owner(project_id).await?;
         let (installation, definition) = self
             .plugins
             .get(
-                account_id,
+                &project_owner,
                 component_id,
                 component_version,
                 plugin_installation_id,
@@ -116,7 +123,7 @@ impl<Ctx: WorkerCtx> PerExecutorOplogProcessorPlugin<Ctx> {
 
         let workers = self.workers.upgradable_read().await;
         let key = (
-            account_id.clone(),
+            project_id.clone(),
             definition.name.to_string(),
             definition.version.to_string(),
         );
@@ -131,10 +138,11 @@ impl<Ctx: WorkerCtx> PerExecutorOplogProcessorPlugin<Ctx> {
                             Self::get_oplog_processor_component_id(&definition)?;
                         let worker_id = self.generate_worker_id_for(&plugin_component_id).await?;
                         let owned_worker_id = OwnedWorkerId {
-                            account_id: account_id.clone(),
+                            project_id: project_id.clone(),
                             worker_id: worker_id.clone(),
                         };
                         let running_plugin = RunningPlugin {
+                            account_id: project_owner,
                             owned_worker_id: owned_worker_id.clone(),
                             configuration: installation.parameters.clone(),
                             component_version: plugin_component_version,
@@ -151,13 +159,9 @@ impl<Ctx: WorkerCtx> PerExecutorOplogProcessorPlugin<Ctx> {
         &self,
         plugin_component_id: &ComponentId,
     ) -> Result<WorkerId, WorkerExecutorError> {
-        let target_worker_id = TargetWorkerId {
-            component_id: plugin_component_id.clone(),
-            worker_name: None,
-        };
-
         let current_assignment = self.shard_service.current_assignment()?;
-        let worker_id = target_worker_id.into_worker_id(
+        let worker_id = Self::generate_local_worker_id(
+            plugin_component_id.clone(),
             &current_assignment.shard_ids,
             current_assignment.number_of_shards,
         );
@@ -178,6 +182,40 @@ impl<Ctx: WorkerCtx> PerExecutorOplogProcessorPlugin<Ctx> {
             )),
         }
     }
+
+    /// Converts a `TargetWorkerId` to a `WorkerId`. If the worker name was not specified,
+    /// it generates a new unique one, and if the `force_in_shard` set is not empty, it guarantees
+    /// that the generated worker ID will belong to one of the provided shards.
+    ///
+    /// If the worker name was specified, `force_in_shard` is ignored.
+    fn generate_local_worker_id(
+        component_id: ComponentId,
+        force_in_shard: &HashSet<ShardId>,
+        number_of_shards: usize,
+    ) -> WorkerId {
+        if force_in_shard.is_empty() || number_of_shards == 0 {
+            let worker_name = Uuid::new_v4().to_string();
+            WorkerId {
+                component_id,
+                worker_name,
+            }
+        } else {
+            let mut current = Uuid::new_v4().to_u128_le();
+            loop {
+                let uuid = Uuid::from_u128_le(current);
+                let worker_name = uuid.to_string();
+                let worker_id = WorkerId {
+                    component_id: component_id.clone(),
+                    worker_name,
+                };
+                let shard_id = ShardId::from_worker_id(&worker_id, number_of_shards);
+                if force_in_shard.contains(&shard_id) {
+                    return worker_id;
+                }
+                current += 1;
+            }
+        }
+    }
 }
 
 #[async_trait]
@@ -191,7 +229,7 @@ impl<Ctx: WorkerCtx> OplogProcessorPlugin for PerExecutorOplogProcessorPlugin<Ct
     ) -> Result<(), WorkerExecutorError> {
         let running_plugin = self
             .resolve_plugin_worker(
-                &worker_metadata.account_id,
+                &worker_metadata.project_id,
                 &worker_metadata.worker_id.component_id,
                 worker_metadata.last_known_status.component_version,
                 plugin_installation_id,
@@ -201,33 +239,30 @@ impl<Ctx: WorkerCtx> OplogProcessorPlugin for PerExecutorOplogProcessorPlugin<Ct
         let worker = self
             .worker_activator
             .get_or_create_running(
+                &running_plugin.account_id,
                 &running_plugin.owned_worker_id,
                 None,
                 None,
+                None,
                 Some(running_plugin.component_version),
                 None,
+                &InvocationContextStack::fresh(),
             )
             .await?;
 
         let idempotency_key = IdempotencyKey::fresh();
 
-        let (component_id_hi, component_id_lo) =
-            worker_metadata.worker_id.component_id.0.as_u64_pair();
-        let wave_account_info = format!(
-            "{{ account-id: {{ value: \"{}\" }} }}",
-            worker_metadata.account_id.value
-        );
-        let wave_component_id =
-            format!("{{ uuid: {{ high-bits: {component_id_hi}, low-bits: {component_id_lo} }} }}");
-        let mut wave_config = "[".to_string();
-        for (idx, (key, value)) in running_plugin.configuration.iter().enumerate() {
-            wave_config.push_str(&format!("( \"{key}\", \"{value}\")"));
-            if idx != running_plugin.configuration.len() - 1 {
-                wave_config.push_str(", ");
-            }
+        let val_account_info = Value::Record(vec![worker_metadata.created_by.clone().into_value()]);
+        let val_component_id = worker_metadata.worker_id.component_id.clone().into_value();
+        let mut config_pairs = Vec::new();
+        for (key, value) in running_plugin.configuration.iter() {
+            config_pairs.push(Value::Tuple(vec![
+                key.clone().into_value(),
+                value.clone().into_value(),
+            ]));
         }
-        wave_config.push(']');
-        let function_name = format!("golem:api/oplog-processor@1.1.7.{{processor({wave_account_info}, {wave_component_id}, {wave_config}).process}}");
+        let val_config = Value::List(config_pairs);
+        let function_name = "golem:api/oplog-processor@1.1.7.{process}".to_string();
 
         let val_worker_id = worker_metadata.worker_id.clone().into_value();
         let val_metadata = worker_metadata.into_value();
@@ -240,6 +275,9 @@ impl<Ctx: WorkerCtx> OplogProcessorPlugin for PerExecutorOplogProcessorPlugin<Ct
         );
 
         let function_input = vec![
+            val_account_info,
+            val_config,
+            val_component_id,
             val_worker_id,
             val_metadata,
             val_first_entry_index,
@@ -296,6 +334,7 @@ impl<Ctx: WorkerCtx> Clone for PerExecutorOplogProcessorPlugin<Ctx> {
             shard_service: self.shard_service.clone(),
             worker_activator: self.worker_activator.clone(),
             plugins: self.plugins.clone(),
+            project_service: self.project_service.clone(),
         }
     }
 }
@@ -340,6 +379,7 @@ struct CreateOplogConstructor {
     plugins: Arc<dyn Plugins>,
     execution_status: Arc<std::sync::RwLock<ExecutionStatus>>,
     initial_worker_metadata: WorkerMetadata,
+    project_service: Arc<dyn ProjectService>,
 }
 
 // We can have clone here independently of whether T is clone due to the Arcs, so deriving
@@ -356,6 +396,7 @@ impl Clone for CreateOplogConstructor {
             plugins: self.plugins.clone(),
             execution_status: self.execution_status.clone(),
             initial_worker_metadata: self.initial_worker_metadata.clone(),
+            project_service: self.project_service.clone(),
         }
     }
 }
@@ -371,6 +412,7 @@ impl CreateOplogConstructor {
         plugins: Arc<dyn Plugins>,
         execution_status: Arc<std::sync::RwLock<ExecutionStatus>>,
         initial_worker_metadata: WorkerMetadata,
+        project_service: Arc<dyn ProjectService>,
     ) -> Self {
         Self {
             owned_worker_id,
@@ -382,6 +424,7 @@ impl CreateOplogConstructor {
             plugins,
             execution_status,
             initial_worker_metadata,
+            project_service,
         }
     }
 }
@@ -415,6 +458,7 @@ impl OplogConstructor for CreateOplogConstructor {
             self.inner,
             self.components,
             self.plugins,
+            self.project_service,
             self.execution_status,
             self.initial_worker_metadata,
             self.last_oplog_index,
@@ -430,6 +474,7 @@ pub struct ForwardingOplogService {
     oplog_plugins: Arc<dyn OplogProcessorPlugin>,
     components: Arc<dyn ComponentService>,
     plugins: Arc<dyn Plugins>,
+    project_service: Arc<dyn ProjectService>,
 }
 
 impl ForwardingOplogService {
@@ -438,6 +483,7 @@ impl ForwardingOplogService {
         oplog_plugins: Arc<dyn OplogProcessorPlugin>,
         components: Arc<dyn ComponentService>,
         plugins: Arc<dyn Plugins>,
+        project_service: Arc<dyn ProjectService>,
     ) -> Self {
         Self {
             inner,
@@ -445,6 +491,7 @@ impl ForwardingOplogService {
             oplog_plugins,
             components,
             plugins,
+            project_service,
         }
     }
 }
@@ -477,6 +524,7 @@ impl OplogService for ForwardingOplogService {
                     self.plugins.clone(),
                     execution_status,
                     initial_worker_metadata,
+                    self.project_service.clone(),
                 ),
             )
             .await
@@ -502,6 +550,7 @@ impl OplogService for ForwardingOplogService {
                     self.plugins.clone(),
                     execution_status,
                     initial_worker_metadata,
+                    self.project_service.clone(),
                 ),
             )
             .await
@@ -530,7 +579,7 @@ impl OplogService for ForwardingOplogService {
 
     async fn scan_for_component(
         &self,
-        account_id: &AccountId,
+        account_id: &ProjectId,
         component_id: &ComponentId,
         cursor: ScanCursor,
         count: u64,
@@ -574,6 +623,7 @@ impl ForwardingOplog {
         oplog_service: Arc<dyn OplogService>,
         components: Arc<dyn ComponentService>,
         plugins: Arc<dyn Plugins>,
+        project_service: Arc<dyn ProjectService>,
         execution_status: Arc<std::sync::RwLock<ExecutionStatus>>,
         initial_worker_metadata: WorkerMetadata,
         last_oplog_idx: OplogIndex,
@@ -590,6 +640,7 @@ impl ForwardingOplog {
             oplog_service,
             components,
             plugins,
+            project_service,
         }));
 
         let timer = tokio::spawn({
@@ -690,6 +741,7 @@ struct ForwardingOplogState {
     oplog_service: Arc<dyn OplogService>,
     components: Arc<dyn ComponentService>,
     plugins: Arc<dyn Plugins>,
+    project_service: Arc<dyn ProjectService>,
 }
 
 impl ForwardingOplogState {
@@ -744,6 +796,7 @@ impl ForwardingOplogState {
                 self.oplog_service.clone(),
                 self.components.clone(),
                 self.plugins.clone(),
+                self.project_service.clone(),
                 &metadata.owned_worker_id(),
                 metadata.last_known_status.component_version, // NOTE: this is only safe if the component version is not changing within one batch
             )
diff --git a/golem-worker-executor/src/services/oplog/primary.rs b/golem-worker-executor/src/services/oplog/primary.rs
index bdfddc5d..05eac0aa 100644
--- a/golem-worker-executor/src/services/oplog/primary.rs
+++ b/golem-worker-executor/src/services/oplog/primary.rs
@@ -21,7 +21,7 @@ use async_trait::async_trait;
 use bytes::Bytes;
 use golem_common::model::oplog::{OplogEntry, OplogIndex, OplogPayload, PayloadId};
 use golem_common::model::{
-    AccountId, ComponentId, OwnedWorkerId, ScanCursor, WorkerId, WorkerMetadata,
+    ComponentId, OwnedWorkerId, ProjectId, ScanCursor, WorkerId, WorkerMetadata,
 };
 use golem_service_base::error::worker_executor::WorkerExecutorError;
 use golem_service_base::storage::blob::{BlobStorage, BlobStorageNamespace};
@@ -106,7 +106,7 @@ impl PrimaryOplogService {
                     "oplog",
                     "upload_payload",
                     BlobStorageNamespace::OplogPayload {
-                        account_id: owned_worker_id.account_id(),
+                        project_id: owned_worker_id.project_id(),
                         worker_id: owned_worker_id.worker_id(),
                     },
                     Path::new(&format!("{}/{}", hex::encode(&md5_hash), payload_id.0)),
@@ -139,7 +139,7 @@ impl PrimaryOplogService {
                         "oplog",
                         "download_payload",
                         BlobStorageNamespace::OplogPayload {
-                            account_id: owned_worker_id.account_id(),
+                            project_id: owned_worker_id.project_id(),
                             worker_id: owned_worker_id.worker_id(),
                         },
                         Path::new(&format!("{}/{}", hex::encode(md5_hash), payload_id.0)),
@@ -298,7 +298,7 @@ impl OplogService for PrimaryOplogService {
 
     async fn scan_for_component(
         &self,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         component_id: &ComponentId,
         cursor: ScanCursor,
         count: u64,
@@ -324,7 +324,7 @@ impl OplogService for PrimaryOplogService {
             keys.into_iter()
                 .map(|key| OwnedWorkerId {
                     worker_id: Self::get_worker_id_from_key(&key, component_id),
-                    account_id: account_id.clone(),
+                    project_id: project_id.clone(),
                 })
                 .collect(),
         ))
diff --git a/golem-worker-executor/src/services/oplog/tests.rs b/golem-worker-executor/src/services/oplog/tests.rs
index 66df919b..e7be4e96 100644
--- a/golem-worker-executor/src/services/oplog/tests.rs
+++ b/golem-worker-executor/src/services/oplog/tests.rs
@@ -25,7 +25,7 @@ use uuid::Uuid;
 use golem_common::config::RedisConfig;
 use golem_common::model::oplog::{LogLevel, SpanData, WorkerError};
 use golem_common::model::regions::OplogRegion;
-use golem_common::model::{ComponentId, ComponentType, WorkerStatusRecord};
+use golem_common::model::{AccountId, ComponentId, ComponentType, WorkerStatusRecord};
 use golem_common::redis::RedisPool;
 use golem_common::tracing::{init_tracing, TracingConfig};
 
@@ -84,34 +84,15 @@ fn rounded_span_data(invocation_context: Vec<SpanData>) -> Vec<SpanData> {
 
 pub fn rounded(entry: OplogEntry) -> OplogEntry {
     match entry {
-        OplogEntry::CreateV1 {
-            timestamp,
-            worker_id,
-            component_version,
-            args,
-            env,
-            account_id,
-            parent,
-            component_size,
-            initial_total_linear_memory_size,
-        } => OplogEntry::CreateV1 {
-            timestamp: rounded_ts(timestamp),
-            worker_id,
-            component_version,
-            args,
-            env,
-            account_id,
-            parent,
-            component_size,
-            initial_total_linear_memory_size,
-        },
         OplogEntry::Create {
             timestamp,
             worker_id,
             component_version,
             args,
             env,
-            account_id,
+            wasi_config_vars,
+            project_id,
+            created_by,
             parent,
             component_size,
             initial_total_linear_memory_size,
@@ -122,46 +103,26 @@ pub fn rounded(entry: OplogEntry) -> OplogEntry {
             component_version,
             args,
             env,
-            account_id,
+            wasi_config_vars,
+            project_id,
+            created_by,
             parent,
             component_size,
             initial_total_linear_memory_size,
             initial_active_plugins,
         },
-        OplogEntry::ImportedFunctionInvokedV1 {
-            timestamp,
-            function_name,
-            response,
-            wrapped_function_type,
-        } => OplogEntry::ImportedFunctionInvokedV1 {
-            timestamp: rounded_ts(timestamp),
-            function_name,
-            response,
-            wrapped_function_type,
-        },
         OplogEntry::ImportedFunctionInvoked {
             timestamp,
             function_name,
             request,
             response,
-            wrapped_function_type,
+            durable_function_type,
         } => OplogEntry::ImportedFunctionInvoked {
             timestamp: rounded_ts(timestamp),
             function_name,
             request,
             response,
-            wrapped_function_type,
-        },
-        OplogEntry::ExportedFunctionInvokedV1 {
-            timestamp,
-            function_name,
-            request,
-            idempotency_key,
-        } => OplogEntry::ExportedFunctionInvokedV1 {
-            timestamp: rounded_ts(timestamp),
-            function_name,
-            request,
-            idempotency_key,
+            durable_function_type,
         },
         OplogEntry::ExportedFunctionInvoked {
             timestamp,
@@ -239,15 +200,6 @@ pub fn rounded(entry: OplogEntry) -> OplogEntry {
             timestamp: rounded_ts(timestamp),
             description,
         },
-        OplogEntry::SuccessfulUpdateV1 {
-            timestamp,
-            target_version,
-            new_component_size,
-        } => OplogEntry::SuccessfulUpdateV1 {
-            timestamp: rounded_ts(timestamp),
-            target_version,
-            new_component_size,
-        },
         OplogEntry::SuccessfulUpdate {
             timestamp,
             target_version,
@@ -283,22 +235,23 @@ pub fn rounded(entry: OplogEntry) -> OplogEntry {
             timestamp: rounded_ts(timestamp),
             delta,
         },
-        OplogEntry::CreateResource { timestamp, id } => OplogEntry::CreateResource {
-            timestamp: rounded_ts(timestamp),
+        OplogEntry::CreateResource {
+            timestamp,
             id,
-        },
-        OplogEntry::DropResource { timestamp, id } => OplogEntry::DropResource {
+            resource_type_id,
+        } => OplogEntry::CreateResource {
             timestamp: rounded_ts(timestamp),
             id,
+            resource_type_id,
         },
-        OplogEntry::DescribeResource {
+        OplogEntry::DropResource {
             timestamp,
             id,
-            indexed_resource,
-        } => OplogEntry::DescribeResource {
+            resource_type_id,
+        } => OplogEntry::DropResource {
             timestamp: rounded_ts(timestamp),
             id,
-            indexed_resource,
+            resource_type_id,
         },
         OplogEntry::Log {
             timestamp,
@@ -389,17 +342,18 @@ async fn open_add_and_read_back(_tracing: &Tracing) {
     let account_id = AccountId {
         value: "user1".to_string(),
     };
+    let project_id = ProjectId::new_v4();
     let worker_id = WorkerId {
         component_id: ComponentId(Uuid::new_v4()),
         worker_name: "test".to_string(),
     };
-    let owned_worker_id = OwnedWorkerId::new(&account_id, &worker_id);
+    let owned_worker_id = OwnedWorkerId::new(&project_id, &worker_id);
     let last_oplog_index = oplog_service.get_last_index(&owned_worker_id).await;
     let oplog = oplog_service
         .open(
             &owned_worker_id,
             last_oplog_index,
-            WorkerMetadata::default(worker_id.clone(), account_id.clone()),
+            WorkerMetadata::default(worker_id.clone(), account_id.clone(), project_id.clone()),
             default_execution_status(ComponentType::Durable),
         )
         .await;
@@ -456,17 +410,18 @@ async fn open_add_and_read_back_ephemeral(_tracing: &Tracing) {
     let account_id = AccountId {
         value: "user1".to_string(),
     };
+    let project_id = ProjectId::new_v4();
     let worker_id = WorkerId {
         component_id: ComponentId(Uuid::new_v4()),
         worker_name: "test".to_string(),
     };
-    let owned_worker_id = OwnedWorkerId::new(&account_id, &worker_id);
+    let owned_worker_id = OwnedWorkerId::new(&project_id, &worker_id);
     let last_oplog_index = oplog_service.get_last_index(&owned_worker_id).await;
     let oplog = oplog_service
         .open(
             &owned_worker_id,
             last_oplog_index,
-            WorkerMetadata::default(worker_id.clone(), account_id.clone()),
+            WorkerMetadata::default(worker_id.clone(), account_id.clone(), project_id.clone()),
             default_execution_status(ComponentType::Ephemeral),
         )
         .await;
@@ -509,18 +464,19 @@ async fn entries_with_small_payload(_tracing: &Tracing) {
     let account_id = AccountId {
         value: "user1".to_string(),
     };
+    let project_id = ProjectId::new_v4();
     let worker_id = WorkerId {
         component_id: ComponentId(Uuid::new_v4()),
         worker_name: "test".to_string(),
     };
-    let owned_worker_id = OwnedWorkerId::new(&account_id, &worker_id);
+    let owned_worker_id = OwnedWorkerId::new(&project_id, &worker_id);
 
     let last_oplog_index = oplog_service.get_last_index(&owned_worker_id).await;
     let oplog = oplog_service
         .open(
             &owned_worker_id,
             last_oplog_index,
-            WorkerMetadata::default(worker_id.clone(), account_id.clone()),
+            WorkerMetadata::default(worker_id.clone(), account_id.clone(), project_id.clone()),
             default_execution_status(ComponentType::Durable),
         )
         .await;
@@ -625,17 +581,18 @@ async fn entries_with_large_payload(_tracing: &Tracing) {
     let account_id = AccountId {
         value: "user1".to_string(),
     };
+    let project_id = ProjectId::new_v4();
     let worker_id = WorkerId {
         component_id: ComponentId(Uuid::new_v4()),
         worker_name: "test".to_string(),
     };
-    let owned_worker_id = OwnedWorkerId::new(&account_id, &worker_id);
+    let owned_worker_id = OwnedWorkerId::new(&project_id, &worker_id);
     let last_oplog_index = oplog_service.get_last_index(&owned_worker_id).await;
     let oplog = oplog_service
         .open(
             &owned_worker_id,
             last_oplog_index,
-            WorkerMetadata::default(worker_id.clone(), account_id.clone()),
+            WorkerMetadata::default(worker_id.clone(), account_id.clone(), project_id.clone()),
             default_execution_status(ComponentType::Durable),
         )
         .await;
@@ -820,18 +777,19 @@ async fn multilayer_transfers_entries_after_limit_reached(
     let account_id = AccountId {
         value: "user1".to_string(),
     };
+    let project_id = ProjectId::new_v4();
     let worker_id = WorkerId {
         component_id: ComponentId(Uuid::new_v4()),
         worker_name: "test".to_string(),
     };
-    let owned_worker_id = OwnedWorkerId::new(&account_id, &worker_id);
+    let owned_worker_id = OwnedWorkerId::new(&project_id, &worker_id);
 
     let last_oplog_index = oplog_service.get_last_index(&owned_worker_id).await;
     let oplog = oplog_service
         .open(
             &owned_worker_id,
             last_oplog_index,
-            WorkerMetadata::default(worker_id.clone(), account_id.clone()),
+            WorkerMetadata::default(worker_id.clone(), account_id.clone(), project_id.clone()),
             default_execution_status(ComponentType::Durable),
         )
         .await;
@@ -859,7 +817,7 @@ async fn multilayer_transfers_entries_after_limit_reached(
             .open(
                 &owned_worker_id,
                 primary_oplog_service.get_last_index(&owned_worker_id).await,
-                WorkerMetadata::default(worker_id.clone(), account_id.clone()),
+                WorkerMetadata::default(worker_id.clone(), account_id.clone(), project_id.clone()),
                 default_execution_status(ComponentType::Durable),
             )
             .await
@@ -885,7 +843,7 @@ async fn multilayer_transfers_entries_after_limit_reached(
         .open(
             &owned_worker_id,
             primary_oplog_service.get_last_index(&owned_worker_id).await,
-            WorkerMetadata::default(worker_id.clone(), account_id.clone()),
+            WorkerMetadata::default(worker_id.clone(), account_id.clone(), project_id.clone()),
             default_execution_status(ComponentType::Durable),
         )
         .await
@@ -950,18 +908,19 @@ async fn read_from_archive_impl(use_blob: bool) {
     let account_id = AccountId {
         value: "user1".to_string(),
     };
+    let project_id = ProjectId::new_v4();
     let worker_id = WorkerId {
         component_id: ComponentId(Uuid::new_v4()),
         worker_name: "test".to_string(),
     };
-    let owned_worker_id = OwnedWorkerId::new(&account_id, &worker_id);
+    let owned_worker_id = OwnedWorkerId::new(&project_id, &worker_id);
 
     let last_oplog_index = oplog_service.get_last_index(&owned_worker_id).await;
     let oplog = oplog_service
         .open(
             &owned_worker_id,
             last_oplog_index,
-            WorkerMetadata::default(worker_id.clone(), account_id.clone()),
+            WorkerMetadata::default(worker_id.clone(), account_id.clone(), project_id.clone()),
             default_execution_status(ComponentType::Durable),
         )
         .await;
@@ -988,7 +947,7 @@ async fn read_from_archive_impl(use_blob: bool) {
         .open(
             &owned_worker_id,
             primary_oplog_service.get_last_index(&owned_worker_id).await,
-            WorkerMetadata::default(worker_id.clone(), account_id.clone()),
+            WorkerMetadata::default(worker_id.clone(), account_id.clone(), project_id.clone()),
             default_execution_status(ComponentType::Durable),
         )
         .await
@@ -1050,14 +1009,15 @@ async fn read_initial_from_archive_impl(use_blob: bool) {
     let account_id = AccountId {
         value: "user1".to_string(),
     };
+    let project_id = ProjectId::new_v4();
     let worker_id = WorkerId {
         component_id: ComponentId(Uuid::new_v4()),
         worker_name: "test".to_string(),
     };
-    let owned_worker_id = OwnedWorkerId::new(&account_id, &worker_id);
+    let owned_worker_id = OwnedWorkerId::new(&project_id, &worker_id);
 
     let timestamp = Timestamp::now_utc();
-    let create_entry = rounded(OplogEntry::CreateV1 {
+    let create_entry = rounded(OplogEntry::Create {
         timestamp,
         worker_id: WorkerId {
             component_id: ComponentId(Uuid::new_v4()),
@@ -1066,19 +1026,22 @@ async fn read_initial_from_archive_impl(use_blob: bool) {
         component_version: 1,
         args: vec![],
         env: vec![],
-        account_id: AccountId {
+        wasi_config_vars: BTreeMap::new(),
+        project_id: project_id.clone(),
+        created_by: AccountId {
             value: "user1".to_string(),
         },
         parent: None,
         component_size: 0,
         initial_total_linear_memory_size: 0,
+        initial_active_plugins: HashSet::new(),
     });
 
     let oplog = oplog_service
         .create(
             &owned_worker_id,
             create_entry.clone(),
-            WorkerMetadata::default(worker_id.clone(), account_id.clone()),
+            WorkerMetadata::default(worker_id.clone(), account_id.clone(), project_id.clone()),
             default_execution_status(ComponentType::Durable),
         )
         .await;
@@ -1191,11 +1154,12 @@ async fn write_after_archive_impl(use_blob: bool, reopen: Reopen) {
     let account_id = AccountId {
         value: "user1".to_string(),
     };
+    let project_id = ProjectId::new_v4();
     let worker_id = WorkerId {
         component_id: ComponentId(Uuid::new_v4()),
         worker_name: "test".to_string(),
     };
-    let owned_worker_id = OwnedWorkerId::new(&account_id, &worker_id);
+    let owned_worker_id = OwnedWorkerId::new(&project_id, &worker_id);
 
     info!("FIRST OPEN");
     let last_oplog_index = oplog_service.get_last_index(&owned_worker_id).await;
@@ -1203,7 +1167,7 @@ async fn write_after_archive_impl(use_blob: bool, reopen: Reopen) {
         .open(
             &owned_worker_id,
             last_oplog_index,
-            WorkerMetadata::default(worker_id.clone(), account_id.clone()),
+            WorkerMetadata::default(worker_id.clone(), account_id.clone(), project_id.clone()),
             default_execution_status(ComponentType::Durable),
         )
         .await;
@@ -1231,7 +1195,7 @@ async fn write_after_archive_impl(use_blob: bool, reopen: Reopen) {
         .open(
             &owned_worker_id,
             primary_oplog_service.get_last_index(&owned_worker_id).await,
-            WorkerMetadata::default(worker_id.clone(), account_id.clone()),
+            WorkerMetadata::default(worker_id.clone(), account_id.clone(), project_id.clone()),
             default_execution_status(ComponentType::Durable),
         )
         .await
@@ -1252,7 +1216,7 @@ async fn write_after_archive_impl(use_blob: bool, reopen: Reopen) {
             .open(
                 &owned_worker_id,
                 last_oplog_index,
-                WorkerMetadata::default(worker_id.clone(), account_id.clone()),
+                WorkerMetadata::default(worker_id.clone(), account_id.clone(), project_id.clone()),
                 default_execution_status(ComponentType::Durable),
             )
             .await
@@ -1272,7 +1236,7 @@ async fn write_after_archive_impl(use_blob: bool, reopen: Reopen) {
             .open(
                 &owned_worker_id,
                 last_oplog_index,
-                WorkerMetadata::default(worker_id.clone(), account_id.clone()),
+                WorkerMetadata::default(worker_id.clone(), account_id.clone(), project_id.clone()),
                 default_execution_status(ComponentType::Durable),
             )
             .await
@@ -1302,7 +1266,7 @@ async fn write_after_archive_impl(use_blob: bool, reopen: Reopen) {
         .open(
             &owned_worker_id,
             primary_oplog_service.get_last_index(&owned_worker_id).await,
-            WorkerMetadata::default(worker_id.clone(), account_id.clone()),
+            WorkerMetadata::default(worker_id.clone(), account_id.clone(), project_id.clone()),
             default_execution_status(ComponentType::Durable),
         )
         .await
@@ -1323,7 +1287,7 @@ async fn write_after_archive_impl(use_blob: bool, reopen: Reopen) {
             .open(
                 &owned_worker_id,
                 last_oplog_index,
-                WorkerMetadata::default(worker_id.clone(), account_id.clone()),
+                WorkerMetadata::default(worker_id.clone(), account_id.clone(), project_id.clone()),
                 default_execution_status(ComponentType::Durable),
             )
             .await
@@ -1343,7 +1307,7 @@ async fn write_after_archive_impl(use_blob: bool, reopen: Reopen) {
             .open(
                 &owned_worker_id,
                 last_oplog_index,
-                WorkerMetadata::default(worker_id.clone(), account_id.clone()),
+                WorkerMetadata::default(worker_id.clone(), account_id.clone(), project_id.clone()),
                 default_execution_status(ComponentType::Durable),
             )
             .await
@@ -1449,18 +1413,19 @@ async fn empty_layer_gets_deleted_impl(use_blob: bool) {
     let account_id = AccountId {
         value: "user1".to_string(),
     };
+    let project_id = ProjectId::new_v4();
     let worker_id = WorkerId {
         component_id: ComponentId(Uuid::new_v4()),
         worker_name: "test".to_string(),
     };
-    let owned_worker_id = OwnedWorkerId::new(&account_id, &worker_id);
+    let owned_worker_id = OwnedWorkerId::new(&project_id, &worker_id);
 
     let last_oplog_index = oplog_service.get_last_index(&owned_worker_id).await;
     let oplog = oplog_service
         .open(
             &owned_worker_id,
             last_oplog_index,
-            WorkerMetadata::default(worker_id.clone(), account_id.clone()),
+            WorkerMetadata::default(worker_id.clone(), account_id.clone(), project_id.clone()),
             default_execution_status(ComponentType::Durable),
         )
         .await;
@@ -1497,7 +1462,7 @@ async fn empty_layer_gets_deleted_impl(use_blob: bool) {
         .open(
             &owned_worker_id,
             primary_oplog_service.get_last_index(&owned_worker_id).await,
-            WorkerMetadata::default(worker_id.clone(), account_id.clone()),
+            WorkerMetadata::default(worker_id.clone(), account_id.clone(), project_id.clone()),
             default_execution_status(ComponentType::Durable),
         )
         .await
@@ -1560,11 +1525,12 @@ async fn scheduled_archive_impl(use_blob: bool) {
     let account_id = AccountId {
         value: "user1".to_string(),
     };
+    let project_id = ProjectId::new_v4();
     let worker_id = WorkerId {
         component_id: ComponentId(Uuid::new_v4()),
         worker_name: "test".to_string(),
     };
-    let owned_worker_id = OwnedWorkerId::new(&account_id, &worker_id);
+    let owned_worker_id = OwnedWorkerId::new(&project_id, &worker_id);
 
     let timestamp = Timestamp::now_utc();
     let entries: Vec<OplogEntry> = (0..100)
@@ -1583,7 +1549,7 @@ async fn scheduled_archive_impl(use_blob: bool) {
             .open(
                 &owned_worker_id,
                 last_oplog_index,
-                WorkerMetadata::default(worker_id.clone(), account_id.clone()),
+                WorkerMetadata::default(worker_id.clone(), account_id.clone(), project_id.clone()),
                 default_execution_status(ComponentType::Durable),
             )
             .await;
@@ -1605,7 +1571,7 @@ async fn scheduled_archive_impl(use_blob: bool) {
         .open(
             &owned_worker_id,
             primary_oplog_service.get_last_index(&owned_worker_id).await,
-            WorkerMetadata::default(worker_id.clone(), account_id.clone()),
+            WorkerMetadata::default(worker_id.clone(), account_id.clone(), project_id.clone()),
             default_execution_status(ComponentType::Durable),
         )
         .await
@@ -1634,7 +1600,7 @@ async fn scheduled_archive_impl(use_blob: bool) {
             .open(
                 &owned_worker_id,
                 last_oplog_index,
-                WorkerMetadata::default(worker_id.clone(), account_id.clone()),
+                WorkerMetadata::default(worker_id.clone(), account_id.clone(), project_id.clone()),
                 default_execution_status(ComponentType::Durable),
             )
             .await;
@@ -1649,7 +1615,7 @@ async fn scheduled_archive_impl(use_blob: bool) {
         .open(
             &owned_worker_id,
             primary_oplog_service.get_last_index(&owned_worker_id).await,
-            WorkerMetadata::default(worker_id.clone(), account_id.clone()),
+            WorkerMetadata::default(worker_id.clone(), account_id.clone(), project_id.clone()),
             default_execution_status(ComponentType::Durable),
         )
         .await
@@ -1694,7 +1660,8 @@ async fn multilayer_scan_for_component(_tracing: &Tracing) {
     let account_id = AccountId {
         value: "user1".to_string(),
     };
-    let component_id = ComponentId(Uuid::new_v4());
+    let project_id = ProjectId::new_v4();
+    let component_id = ComponentId::new_v4();
 
     // Adding some workers
     let mut primary_workers = Vec::new();
@@ -1710,6 +1677,8 @@ async fn multilayer_scan_for_component(_tracing: &Tracing) {
             1,
             Vec::new(),
             Vec::new(),
+            BTreeMap::new(),
+            project_id.clone(),
             account_id.clone(),
             None,
             100,
@@ -1717,12 +1686,12 @@ async fn multilayer_scan_for_component(_tracing: &Tracing) {
             HashSet::new(),
         );
 
-        let owned_worker_id = OwnedWorkerId::new(&account_id, &worker_id);
+        let owned_worker_id = OwnedWorkerId::new(&project_id, &worker_id);
         let oplog = oplog_service
             .create(
                 &owned_worker_id,
                 create_entry,
-                WorkerMetadata::default(worker_id.clone(), account_id.clone()),
+                WorkerMetadata::default(worker_id.clone(), account_id.clone(), project_id.clone()),
                 default_execution_status(ComponentType::Durable),
             )
             .await;
@@ -1793,7 +1762,7 @@ async fn multilayer_scan_for_component(_tracing: &Tracing) {
     let page_size = 10;
     loop {
         let (new_cursor, ids) = oplog_service
-            .scan_for_component(&account_id, &component_id, cursor, page_size)
+            .scan_for_component(&project_id, &component_id, cursor, page_size)
             .await
             .unwrap();
         debug!("Got {} elements, new cursor is {}", ids.len(), new_cursor);
diff --git a/golem-worker-executor/src/services/rdbms/mysql/sqlx_rdbms.rs b/golem-worker-executor/src/services/rdbms/mysql/sqlx_rdbms.rs
index 1a6a3a37..9d61c71c 100644
--- a/golem-worker-executor/src/services/rdbms/mysql/sqlx_rdbms.rs
+++ b/golem-worker-executor/src/services/rdbms/mysql/sqlx_rdbms.rs
@@ -22,7 +22,7 @@ use crate::services::rdbms::{DbResult, DbResultStream, DbRow, Error, Rdbms, Rdbm
 use async_trait::async_trait;
 use bigdecimal::BigDecimal;
 use bit_vec::BitVec;
-use futures_util::stream::BoxStream;
+use futures::stream::BoxStream;
 use sqlx::{Column, ConnectOptions, Pool, Row, TypeInfo};
 use std::sync::Arc;
 
diff --git a/golem-worker-executor/src/services/rdbms/postgres/sqlx_rdbms.rs b/golem-worker-executor/src/services/rdbms/postgres/sqlx_rdbms.rs
index 471f27fe..e06ef956 100644
--- a/golem-worker-executor/src/services/rdbms/postgres/sqlx_rdbms.rs
+++ b/golem-worker-executor/src/services/rdbms/postgres/sqlx_rdbms.rs
@@ -25,7 +25,7 @@ use crate::services::rdbms::{DbResult, DbResultStream, DbRow, Error, Rdbms, Rdbm
 use async_trait::async_trait;
 use bigdecimal::BigDecimal;
 use bit_vec::BitVec;
-use futures_util::stream::BoxStream;
+use futures::stream::BoxStream;
 use mac_address::MacAddress;
 use serde_json::json;
 use sqlx::postgres::types::{Oid, PgInterval, PgMoney, PgRange, PgTimeTz};
diff --git a/golem-worker-executor/src/services/rdbms/sqlx_common.rs b/golem-worker-executor/src/services/rdbms/sqlx_common.rs
index e62b7c49..f94e69f2 100644
--- a/golem-worker-executor/src/services/rdbms/sqlx_common.rs
+++ b/golem-worker-executor/src/services/rdbms/sqlx_common.rs
@@ -18,12 +18,12 @@ use crate::services::rdbms::{
     DbResult, DbResultStream, DbRow, DbTransaction, Error, Rdbms, RdbmsPoolKey, RdbmsStatus,
     RdbmsType,
 };
-use async_dropper_simple::{AsyncDrop, AsyncDropper};
+use async_dropper_simple::AsyncDrop;
 use async_trait::async_trait;
 use dashmap::DashMap;
-use futures_util::future::BoxFuture;
-use futures_util::stream::BoxStream;
-use futures_util::StreamExt;
+use futures::future::BoxFuture;
+use futures::stream::BoxStream;
+use futures::StreamExt;
 use golem_common::cache::{BackgroundEvictionMode, Cache, FullCacheEvictionMode, SimpleCache};
 use golem_common::model::WorkerId;
 use itertools::Either;
@@ -167,17 +167,9 @@ where
     }
 
     fn remove(&self, key: &RdbmsPoolKey, worker_id: &WorkerId) -> bool {
-        if let dashmap::mapref::entry::Entry::Occupied(mut occupied) =
-            self.pool_workers_cache.entry(key.clone())
-        {
-            let removed = occupied.get_mut().remove(worker_id);
-            // cleanup empty entries
-            if removed && occupied.get().is_empty() {
-                occupied.remove();
-            }
-            removed
-        } else {
-            false
+        match self.pool_workers_cache.get_mut(key) {
+            Some(mut workers) => (*workers).remove(worker_id),
+            None => false,
         }
     }
 
@@ -329,9 +321,9 @@ where
                 .await
                 .map_err(Error::query_execution_failure)?;
 
-            let tx = SqlxDbTransaction::new(key.clone(), connection, self.config.query);
-            let db_transaction: Arc<dyn DbTransaction<T> + Send + Sync> =
-                Arc::new(AsyncDropper::new(tx));
+            let db_transaction: Arc<dyn DbTransaction<T> + Send + Sync> = Arc::new(
+                SqlxDbTransaction::new(key.clone(), connection, self.config.query),
+            );
 
             Ok(db_transaction)
         };
@@ -427,7 +419,7 @@ impl<DB: Database> Debug for SqlxDbTransactionConnection<DB> {
 }
 
 #[derive(Clone)]
-pub(crate) struct SqlxDbTransaction<T: RdbmsType, DB: Database> {
+pub struct SqlxDbTransaction<T: RdbmsType, DB: Database> {
     rdbms_type: T,
     pool_key: RdbmsPoolKey,
     tx_connection: SqlxDbTransactionConnection<DB>,
@@ -487,7 +479,7 @@ where
         'p: 'e,
         E: 'q + Execute<'q, Self::Database>,
     {
-        use futures_util::TryStreamExt;
+        use futures::TryStreamExt;
         let tx = self.clone();
         Box::pin(sqlx_core::try_stream! {
             let mut tx_conn = tx.0.lock().await;
@@ -739,57 +731,6 @@ where
     }
 }
 
-#[async_trait]
-impl<T, DB> DbTransaction<T> for AsyncDropper<SqlxDbTransaction<T, DB>>
-where
-    T: RdbmsType + Sync + QueryExecutor<T, DB>,
-    DB: Database,
-    for<'c> &'c mut <DB as Database>::Connection: sqlx::Executor<'c, Database = DB>,
-{
-    async fn execute(&self, statement: &str, params: Vec<T::DbValue>) -> Result<u64, Error>
-    where
-        <T as RdbmsType>::DbValue: 'async_trait,
-    {
-        <SqlxDbTransaction<T, DB> as DbTransaction<T>>::execute(self.inner(), statement, params)
-            .await
-    }
-
-    async fn query(&self, statement: &str, params: Vec<T::DbValue>) -> Result<DbResult<T>, Error>
-    where
-        <T as RdbmsType>::DbValue: 'async_trait,
-    {
-        <SqlxDbTransaction<T, DB> as DbTransaction<T>>::query(self.inner(), statement, params).await
-    }
-
-    async fn query_stream(
-        &self,
-        statement: &str,
-        params: Vec<T::DbValue>,
-    ) -> Result<Arc<dyn DbResultStream<T> + Send + Sync>, Error>
-    where
-        <T as RdbmsType>::DbValue: 'async_trait,
-    {
-        <SqlxDbTransaction<T, DB> as DbTransaction<T>>::query_stream(
-            self.inner(),
-            statement,
-            params,
-        )
-        .await
-    }
-
-    async fn commit(&self) -> Result<(), Error> {
-        <SqlxDbTransaction<T, DB> as DbTransaction<T>>::commit(self.inner()).await
-    }
-
-    async fn rollback(&self) -> Result<(), Error> {
-        <SqlxDbTransaction<T, DB> as DbTransaction<T>>::rollback(self.inner()).await
-    }
-
-    async fn rollback_if_open(&self) -> Result<(), Error> {
-        <SqlxDbTransaction<T, DB> as DbTransaction<T>>::rollback_if_open(self.inner()).await
-    }
-}
-
 #[derive(Clone)]
 #[allow(clippy::type_complexity)]
 pub struct SqlxDbResultStream<'q, T: RdbmsType, DB: Database> {
diff --git a/golem-worker-executor/src/services/rpc.rs b/golem-worker-executor/src/services/rpc.rs
index 54388302..a412c5ca 100644
--- a/golem-worker-executor/src/services/rpc.rs
+++ b/golem-worker-executor/src/services/rpc.rs
@@ -12,7 +12,7 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use std::collections::HashMap;
+use std::collections::{BTreeMap, HashMap};
 use std::fmt::{Display, Formatter};
 use std::sync::Arc;
 
@@ -20,34 +20,45 @@ use super::file_loader::FileLoader;
 use crate::services::events::Events;
 use crate::services::oplog::plugin::OplogProcessorPlugin;
 use crate::services::plugins::Plugins;
+use crate::services::projects::ProjectService;
 use crate::services::resource_limits::ResourceLimits;
 use crate::services::shard::ShardService;
 use crate::services::worker_proxy::{WorkerProxy, WorkerProxyError};
 use crate::services::{
-    active_workers, blob_store, component, golem_config, key_value, oplog, promise, rdbms,
-    scheduler, shard, shard_manager, worker, worker_activator, worker_enumeration, worker_fork,
-    HasActiveWorkers, HasBlobStoreService, HasComponentService, HasConfig, HasEvents, HasExtraDeps,
-    HasFileLoader, HasKeyValueService, HasOplogProcessorPlugin, HasOplogService, HasPlugins,
-    HasPromiseService, HasRdbmsService, HasResourceLimits, HasRpc,
-    HasRunningWorkerEnumerationService, HasSchedulerService, HasShardManagerService,
-    HasShardService, HasWasmtimeEngine, HasWorkerActivator, HasWorkerEnumerationService,
-    HasWorkerForkService, HasWorkerProxy, HasWorkerService,
+    active_workers, agent_types, blob_store, component, golem_config, key_value, oplog, promise,
+    rdbms, scheduler, shard_manager, worker, worker_activator, worker_enumeration, worker_fork,
+    HasActiveWorkers, HasAgentTypesService, HasBlobStoreService, HasComponentService, HasConfig,
+    HasEvents, HasExtraDeps, HasFileLoader, HasKeyValueService, HasOplogProcessorPlugin,
+    HasOplogService, HasPlugins, HasProjectService, HasPromiseService, HasRdbmsService,
+    HasResourceLimits, HasRpc, HasRunningWorkerEnumerationService, HasSchedulerService,
+    HasShardManagerService, HasShardService, HasWasmtimeEngine, HasWorkerActivator,
+    HasWorkerEnumerationService, HasWorkerForkService, HasWorkerProxy, HasWorkerService,
 };
 use crate::worker::Worker;
 use crate::workerctx::WorkerCtx;
 use async_trait::async_trait;
 use bincode::{Decode, Encode};
 use golem_common::model::invocation_context::InvocationContextStack;
-use golem_common::model::{IdempotencyKey, OwnedWorkerId, TargetWorkerId, WorkerId};
+use golem_common::model::{AccountId, IdempotencyKey, OwnedWorkerId, WorkerId};
 use golem_service_base::error::worker_executor::WorkerExecutorError;
 use golem_wasm_rpc::{ValueAndType, WitValue};
 use golem_wasm_rpc_derive::IntoValue;
+use rib::ParsedFunctionName;
 use tokio::runtime::Handle;
 use tracing::debug;
 
 #[async_trait]
 pub trait Rpc: Send + Sync {
-    async fn create_demand(&self, owned_worker_id: &OwnedWorkerId) -> Box<dyn RpcDemand>;
+    async fn create_demand(
+        &self,
+        owned_worker_id: &OwnedWorkerId,
+        self_created_by: &AccountId,
+        self_worker_id: &WorkerId,
+        self_args: &[String],
+        self_env: &[(String, String)],
+        self_config: BTreeMap<String, String>,
+        self_stack: InvocationContextStack,
+    ) -> Result<Box<dyn RpcDemand>, RpcError>;
 
     async fn invoke_and_await(
         &self,
@@ -55,9 +66,11 @@ pub trait Rpc: Send + Sync {
         idempotency_key: Option<IdempotencyKey>,
         function_name: String,
         function_params: Vec<WitValue>,
+        self_created_by: &AccountId,
         self_worker_id: &WorkerId,
         self_args: &[String],
         self_env: &[(String, String)],
+        self_config: BTreeMap<String, String>,
         self_stack: InvocationContextStack,
     ) -> Result<Option<ValueAndType>, RpcError>;
 
@@ -67,16 +80,13 @@ pub trait Rpc: Send + Sync {
         idempotency_key: Option<IdempotencyKey>,
         function_name: String,
         function_params: Vec<WitValue>,
+        self_created_by: &AccountId,
         self_worker_id: &WorkerId,
         self_args: &[String],
         self_env: &[(String, String)],
+        self_config: BTreeMap<String, String>,
         self_stack: InvocationContextStack,
     ) -> Result<(), RpcError>;
-
-    async fn generate_unique_local_worker_id(
-        &self,
-        target_worker_id: TargetWorkerId,
-    ) -> Result<WorkerId, WorkerExecutorError>;
 }
 
 #[derive(Debug, Clone, PartialEq, Eq, Encode, Decode, IntoValue)]
@@ -169,14 +179,14 @@ pub trait RpcDemand: Send + Sync {}
 
 pub struct RemoteInvocationRpc {
     worker_proxy: Arc<dyn WorkerProxy>,
-    shard_service: Arc<dyn ShardService>,
+    _shard_service: Arc<dyn ShardService>,
 }
 
 impl RemoteInvocationRpc {
     pub fn new(worker_proxy: Arc<dyn WorkerProxy>, shard_service: Arc<dyn ShardService>) -> Self {
         Self {
             worker_proxy,
-            shard_service,
+            _shard_service: shard_service,
         }
     }
 }
@@ -203,9 +213,30 @@ impl Drop for LoggingDemand {
 /// Rpc implementation simply calling the public Golem Worker API for invocation
 #[async_trait]
 impl Rpc for RemoteInvocationRpc {
-    async fn create_demand(&self, owned_worker_id: &OwnedWorkerId) -> Box<dyn RpcDemand> {
+    async fn create_demand(
+        &self,
+        owned_worker_id: &OwnedWorkerId,
+        _self_created_by: &AccountId,
+        _self_worker_id: &WorkerId,
+        self_args: &[String],
+        self_env: &[(String, String)],
+        self_config: BTreeMap<String, String>,
+        _self_stack: InvocationContextStack, // TODO: make invocation context propagating through the worker start API
+    ) -> Result<Box<dyn RpcDemand>, RpcError> {
+        debug!("Ensuring remote target worker exists");
+
         let demand = LoggingDemand::new(owned_worker_id.worker_id());
-        Box::new(demand)
+
+        self.worker_proxy
+            .start(
+                owned_worker_id,
+                self_args.to_vec(),
+                HashMap::from_iter(self_env.to_vec()),
+                self_config,
+            )
+            .await?;
+
+        Ok(Box::new(demand))
     }
 
     async fn invoke_and_await(
@@ -214,9 +245,11 @@ impl Rpc for RemoteInvocationRpc {
         idempotency_key: Option<IdempotencyKey>,
         function_name: String,
         function_params: Vec<WitValue>,
+        _self_created_by: &AccountId,
         self_worker_id: &WorkerId,
         self_args: &[String],
         self_env: &[(String, String)],
+        self_config: BTreeMap<String, String>,
         self_stack: InvocationContextStack,
     ) -> Result<Option<ValueAndType>, RpcError> {
         Ok(self
@@ -229,6 +262,7 @@ impl Rpc for RemoteInvocationRpc {
                 self_worker_id.clone(),
                 self_args.to_vec(),
                 HashMap::from_iter(self_env.to_vec()),
+                self_config,
                 self_stack,
             )
             .await?)
@@ -240,9 +274,11 @@ impl Rpc for RemoteInvocationRpc {
         idempotency_key: Option<IdempotencyKey>,
         function_name: String,
         function_params: Vec<WitValue>,
+        _self_created_by: &AccountId,
         self_worker_id: &WorkerId,
         self_args: &[String],
         self_env: &[(String, String)],
+        self_config: BTreeMap<String, String>,
         self_stack: InvocationContextStack,
     ) -> Result<(), RpcError> {
         Ok(self
@@ -255,21 +291,11 @@ impl Rpc for RemoteInvocationRpc {
                 self_worker_id.clone(),
                 self_args.to_vec(),
                 HashMap::from_iter(self_env.to_vec()),
+                self_config,
                 self_stack,
             )
             .await?)
     }
-
-    async fn generate_unique_local_worker_id(
-        &self,
-        target_worker_id: TargetWorkerId,
-    ) -> Result<WorkerId, WorkerExecutorError> {
-        let current_assignment = self.shard_service.current_assignment()?;
-        Ok(target_worker_id.into_worker_id(
-            &current_assignment.shard_ids,
-            current_assignment.number_of_shards,
-        ))
-    }
 }
 
 pub struct DirectWorkerInvocationRpc<Ctx: WorkerCtx> {
@@ -287,7 +313,7 @@ pub struct DirectWorkerInvocationRpc<Ctx: WorkerCtx> {
         Arc<dyn worker_enumeration::RunningWorkerEnumerationService>,
     promise_service: Arc<dyn promise::PromiseService>,
     golem_config: Arc<golem_config::GolemConfig>,
-    shard_service: Arc<dyn shard::ShardService>,
+    shard_service: Arc<dyn ShardService>,
     key_value_service: Arc<dyn key_value::KeyValueService>,
     blob_store_service: Arc<dyn blob_store::BlobStoreService>,
     rdbms_service: Arc<dyn rdbms::RdbmsService>,
@@ -299,6 +325,8 @@ pub struct DirectWorkerInvocationRpc<Ctx: WorkerCtx> {
     plugins: Arc<dyn Plugins>,
     oplog_processor_plugin: Arc<dyn OplogProcessorPlugin>,
     resource_limits: Arc<dyn ResourceLimits>,
+    project_service: Arc<dyn ProjectService>,
+    agent_types_service: Arc<dyn agent_types::AgentTypesService>,
     extra_deps: Ctx::ExtraDeps,
 }
 
@@ -330,6 +358,8 @@ impl<Ctx: WorkerCtx> Clone for DirectWorkerInvocationRpc<Ctx> {
             plugins: self.plugins.clone(),
             oplog_processor_plugin: self.oplog_processor_plugin.clone(),
             resource_limits: self.resource_limits.clone(),
+            project_service: self.project_service.clone(),
+            agent_types_service: self.agent_types_service.clone(),
             extra_deps: self.extra_deps.clone(),
         }
     }
@@ -347,6 +377,12 @@ impl<Ctx: WorkerCtx> HasActiveWorkers<Ctx> for DirectWorkerInvocationRpc<Ctx> {
     }
 }
 
+impl<Ctx: WorkerCtx> HasAgentTypesService for DirectWorkerInvocationRpc<Ctx> {
+    fn agent_types(&self) -> Arc<dyn agent_types::AgentTypesService> {
+        self.agent_types_service.clone()
+    }
+}
+
 impl<Ctx: WorkerCtx> HasComponentService for DirectWorkerInvocationRpc<Ctx> {
     fn component_service(&self) -> Arc<dyn component::ComponentService> {
         self.component_service.clone()
@@ -442,7 +478,7 @@ impl<Ctx: WorkerCtx> HasExtraDeps<Ctx> for DirectWorkerInvocationRpc<Ctx> {
 }
 
 impl<Ctx: WorkerCtx> HasShardService for DirectWorkerInvocationRpc<Ctx> {
-    fn shard_service(&self) -> Arc<dyn shard::ShardService> {
+    fn shard_service(&self) -> Arc<dyn ShardService> {
         self.shard_service.clone()
     }
 }
@@ -495,6 +531,12 @@ impl<Ctx: WorkerCtx> HasResourceLimits for DirectWorkerInvocationRpc<Ctx> {
     }
 }
 
+impl<Ctx: WorkerCtx> HasProjectService for DirectWorkerInvocationRpc<Ctx> {
+    fn project_service(&self) -> Arc<dyn ProjectService> {
+        self.project_service.clone()
+    }
+}
+
 #[allow(clippy::too_many_arguments)]
 impl<Ctx: WorkerCtx> DirectWorkerInvocationRpc<Ctx> {
     #[allow(clippy::too_many_arguments)]
@@ -513,7 +555,7 @@ impl<Ctx: WorkerCtx> DirectWorkerInvocationRpc<Ctx> {
         >,
         promise_service: Arc<dyn promise::PromiseService>,
         golem_config: Arc<golem_config::GolemConfig>,
-        shard_service: Arc<dyn shard::ShardService>,
+        shard_service: Arc<dyn ShardService>,
         shard_manager_service: Arc<dyn shard_manager::ShardManagerService>,
         key_value_service: Arc<dyn key_value::KeyValueService>,
         blob_store_service: Arc<dyn blob_store::BlobStoreService>,
@@ -526,6 +568,8 @@ impl<Ctx: WorkerCtx> DirectWorkerInvocationRpc<Ctx> {
         plugins: Arc<dyn Plugins>,
         oplog_processor_plugin: Arc<dyn OplogProcessorPlugin>,
         resource_limits: Arc<dyn ResourceLimits>,
+        project_service: Arc<dyn ProjectService>,
+        agent_types_service: Arc<dyn agent_types::AgentTypesService>,
         extra_deps: Ctx::ExtraDeps,
     ) -> Self {
         Self {
@@ -554,16 +598,134 @@ impl<Ctx: WorkerCtx> DirectWorkerInvocationRpc<Ctx> {
             plugins,
             oplog_processor_plugin,
             resource_limits,
+            project_service,
+            agent_types_service,
             extra_deps,
         }
     }
+
+    /// As we know the target component's metadata, and it includes the root package name, we can
+    /// accept function names which are not fully qualified by falling back to use this root package
+    /// when the package part is missing.
+    async fn enrich_function_name(
+        &self,
+        target_worker_id: &OwnedWorkerId,
+        function_name: String,
+    ) -> String {
+        let parsed_function_name: Option<ParsedFunctionName> =
+            ParsedFunctionName::parse(&function_name).ok();
+        if parsed_function_name.is_some() {
+            // already valid function name, doing nothing
+            function_name
+        } else if let Ok(target_component) = self
+            .component_service
+            .get_metadata(
+                &target_worker_id.project_id,
+                &target_worker_id.worker_id.component_id,
+                None,
+            )
+            .await
+        {
+            enrich_function_name_by_target_information(
+                function_name,
+                target_component.metadata.root_package_name().clone(),
+                target_component.metadata.root_package_version().clone(),
+            )
+        } else {
+            // If we cannot get the target metadata, we just go with the original function name
+            // and let it fail on that.
+            function_name
+        }
+    }
+}
+
+fn enrich_function_name_by_target_information(
+    function_name: String,
+    root_package_name: Option<String>,
+    root_package_version: Option<String>,
+) -> String {
+    if let Some(root_package_name) = root_package_name {
+        if let Some(root_package_version) = root_package_version {
+            // The target root package is versioned, and the version has to be put _after_ the interface
+            // name which we assume to be the first section (before a dot) of the provided string:
+
+            if let Some((interface_name, rest)) = function_name.split_once('.') {
+                let enriched_function_name =
+                    format!("{root_package_name}/{interface_name}@{root_package_version}.{rest}");
+                if ParsedFunctionName::parse(&enriched_function_name).is_ok() {
+                    enriched_function_name
+                } else {
+                    // If the enriched function name is still not valid, we just return the original function name
+                    function_name
+                }
+            } else {
+                // Unexpected format, we just return the original function name
+                function_name
+            }
+        } else {
+            // The target root package is not versioned, so we can just simply prefix the root package name
+            // to the provided function name and see if it is valid:
+            let enriched_function_name = format!("{root_package_name}/{function_name}");
+            if ParsedFunctionName::parse(&enriched_function_name).is_ok() {
+                enriched_function_name
+            } else {
+                // If the enriched function name is still not valid, we just return the original function name
+                function_name
+            }
+        }
+    } else {
+        // No root package information in the target, we can't do anything
+        function_name
+    }
 }
 
 #[async_trait]
 impl<Ctx: WorkerCtx> Rpc for DirectWorkerInvocationRpc<Ctx> {
-    async fn create_demand(&self, owned_worker_id: &OwnedWorkerId) -> Box<dyn RpcDemand> {
-        let demand = LoggingDemand::new(owned_worker_id.worker_id());
-        Box::new(demand)
+    async fn create_demand(
+        &self,
+        owned_worker_id: &OwnedWorkerId,
+        self_created_by: &AccountId,
+        self_worker_id: &WorkerId,
+        self_args: &[String],
+        self_env: &[(String, String)],
+        self_config: BTreeMap<String, String>,
+        self_stack: InvocationContextStack,
+    ) -> Result<Box<dyn RpcDemand>, RpcError> {
+        if self
+            .shard_service()
+            .check_worker(&owned_worker_id.worker_id)
+            .is_ok()
+        {
+            debug!("Ensuring local target worker exists");
+
+            let _worker = Worker::get_or_create_running(
+                self,
+                self_created_by,
+                owned_worker_id,
+                Some(self_args.to_vec()),
+                Some(self_env.to_vec()),
+                Some(self_config),
+                None,
+                Some(self_worker_id.clone()),
+                &self_stack,
+            )
+            .await?;
+
+            let demand = LoggingDemand::new(owned_worker_id.worker_id());
+            Ok(Box::new(demand))
+        } else {
+            self.remote_rpc
+                .create_demand(
+                    owned_worker_id,
+                    self_created_by,
+                    self_worker_id,
+                    self_args,
+                    self_env,
+                    self_config,
+                    self_stack,
+                )
+                .await
+        }
     }
 
     async fn invoke_and_await(
@@ -572,12 +734,17 @@ impl<Ctx: WorkerCtx> Rpc for DirectWorkerInvocationRpc<Ctx> {
         idempotency_key: Option<IdempotencyKey>,
         function_name: String,
         function_params: Vec<WitValue>,
+        self_created_by: &AccountId,
         self_worker_id: &WorkerId,
         self_args: &[String],
         self_env: &[(String, String)],
+        self_config: BTreeMap<String, String>,
         self_stack: InvocationContextStack,
     ) -> Result<Option<ValueAndType>, RpcError> {
         let idempotency_key = idempotency_key.unwrap_or(IdempotencyKey::fresh());
+        let function_name = self
+            .enrich_function_name(owned_worker_id, function_name)
+            .await;
 
         if self
             .shard_service()
@@ -593,11 +760,14 @@ impl<Ctx: WorkerCtx> Rpc for DirectWorkerInvocationRpc<Ctx> {
 
             let worker = Worker::get_or_create_running(
                 self,
+                self_created_by,
                 owned_worker_id,
                 Some(self_args.to_vec()),
                 Some(self_env.to_vec()),
+                Some(self_config),
                 None,
                 Some(self_worker_id.clone()),
+                &self_stack,
             )
             .await?;
 
@@ -613,9 +783,11 @@ impl<Ctx: WorkerCtx> Rpc for DirectWorkerInvocationRpc<Ctx> {
                     Some(idempotency_key),
                     function_name,
                     function_params,
+                    self_created_by,
                     self_worker_id,
                     self_args,
                     self_env,
+                    self_config,
                     self_stack,
                 )
                 .await
@@ -628,12 +800,17 @@ impl<Ctx: WorkerCtx> Rpc for DirectWorkerInvocationRpc<Ctx> {
         idempotency_key: Option<IdempotencyKey>,
         function_name: String,
         function_params: Vec<WitValue>,
+        self_created_by: &AccountId,
         self_worker_id: &WorkerId,
         self_args: &[String],
         self_env: &[(String, String)],
+        self_config: BTreeMap<String, String>,
         self_stack: InvocationContextStack,
     ) -> Result<(), RpcError> {
         let idempotency_key = idempotency_key.unwrap_or(IdempotencyKey::fresh());
+        let function_name = self
+            .enrich_function_name(owned_worker_id, function_name)
+            .await;
 
         if self
             .shard_service()
@@ -649,11 +826,14 @@ impl<Ctx: WorkerCtx> Rpc for DirectWorkerInvocationRpc<Ctx> {
 
             let worker = Worker::get_or_create_running(
                 self,
+                self_created_by,
                 owned_worker_id,
                 Some(self_args.to_vec()),
                 Some(self_env.to_vec()),
+                Some(self_config),
                 None,
                 Some(self_worker_id.clone()),
+                &self_stack,
             )
             .await?;
 
@@ -668,23 +848,54 @@ impl<Ctx: WorkerCtx> Rpc for DirectWorkerInvocationRpc<Ctx> {
                     Some(idempotency_key),
                     function_name,
                     function_params,
+                    self_created_by,
                     self_worker_id,
                     self_args,
                     self_env,
+                    self_config,
                     self_stack,
                 )
                 .await
         }
     }
-
-    async fn generate_unique_local_worker_id(
-        &self,
-        target_worker_id: TargetWorkerId,
-    ) -> Result<WorkerId, WorkerExecutorError> {
-        self.remote_rpc
-            .generate_unique_local_worker_id(target_worker_id)
-            .await
-    }
 }
 
 impl RpcDemand for () {}
+
+#[cfg(test)]
+mod tests {
+    use crate::services::rpc::enrich_function_name_by_target_information;
+    use test_r::test;
+
+    #[test]
+    fn test_enrich_function_name_by_target_information() {
+        assert_eq!(
+            enrich_function_name_by_target_information("api.{x}".to_string(), None, None),
+            "api.{x}".to_string()
+        );
+        assert_eq!(
+            enrich_function_name_by_target_information(
+                "api.{x}".to_string(),
+                Some("test:pkg".to_string()),
+                None
+            ),
+            "test:pkg/api.{x}".to_string()
+        );
+        assert_eq!(
+            enrich_function_name_by_target_information(
+                "api.{x}".to_string(),
+                Some("test:pkg".to_string()),
+                Some("1.0.0".to_string())
+            ),
+            "test:pkg/api@1.0.0.{x}".to_string()
+        );
+        assert_eq!(
+            enrich_function_name_by_target_information(
+                "run".to_string(),
+                Some("test:pkg".to_string()),
+                Some("1.0.0".to_string())
+            ),
+            "run".to_string()
+        );
+    }
+}
diff --git a/golem-worker-executor/src/services/scheduler.rs b/golem-worker-executor/src/services/scheduler.rs
index d367d60f..d16b8234 100644
--- a/golem-worker-executor/src/services/scheduler.rs
+++ b/golem-worker-executor/src/services/scheduler.rs
@@ -28,7 +28,7 @@ use crate::workerctx::WorkerCtx;
 use async_trait::async_trait;
 use chrono::{DateTime, TimeZone, Utc};
 use golem_common::model::invocation_context::InvocationContextStack;
-use golem_common::model::{IdempotencyKey, OwnedWorkerId, ScheduleId, ScheduledAction};
+use golem_common::model::{AccountId, IdempotencyKey, OwnedWorkerId, ScheduleId, ScheduledAction};
 use golem_service_base::error::worker_executor::WorkerExecutorError;
 use golem_wasm_rpc::Value;
 use std::ops::{Add, Deref};
@@ -49,15 +49,17 @@ pub trait SchedulerService: Send + Sync {
 /// for `SchedulerServiceDefault`, making it easier to test (by being independent of `WorkerCtx`).
 #[async_trait]
 pub trait SchedulerWorkerAccess {
-    async fn activate_worker(&self, owned_worker_id: &OwnedWorkerId);
+    async fn activate_worker(&self, created_by: &AccountId, owned_worker_id: &OwnedWorkerId);
     async fn open_oplog(
         &self,
+        created_by: &AccountId,
         owned_worker_id: &OwnedWorkerId,
     ) -> Result<Arc<dyn Oplog>, WorkerExecutorError>;
 
     // enqueue and invocation to the worker
     async fn enqueue_invocation(
         &self,
+        created_by: &AccountId,
         owned_worker_id: &OwnedWorkerId,
         idempotency_key: IdempotencyKey,
         full_function_name: String,
@@ -68,22 +70,35 @@ pub trait SchedulerWorkerAccess {
 
 #[async_trait]
 impl<Ctx: WorkerCtx> SchedulerWorkerAccess for Arc<dyn WorkerActivator<Ctx>> {
-    async fn activate_worker(&self, owned_worker_id: &OwnedWorkerId) {
-        self.deref().activate_worker(owned_worker_id).await;
+    async fn activate_worker(&self, created_by: &AccountId, owned_worker_id: &OwnedWorkerId) {
+        self.deref()
+            .activate_worker(created_by, owned_worker_id)
+            .await;
     }
 
     async fn open_oplog(
         &self,
+        created_by: &AccountId,
         owned_worker_id: &OwnedWorkerId,
     ) -> Result<Arc<dyn Oplog>, WorkerExecutorError> {
         let worker = self
-            .get_or_create_suspended(owned_worker_id, None, None, None, None)
+            .get_or_create_suspended(
+                created_by,
+                owned_worker_id,
+                None,
+                None,
+                None,
+                None,
+                None,
+                &InvocationContextStack::fresh(),
+            )
             .await?;
         Ok(worker.oplog())
     }
 
     async fn enqueue_invocation(
         &self,
+        created_by: &AccountId,
         owned_worker_id: &OwnedWorkerId,
         idempotency_key: IdempotencyKey,
         full_function_name: String,
@@ -91,7 +106,16 @@ impl<Ctx: WorkerCtx> SchedulerWorkerAccess for Arc<dyn WorkerActivator<Ctx>> {
         invocation_context: InvocationContextStack,
     ) -> Result<(), WorkerExecutorError> {
         let worker = self
-            .get_or_create_suspended(owned_worker_id, None, None, None, None)
+            .get_or_create_suspended(
+                created_by,
+                owned_worker_id,
+                None,
+                None,
+                None,
+                None,
+                None,
+                &InvocationContextStack::fresh(),
+            )
             .await?;
 
         worker
@@ -217,10 +241,11 @@ impl SchedulerServiceDefault {
         for (key, action) in matching {
             match action.clone() {
                 ScheduledAction::CompletePromise {
-                    promise_id,
                     account_id,
+                    promise_id,
+                    project_id,
                 } => {
-                    let owned_worker_id = OwnedWorkerId::new(&account_id, &promise_id.worker_id);
+                    let owned_worker_id = OwnedWorkerId::new(&project_id, &promise_id.worker_id);
 
                     let result = self
                         .promise_service
@@ -238,7 +263,7 @@ impl SchedulerServiceDefault {
                                     worker_id = owned_worker_id.worker_id.to_string()
                                 );
                                 self.worker_access
-                                    .activate_worker(&owned_worker_id)
+                                    .activate_worker(&account_id, &owned_worker_id)
                                     .instrument(span)
                                     .await;
                             }
@@ -255,6 +280,7 @@ impl SchedulerServiceDefault {
                     }
                 }
                 ScheduledAction::ArchiveOplog {
+                    account_id,
                     owned_worker_id,
                     last_oplog_index,
                     next_after,
@@ -264,7 +290,11 @@ impl SchedulerServiceDefault {
                             self.oplog_service.get_last_index(&owned_worker_id).await;
                         if current_last_index == last_oplog_index {
                             // Need to create the `Worker` instance to avoid race conditions
-                            match self.worker_access.open_oplog(&owned_worker_id).await {
+                            match self
+                                .worker_access
+                                .open_oplog(&account_id, &owned_worker_id)
+                                .await
+                            {
                                 Ok(oplog) => {
                                     let start = Instant::now();
                                     if let Some(more) = MultiLayerOplog::try_archive(&oplog).await {
@@ -273,6 +303,7 @@ impl SchedulerServiceDefault {
                                             self.schedule(
                                                 now.add(next_after),
                                                 ScheduledAction::ArchiveOplog {
+                                                    account_id,
                                                     owned_worker_id,
                                                     last_oplog_index,
                                                     next_after,
@@ -304,6 +335,7 @@ impl SchedulerServiceDefault {
                     }
                 }
                 ScheduledAction::Invoke {
+                    account_id,
                     owned_worker_id,
                     idempotency_key,
                     full_function_name,
@@ -315,6 +347,7 @@ impl SchedulerServiceDefault {
                     let result = self
                         .worker_access
                         .enqueue_invocation(
+                            &account_id,
                             &owned_worker_id,
                             idempotency_key,
                             full_function_name.clone(),
@@ -431,8 +464,8 @@ mod tests {
     use golem_common::model::invocation_context::InvocationContextStack;
     use golem_common::model::oplog::OplogIndex;
     use golem_common::model::{
-        AccountId, ComponentId, IdempotencyKey, OwnedWorkerId, PromiseId, ScheduledAction, ShardId,
-        WorkerId,
+        AccountId, ComponentId, IdempotencyKey, OwnedWorkerId, ProjectId, PromiseId,
+        ScheduledAction, ShardId, WorkerId,
     };
     use golem_service_base::error::worker_executor::WorkerExecutorError;
     use golem_service_base::storage::blob::memory::InMemoryBlobStorage;
@@ -448,15 +481,18 @@ mod tests {
 
     #[async_trait]
     impl SchedulerWorkerAccess for SchedulerWorkerAccessMock {
-        async fn activate_worker(&self, _owned_worker_id: &OwnedWorkerId) {}
+        async fn activate_worker(&self, _created_by: &AccountId, _owned_worker_id: &OwnedWorkerId) {
+        }
         async fn open_oplog(
             &self,
+            _created_by: &AccountId,
             _owned_worker_id: &OwnedWorkerId,
         ) -> Result<Arc<dyn Oplog>, WorkerExecutorError> {
             unimplemented!()
         }
         async fn enqueue_invocation(
             &self,
+            _created_by: &AccountId,
             _owned_worker_id: &OwnedWorkerId,
             _idempotency_key: IdempotencyKey,
             _full_function_name: String,
@@ -526,9 +562,7 @@ mod tests {
             worker_name: "inst2".to_string(),
         };
 
-        let account_id = AccountId {
-            value: "test-account".to_string(),
-        };
+        let project_id = ProjectId::new_v4();
 
         let p1: PromiseId = PromiseId {
             worker_id: i1.clone(),
@@ -567,11 +601,16 @@ mod tests {
             Duration::from_secs(1000), // not testing process() here
         );
 
+        let account_id = AccountId {
+            value: "test_account".to_string(),
+        };
+
         let _s1 = svc
             .schedule(
                 DateTime::from_str("2023-07-17T10:05:00Z").unwrap(),
                 ScheduledAction::CompletePromise {
                     account_id: account_id.clone(),
+                    project_id: project_id.clone(),
                     promise_id: p1.clone(),
                 },
             )
@@ -580,8 +619,9 @@ mod tests {
             .schedule(
                 DateTime::from_str("2023-07-17T09:59:00Z").unwrap(),
                 ScheduledAction::CompletePromise {
-                    promise_id: p2.clone(),
                     account_id: account_id.clone(),
+                    promise_id: p2.clone(),
+                    project_id: project_id.clone(),
                 },
             )
             .await;
@@ -589,8 +629,9 @@ mod tests {
             .schedule(
                 DateTime::from_str("2023-07-17T10:05:01Z").unwrap(),
                 ScheduledAction::CompletePromise {
-                    promise_id: p3.clone(),
                     account_id: account_id.clone(),
+                    promise_id: p3.clone(),
+                    project_id: project_id.clone(),
                 },
             )
             .await;
@@ -608,8 +649,9 @@ mod tests {
                     vec![(
                         3540000.0,
                         serialized_bytes(&ScheduledAction::CompletePromise {
+                            account_id: account_id.clone(),
                             promise_id: p2,
-                            account_id: account_id.clone()
+                            project_id: project_id.clone()
                         })
                     )]
                 ),
@@ -619,15 +661,17 @@ mod tests {
                         (
                             300000.0,
                             serialized_bytes(&ScheduledAction::CompletePromise {
+                                account_id: account_id.clone(),
                                 promise_id: p1,
-                                account_id: account_id.clone()
+                                project_id: project_id.clone()
                             })
                         ),
                         (
                             301000.0,
                             serialized_bytes(&ScheduledAction::CompletePromise {
+                                account_id: account_id.clone(),
                                 promise_id: p3,
-                                account_id: account_id.clone()
+                                project_id: project_id.clone()
                             })
                         )
                     ]
@@ -648,9 +692,7 @@ mod tests {
             worker_name: "inst2".to_string(),
         };
 
-        let account_id = AccountId {
-            value: "test-account".to_string(),
-        };
+        let project_id = ProjectId::new_v4();
 
         let p1: PromiseId = PromiseId {
             worker_id: i1.clone(),
@@ -690,12 +732,17 @@ mod tests {
             Duration::from_secs(1000), // not testing process() here
         );
 
+        let account_id = AccountId {
+            value: "test_account".to_string(),
+        };
+
         let _s1 = svc
             .schedule(
                 DateTime::from_str("2023-07-17T10:05:00Z").unwrap(),
                 ScheduledAction::CompletePromise {
-                    promise_id: p1.clone(),
                     account_id: account_id.clone(),
+                    promise_id: p1.clone(),
+                    project_id: project_id.clone(),
                 },
             )
             .await;
@@ -703,8 +750,9 @@ mod tests {
             .schedule(
                 DateTime::from_str("2023-07-17T09:59:00Z").unwrap(),
                 ScheduledAction::CompletePromise {
-                    promise_id: p2.clone(),
                     account_id: account_id.clone(),
+                    promise_id: p2.clone(),
+                    project_id: project_id.clone(),
                 },
             )
             .await;
@@ -712,8 +760,9 @@ mod tests {
             .schedule(
                 DateTime::from_str("2023-07-17T10:05:01Z").unwrap(),
                 ScheduledAction::CompletePromise {
-                    promise_id: p3.clone(),
                     account_id: account_id.clone(),
+                    promise_id: p3.clone(),
+                    project_id: project_id.clone(),
                 },
             )
             .await;
@@ -735,8 +784,9 @@ mod tests {
                     vec![(
                         300000.0,
                         serialized_bytes(&ScheduledAction::CompletePromise {
+                            account_id: account_id.clone(),
                             promise_id: p1,
-                            account_id: account_id.clone()
+                            project_id: project_id.clone()
                         })
                     )]
                 )
@@ -756,9 +806,7 @@ mod tests {
             worker_name: "inst2".to_string(),
         };
 
-        let account_id = AccountId {
-            value: "test-account".to_string(),
-        };
+        let project_id = ProjectId::new_v4();
 
         let p1: PromiseId = PromiseId {
             worker_id: i1.clone(),
@@ -797,12 +845,17 @@ mod tests {
             Duration::from_secs(1000), // explicitly calling process for testing
         );
 
+        let account_id = AccountId {
+            value: "test_account".to_string(),
+        };
+
         let _s1 = svc
             .schedule(
                 DateTime::from_str("2023-07-17T10:05:00Z").unwrap(),
                 ScheduledAction::CompletePromise {
-                    promise_id: p1.clone(),
                     account_id: account_id.clone(),
+                    promise_id: p1.clone(),
+                    project_id: project_id.clone(),
                 },
             )
             .await;
@@ -810,8 +863,9 @@ mod tests {
             .schedule(
                 DateTime::from_str("2023-07-17T10:59:00Z").unwrap(),
                 ScheduledAction::CompletePromise {
-                    promise_id: p2.clone(),
                     account_id: account_id.clone(),
+                    promise_id: p2.clone(),
+                    project_id: project_id.clone(),
                 },
             )
             .await;
@@ -819,8 +873,9 @@ mod tests {
             .schedule(
                 DateTime::from_str("2023-07-17T10:11:01Z").unwrap(),
                 ScheduledAction::CompletePromise {
-                    promise_id: p3.clone(),
                     account_id: account_id.clone(),
+                    promise_id: p3.clone(),
+                    project_id: project_id.clone(),
                 },
             )
             .await;
@@ -842,8 +897,9 @@ mod tests {
                 vec![(
                     3540000.0,
                     serialized_bytes(&ScheduledAction::CompletePromise {
+                        account_id: account_id.clone(),
                         promise_id: p2.clone(),
-                        account_id: account_id.clone()
+                        project_id: project_id.clone()
                     })
                 )]
             )])
@@ -868,9 +924,7 @@ mod tests {
             worker_name: "inst2".to_string(),
         };
 
-        let account_id = AccountId {
-            value: "test-account".to_string(),
-        };
+        let project_id = ProjectId::new_v4();
 
         let p1: PromiseId = PromiseId {
             worker_id: i1.clone(),
@@ -909,12 +963,17 @@ mod tests {
             Duration::from_secs(1000), // explicitly calling process for testing
         );
 
+        let account_id = AccountId {
+            value: "test_account".to_string(),
+        };
+
         let _s1 = svc
             .schedule(
                 DateTime::from_str("2023-07-17T10:05:00Z").unwrap(),
                 ScheduledAction::CompletePromise {
-                    promise_id: p1.clone(),
                     account_id: account_id.clone(),
+                    promise_id: p1.clone(),
+                    project_id: project_id.clone(),
                 },
             )
             .await;
@@ -922,8 +981,9 @@ mod tests {
             .schedule(
                 DateTime::from_str("2023-07-17T09:59:00Z").unwrap(),
                 ScheduledAction::CompletePromise {
-                    promise_id: p2.clone(),
                     account_id: account_id.clone(),
+                    promise_id: p2.clone(),
+                    project_id: project_id.clone(),
                 },
             )
             .await;
@@ -931,8 +991,9 @@ mod tests {
             .schedule(
                 DateTime::from_str("2023-07-17T10:11:01Z").unwrap(),
                 ScheduledAction::CompletePromise {
-                    promise_id: p3.clone(),
                     account_id: account_id.clone(),
+                    promise_id: p3.clone(),
+                    project_id: project_id.clone(),
                 },
             )
             .await;
@@ -974,9 +1035,7 @@ mod tests {
             worker_name: "inst2".to_string(),
         };
 
-        let account_id = AccountId {
-            value: "test-account".to_string(),
-        };
+        let project_id = ProjectId::new_v4();
 
         let p1: PromiseId = PromiseId {
             worker_id: i1.clone(),
@@ -1019,12 +1078,17 @@ mod tests {
             Duration::from_secs(1000), // explicitly calling process for testing
         );
 
+        let account_id = AccountId {
+            value: "test_account".to_string(),
+        };
+
         let _s1 = svc
             .schedule(
                 DateTime::from_str("2023-07-17T10:05:00Z").unwrap(),
                 ScheduledAction::CompletePromise {
-                    promise_id: p1.clone(),
                     account_id: account_id.clone(),
+                    promise_id: p1.clone(),
+                    project_id: project_id.clone(),
                 },
             )
             .await;
@@ -1032,8 +1096,9 @@ mod tests {
             .schedule(
                 DateTime::from_str("2023-07-17T09:59:00Z").unwrap(),
                 ScheduledAction::CompletePromise {
-                    promise_id: p2.clone(),
                     account_id: account_id.clone(),
+                    promise_id: p2.clone(),
+                    project_id: project_id.clone(),
                 },
             )
             .await;
@@ -1041,8 +1106,9 @@ mod tests {
             .schedule(
                 DateTime::from_str("2023-07-17T10:11:01Z").unwrap(),
                 ScheduledAction::CompletePromise {
-                    promise_id: p3.clone(),
                     account_id: account_id.clone(),
+                    promise_id: p3.clone(),
+                    project_id: project_id.clone(),
                 },
             )
             .await;
@@ -1050,8 +1116,9 @@ mod tests {
             .schedule(
                 DateTime::from_str("2023-07-17T09:47:00Z").unwrap(),
                 ScheduledAction::CompletePromise {
-                    promise_id: p4.clone(),
                     account_id: account_id.clone(),
+                    promise_id: p4.clone(),
+                    project_id: project_id.clone(),
                 },
             )
             .await;
@@ -1094,9 +1161,7 @@ mod tests {
             worker_name: "inst2".to_string(),
         };
 
-        let account_id = AccountId {
-            value: "test-account".to_string(),
-        };
+        let project_id = ProjectId::new_v4();
 
         let p1: PromiseId = PromiseId {
             worker_id: i1.clone(),
@@ -1135,12 +1200,17 @@ mod tests {
             Duration::from_secs(1000), // explicitly calling process for testing
         );
 
+        let account_id = AccountId {
+            value: "test_account".to_string(),
+        };
+
         let _s1 = svc
             .schedule(
                 DateTime::from_str("2023-07-17T10:05:00Z").unwrap(),
                 ScheduledAction::CompletePromise {
-                    promise_id: p1.clone(),
                     account_id: account_id.clone(),
+                    promise_id: p1.clone(),
+                    project_id: project_id.clone(),
                 },
             )
             .await;
@@ -1148,8 +1218,9 @@ mod tests {
             .schedule(
                 DateTime::from_str("2023-07-17T09:59:00Z").unwrap(),
                 ScheduledAction::CompletePromise {
-                    promise_id: p2.clone(),
                     account_id: account_id.clone(),
+                    promise_id: p2.clone(),
+                    project_id: project_id.clone(),
                 },
             )
             .await;
@@ -1157,8 +1228,9 @@ mod tests {
             .schedule(
                 DateTime::from_str("2023-07-17T09:47:00Z").unwrap(),
                 ScheduledAction::CompletePromise {
-                    promise_id: p3.clone(),
                     account_id: account_id.clone(),
+                    promise_id: p3.clone(),
+                    project_id: project_id.clone(),
                 },
             )
             .await;
diff --git a/golem-worker-executor/src/services/worker.rs b/golem-worker-executor/src/services/worker.rs
index e44bb09f..2db27637 100644
--- a/golem-worker-executor/src/services/worker.rs
+++ b/golem-worker-executor/src/services/worker.rs
@@ -25,10 +25,11 @@ use crate::worker::status::calculate_last_known_status;
 use async_trait::async_trait;
 use golem_common::model::oplog::{OplogEntry, OplogIndex};
 use golem_common::model::{
-    ComponentType, OwnedWorkerId, ShardId, Timestamp, WorkerId, WorkerMetadata, WorkerStatus,
-    WorkerStatusRecord,
+    AccountId, ComponentType, OwnedWorkerId, ShardId, Timestamp, WorkerId, WorkerMetadata,
+    WorkerStatus, WorkerStatusRecord,
 };
 use golem_service_base::error::worker_executor::WorkerExecutorError;
+use std::collections::BTreeMap;
 use std::sync::{Arc, RwLock};
 use tracing::{debug, warn};
 
@@ -122,14 +123,16 @@ impl WorkerService for DefaultWorkerService {
         record_worker_call("add");
 
         let worker_id = &worker_metadata.worker_id;
-        let owned_worker_id = OwnedWorkerId::new(&worker_metadata.account_id, worker_id);
+        let owned_worker_id = OwnedWorkerId::new(&worker_metadata.project_id, worker_id);
 
         let initial_oplog_entry = OplogEntry::create(
             worker_metadata.worker_id.clone(),
             worker_metadata.last_known_status.component_version,
             worker_metadata.args.clone(),
             worker_metadata.env.clone(),
-            worker_metadata.account_id.clone(),
+            worker_metadata.wasi_config_vars.clone(),
+            worker_metadata.project_id.clone(),
+            worker_metadata.created_by.clone(),
             worker_metadata.parent.clone(),
             worker_metadata.last_known_status.component_size,
             worker_metadata.last_known_status.total_linear_memory_size,
@@ -199,71 +202,6 @@ impl WorkerService for DefaultWorkerService {
 
         match initial_oplog_entry {
             None => None,
-            Some((
-                _,
-                OplogEntry::CreateV1 {
-                    worker_id,
-                    component_version,
-                    args,
-                    env,
-                    account_id,
-                    timestamp,
-                    parent,
-                    component_size,
-                    initial_total_linear_memory_size,
-                },
-            )) => {
-                let mut details = WorkerMetadata {
-                    worker_id,
-                    args,
-                    env,
-                    account_id,
-                    created_at: timestamp,
-                    parent,
-                    last_known_status: WorkerStatusRecord {
-                        component_version,
-                        component_size,
-                        total_linear_memory_size: initial_total_linear_memory_size,
-                        ..WorkerStatusRecord::default()
-                    },
-                };
-
-                let status_value: Option<Result<WorkerStatusRecord, String>> = self
-                    .key_value_storage
-                    .with_entity("worker", "get", "worker_status")
-                    .get_attempt_deserialize(
-                        KeyValueStorageNamespace::Worker,
-                        &Self::status_key(&owned_worker_id.worker_id),
-                    )
-                    .await
-                    .unwrap_or_else(|err| {
-                        panic!("failed to get worker status for {owned_worker_id} from KV storage: {err}")
-                    });
-
-                match status_value {
-                    Some(Ok(status)) => {
-                        details.last_known_status = status;
-                    }
-                    // We had a status, but it was written in a previous format and is not longer valid -> recompute
-                    Some(Err(_)) => {
-                        let last_known_status = calculate_last_known_status(self, owned_worker_id, &None)
-                            .await
-                            .unwrap_or_else(|err| {
-                                panic!("failed to recalculate last known status {owned_worker_id} from KV storage: {err}")
-                            });
-                        self.update_status(
-                            owned_worker_id,
-                            &last_known_status,
-                            ComponentType::Durable,
-                        )
-                        .await;
-                        details.last_known_status = last_known_status;
-                    }
-                    None => {}
-                }
-
-                Some(details)
-            }
             Some((
                 _,
                 OplogEntry::Create {
@@ -271,19 +209,23 @@ impl WorkerService for DefaultWorkerService {
                     component_version,
                     args,
                     env,
-                    account_id,
+                    project_id,
+                    created_by,
                     timestamp,
                     parent,
                     component_size,
                     initial_total_linear_memory_size,
                     initial_active_plugins,
+                    wasi_config_vars,
                 },
             )) => {
                 let mut details = WorkerMetadata {
                     worker_id,
                     args,
                     env,
-                    account_id,
+                    wasi_config_vars,
+                    project_id,
+                    created_by,
                     created_at: timestamp,
                     parent,
                     last_known_status: WorkerStatusRecord {
@@ -350,7 +292,11 @@ impl WorkerService for DefaultWorkerService {
                     worker_id: owned_worker_id.worker_id(),
                     args: vec![],
                     env: vec![],
-                    account_id: owned_worker_id.account_id(),
+                    wasi_config_vars: BTreeMap::new(),
+                    project_id: owned_worker_id.project_id(),
+                    created_by: AccountId {
+                        value: "system".to_string(),
+                    },
                     created_at: Timestamp::now_utc(),
                     parent: None,
                     last_known_status: WorkerStatusRecord {
diff --git a/golem-worker-executor/src/services/worker_activator.rs b/golem-worker-executor/src/services/worker_activator.rs
index a1fb3409..acbbe724 100644
--- a/golem-worker-executor/src/services/worker_activator.rs
+++ b/golem-worker-executor/src/services/worker_activator.rs
@@ -16,8 +16,10 @@ use crate::services::HasAll;
 use crate::worker::Worker;
 use crate::workerctx::WorkerCtx;
 use async_trait::async_trait;
-use golem_common::model::{OwnedWorkerId, WorkerId};
+use golem_common::model::invocation_context::InvocationContextStack;
+use golem_common::model::{AccountId, OwnedWorkerId, WorkerId};
 use golem_service_base::error::worker_executor::WorkerExecutorError;
+use std::collections::BTreeMap;
 use std::marker::PhantomData;
 use std::sync::{Arc, Mutex};
 use tracing::{error, warn};
@@ -26,26 +28,32 @@ use tracing::{error, warn};
 #[async_trait]
 pub trait WorkerActivator<Ctx: WorkerCtx>: Send + Sync {
     /// Makes sure an already existing worker is active in a background task. Returns immediately
-    async fn activate_worker(&self, owned_worker_id: &OwnedWorkerId);
+    async fn activate_worker(&self, created_by: &AccountId, owned_worker_id: &OwnedWorkerId);
 
     /// Gets or creates a worker in suspended state
     async fn get_or_create_suspended(
         &self,
+        created_by: &AccountId,
         owned_worker_id: &OwnedWorkerId,
         worker_args: Option<Vec<String>>,
         worker_env: Option<Vec<(String, String)>>,
+        worker_config: Option<BTreeMap<String, String>>,
         component_version: Option<u64>,
         parent: Option<WorkerId>,
+        invocation_context: &InvocationContextStack,
     ) -> Result<Arc<Worker<Ctx>>, WorkerExecutorError>;
 
     /// Gets or creates a worker and starts it
     async fn get_or_create_running(
         &self,
+        created_by: &AccountId,
         owned_worker_id: &OwnedWorkerId,
         worker_args: Option<Vec<String>>,
         worker_env: Option<Vec<(String, String)>>,
+        worker_config: Option<BTreeMap<String, String>>,
         component_version: Option<u64>,
         parent: Option<WorkerId>,
+        invocation_context: &InvocationContextStack,
     ) -> Result<Arc<Worker<Ctx>>, WorkerExecutorError>;
 }
 
@@ -73,32 +81,42 @@ impl<Ctx: WorkerCtx> Default for LazyWorkerActivator<Ctx> {
 
 #[async_trait]
 impl<Ctx: WorkerCtx> WorkerActivator<Ctx> for LazyWorkerActivator<Ctx> {
-    async fn activate_worker(&self, owned_worker_id: &OwnedWorkerId) {
+    async fn activate_worker(&self, created_by: &AccountId, owned_worker_id: &OwnedWorkerId) {
         let maybe_worker_activator = self.worker_activator.lock().unwrap().clone();
         match maybe_worker_activator {
-            Some(worker_activator) => worker_activator.activate_worker(owned_worker_id).await,
+            Some(worker_activator) => {
+                worker_activator
+                    .activate_worker(created_by, owned_worker_id)
+                    .await
+            }
             None => warn!("WorkerActivator is disabled, not activating instance"),
         }
     }
 
     async fn get_or_create_suspended(
         &self,
+        created_by: &AccountId,
         owned_worker_id: &OwnedWorkerId,
         worker_args: Option<Vec<String>>,
         worker_env: Option<Vec<(String, String)>>,
+        worker_config: Option<BTreeMap<String, String>>,
         component_version: Option<u64>,
         parent: Option<WorkerId>,
+        invocation_context: &InvocationContextStack,
     ) -> Result<Arc<Worker<Ctx>>, WorkerExecutorError> {
         let maybe_worker_activator = self.worker_activator.lock().unwrap().clone();
         match maybe_worker_activator {
             Some(worker_activator) => {
                 worker_activator
                     .get_or_create_suspended(
+                        created_by,
                         owned_worker_id,
                         worker_args,
                         worker_env,
+                        worker_config,
                         component_version,
                         parent,
+                        invocation_context,
                     )
                     .await
             }
@@ -110,22 +128,28 @@ impl<Ctx: WorkerCtx> WorkerActivator<Ctx> for LazyWorkerActivator<Ctx> {
 
     async fn get_or_create_running(
         &self,
+        created_by: &AccountId,
         owned_worker_id: &OwnedWorkerId,
         worker_args: Option<Vec<String>>,
         worker_env: Option<Vec<(String, String)>>,
+        worker_config: Option<BTreeMap<String, String>>,
         component_version: Option<u64>,
         parent: Option<WorkerId>,
+        invocation_context: &InvocationContextStack,
     ) -> Result<Arc<Worker<Ctx>>, WorkerExecutorError> {
         let maybe_worker_activator = self.worker_activator.lock().unwrap().clone();
         match maybe_worker_activator {
             Some(worker_activator) => {
                 worker_activator
                     .get_or_create_running(
+                        created_by,
                         owned_worker_id,
                         worker_args,
                         worker_env,
+                        worker_config,
                         component_version,
                         parent,
+                        invocation_context,
                     )
                     .await
             }
@@ -155,17 +179,20 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx>> DefaultWorkerActivator<Ctx, Svcs> {
 impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + Send + Sync + 'static> WorkerActivator<Ctx>
     for DefaultWorkerActivator<Ctx, Svcs>
 {
-    async fn activate_worker(&self, owned_worker_id: &OwnedWorkerId) {
+    async fn activate_worker(&self, created_by: &AccountId, owned_worker_id: &OwnedWorkerId) {
         let metadata = self.all.worker_service().get(owned_worker_id).await;
         match metadata {
             Some(_) => {
                 if let Err(err) = Worker::get_or_create_running(
                     &self.all,
+                    created_by,
                     owned_worker_id,
                     None,
                     None,
                     None,
                     None,
+                    None,
+                    &InvocationContextStack::fresh(),
                 )
                 .await
                 {
@@ -180,38 +207,50 @@ impl<Ctx: WorkerCtx, Svcs: HasAll<Ctx> + Send + Sync + 'static> WorkerActivator<
 
     async fn get_or_create_suspended(
         &self,
+        created_by: &AccountId,
         owned_worker_id: &OwnedWorkerId,
         worker_args: Option<Vec<String>>,
         worker_env: Option<Vec<(String, String)>>,
+        worker_config: Option<BTreeMap<String, String>>,
         component_version: Option<u64>,
         parent: Option<WorkerId>,
+        invocation_context: &InvocationContextStack,
     ) -> Result<Arc<Worker<Ctx>>, WorkerExecutorError> {
         Worker::get_or_create_suspended(
             &self.all,
+            created_by,
             owned_worker_id,
             worker_args,
             worker_env,
+            worker_config,
             component_version,
             parent,
+            invocation_context,
         )
         .await
     }
 
     async fn get_or_create_running(
         &self,
+        created_by: &AccountId,
         owned_worker_id: &OwnedWorkerId,
         worker_args: Option<Vec<String>>,
         worker_env: Option<Vec<(String, String)>>,
+        worker_config: Option<BTreeMap<String, String>>,
         component_version: Option<u64>,
         parent: Option<WorkerId>,
+        invocation_context: &InvocationContextStack,
     ) -> Result<Arc<Worker<Ctx>>, WorkerExecutorError> {
         Worker::get_or_create_running(
             &self.all,
+            created_by,
             owned_worker_id,
             worker_args,
             worker_env,
+            worker_config,
             component_version,
             parent,
+            invocation_context,
         )
         .await
     }
diff --git a/golem-worker-executor/src/services/worker_enumeration.rs b/golem-worker-executor/src/services/worker_enumeration.rs
index 5b6e4951..aade5a1a 100644
--- a/golem-worker-executor/src/services/worker_enumeration.rs
+++ b/golem-worker-executor/src/services/worker_enumeration.rs
@@ -7,7 +7,7 @@ use crate::worker::status::calculate_last_known_status;
 use crate::workerctx::WorkerCtx;
 use async_trait::async_trait;
 use golem_common::model::{
-    AccountId, ComponentId, ScanCursor, WorkerFilter, WorkerMetadata, WorkerStatus,
+    ComponentId, ProjectId, ScanCursor, WorkerFilter, WorkerMetadata, WorkerStatus,
 };
 use golem_service_base::error::worker_executor::WorkerExecutorError;
 use std::sync::Arc;
@@ -71,7 +71,7 @@ impl<Ctx: WorkerCtx> RunningWorkerEnumerationServiceDefault<Ctx> {
 pub trait WorkerEnumerationService: Send + Sync {
     async fn get(
         &self,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         component_id: &ComponentId,
         filter: Option<WorkerFilter>,
         cursor: ScanCursor,
@@ -102,7 +102,7 @@ impl DefaultWorkerEnumerationService {
 
     async fn get_internal(
         &self,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         component_id: &ComponentId,
         filter: Option<WorkerFilter>,
         cursor: ScanCursor,
@@ -113,7 +113,7 @@ impl DefaultWorkerEnumerationService {
 
         let (new_cursor, keys) = self
             .oplog_service
-            .scan_for_component(account_id, component_id, cursor, count)
+            .scan_for_component(project_id, component_id, cursor, count)
             .instrument(tracing::info_span!("scan_for_component"))
             .await?;
 
@@ -173,7 +173,7 @@ impl HasConfig for DefaultWorkerEnumerationService {
 impl WorkerEnumerationService for DefaultWorkerEnumerationService {
     async fn get(
         &self,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         component_id: &ComponentId,
         filter: Option<WorkerFilter>,
         cursor: ScanCursor,
@@ -181,14 +181,16 @@ impl WorkerEnumerationService for DefaultWorkerEnumerationService {
         precise: bool,
     ) -> Result<(Option<ScanCursor>, Vec<WorkerMetadata>), WorkerExecutorError> {
         info!(
-            "Get workers - filter: {}, cursor: {}, count: {}, precise: {}",
-            filter
+            project_id = %project_id,
+            component_id = %component_id,
+            filter = filter
                 .clone()
                 .map(|f| f.to_string())
                 .unwrap_or("N/A".to_string()),
-            cursor,
-            count,
-            precise
+            cursor = %cursor,
+            count = %count,
+            precise = %precise,
+            "Enumerating workers"
         );
         let mut new_cursor: Option<ScanCursor> = Some(cursor);
         let mut workers: Vec<WorkerMetadata> = vec![];
@@ -198,7 +200,7 @@ impl WorkerEnumerationService for DefaultWorkerEnumerationService {
 
             let (next_cursor, workers_page) = self
                 .get_internal(
-                    account_id,
+                    project_id,
                     component_id,
                     filter.clone(),
                     new_cursor.unwrap_or_default(),
diff --git a/golem-worker-executor/src/services/worker_event.rs b/golem-worker-executor/src/services/worker_event.rs
index 8f4e3b55..1260ed05 100644
--- a/golem-worker-executor/src/services/worker_event.rs
+++ b/golem-worker-executor/src/services/worker_event.rs
@@ -15,8 +15,8 @@
 use crate::metrics::events::{record_broadcast_event, record_event};
 use crate::model::event::InternalWorkerEvent;
 use applying::Apply;
-use futures_util::{stream, StreamExt};
-use golem_common::model::{IdempotencyKey, LogLevel};
+use futures::{stream, StreamExt};
+use golem_common::model::IdempotencyKey;
 use ringbuf::storage::Heap;
 use ringbuf::traits::{Consumer, Producer, Split};
 use ringbuf::*;
@@ -43,21 +43,6 @@ pub trait WorkerEventService: Send + Sync {
     /// guaranteed to contain information only emitted during the _last_ invocation.
     fn get_last_invocation_errors(&self) -> String;
 
-    fn emit_stdout(&self, bytes: Vec<u8>, is_live: bool) {
-        self.emit_event(InternalWorkerEvent::stdout(bytes), is_live)
-    }
-
-    fn emit_stderr(&self, bytes: Vec<u8>, is_live: bool) {
-        self.emit_event(InternalWorkerEvent::stderr(bytes), is_live)
-    }
-
-    fn emit_log(&self, log_level: LogLevel, context: &str, message: &str, is_live: bool) {
-        self.emit_event(
-            InternalWorkerEvent::log(log_level, context, message),
-            is_live,
-        )
-    }
-
     fn emit_invocation_start(
         &self,
         function: &str,
@@ -187,7 +172,7 @@ fn label(event: &InternalWorkerEvent) -> &'static str {
 mod tests {
     use crate::model::event::InternalWorkerEvent;
     use crate::services::worker_event::{WorkerEventService, WorkerEventServiceDefault};
-    use futures_util::StreamExt;
+    use futures::StreamExt;
     use std::sync::Arc;
     use std::time::Duration;
     use test_r::{test, timeout};
diff --git a/golem-worker-executor/src/services/worker_fork.rs b/golem-worker-executor/src/services/worker_fork.rs
index 8388eba0..67d6eda5 100644
--- a/golem-worker-executor/src/services/worker_fork.rs
+++ b/golem-worker-executor/src/services/worker_fork.rs
@@ -17,29 +17,33 @@ use crate::durable_host::serialized::SerializableError;
 use crate::metrics::workers::record_worker_call;
 use crate::model::ExecutionStatus;
 use crate::preview2::golem_api_1_x::host::ForkResult;
+use crate::services::agent_types::AgentTypesService;
 use crate::services::events::Events;
 use crate::services::oplog::plugin::OplogProcessorPlugin;
 use crate::services::oplog::{CommitLevel, Oplog, OplogOps};
 use crate::services::plugins::Plugins;
+use crate::services::projects::ProjectService;
 use crate::services::resource_limits::ResourceLimits;
 use crate::services::rpc::Rpc;
 use crate::services::shard::ShardService;
 use crate::services::worker_proxy::WorkerProxy;
 use crate::services::{
-    active_workers, blob_store, component, golem_config, key_value, oplog, promise, scheduler,
-    shard, shard_manager, worker, worker_activator, worker_enumeration, HasActiveWorkers,
-    HasBlobStoreService, HasComponentService, HasConfig, HasEvents, HasExtraDeps, HasFileLoader,
-    HasKeyValueService, HasOplogProcessorPlugin, HasOplogService, HasPlugins, HasPromiseService,
-    HasResourceLimits, HasRpc, HasRunningWorkerEnumerationService, HasSchedulerService,
-    HasShardManagerService, HasShardService, HasWasmtimeEngine, HasWorkerActivator,
-    HasWorkerEnumerationService, HasWorkerProxy, HasWorkerService,
+    active_workers, agent_types, blob_store, component, golem_config, key_value, oplog, promise,
+    scheduler, shard_manager, worker, worker_activator, worker_enumeration, HasActiveWorkers,
+    HasAgentTypesService, HasBlobStoreService, HasComponentService, HasConfig, HasEvents,
+    HasExtraDeps, HasFileLoader, HasKeyValueService, HasOplogProcessorPlugin, HasOplogService,
+    HasPlugins, HasProjectService, HasPromiseService, HasResourceLimits, HasRpc,
+    HasRunningWorkerEnumerationService, HasSchedulerService, HasShardManagerService,
+    HasShardService, HasWasmtimeEngine, HasWorkerActivator, HasWorkerEnumerationService,
+    HasWorkerProxy, HasWorkerService,
 };
 use crate::services::{rdbms, HasOplog, HasRdbmsService, HasWorkerForkService};
 use crate::worker::Worker;
 use crate::workerctx::WorkerCtx;
 use async_trait::async_trait;
+use golem_common::model::invocation_context::InvocationContextStack;
 use golem_common::model::oplog::{DurableFunctionType, OplogIndex, OplogIndexRange};
-use golem_common::model::{AccountId, Timestamp, WorkerMetadata, WorkerStatusRecord};
+use golem_common::model::{AccountId, ProjectId, Timestamp, WorkerMetadata, WorkerStatusRecord};
 use golem_common::model::{OwnedWorkerId, WorkerId};
 use golem_common::serialization::serialize;
 use golem_service_base::error::worker_executor::WorkerExecutorError;
@@ -51,6 +55,7 @@ use tokio::runtime::Handle;
 pub trait WorkerForkService: Send + Sync {
     async fn fork(
         &self,
+        fork_account_id: &AccountId,
         source_worker_id: &OwnedWorkerId,
         target_worker_id: &WorkerId,
         oplog_index_cut_off: OplogIndex,
@@ -58,6 +63,7 @@ pub trait WorkerForkService: Send + Sync {
 
     async fn fork_and_write_fork_result(
         &self,
+        fork_account_id: &AccountId,
         source_worker_id: &OwnedWorkerId,
         target_worker_id: &WorkerId,
         oplog_index_cut_off: OplogIndex,
@@ -67,6 +73,7 @@ pub trait WorkerForkService: Send + Sync {
 pub struct DefaultWorkerFork<Ctx: WorkerCtx> {
     pub rpc: Arc<dyn Rpc>,
     pub active_workers: Arc<active_workers::ActiveWorkers<Ctx>>,
+    pub agent_types: Arc<dyn agent_types::AgentTypesService>,
     pub engine: Arc<wasmtime::Engine>,
     pub linker: Arc<wasmtime::component::Linker<Ctx>>,
     pub runtime: Handle,
@@ -91,6 +98,7 @@ pub struct DefaultWorkerFork<Ctx: WorkerCtx> {
     pub plugins: Arc<dyn Plugins>,
     pub oplog_processor_plugin: Arc<dyn OplogProcessorPlugin>,
     pub resource_limits: Arc<dyn ResourceLimits>,
+    pub project_service: Arc<dyn ProjectService>,
     pub extra_deps: Ctx::ExtraDeps,
 }
 
@@ -106,6 +114,12 @@ impl<Ctx: WorkerCtx> HasActiveWorkers<Ctx> for DefaultWorkerFork<Ctx> {
     }
 }
 
+impl<Ctx: WorkerCtx> HasAgentTypesService for DefaultWorkerFork<Ctx> {
+    fn agent_types(&self) -> Arc<dyn agent_types::AgentTypesService> {
+        self.agent_types.clone()
+    }
+}
+
 impl<Ctx: WorkerCtx> HasComponentService for DefaultWorkerFork<Ctx> {
     fn component_service(&self) -> Arc<dyn component::ComponentService> {
         self.component_service.clone()
@@ -207,7 +221,7 @@ impl<Ctx: WorkerCtx> HasExtraDeps<Ctx> for DefaultWorkerFork<Ctx> {
 }
 
 impl<Ctx: WorkerCtx> HasShardService for DefaultWorkerFork<Ctx> {
-    fn shard_service(&self) -> Arc<dyn shard::ShardService> {
+    fn shard_service(&self) -> Arc<dyn ShardService> {
         self.shard_service.clone()
     }
 }
@@ -254,11 +268,18 @@ impl<Ctx: WorkerCtx> HasResourceLimits for DefaultWorkerFork<Ctx> {
     }
 }
 
+impl<Ctx: WorkerCtx> HasProjectService for DefaultWorkerFork<Ctx> {
+    fn project_service(&self) -> Arc<dyn ProjectService> {
+        self.project_service.clone()
+    }
+}
+
 impl<Ctx: WorkerCtx> Clone for DefaultWorkerFork<Ctx> {
     fn clone(&self) -> Self {
         Self {
             rpc: self.rpc.clone(),
             active_workers: self.active_workers.clone(),
+            agent_types: self.agent_types.clone(),
             engine: self.engine.clone(),
             linker: self.linker.clone(),
             runtime: self.runtime.clone(),
@@ -282,6 +303,7 @@ impl<Ctx: WorkerCtx> Clone for DefaultWorkerFork<Ctx> {
             plugins: self.plugins.clone(),
             oplog_processor_plugin: self.oplog_processor_plugin.clone(),
             resource_limits: self.resource_limits.clone(),
+            project_service: self.project_service.clone(),
             extra_deps: self.extra_deps.clone(),
         }
     }
@@ -317,11 +339,14 @@ impl<Ctx: WorkerCtx> DefaultWorkerFork<Ctx> {
         plugins: Arc<dyn Plugins>,
         oplog_processor_plugin: Arc<dyn OplogProcessorPlugin>,
         resource_limits: Arc<dyn ResourceLimits>,
+        project_service: Arc<dyn ProjectService>,
+        agent_types: Arc<dyn AgentTypesService>,
         extra_deps: Ctx::ExtraDeps,
     ) -> Self {
         Self {
             rpc,
             active_workers,
+            agent_types,
             engine,
             linker,
             runtime,
@@ -345,13 +370,14 @@ impl<Ctx: WorkerCtx> DefaultWorkerFork<Ctx> {
             plugins,
             oplog_processor_plugin,
             resource_limits,
+            project_service,
             extra_deps,
         }
     }
 
     async fn validate_worker_forking(
         &self,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         source_worker_id: &WorkerId,
         target_worker_id: &WorkerId,
         oplog_index_cut_off: OplogIndex,
@@ -364,7 +390,7 @@ impl<Ctx: WorkerCtx> DefaultWorkerFork<Ctx> {
             ));
         }
 
-        let owned_target_worker_id = OwnedWorkerId::new(account_id, target_worker_id);
+        let owned_target_worker_id = OwnedWorkerId::new(project_id, target_worker_id);
 
         let target_metadata = self.worker_service.get(&owned_target_worker_id).await;
 
@@ -378,7 +404,7 @@ impl<Ctx: WorkerCtx> DefaultWorkerFork<Ctx> {
         // We assume the source worker belongs to this executor
         self.shard_service.check_worker(source_worker_id)?;
 
-        let owned_source_worker_id = OwnedWorkerId::new(account_id, source_worker_id);
+        let owned_source_worker_id = OwnedWorkerId::new(project_id, source_worker_id);
 
         self.worker_service
             .get(&owned_source_worker_id)
@@ -392,6 +418,7 @@ impl<Ctx: WorkerCtx> DefaultWorkerFork<Ctx> {
 
     async fn copy_source_oplog(
         &self,
+        fork_account_id: &AccountId,
         source_worker_id: &OwnedWorkerId,
         target_worker_id: &WorkerId,
         oplog_index_cut_off: OplogIndex,
@@ -400,7 +427,7 @@ impl<Ctx: WorkerCtx> DefaultWorkerFork<Ctx> {
 
         let (owned_source_worker_id, owned_target_worker_id) = self
             .validate_worker_forking(
-                &source_worker_id.account_id,
+                &source_worker_id.project_id,
                 &source_worker_id.worker_id,
                 target_worker_id,
                 oplog_index_cut_off,
@@ -408,19 +435,30 @@ impl<Ctx: WorkerCtx> DefaultWorkerFork<Ctx> {
             .await?;
 
         let target_worker_id = owned_target_worker_id.worker_id.clone();
-        let account_id = owned_target_worker_id.account_id.clone();
-
-        let source_worker_instance =
-            Worker::get_or_create_suspended(self, &owned_source_worker_id, None, None, None, None)
-                .await?;
+        let project_id = owned_target_worker_id.project_id.clone();
+
+        let source_worker_instance = Worker::get_or_create_suspended(
+            self,
+            fork_account_id,
+            &owned_source_worker_id,
+            None,
+            None,
+            None,
+            None,
+            None,
+            &InvocationContextStack::fresh(),
+        )
+        .await?;
 
         let source_worker_metadata = source_worker_instance.get_metadata()?;
 
         let target_worker_metadata = WorkerMetadata {
             worker_id: target_worker_id.clone(),
-            account_id,
+            created_by: fork_account_id.clone(),
+            project_id,
             env: source_worker_metadata.env.clone(),
             args: source_worker_metadata.args.clone(),
+            wasi_config_vars: source_worker_metadata.wasi_config_vars.clone(),
             created_at: Timestamp::now_utc(),
             parent: None,
             last_known_status: WorkerStatusRecord::default(),
@@ -468,12 +506,18 @@ impl<Ctx: WorkerCtx> DefaultWorkerFork<Ctx> {
 impl<Ctx: WorkerCtx> WorkerForkService for DefaultWorkerFork<Ctx> {
     async fn fork(
         &self,
+        fork_account_id: &AccountId,
         source_worker_id: &OwnedWorkerId,
         target_worker_id: &WorkerId,
         oplog_index_cut_off: OplogIndex,
     ) -> Result<(), WorkerExecutorError> {
         let new_oplog = self
-            .copy_source_oplog(source_worker_id, target_worker_id, oplog_index_cut_off)
+            .copy_source_oplog(
+                fork_account_id,
+                source_worker_id,
+                target_worker_id,
+                oplog_index_cut_off,
+            )
             .await?;
 
         new_oplog.commit(CommitLevel::Always).await;
@@ -494,12 +538,18 @@ impl<Ctx: WorkerCtx> WorkerForkService for DefaultWorkerFork<Ctx> {
 
     async fn fork_and_write_fork_result(
         &self,
+        fork_account_id: &AccountId,
         source_worker_id: &OwnedWorkerId,
         target_worker_id: &WorkerId,
         oplog_index_cut_off: OplogIndex,
     ) -> Result<(), WorkerExecutorError> {
         let new_oplog = self
-            .copy_source_oplog(source_worker_id, target_worker_id, oplog_index_cut_off)
+            .copy_source_oplog(
+                fork_account_id,
+                source_worker_id,
+                target_worker_id,
+                oplog_index_cut_off,
+            )
             .await?;
 
         // durability.persist will write an ImportedFunctionInvoked entry persisting ForkResult::Original
diff --git a/golem-worker-executor/src/services/worker_proxy.rs b/golem-worker-executor/src/services/worker_proxy.rs
index 8d80e513..ec7eabda 100644
--- a/golem-worker-executor/src/services/worker_proxy.rs
+++ b/golem-worker-executor/src/services/worker_proxy.rs
@@ -17,11 +17,12 @@ use async_trait::async_trait;
 use bincode::{Decode, Encode};
 use golem_api_grpc::proto::golem::worker::v1::worker_service_client::WorkerServiceClient;
 use golem_api_grpc::proto::golem::worker::v1::{
-    fork_worker_response, invoke_and_await_typed_response, invoke_response, resume_worker_response,
-    revert_worker_response, update_worker_response, worker_error, ForkWorkerRequest,
-    InvokeAndAwaitRequest, InvokeAndAwaitTypedResponse, InvokeRequest, InvokeResponse,
-    ResumeWorkerRequest, ResumeWorkerResponse, RevertWorkerRequest, RevertWorkerResponse,
-    UpdateWorkerRequest, UpdateWorkerResponse, WorkerError,
+    fork_worker_response, invoke_and_await_typed_response, invoke_response,
+    launch_new_worker_response, resume_worker_response, revert_worker_response,
+    update_worker_response, worker_error, ForkWorkerRequest, InvokeAndAwaitRequest,
+    InvokeAndAwaitTypedResponse, InvokeRequest, InvokeResponse, LaunchNewWorkerRequest,
+    LaunchNewWorkerResponse, ResumeWorkerRequest, ResumeWorkerResponse, RevertWorkerRequest,
+    RevertWorkerResponse, UpdateWorkerRequest, UpdateWorkerResponse, WorkerError,
 };
 use golem_api_grpc::proto::golem::worker::{InvokeParameters, UpdateMode};
 use golem_common::client::{GrpcClient, GrpcClientConfig};
@@ -32,7 +33,7 @@ use golem_service_base::error::worker_executor::WorkerExecutorError;
 use golem_service_base::model::RevertWorkerTarget;
 use golem_wasm_rpc::{Value, ValueAndType, WitValue};
 use http::Uri;
-use std::collections::HashMap;
+use std::collections::{BTreeMap, HashMap};
 use std::error::Error;
 use std::fmt::{Display, Formatter};
 use std::time::Duration;
@@ -43,6 +44,14 @@ use uuid::Uuid;
 
 #[async_trait]
 pub trait WorkerProxy: Send + Sync {
+    async fn start(
+        &self,
+        owned_worker_id: &OwnedWorkerId,
+        caller_args: Vec<String>,
+        caller_env: HashMap<String, String>,
+        caller_wasi_config_vars: BTreeMap<String, String>,
+    ) -> Result<(), WorkerProxyError>;
+
     async fn invoke_and_await(
         &self,
         owned_worker_id: &OwnedWorkerId,
@@ -52,6 +61,7 @@ pub trait WorkerProxy: Send + Sync {
         caller_worker_id: WorkerId,
         caller_args: Vec<String>,
         caller_env: HashMap<String, String>,
+        caller_wasi_config_vars: BTreeMap<String, String>,
         caller_stack: InvocationContextStack,
     ) -> Result<Option<ValueAndType>, WorkerProxyError>;
 
@@ -64,6 +74,7 @@ pub trait WorkerProxy: Send + Sync {
         caller_worker_id: WorkerId,
         caller_args: Vec<String>,
         caller_env: HashMap<String, String>,
+        caller_wasi_config_vars: BTreeMap<String, String>,
         caller_stack: InvocationContextStack,
     ) -> Result<(), WorkerProxyError>;
 
@@ -86,7 +97,7 @@ pub trait WorkerProxy: Send + Sync {
 
     async fn revert(
         &self,
-        worker_id: WorkerId,
+        worker_id: &WorkerId,
         target: RevertWorkerTarget,
     ) -> Result<(), WorkerProxyError>;
 }
@@ -214,6 +225,48 @@ impl RemoteWorkerProxy {
 
 #[async_trait]
 impl WorkerProxy for RemoteWorkerProxy {
+    async fn start(
+        &self,
+        owned_worker_id: &OwnedWorkerId,
+        caller_args: Vec<String>,
+        caller_env: HashMap<String, String>,
+        caller_wasi_config_vars: BTreeMap<String, String>,
+    ) -> Result<(), WorkerProxyError> {
+        debug!(owned_worker_id=%owned_worker_id, "Starting remote worker");
+
+        let response: LaunchNewWorkerResponse = self
+            .client
+            .call("launch_new_worker", move |client| {
+                let caller_args = caller_args.clone();
+                let caller_env = caller_env.clone();
+                let caller_wasi_config_vars = caller_wasi_config_vars.clone();
+                Box::pin(client.launch_new_worker(authorised_grpc_request(
+                    LaunchNewWorkerRequest {
+                        component_id: Some(owned_worker_id.component_id().into()),
+                        name: owned_worker_id.worker_name(),
+                        args: caller_args,
+                        env: caller_env,
+                        wasi_config_vars: Some(caller_wasi_config_vars.clone().into()),
+                        ignore_already_existing: true,
+                    },
+                    &self.access_token,
+                )))
+            })
+            .await?
+            .into_inner();
+
+        match response.result {
+            Some(launch_new_worker_response::Result::Success(_)) => Ok(()),
+            Some(launch_new_worker_response::Result::Error(error)) => match error.error {
+                Some(worker_error::Error::AlreadyExists(_)) => Ok(()),
+                _ => Err(error.into()),
+            },
+            None => Err(WorkerProxyError::InternalError(
+                WorkerExecutorError::unknown("Empty response through the worker API".to_string()),
+            )),
+        }
+    }
+
     async fn invoke_and_await(
         &self,
         owned_worker_id: &OwnedWorkerId,
@@ -223,6 +276,7 @@ impl WorkerProxy for RemoteWorkerProxy {
         caller_worker_id: WorkerId,
         caller_args: Vec<String>,
         caller_env: HashMap<String, String>,
+        caller_wasi_config_vars: BTreeMap<String, String>,
         caller_stack: InvocationContextStack,
     ) -> Result<Option<ValueAndType>, WorkerProxyError> {
         debug!(
@@ -245,7 +299,7 @@ impl WorkerProxy for RemoteWorkerProxy {
             .call("invoke_and_await_typed", move |client| {
                 Box::pin(client.invoke_and_await_typed(authorised_grpc_request(
                     InvokeAndAwaitRequest {
-                        worker_id: Some(owned_worker_id.worker_id().into_target_worker_id().into()),
+                        worker_id: Some(owned_worker_id.worker_id().into()),
                         idempotency_key: idempotency_key.clone().map(|k| k.into()),
                         function: function_name.clone(),
                         invoke_parameters: invoke_parameters.clone(),
@@ -253,6 +307,7 @@ impl WorkerProxy for RemoteWorkerProxy {
                             parent: Some(caller_worker_id.clone().into()),
                             args: caller_args.clone(),
                             env: caller_env.clone(),
+                            wasi_config_vars: Some(caller_wasi_config_vars.clone().into()),
                             tracing: Some(caller_stack.clone().into()),
                         }),
                     },
@@ -266,21 +321,12 @@ impl WorkerProxy for RemoteWorkerProxy {
             Some(invoke_and_await_typed_response::Result::Success(result)) => {
                 let result = result
                     .result
-                    .map(|tav| {
-                        tav.type_annotated_value
-                            .ok_or(WorkerProxyError::InternalError(
-                                WorkerExecutorError::unknown(
-                                    "Missing type_annotated_value in the worker API response"
-                                        .to_string(),
-                                ),
-                            ))
-                            .and_then(|tav| {
-                                ValueAndType::try_from(tav).map_err(|e| {
-                                    WorkerProxyError::InternalError(WorkerExecutorError::unknown(
-                                        format!("Failed to parse invocation result value: {e}"),
-                                    ))
-                                })
-                            })
+                    .map(|proto_vnt| {
+                        ValueAndType::try_from(proto_vnt).map_err(|e| {
+                            WorkerProxyError::InternalError(WorkerExecutorError::unknown(format!(
+                                "Failed to parse invocation result value: {e}"
+                            )))
+                        })
                     })
                     .transpose()?;
                 Ok(result)
@@ -301,6 +347,7 @@ impl WorkerProxy for RemoteWorkerProxy {
         caller_worker_id: WorkerId,
         caller_args: Vec<String>,
         caller_env: HashMap<String, String>,
+        caller_wasi_config_vars: BTreeMap<String, String>,
         caller_stack: InvocationContextStack,
     ) -> Result<(), WorkerProxyError> {
         debug!("Invoking remote worker function {function_name} with parameters {function_params:?} without awaiting for the result");
@@ -321,7 +368,7 @@ impl WorkerProxy for RemoteWorkerProxy {
             .call("invoke", move |client| {
                 Box::pin(client.invoke(authorised_grpc_request(
                     InvokeRequest {
-                        worker_id: Some(owned_worker_id.worker_id().into_target_worker_id().into()),
+                        worker_id: Some(owned_worker_id.worker_id().into()),
                         idempotency_key: idempotency_key.clone().map(|k| k.into()),
                         function: function_name.clone(),
                         invoke_parameters: invoke_parameters.clone(),
@@ -329,6 +376,7 @@ impl WorkerProxy for RemoteWorkerProxy {
                             parent: Some(caller_worker_id.clone().into()),
                             args: caller_args.clone(),
                             env: caller_env.clone(),
+                            wasi_config_vars: Some(caller_wasi_config_vars.clone().into()),
                             tracing: Some(caller_stack.clone().into()),
                         }),
                     },
@@ -441,7 +489,7 @@ impl WorkerProxy for RemoteWorkerProxy {
 
     async fn revert(
         &self,
-        worker_id: WorkerId,
+        worker_id: &WorkerId,
         target: RevertWorkerTarget,
     ) -> Result<(), WorkerProxyError> {
         let response: RevertWorkerResponse = self
diff --git a/golem-worker-executor/src/storage/keyvalue/mod.rs b/golem-worker-executor/src/storage/keyvalue/mod.rs
index 45b05535..720805df 100644
--- a/golem-worker-executor/src/storage/keyvalue/mod.rs
+++ b/golem-worker-executor/src/storage/keyvalue/mod.rs
@@ -19,7 +19,7 @@ pub mod sqlite;
 use async_trait::async_trait;
 use bincode::{Decode, Encode};
 use bytes::Bytes;
-use golem_common::model::AccountId;
+use golem_common::base_model::ProjectId;
 use golem_common::serialization::{deserialize, serialize};
 use std::fmt::Debug;
 
@@ -625,7 +625,7 @@ pub enum KeyValueStorageNamespace {
     Promise,
     Schedule,
     UserDefined {
-        account_id: AccountId,
+        project_id: ProjectId,
         bucket: String,
     },
 }
diff --git a/golem-worker-executor/src/storage/keyvalue/redis.rs b/golem-worker-executor/src/storage/keyvalue/redis.rs
index 2c6a580d..9177dff0 100644
--- a/golem-worker-executor/src/storage/keyvalue/redis.rs
+++ b/golem-worker-executor/src/storage/keyvalue/redis.rs
@@ -37,8 +37,8 @@ impl RedisKeyValueStorage {
             KeyValueStorageNamespace::Worker => None,
             KeyValueStorageNamespace::Promise => Some("promises".to_string()),
             KeyValueStorageNamespace::Schedule => None,
-            KeyValueStorageNamespace::UserDefined { account_id, bucket } => {
-                Some(format!("user-defined:{account_id}:{bucket}"))
+            KeyValueStorageNamespace::UserDefined { project_id, bucket } => {
+                Some(format!("user-defined:{project_id}:{bucket}"))
             }
         }
     }
diff --git a/golem-worker-executor/src/storage/keyvalue/sqlite.rs b/golem-worker-executor/src/storage/keyvalue/sqlite.rs
index e7a1b00f..718bbcea 100644
--- a/golem-worker-executor/src/storage/keyvalue/sqlite.rs
+++ b/golem-worker-executor/src/storage/keyvalue/sqlite.rs
@@ -96,8 +96,8 @@ impl SqliteKeyValueStorage {
             KeyValueStorageNamespace::Worker => "worker".to_string(),
             KeyValueStorageNamespace::Promise => "promise".to_string(),
             KeyValueStorageNamespace::Schedule => "schedule".to_string(),
-            KeyValueStorageNamespace::UserDefined { account_id, bucket } => {
-                format!("user-defined:{account_id}:{bucket}")
+            KeyValueStorageNamespace::UserDefined { project_id, bucket } => {
+                format!("user-defined:{project_id}:{bucket}")
             }
         }
     }
diff --git a/golem-worker-executor/src/worker/invocation.rs b/golem-worker-executor/src/worker/invocation.rs
index f53acc51..00d6009c 100644
--- a/golem-worker-executor/src/worker/invocation.rs
+++ b/golem-worker-executor/src/worker/invocation.rs
@@ -17,13 +17,12 @@ use crate::model::TrapType;
 use crate::virtual_export_compat;
 use crate::workerctx::{PublicWorkerIo, WorkerCtx};
 use anyhow::anyhow;
-use golem_common::model::oplog::{WorkerError, WorkerResourceId};
+use golem_common::model::component_metadata::{ComponentMetadata, InvokableFunction};
+use golem_common::model::oplog::WorkerError;
 use golem_common::model::{IdempotencyKey, WorkerStatus};
 use golem_common::virtual_exports;
 use golem_service_base::error::worker_executor::{InterruptKind, WorkerExecutorError};
-use golem_wasm_rpc::wasmtime::{
-    decode_param, encode_output, type_to_analysed_type, DecodeParamResult,
-};
+use golem_wasm_rpc::wasmtime::{decode_param, encode_output, DecodeParamResult};
 use golem_wasm_rpc::Value;
 use rib::{ParsedFunctionName, ParsedFunctionReference};
 use tracing::{debug, error, Instrument};
@@ -46,6 +45,7 @@ pub async fn invoke_observed_and_traced<Ctx: WorkerCtx>(
     function_input: Vec<Value>,
     store: &mut impl AsContextMut<Data = Ctx>,
     instance: &wasmtime::component::Instance,
+    component_metadata: &ComponentMetadata,
 ) -> Result<InvokeResult, WorkerExecutorError> {
     let mut store = store.as_context_mut();
     let was_live_before = store.data().is_live();
@@ -57,6 +57,7 @@ pub async fn invoke_observed_and_traced<Ctx: WorkerCtx>(
         function_input,
         &mut store,
         instance,
+        component_metadata,
     )
     .await;
 
@@ -101,30 +102,6 @@ pub async fn invoke_observed_and_traced<Ctx: WorkerCtx>(
     }
 }
 
-/// Returns the first function from the given list that is available on the instance
-///
-/// This can be used to find an exported function when multiple versions of an interface
-/// is supported, such as for the load-snapshot/save-snapshot interfaces.
-///
-/// This function should not be used on the hot path.
-pub fn find_first_available_function<Ctx: WorkerCtx>(
-    store: &mut impl AsContextMut<Data = Ctx>,
-    instance: &wasmtime::component::Instance,
-    names: Vec<String>,
-) -> Option<String> {
-    let mut store = store.as_context_mut();
-    for name in names {
-        let parsed = ParsedFunctionName::parse(&name).ok()?;
-
-        if let Ok(FindFunctionResult::ExportedFunction(_)) =
-            find_function(&mut store, instance, &parsed)
-        {
-            return Some(name);
-        }
-    }
-    None
-}
-
 fn find_function<'a, Ctx: WorkerCtx>(
     mut store: &mut StoreContextMut<'a, Ctx>,
     instance: &'a wasmtime::component::Instance,
@@ -139,7 +116,6 @@ fn find_function<'a, Ctx: WorkerCtx>(
     if matches!(
         parsed_function_ref,
         ParsedFunctionReference::RawResourceDrop { .. }
-            | ParsedFunctionReference::IndexedResourceDrop { .. }
     ) {
         return Ok(FindFunctionResult::ResourceDrop);
     }
@@ -198,9 +174,10 @@ fn find_function<'a, Ctx: WorkerCtx>(
 /// Invokes a worker and calls the appropriate hooks to observe the invocation
 async fn invoke_observed<Ctx: WorkerCtx>(
     full_function_name: String,
-    mut function_input: Vec<Value>,
+    function_input: Vec<Value>,
     store: &mut impl AsContextMut<Data = Ctx>,
     instance: &wasmtime::component::Instance,
+    component_metadata: &ComponentMetadata,
 ) -> Result<InvokeResult, WorkerExecutorError> {
     let mut store = store.as_context_mut();
 
@@ -210,14 +187,9 @@ async fn invoke_observed<Ctx: WorkerCtx>(
 
     let function = find_function(&mut store, instance, &parsed)?;
 
-    let decoded_params = validate_function_parameters(
-        &mut store,
-        &function,
-        &full_function_name,
-        &function_input,
-        parsed.function().is_indexed_resource(),
-    )
-    .await?;
+    let decoded_params =
+        validate_function_parameters(&mut store, &function, &full_function_name, &function_input)
+            .await?;
 
     if store.data().is_live() {
         store
@@ -232,61 +204,35 @@ async fn invoke_observed<Ctx: WorkerCtx>(
         .store_worker_status(WorkerStatus::Running)
         .await;
 
-    let mut extra_fuel = 0;
-
-    if parsed.function().is_indexed_resource() {
-        let resource_handle =
-            get_or_create_indexed_resource(&mut store, instance, &parsed, &full_function_name)
-                .await?;
-
-        match resource_handle {
-            InvokeResult::Succeeded {
-                consumed_fuel,
-                output,
-            } => {
-                function_input = [output.into_iter().collect(), function_input].concat();
-                extra_fuel = consumed_fuel;
-            }
-            other => {
-                // Early return because of a failed invocation of the resource constructor
-                return Ok(other);
-            }
-        }
-    }
+    let metadata = component_metadata
+        .find_parsed_function(&parsed)
+        .await
+        .map_err(WorkerExecutorError::runtime)?
+        .ok_or_else(|| {
+            WorkerExecutorError::invalid_request(format!(
+                "Could not find exported function: {parsed}"
+            ))
+        })?;
 
-    let mut call_result = match function {
+    let call_result = match function {
         FindFunctionResult::ExportedFunction(function) => {
-            let final_decoded_params = if parsed.function().is_indexed_resource() {
-                let param_types = function.params(&store);
-                let decoded_self_param =
-                    decode_param(&function_input[0], &param_types[0].1, store.data_mut()).await?;
-
-                let mut result = vec![decoded_self_param];
-                result.extend(decoded_params);
-                result
-            } else {
-                decoded_params
-            };
-
             invoke(
                 &mut store,
                 function,
-                final_decoded_params,
+                decoded_params,
                 &full_function_name,
+                &metadata,
             )
             .await
         }
         FindFunctionResult::ResourceDrop => {
             // Special function: drop
-            drop_resource(&mut store, &parsed, &function_input, &full_function_name).await
+            drop_resource(&mut store, &function_input, &full_function_name).await
         }
         FindFunctionResult::IncomingHttpHandlerBridge => {
             invoke_http_handler(&mut store, instance, &function_input, &full_function_name).await
         }
     };
-    if let Ok(r) = call_result.as_mut() {
-        r.add_fuel(extra_fuel);
-    }
 
     store.data().set_suspended().await?;
 
@@ -298,17 +244,11 @@ async fn validate_function_parameters(
     function: &FindFunctionResult,
     raw_function_name: &str,
     function_input: &[Value],
-    using_indexed_resource: bool,
 ) -> Result<Vec<DecodeParamResult>, WorkerExecutorError> {
     match function {
         FindFunctionResult::ExportedFunction(func) => {
             let mut store = store.as_context_mut();
-            let param_types: Vec<_> = if using_indexed_resource {
-                // For indexed resources we are going to inject the resource handle as the first parameter
-                // later so we only have to validate the remaining parameters
-                let params = func.params(&store);
-                params.iter().skip(1).cloned().collect()
-            } else {
+            let param_types: Vec<_> = {
                 let params = func.params(&store);
                 params.to_vec()
             };
@@ -333,152 +273,36 @@ async fn validate_function_parameters(
             Ok(results)
         }
         FindFunctionResult::ResourceDrop => {
-            let expected = if using_indexed_resource { 0 } else { 1 };
-            if function_input.len() != expected {
+            if function_input.len() != 1 {
                 return Err(WorkerExecutorError::ValueMismatch {
                     details: "unexpected parameter count for drop".to_string(),
                 });
             }
 
-            if !using_indexed_resource {
-                let store = store.as_context_mut();
-                let self_uri = store.data().self_uri();
-
-                match function_input.first() {
-                    Some(Value::Handle { uri, resource_id }) => {
-                        if uri == &self_uri.value {
-                            Ok(*resource_id)
-                        } else {
-                            Err(WorkerExecutorError::ValueMismatch {
-                                details: format!(
-                                    "trying to drop handle for on wrong worker ({} vs {}) {}",
-                                    uri, self_uri.value, raw_function_name
-                                ),
-                            })
-                        }
+            let store = store.as_context_mut();
+            let self_uri = store.data().self_uri();
+
+            match function_input.first() {
+                Some(Value::Handle { uri, resource_id }) => {
+                    if uri == &self_uri.value {
+                        Ok(*resource_id)
+                    } else {
+                        Err(WorkerExecutorError::ValueMismatch {
+                            details: format!(
+                                "trying to drop handle for on wrong worker ({} vs {}) {}",
+                                uri, self_uri.value, raw_function_name
+                            ),
+                        })
                     }
-                    _ => Err(WorkerExecutorError::ValueMismatch {
-                        details: format!(
-                            "unexpected function input for drop for {raw_function_name}"
-                        ),
-                    }),
-                }?;
-            }
-            Ok(vec![])
-        }
-        FindFunctionResult::IncomingHttpHandlerBridge => Ok(vec![]),
-    }
-}
-
-async fn get_or_create_indexed_resource<'a, Ctx: WorkerCtx>(
-    store: &mut StoreContextMut<'a, Ctx>,
-    instance: &'a wasmtime::component::Instance,
-    parsed_function_name: &ParsedFunctionName,
-    raw_function_name: &str,
-) -> Result<InvokeResult, WorkerExecutorError> {
-    let resource_name = parsed_function_name.function().resource_name().ok_or(
-        WorkerExecutorError::invalid_request("Cannot extract resource name from function name"),
-    )?;
-
-    let resource_constructor_name = ParsedFunctionName::new(
-        parsed_function_name.site().clone(),
-        ParsedFunctionReference::RawResourceConstructor {
-            resource: resource_name.clone(),
-        },
-    );
-
-    let resource_constructor = if let FindFunctionResult::ExportedFunction(func) =
-        find_function(store, instance, &resource_constructor_name)?
-    {
-        func
-    } else {
-        Err(WorkerExecutorError::invalid_request(format!(
-            "could not find resource constructor for resource {resource_name}"
-        )))?
-    };
-
-    let constructor_param_types = resource_constructor.params(store as &StoreContextMut<'a, Ctx>).iter().map(
-        |(_, t)| type_to_analysed_type(t)).collect::<Result<Vec<_>, _>>()
-        .map_err(|err| WorkerExecutorError::invalid_request(format!("Indexed resource invocation cannot be used with owned or borrowed resource handles in constructor parameter position! ({err})")))?;
-
-    let raw_constructor_params = parsed_function_name
-        .function()
-        .raw_resource_params()
-        .ok_or(WorkerExecutorError::invalid_request(
-            "Could not extract raw resource constructor parameters from function name",
-        ))?;
-
-    match store
-        .data()
-        .get_indexed_resource(resource_name, raw_constructor_params)
-    {
-        Some(resource_id) => {
-            debug!("Using existing indexed resource with id {resource_id}");
-            Ok(InvokeResult::from_success(
-                0,
-                Some(Value::Handle {
-                    uri: store.data().self_uri().value,
-                    resource_id: resource_id.0,
-                }),
-            ))
-        }
-        None => {
-            let constructor_params = parsed_function_name
-                .function()
-                .resource_params(&constructor_param_types)
-                .map_err(|err| {
-                    WorkerExecutorError::invalid_request(format!(
-                        "Failed to parse resource constructor parameters: {err}"
-                    ))
-                })?
-                .ok_or(WorkerExecutorError::invalid_request(
-                    "Could not extract resource constructor parameters from function name",
-                ))?;
-
-            let constructor_params: Vec<Value> = constructor_params
-                .into_iter()
-                .map(|vnt| vnt.value)
-                .collect();
-
-            let decoded_constructor_params: Vec<DecodeParamResult> = validate_function_parameters(
-                store,
-                &FindFunctionResult::ExportedFunction(resource_constructor),
-                raw_function_name,
-                &constructor_params,
-                false,
-            )
-            .await?;
-
-            debug!("Creating new indexed resource with parameters {constructor_params:?}");
-
-            let constructor_result = invoke(
-                store,
-                resource_constructor,
-                decoded_constructor_params,
-                raw_function_name,
-            )
-            .await?;
-
-            if let InvokeResult::Succeeded { output, .. } = &constructor_result {
-                if let Some(Value::Handle { resource_id, .. }) = output {
-                    debug!("Storing indexed resource with id {resource_id}");
-                    store
-                        .data_mut()
-                        .store_indexed_resource(
-                            resource_name,
-                            raw_constructor_params,
-                            WorkerResourceId(*resource_id),
-                        )
-                        .await;
-                } else {
-                    return Err(WorkerExecutorError::invalid_request(
-                        "Resource constructor did not return a resource handle",
-                    ));
                 }
-            }
+                _ => Err(WorkerExecutorError::ValueMismatch {
+                    details: format!("unexpected function input for drop for {raw_function_name}"),
+                }),
+            }?;
 
-            Ok(constructor_result)
+            Ok(vec![])
         }
+        FindFunctionResult::IncomingHttpHandlerBridge => Ok(vec![]),
     }
 }
 
@@ -487,6 +311,7 @@ async fn invoke<Ctx: WorkerCtx>(
     function: Func,
     decoded_function_input: Vec<DecodeParamResult>,
     raw_function_name: &str,
+    metadata: &InvokableFunction,
 ) -> Result<InvokeResult, WorkerExecutorError> {
     let mut store = store.as_context_mut();
 
@@ -514,9 +339,14 @@ async fn invoke<Ctx: WorkerCtx>(
                     "Function returned with more than one values, which is not supported",
                 ))
             } else {
-                match results.iter().zip(types.iter()).next() {
-                    Some((val, typ)) => {
-                        let output = encode_output(val, typ, store.data_mut())
+                match results
+                    .iter()
+                    .zip(types.iter())
+                    .zip(metadata.analysed_export.result.as_ref().map(|r| &r.typ))
+                    .next()
+                {
+                    Some(((val, typ), analysed_type)) => {
+                        let output = encode_output(val, typ, analysed_type, store.data_mut())
                             .await
                             .map_err(WorkerExecutorError::from)?;
                         Ok(InvokeResult::from_success(consumed_fuel, Some(output)))
@@ -525,10 +355,7 @@ async fn invoke<Ctx: WorkerCtx>(
                 }
             }
         }
-        Err(err) => {
-            println!("err: {err:?}");
-            Ok(InvokeResult::from_error::<Ctx>(consumed_fuel, &err))
-        }
+        Err(err) => Ok(InvokeResult::from_error::<Ctx>(consumed_fuel, &err)),
     }
 }
 
@@ -540,7 +367,7 @@ async fn invoke_http_handler<Ctx: WorkerCtx>(
 ) -> Result<InvokeResult, WorkerExecutorError> {
     let (sender, receiver) = tokio::sync::oneshot::channel();
 
-    let proxy = Proxy::new(&mut *store, instance).unwrap();
+    let proxy = Proxy::new(&mut *store, instance)?;
     let mut store_context = store.as_context_mut();
 
     store_context.data_mut().borrow_fuel().await?;
@@ -566,13 +393,11 @@ async fn invoke_http_handler<Ctx: WorkerCtx>(
         let incoming = store_context
             .data_mut()
             .as_wasi_http_view()
-            .new_incoming_request(scheme, hyper_request)
-            .unwrap();
+            .new_incoming_request(scheme, hyper_request)?;
         let outgoing = store_context
             .data_mut()
             .as_wasi_http_view()
-            .new_response_outparam(sender)
-            .unwrap();
+            .new_response_outparam(sender)?;
 
         // unsafety comes from scope_and_collect:
         //
@@ -603,10 +428,10 @@ async fn invoke_http_handler<Ctx: WorkerCtx>(
             // An error in the receiver (`RecvError`) only indicates that the
             // task exited before a response was sent (i.e., the sender was
             // dropped); it does not describe the underlying cause of failure.
-            // Instead we retrieve and propagate the error from inside the task
+            // Instead, we retrieve and propagate the error from inside the task
             // which should more clearly tell the user what went wrong. Note
-            // that we assume the task has already exited at this point so the
-            // `await` should resolve immediately.
+            // that we assume the task has already exited at this point, so the
+            // `await` should be resolved immediately.
             let task_exit = task_exits.remove(0);
             let e = match task_exit {
                 Ok(r) => r.expect_err("if the receiver has an error, the task must have failed"),
@@ -631,7 +456,6 @@ async fn invoke_http_handler<Ctx: WorkerCtx>(
 
 async fn drop_resource<Ctx: WorkerCtx>(
     store: &mut impl AsContextMut<Data = Ctx>,
-    parsed_function_name: &ParsedFunctionName,
     function_input: &[Value],
     raw_function_name: &str,
 ) -> Result<InvokeResult, WorkerExecutorError> {
@@ -642,20 +466,7 @@ async fn drop_resource<Ctx: WorkerCtx>(
         _ => unreachable!(), // previously validated by `validate_function_parameters`
     };
 
-    if let ParsedFunctionReference::IndexedResourceDrop {
-        resource,
-        resource_params,
-    } = parsed_function_name.function()
-    {
-        debug!(
-            "Dropping indexed resource {resource:?} with params {resource_params:?} in {raw_function_name}"
-        );
-        store
-            .data_mut()
-            .drop_indexed_resource(resource, resource_params);
-    }
-
-    if let Some(resource) = store.data_mut().get(resource_id).await {
+    if let Some((_, resource)) = store.data_mut().get(resource_id).await {
         debug!("Dropping resource {resource:?} in {raw_function_name}");
         store.data_mut().borrow_fuel().await?;
 
diff --git a/golem-worker-executor/src/worker/invocation_loop.rs b/golem-worker-executor/src/worker/invocation_loop.rs
index 5666f797..2fa03699 100644
--- a/golem-worker-executor/src/worker/invocation_loop.rs
+++ b/golem-worker-executor/src/worker/invocation_loop.rs
@@ -12,13 +12,11 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use crate::model::{ListDirectoryResult, ReadFileResult, TrapType};
+use crate::model::{ReadFileResult, TrapType};
 use crate::services::events::Event;
 use crate::services::oplog::{CommitLevel, OplogOps};
 use crate::services::{HasEvents, HasOplog, HasWorker};
-use crate::worker::invocation::{
-    find_first_available_function, invoke_observed_and_traced, InvokeResult,
-};
+use crate::worker::invocation::{invoke_observed_and_traced, InvokeResult};
 use crate::worker::{
     interpret_function_result, QueuedWorkerInvocation, RetryDecision, RunningWorker, Worker,
     WorkerCommand,
@@ -29,10 +27,13 @@ use async_mutex::Mutex;
 use drop_stream::DropStream;
 use futures::channel::oneshot;
 use futures::channel::oneshot::Sender;
-use golem_common::model::invocation_context::{AttributeValue, InvocationContextStack};
 use golem_common::model::oplog::WorkerError;
 use golem_common::model::{
-    exports, ComponentFilePath, ComponentType, ComponentVersion, IdempotencyKey, OwnedWorkerId,
+    invocation_context::{AttributeValue, InvocationContextStack},
+    GetFileSystemNodeResult,
+};
+use golem_common::model::{
+    ComponentFilePath, ComponentType, ComponentVersion, IdempotencyKey, OwnedWorkerId,
     TimestampedWorkerInvocation, WorkerId, WorkerInvocation,
 };
 use golem_common::retries::get_delay;
@@ -304,7 +305,7 @@ impl<Ctx: WorkerCtx> InnerInvocationLoop<'_, Ctx> {
     async fn resume_replay(&self) -> CommandOutcome {
         let mut store = self.store.lock().await;
 
-        let resume_replay_result = Ctx::resume_replay(&mut *store, self.instance).await;
+        let resume_replay_result = Ctx::resume_replay(&mut *store, self.instance, true).await;
 
         match resume_replay_result {
             Ok(RetryDecision::None) => CommandOutcome::Continue,
@@ -376,14 +377,18 @@ impl<Ctx: WorkerCtx> Invocation<'_, Ctx> {
                     CommandOutcome::Continue
                 }
             }
-            QueuedWorkerInvocation::ListDirectory { path, sender } => {
-                self.list_directory(path, sender).await;
+            QueuedWorkerInvocation::GetFileSystemNode { path, sender } => {
+                self.get_file_system_node(path, sender).await;
                 CommandOutcome::Continue
             }
             QueuedWorkerInvocation::ReadFile { path, sender } => {
                 self.read_file(path, sender).await;
                 CommandOutcome::Continue
             }
+            QueuedWorkerInvocation::AwaitReadyToProcessCommands { sender } => {
+                let _ = sender.send(Ok(()));
+                CommandOutcome::Continue
+            }
         }
     }
 
@@ -498,6 +503,8 @@ impl<Ctx: WorkerCtx> Invocation<'_, Ctx> {
             .set_current_idempotency_key(idempotency_key.clone())
             .await;
 
+        let component_metadata = self.store.data().component_metadata().metadata.clone();
+
         Self::extend_invocation_context(
             &mut invocation_context,
             &idempotency_key,
@@ -529,6 +536,7 @@ impl<Ctx: WorkerCtx> Invocation<'_, Ctx> {
             function_input.to_owned(),
             self.store,
             self.instance,
+            &component_metadata,
         )
         .await;
 
@@ -560,12 +568,14 @@ impl<Ctx: WorkerCtx> Invocation<'_, Ctx> {
     ) -> CommandOutcome {
         let component_metadata = self.store.as_context().data().component_metadata();
 
-        let function_results =
-            exports::function_by_name(&component_metadata.exports, &full_function_name);
+        let function_results = component_metadata
+            .metadata
+            .find_function(&full_function_name)
+            .await;
 
         match function_results {
-            Ok(Some(export_function)) => {
-                let function_results = export_function.result.clone();
+            Ok(Some(invokable_function)) => {
+                let function_results = invokable_function.analysed_export.result.clone();
 
                 match self
                     .exported_function_invocation_finished_with_type(
@@ -704,105 +714,118 @@ impl<Ctx: WorkerCtx> Invocation<'_, Ctx> {
                 .await;
             idempotency_key
         };
-
-        if let Some(save_snapshot) = find_first_available_function(
-            self.store,
-            self.instance,
-            vec![
-                "golem:api/save-snapshot@1.1.0.{save}".to_string(),
-                "golem:api/save-snapshot@0.2.0.{save}".to_string(),
-            ],
-        ) {
-            self.store.data_mut().begin_call_snapshotting_function();
-
-            let result =
-                invoke_observed_and_traced(save_snapshot, vec![], self.store, self.instance).await;
-            self.store.data_mut().end_call_snapshotting_function();
-
-            match result {
-                Ok(InvokeResult::Succeeded { output, .. }) => {
-                    if let Some(bytes) = Self::decode_snapshot_result(output) {
-                        match self
-                            .store
-                            .data()
-                            .get_public_state()
-                            .oplog()
-                            .create_snapshot_based_update_description(target_version, &bytes)
-                            .await
-                        {
-                            Ok(update_description) => {
-                                // Enqueue the update
-                                self.parent.enqueue_update(update_description).await;
-
-                                // Make sure to update the pending updates queue
-                                self.store.data().update_pending_updates().await;
-
-                                // Reactivate the worker
-                                CommandOutcome::BreakInnerLoop(RetryDecision::Immediate)
-                                // Stop processing the queue to avoid race conditions
-                            }
-                            Err(error) => {
-                                self.fail_update(
-                                    target_version,
-                                    format!(
-                                        "failed to store the snapshot for manual update: {error}"
-                                    ),
-                                )
+        let component_metadata = self.store.data().component_metadata().metadata.clone();
+
+        match component_metadata.save_snapshot().await {
+            Ok(Some(save_snapshot)) => {
+                self.store.data_mut().begin_call_snapshotting_function();
+
+                let result = invoke_observed_and_traced(
+                    save_snapshot.name.to_string(),
+                    vec![],
+                    self.store,
+                    self.instance,
+                    &component_metadata,
+                )
+                .await;
+                self.store.data_mut().end_call_snapshotting_function();
+
+                match result {
+                    Ok(InvokeResult::Succeeded { output, .. }) => {
+                        if let Some(bytes) = Self::decode_snapshot_result(output) {
+                            match self
+                                .store
+                                .data()
+                                .get_public_state()
+                                .oplog()
+                                .create_snapshot_based_update_description(target_version, &bytes)
                                 .await
+                            {
+                                Ok(update_description) => {
+                                    // Enqueue the update
+                                    self.parent.enqueue_update(update_description).await;
+
+                                    // Make sure to update the pending updates queue
+                                    self.store.data().update_pending_updates().await;
+
+                                    // Reactivate the worker
+                                    CommandOutcome::BreakInnerLoop(RetryDecision::Immediate)
+                                    // Stop processing the queue to avoid race conditions
+                                }
+                                Err(error) => {
+                                    self.fail_update(
+                                        target_version,
+                                        format!(
+                                            "failed to store the snapshot for manual update: {error}"
+                                        ),
+                                    )
+                                        .await
+                                }
                             }
+                        } else {
+                            self.fail_update(
+                                target_version,
+                                "failed to get a snapshot for manual update: invalid snapshot result"
+                                    .to_string(),
+                            )
+                                .await
                         }
-                    } else {
+                    }
+                    Ok(InvokeResult::Failed { error, .. }) => {
+                        let stderr = self
+                            .store
+                            .data()
+                            .get_public_state()
+                            .event_service()
+                            .get_last_invocation_errors();
+                        let error = error.to_string(&stderr);
                         self.fail_update(
                             target_version,
-                            "failed to get a snapshot for manual update: invalid snapshot result"
+                            format!("failed to get a snapshot for manual update: {error}"),
+                        )
+                        .await
+                    }
+                    Ok(InvokeResult::Exited { .. }) => {
+                        self.fail_update(
+                            target_version,
+                            "failed to get a snapshot for manual update: it called exit"
                                 .to_string(),
                         )
                         .await
                     }
-                }
-                Ok(InvokeResult::Failed { error, .. }) => {
-                    let stderr = self
-                        .store
-                        .data()
-                        .get_public_state()
-                        .event_service()
-                        .get_last_invocation_errors();
-                    let error = error.to_string(&stderr);
-                    self.fail_update(
-                        target_version,
-                        format!("failed to get a snapshot for manual update: {error}"),
-                    )
-                    .await
-                }
-                Ok(InvokeResult::Exited { .. }) => {
-                    self.fail_update(
-                        target_version,
-                        "failed to get a snapshot for manual update: it called exit".to_string(),
-                    )
-                    .await
-                }
-                Ok(InvokeResult::Interrupted { interrupt_kind, .. }) => {
-                    self.fail_update(
-                        target_version,
-                        format!("failed to get a snapshot for manual update: {interrupt_kind:?}"),
-                    )
-                    .await
-                }
-                Err(error) => {
-                    self.fail_update(
-                        target_version,
-                        format!("failed to get a snapshot for manual update: {error:?}"),
-                    )
-                    .await
+                    Ok(InvokeResult::Interrupted { interrupt_kind, .. }) => {
+                        self.fail_update(
+                            target_version,
+                            format!(
+                                "failed to get a snapshot for manual update: {interrupt_kind:?}"
+                            ),
+                        )
+                        .await
+                    }
+                    Err(error) => {
+                        self.fail_update(
+                            target_version,
+                            format!("failed to get a snapshot for manual update: {error:?}"),
+                        )
+                        .await
+                    }
                 }
             }
-        } else {
-            self.fail_update(
-                target_version,
-                "failed to get a snapshot for manual update: save-snapshot is not exported"
-                    .to_string(),
-            )
-            .await
+            Ok(None) => {
+                self.fail_update(
+                    target_version,
+                    "failed to get a snapshot for manual update: save-snapshot is not exported"
+                        .to_string(),
+                )
+                .await
+            }
+            Err(error) => {
+                self.fail_update(
+                    target_version,
+                    format!("failed to get a snapshot for manual update: error while finding the exported save-snapshot function: {error}"),
+                )
+                .await
+            }
         }
     }
 
@@ -810,12 +833,12 @@ impl<Ctx: WorkerCtx> Invocation<'_, Ctx> {
     ///
     /// These are threaded through the invocation loop to make sure they are not accessing the file system concurrently with invocations
     /// that may modify them.
-    async fn list_directory(
+    async fn get_file_system_node(
         &self,
         path: ComponentFilePath,
-        sender: Sender<Result<ListDirectoryResult, WorkerExecutorError>>,
+        sender: Sender<Result<GetFileSystemNodeResult, WorkerExecutorError>>,
     ) {
-        let result = self.store.data().list_directory(&path).await;
+        let result = self.store.data().get_file_system_node(&path).await;
         let _ = sender.send(result);
     }
 
diff --git a/golem-worker-executor/src/worker/mod.rs b/golem-worker-executor/src/worker/mod.rs
index 16f3c4d6..a50fe2d0 100644
--- a/golem-worker-executor/src/worker/mod.rs
+++ b/golem-worker-executor/src/worker/mod.rs
@@ -16,48 +16,47 @@ pub mod invocation;
 mod invocation_loop;
 pub mod status;
 
-use std::collections::{HashMap, HashSet, VecDeque};
+use std::collections::{BTreeMap, HashMap, HashSet, VecDeque};
 use std::mem;
 use std::sync::atomic::{AtomicBool, Ordering};
 use std::sync::Arc;
 use std::time::Duration;
 
 use crate::durable_host::recover_stderr_logs;
-use crate::model::{
-    ExecutionStatus, ListDirectoryResult, LookupResult, ReadFileResult, TrapType, WorkerConfig,
-};
+use crate::model::{ExecutionStatus, LookupResult, ReadFileResult, TrapType, WorkerConfig};
 use crate::services::events::{Event, EventsSubscription};
 use crate::services::oplog::{CommitLevel, Oplog, OplogOps};
 use crate::services::worker_event::{WorkerEventService, WorkerEventServiceDefault};
 use crate::services::{
-    All, HasActiveWorkers, HasAll, HasBlobStoreService, HasComponentService, HasConfig, HasEvents,
-    HasExtraDeps, HasFileLoader, HasKeyValueService, HasOplog, HasOplogService, HasPlugins,
-    HasPromiseService, HasRdbmsService, HasResourceLimits, HasRpc, HasSchedulerService,
-    HasWasmtimeEngine, HasWorkerEnumerationService, HasWorkerForkService, HasWorkerProxy,
-    HasWorkerService, UsesAllDeps,
+    All, HasActiveWorkers, HasAgentTypesService, HasAll, HasBlobStoreService, HasComponentService,
+    HasConfig, HasEvents, HasExtraDeps, HasFileLoader, HasKeyValueService, HasOplog,
+    HasOplogService, HasPlugins, HasProjectService, HasPromiseService, HasRdbmsService,
+    HasResourceLimits, HasRpc, HasSchedulerService, HasWasmtimeEngine, HasWorkerEnumerationService,
+    HasWorkerForkService, HasWorkerProxy, HasWorkerService, UsesAllDeps,
 };
 use crate::worker::invocation_loop::InvocationLoop;
 use crate::worker::status::calculate_last_known_status;
 use crate::workerctx::WorkerCtx;
 use anyhow::anyhow;
 use futures::channel::oneshot;
+use golem_common::model::agent::AgentId;
 use golem_common::model::invocation_context::InvocationContextStack;
 use golem_common::model::oplog::{
     OplogEntry, OplogIndex, TimestampedUpdateDescription, UpdateDescription, WorkerError,
 };
 use golem_common::model::regions::{DeletedRegions, DeletedRegionsBuilder, OplogRegion};
-use golem_common::model::RetryConfig;
+use golem_common::model::{AccountId, RetryConfig};
 use golem_common::model::{ComponentFilePath, ComponentType, PluginInstallationId};
 use golem_common::model::{
-    ComponentVersion, IdempotencyKey, OwnedWorkerId, Timestamp, TimestampedWorkerInvocation,
-    WorkerId, WorkerInvocation, WorkerMetadata, WorkerStatusRecord,
+    ComponentVersion, GetFileSystemNodeResult, IdempotencyKey, OwnedWorkerId, Timestamp,
+    TimestampedWorkerInvocation, WorkerId, WorkerInvocation, WorkerMetadata, WorkerStatusRecord,
 };
 use golem_service_base::error::worker_executor::{
     InterruptKind, WorkerExecutorError, WorkerOutOfMemory,
 };
 use golem_service_base::model::RevertWorkerTarget;
 use golem_wasm_ast::analysis::AnalysedFunctionResult;
-use golem_wasm_rpc::{Value, ValueAndType};
+use golem_wasm_rpc::{IntoValue, Value, ValueAndType};
 use tokio::sync::broadcast::error::RecvError;
 use tokio::sync::broadcast::Receiver;
 use tokio::sync::mpsc::{UnboundedReceiver, UnboundedSender};
@@ -118,11 +117,14 @@ impl<Ctx: WorkerCtx> Worker<Ctx> {
     /// Gets or creates a worker, but does not start it
     pub async fn get_or_create_suspended<T>(
         deps: &T,
+        account_id: &AccountId,
         owned_worker_id: &OwnedWorkerId,
         worker_args: Option<Vec<String>>,
         worker_env: Option<Vec<(String, String)>>,
+        worker_wasi_config_vars: Option<BTreeMap<String, String>>,
         component_version: Option<u64>,
         parent: Option<WorkerId>,
+        invocation_context_stack: &InvocationContextStack,
     ) -> Result<Arc<Self>, WorkerExecutorError>
     where
         T: HasAll<Ctx> + Clone + Send + Sync + 'static,
@@ -131,10 +133,13 @@ impl<Ctx: WorkerCtx> Worker<Ctx> {
             .get_or_add(
                 deps,
                 owned_worker_id,
+                account_id,
                 worker_args,
                 worker_env,
+                worker_wasi_config_vars,
                 component_version,
                 parent,
+                invocation_context_stack,
             )
             .await
     }
@@ -142,22 +147,28 @@ impl<Ctx: WorkerCtx> Worker<Ctx> {
     /// Gets or creates a worker and makes sure it is running
     pub async fn get_or_create_running<T>(
         deps: &T,
+        account_id: &AccountId,
         owned_worker_id: &OwnedWorkerId,
         worker_args: Option<Vec<String>>,
         worker_env: Option<Vec<(String, String)>>,
+        worker_wasi_config_vars: Option<BTreeMap<String, String>>,
         component_version: Option<u64>,
         parent: Option<WorkerId>,
+        invocation_context_stack: &InvocationContextStack,
     ) -> Result<Arc<Self>, WorkerExecutorError>
     where
         T: HasAll<Ctx> + Send + Sync + Clone + 'static,
     {
         let worker = Self::get_or_create_suspended(
             deps,
+            account_id,
             owned_worker_id,
             worker_args,
             worker_env,
+            worker_wasi_config_vars,
             component_version,
             parent,
+            invocation_context_stack,
         )
         .await?;
         Self::start_if_needed(worker.clone()).await?;
@@ -189,26 +200,32 @@ impl<Ctx: WorkerCtx> Worker<Ctx> {
 
     pub async fn new<T: HasAll<Ctx>>(
         deps: &T,
+        account_id: &AccountId,
         owned_worker_id: OwnedWorkerId,
         worker_args: Option<Vec<String>>,
         worker_env: Option<Vec<(String, String)>>,
+        worker_config: Option<BTreeMap<String, String>>,
         component_version: Option<u64>,
         parent: Option<WorkerId>,
+        invocation_context_stack: &InvocationContextStack,
     ) -> Result<Self, WorkerExecutorError> {
         let (worker_metadata, execution_status) = Self::get_or_create_worker_metadata(
             deps,
+            account_id,
             &owned_worker_id,
             component_version,
             worker_args,
             worker_env,
+            worker_config,
             parent,
+            invocation_context_stack,
         )
         .await?;
 
         let initial_component_metadata = deps
             .component_service()
             .get_metadata(
-                &owned_worker_id.account_id,
+                &owned_worker_id.project_id,
                 &owned_worker_id.worker_id.component_id,
                 Some(worker_metadata.last_known_status.component_version),
             )
@@ -357,7 +374,7 @@ impl<Ctx: WorkerCtx> Worker<Ctx> {
     /// Here we first acquire the `instance` lock. This means the worker cannot be started/stopped while we
     /// are processing this method.
     /// If it was not running, then we don't have to stop it.
-    /// If it was running then we recheck the conditions and then stop the worker.
+    /// If it was running, then we recheck the conditions and then stop the worker.
     ///
     /// We know that the conditions remain true because:
     /// - the invocation queue is empty, so it cannot get into `ExecutionStatus::Running`, as there is nothing to run
@@ -879,10 +896,10 @@ impl<Ctx: WorkerCtx> Worker<Ctx> {
             .expect("update_metadata failed");
     }
 
-    pub async fn list_directory(
+    pub async fn get_file_system_node(
         &self,
         path: ComponentFilePath,
-    ) -> Result<ListDirectoryResult, WorkerExecutorError> {
+    ) -> Result<GetFileSystemNodeResult, WorkerExecutorError> {
         let (sender, receiver) = oneshot::channel();
 
         let mutex = self.instance.lock().await;
@@ -890,7 +907,7 @@ impl<Ctx: WorkerCtx> Worker<Ctx> {
         self.queue
             .write()
             .await
-            .push_back(QueuedWorkerInvocation::ListDirectory { path, sender });
+            .push_back(QueuedWorkerInvocation::GetFileSystemNode { path, sender });
 
         // Two cases here:
         // - Worker is running, we can send the invocation command and the worker will look at the queue immediately
@@ -1226,12 +1243,15 @@ impl<Ctx: WorkerCtx> Worker<Ctx> {
                                 }
                             }
                         }
-                        QueuedWorkerInvocation::ListDirectory { sender, .. } => {
+                        QueuedWorkerInvocation::GetFileSystemNode { sender, .. } => {
                             let _ = sender.send(Err(fail_pending_invocations.clone()));
                         }
                         QueuedWorkerInvocation::ReadFile { sender, .. } => {
                             let _ = sender.send(Err(fail_pending_invocations.clone()));
                         }
+                        QueuedWorkerInvocation::AwaitReadyToProcessCommands { sender } => {
+                            let _ = sender.send(Err(fail_pending_invocations.clone()));
+                        }
                     }
                 }
             } else {
@@ -1267,47 +1287,84 @@ impl<Ctx: WorkerCtx> Worker<Ctx> {
         T: HasWorkerService + HasComponentService + HasConfig + HasOplogService + Sync,
     >(
         this: &T,
+        account_id: &AccountId,
         owned_worker_id: &OwnedWorkerId,
         component_version: Option<ComponentVersion>,
         worker_args: Option<Vec<String>>,
         worker_env: Option<Vec<(String, String)>>,
+        worker_wasi_config_vars: Option<BTreeMap<String, String>>,
         parent: Option<WorkerId>,
+        invocation_context: &InvocationContextStack,
     ) -> Result<(WorkerMetadata, Arc<std::sync::RwLock<ExecutionStatus>>), WorkerExecutorError>
     {
         let component_id = owned_worker_id.component_id();
-        let component_metadata = this
+        let component = this
             .component_service()
             .get_metadata(
-                &owned_worker_id.account_id,
+                &owned_worker_id.project_id,
                 &component_id,
                 component_version,
             )
             .await?;
 
-        let worker_env = merge_worker_env_with_component_env(worker_env, component_metadata.env);
+        let worker_env = merge_worker_env_with_component_env(worker_env, component.env);
 
         match this.worker_service().get(owned_worker_id).await {
             None => {
-                let initial_status =
+                let mut initial_status =
                     calculate_last_known_status(this, owned_worker_id, &None).await?;
+
+                let created_at = Timestamp::now_utc();
+                if component.metadata.is_agent() {
+                    let agent_id =
+                        AgentId::parse(&owned_worker_id.worker_id.worker_name, &component.metadata)
+                            .await
+                            .map_err(|err| {
+                                WorkerExecutorError::invalid_request(format!(
+                                    "Invalid agent id: {}",
+                                    err
+                                ))
+                            })?;
+
+                    info!(
+                        "Enqueuing agent initialization for agent type {} with parameters {}",
+                        agent_id.agent_type, agent_id.parameters
+                    );
+
+                    initial_status
+                        .pending_invocations
+                        .push(TimestampedWorkerInvocation {
+                            timestamp: created_at,
+                            invocation: WorkerInvocation::ExportedFunction {
+                                idempotency_key: IdempotencyKey::fresh(),
+                                full_function_name: "golem:agent/guest.{initialize}".to_string(),
+                                function_input: vec![agent_id.parameters.into_value()],
+                                invocation_context: invocation_context.clone(),
+                            },
+                        });
+                }
+
                 let worker_metadata = WorkerMetadata {
                     worker_id: owned_worker_id.worker_id(),
                     args: worker_args.unwrap_or_default(),
                     env: worker_env,
-                    account_id: owned_worker_id.account_id(),
-                    created_at: Timestamp::now_utc(),
+                    wasi_config_vars: worker_wasi_config_vars.unwrap_or_default(),
+                    project_id: owned_worker_id.project_id(),
+                    created_by: account_id.clone(),
+                    created_at,
                     parent,
                     last_known_status: WorkerStatusRecord {
-                        component_version: component_metadata.version,
-                        component_version_for_replay: component_metadata.version,
-                        component_size: component_metadata.size,
-                        total_linear_memory_size: component_metadata
-                            .memories
+                        component_version: component.versioned_component_id.version,
+                        component_version_for_replay: component.versioned_component_id.version,
+                        component_size: component.component_size,
+                        total_linear_memory_size: component
+                            .metadata
+                            .memories()
                             .iter()
                             .map(|m| m.initial)
                             .sum(),
-                        active_plugins: component_metadata
-                            .plugin_installations
+                        active_plugins: component
+                            .installed_plugins
                             .iter()
                             .map(|i| i.id.clone())
                             .collect(),
@@ -1316,7 +1373,7 @@ impl<Ctx: WorkerCtx> Worker<Ctx> {
                 };
                 let execution_status = this
                     .worker_service()
-                    .add(&worker_metadata, component_metadata.component_type)
+                    .add(&worker_metadata, component.component_type)
                     .await?;
                 Ok((worker_metadata, execution_status))
             }
@@ -1333,13 +1390,32 @@ impl<Ctx: WorkerCtx> Worker<Ctx> {
                 let execution_status =
                     Arc::new(std::sync::RwLock::new(ExecutionStatus::Suspended {
                         last_known_status: worker_metadata.last_known_status.clone(),
-                        component_type: component_metadata.component_type,
+                        component_type: component.component_type,
                         timestamp: Timestamp::now_utc(),
                     }));
                 Ok((worker_metadata, execution_status))
             }
         }
     }
+
+    pub async fn await_ready_to_process_commands(&self) -> Result<(), WorkerExecutorError> {
+        let (sender, receiver) = oneshot::channel();
+
+        let mutex = self.instance.lock().await;
+
+        self.queue
+            .write()
+            .await
+            .push_back(QueuedWorkerInvocation::AwaitReadyToProcessCommands { sender });
+
+        if let WorkerInstance::Running(running) = &*mutex {
+            running.sender.send(WorkerCommand::Invocation).unwrap();
+        };
+
+        drop(mutex);
+
+        receiver.await.unwrap()
+    }
 }
 
 pub fn merge_worker_env_with_component_env(
@@ -1555,7 +1631,7 @@ impl RunningWorker {
     async fn create_instance<Ctx: WorkerCtx>(
         parent: Arc<Worker<Ctx>>,
     ) -> Result<(Instance, async_mutex::Mutex<Store<Ctx>>), WorkerExecutorError> {
-        let account_id = parent.owned_worker_id.account_id();
+        let project_id = parent.owned_worker_id.project_id();
         let component_id = parent.owned_worker_id.component_id();
         let worker_metadata = parent.get_metadata()?;
 
@@ -1584,7 +1660,7 @@ impl RunningWorker {
                 .component_service()
                 .get(
                     &parent.engine(),
-                    &account_id,
+                    &project_id,
                     &component_id,
                     component_version,
                 )
@@ -1601,6 +1677,7 @@ impl RunningWorker {
                         parent.pop_pending_update().await;
                         Ctx::on_worker_update_failed_to_start(
                             &parent.deps,
+                            &parent.initial_worker_metadata.created_by,
                             &parent.owned_worker_id,
                             component_version,
                             Some(error.to_string()),
@@ -1611,7 +1688,7 @@ impl RunningWorker {
                             .component_service()
                             .get(
                                 &parent.engine(),
-                                &account_id,
+                                &project_id,
                                 &component_id,
                                 worker_metadata.last_known_status.component_version,
                             )
@@ -1643,7 +1720,8 @@ impl RunningWorker {
             );
 
         let context = Ctx::create(
-            OwnedWorkerId::new(&worker_metadata.account_id, &worker_metadata.worker_id),
+            worker_metadata.created_by,
+            OwnedWorkerId::new(&worker_metadata.project_id, &worker_metadata.worker_id),
             parent.promise_service(),
             parent.worker_service(),
             parent.worker_enumeration_service(),
@@ -1663,18 +1741,22 @@ impl RunningWorker {
             parent.config(),
             WorkerConfig::new(
                 worker_metadata.worker_id.clone(),
-                component_metadata.version,
+                component_metadata.versioned_component_id.version,
                 worker_metadata.args.clone(),
                 worker_env,
                 worker_metadata.last_known_status.skipped_regions.clone(),
                 worker_metadata.last_known_status.total_linear_memory_size,
                 component_version_for_replay,
+                parent.initial_worker_metadata.created_by.clone(),
+                worker_metadata.wasi_config_vars,
             ),
             parent.execution_status.clone(),
             parent.file_loader(),
             parent.plugins(),
             parent.worker_fork_service(),
             parent.resource_limits(),
+            parent.project_service(),
+            parent.agent_types(),
         )
         .await?;
 
@@ -1849,15 +1931,21 @@ pub enum QueuedWorkerInvocation {
         invocation: TimestampedWorkerInvocation,
         canceled: bool,
     },
-    ListDirectory {
+    GetFileSystemNode {
         path: ComponentFilePath,
-        sender: oneshot::Sender<Result<ListDirectoryResult, WorkerExecutorError>>,
+        sender: oneshot::Sender<Result<GetFileSystemNodeResult, WorkerExecutorError>>,
     },
     // The worker will suspend execution until the stream is dropped, so consume in a timely manner.
     ReadFile {
         path: ComponentFilePath,
         sender: oneshot::Sender<Result<ReadFileResult, WorkerExecutorError>>,
     },
+    // Waits for the invocation loop to pick up this message, ensuring that the worker is ready to process followup commands.
+    // The sender will be called with Ok if the worker is in a running state.
+    // If the worker initializaiton fails and will not recover without manual intervention it will be called with Err.
+    AwaitReadyToProcessCommands {
+        sender: oneshot::Sender<Result<(), WorkerExecutorError>>,
+    },
 }
 
 impl QueuedWorkerInvocation {
diff --git a/golem-worker-executor/src/worker/status.rs b/golem-worker-executor/src/worker/status.rs
index 2b9299b9..f92634f1 100644
--- a/golem-worker-executor/src/worker/status.rs
+++ b/golem-worker-executor/src/worker/status.rs
@@ -110,11 +110,8 @@ where
                 &new_entries,
             );
 
-            let owned_resources = calculate_owned_resources(
-                last_known.owned_resources,
-                &skipped_regions,
-                &new_entries,
-            );
+            let owned_resources =
+                collect_resources(last_known.owned_resources, &skipped_regions, &new_entries);
 
             let active_plugins =
                 calculate_active_plugins(active_plugins, &deleted_regions, &new_entries);
@@ -167,15 +164,9 @@ fn calculate_latest_worker_status(
             OplogEntry::Create { .. } => {
                 result = WorkerStatus::Idle;
             }
-            OplogEntry::ImportedFunctionInvokedV1 { .. } => {
-                result = WorkerStatus::Running;
-            }
             OplogEntry::ImportedFunctionInvoked { .. } => {
                 result = WorkerStatus::Running;
             }
-            OplogEntry::ExportedFunctionInvokedV1 { .. } => {
-                result = WorkerStatus::Running;
-            }
             OplogEntry::ExportedFunctionInvoked { .. } => {
                 result = WorkerStatus::Running;
             }
@@ -239,17 +230,12 @@ fn calculate_latest_worker_status(
             OplogEntry::GrowMemory { .. } => {}
             OplogEntry::CreateResource { .. } => {}
             OplogEntry::DropResource { .. } => {}
-            OplogEntry::DescribeResource { .. } => {}
             OplogEntry::Log { .. } => {
                 result = WorkerStatus::Running;
             }
             OplogEntry::Restart { .. } => {
                 result = WorkerStatus::Idle;
             }
-            OplogEntry::CreateV1 { .. } => {
-                result = WorkerStatus::Idle;
-            }
-            OplogEntry::SuccessfulUpdateV1 { .. } => {}
             OplogEntry::ActivatePlugin { .. } => {}
             OplogEntry::DeactivatePlugin { .. } => {}
             OplogEntry::Revert { .. } => {}
@@ -322,7 +308,7 @@ fn calculate_skipped_regions(
                     .build(),
                 )
             }
-            OplogEntry::SuccessfulUpdate { .. } | OplogEntry::SuccessfulUpdateV1 { .. } => {
+            OplogEntry::SuccessfulUpdate { .. } => {
                 if let Some(ovrd) = skipped_override {
                     for region in ovrd.into_regions() {
                         skipped_builder.add(region);
@@ -391,10 +377,7 @@ fn calculate_pending_invocations(
                     invocation: invocation.clone(),
                 });
             }
-            OplogEntry::ExportedFunctionInvokedV1 {
-                idempotency_key, ..
-            }
-            | OplogEntry::ExportedFunctionInvoked {
+            OplogEntry::ExportedFunctionInvoked {
                 idempotency_key, ..
             } => {
                 result.retain(|invocation| match invocation {
@@ -484,15 +467,6 @@ fn calculate_update_fields(
                 component_version_for_replay = *component_version;
                 size = *component_size;
             }
-            OplogEntry::CreateV1 {
-                component_version,
-                component_size,
-                ..
-            } => {
-                version = *component_version;
-                component_version_for_replay = *component_version;
-                size = *component_size;
-            }
             OplogEntry::PendingUpdate {
                 timestamp,
                 description,
@@ -516,29 +490,6 @@ fn calculate_update_fields(
                 });
                 pending_updates.pop_front();
             }
-            OplogEntry::SuccessfulUpdateV1 {
-                timestamp,
-                target_version,
-                new_component_size,
-            } => {
-                successful_updates.push(SuccessfulUpdateRecord {
-                    timestamp: *timestamp,
-                    target_version: *target_version,
-                });
-                version = *target_version;
-                size = *new_component_size;
-
-                let applied_update = pending_updates.pop_front();
-                if matches!(
-                    applied_update,
-                    Some(TimestampedUpdateDescription {
-                        description: UpdateDescription::SnapshotBased { .. },
-                        ..
-                    })
-                ) {
-                    component_version_for_replay = *target_version
-                }
-            }
             OplogEntry::SuccessfulUpdate {
                 timestamp,
                 target_version,
@@ -592,10 +543,7 @@ fn calculate_invocation_results(
         }
 
         match entry {
-            OplogEntry::ExportedFunctionInvokedV1 {
-                idempotency_key, ..
-            }
-            | OplogEntry::ExportedFunctionInvoked {
+            OplogEntry::ExportedFunctionInvoked {
                 idempotency_key, ..
             } => {
                 current_idempotency_key = Some(idempotency_key.clone());
@@ -642,12 +590,6 @@ fn calculate_total_linear_memory_size(
             } => {
                 result = *initial_total_linear_memory_size;
             }
-            OplogEntry::CreateV1 {
-                initial_total_linear_memory_size,
-                ..
-            } => {
-                result = *initial_total_linear_memory_size;
-            }
             OplogEntry::GrowMemory { delta, .. } => {
                 result += *delta;
             }
@@ -657,7 +599,7 @@ fn calculate_total_linear_memory_size(
     result
 }
 
-fn calculate_owned_resources(
+fn collect_resources(
     initial: HashMap<WorkerResourceId, WorkerResourceDescription>,
     skipped_regions: &DeletedRegions,
     entries: &BTreeMap<OplogIndex, OplogEntry>,
@@ -670,27 +612,24 @@ fn calculate_owned_resources(
         }
 
         match entry {
-            OplogEntry::CreateResource { id, timestamp } => {
+            OplogEntry::CreateResource {
+                id,
+                timestamp,
+                resource_type_id,
+            } => {
                 result.insert(
                     *id,
                     WorkerResourceDescription {
                         created_at: *timestamp,
-                        indexed_resource_key: None,
+                        resource_owner: resource_type_id.owner.clone(),
+                        resource_name: resource_type_id.name.clone(),
                     },
                 );
             }
             OplogEntry::DropResource { id, .. } => {
                 result.remove(id);
             }
-            OplogEntry::DescribeResource {
-                id,
-                indexed_resource,
-                ..
-            } => {
-                if let Some(description) = result.get_mut(id) {
-                    description.indexed_resource_key = Some(indexed_resource.clone());
-                }
-            }
+
             _ => {}
         }
     }
@@ -747,9 +686,9 @@ mod test {
     use golem_common::model::regions::{DeletedRegions, OplogRegion};
     use golem_common::model::{
         AccountId, ComponentId, ComponentVersion, FailedUpdateRecord, IdempotencyKey,
-        OwnedWorkerId, PluginInstallationId, RetryConfig, ScanCursor, SuccessfulUpdateRecord,
-        Timestamp, TimestampedWorkerInvocation, WorkerId, WorkerInvocation, WorkerMetadata,
-        WorkerStatus, WorkerStatusRecord,
+        OwnedWorkerId, PluginInstallationId, ProjectId, RetryConfig, ScanCursor,
+        SuccessfulUpdateRecord, Timestamp, TimestampedWorkerInvocation, WorkerId, WorkerInvocation,
+        WorkerMetadata, WorkerStatus, WorkerStatusRecord,
     };
     use golem_common::serialization::serialize;
     use golem_service_base::error::worker_executor::WorkerExecutorError;
@@ -1046,10 +985,15 @@ mod test {
         entries: Vec<TestEntry>,
         previous_status_record: WorkerStatusRecord,
         owned_worker_id: OwnedWorkerId,
+        account_id: AccountId,
     }
 
     impl TestCaseBuilder {
-        pub fn new(owned_worker_id: OwnedWorkerId, component_version: ComponentVersion) -> Self {
+        pub fn new(
+            account_id: AccountId,
+            owned_worker_id: OwnedWorkerId,
+            component_version: ComponentVersion,
+        ) -> Self {
             let status = WorkerStatusRecord {
                 component_version,
                 component_version_for_replay: component_version,
@@ -1065,7 +1009,9 @@ mod test {
                         component_version,
                         vec![],
                         vec![],
-                        owned_worker_id.account_id(),
+                        BTreeMap::new(),
+                        owned_worker_id.project_id(),
+                        account_id.clone(),
                         None,
                         100,
                         200,
@@ -1075,6 +1021,7 @@ mod test {
                 }],
                 previous_status_record: status,
                 owned_worker_id,
+                account_id,
             }
         }
 
@@ -1154,7 +1101,7 @@ mod test {
                     function_name: name.to_string(),
                     request: OplogPayload::Inline(serialize(i).unwrap().to_vec()),
                     response: OplogPayload::Inline(serialize(o).unwrap().to_vec()),
-                    wrapped_function_type: func_type,
+                    durable_function_type: func_type,
                 },
                 |status| status,
             )
@@ -1354,6 +1301,7 @@ mod test {
 
         pub fn build(self) -> TestCase {
             TestCase {
+                account_id: self.account_id,
                 owned_worker_id: self.owned_worker_id,
                 entries: self
                     .entries
@@ -1381,22 +1329,25 @@ mod test {
 
     #[derive(Debug, Clone)]
     struct TestCase {
+        account_id: AccountId,
         owned_worker_id: OwnedWorkerId,
         entries: Vec<TestEntry>,
     }
 
     impl TestCase {
         pub fn builder(initial_component_version: ComponentVersion) -> TestCaseBuilder {
+            let project_id = ProjectId::new_v4();
+            let account_id = AccountId {
+                value: "test-account".to_string(),
+            };
             let owned_worker_id = OwnedWorkerId::new(
-                &AccountId {
-                    value: "test-account".to_string(),
-                },
+                &project_id,
                 &WorkerId {
                     component_id: ComponentId::new_v4(),
                     worker_name: "test-worker".to_string(),
                 },
             );
-            TestCaseBuilder::new(owned_worker_id, initial_component_version)
+            TestCaseBuilder::new(account_id, owned_worker_id, initial_component_version)
         }
     }
 
@@ -1458,7 +1409,7 @@ mod test {
 
         async fn scan_for_component(
             &self,
-            _account_id: &AccountId,
+            _project_id: &ProjectId,
             _component_id: &ComponentId,
             _cursor: ScanCursor,
             _count: u64,
@@ -1503,7 +1454,8 @@ mod test {
                     last_known_status: test_case.entries[idx - 1].expected_status.clone(),
                     ..WorkerMetadata::default(
                         test_case.owned_worker_id.worker_id(),
-                        test_case.owned_worker_id.account_id(),
+                        test_case.account_id.clone(),
+                        test_case.owned_worker_id.project_id(),
                     )
                 })
             };
@@ -1516,7 +1468,7 @@ mod test {
             .unwrap();
 
             assert_eq!(
-                final_status.status, final_expected_status.status,
+                final_status, final_expected_status,
                 "Calculating the last known status from oplog index {idx}"
             )
         }
diff --git a/golem-worker-executor/src/workerctx/mod.rs b/golem-worker-executor/src/workerctx/mod.rs
index 32d53a69..a039f018 100644
--- a/golem-worker-executor/src/workerctx/mod.rs
+++ b/golem-worker-executor/src/workerctx/mod.rs
@@ -12,20 +12,21 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-pub mod cloud;
+pub mod default;
 
 use crate::model::{
-    CurrentResourceLimits, ExecutionStatus, LastError, ListDirectoryResult, ReadFileResult,
-    TrapType, WorkerConfig,
+    CurrentResourceLimits, ExecutionStatus, LastError, ReadFileResult, TrapType, WorkerConfig,
 };
 use crate::services::active_workers::ActiveWorkers;
+use crate::services::agent_types::AgentTypesService;
 use crate::services::blob_store::BlobStoreService;
-use crate::services::component::{ComponentMetadata, ComponentService};
+use crate::services::component::ComponentService;
 use crate::services::file_loader::FileLoader;
 use crate::services::golem_config::GolemConfig;
 use crate::services::key_value::KeyValueService;
 use crate::services::oplog::{Oplog, OplogService};
 use crate::services::plugins::Plugins;
+use crate::services::projects::ProjectService;
 use crate::services::promise::PromiseService;
 use crate::services::rdbms::RdbmsService;
 use crate::services::resource_limits::ResourceLimits;
@@ -44,16 +45,15 @@ use golem_common::model::invocation_context::{
     AttributeValue, InvocationContextSpan, InvocationContextStack, SpanId,
 };
 use golem_common::model::oplog::UpdateDescription;
-use golem_common::model::oplog::WorkerResourceId;
 use golem_common::model::{
-    AccountId, ComponentFilePath, ComponentVersion, IdempotencyKey, OwnedWorkerId,
-    PluginInstallationId, TargetWorkerId, WorkerId, WorkerMetadata, WorkerStatus,
+    AccountId, ComponentFilePath, ComponentVersion, GetFileSystemNodeResult, IdempotencyKey,
+    OwnedWorkerId, PluginInstallationId, ProjectId, WorkerId, WorkerMetadata, WorkerStatus,
     WorkerStatusRecord,
 };
 use golem_service_base::error::worker_executor::{InterruptKind, WorkerExecutorError};
 use golem_wasm_rpc::wasmtime::ResourceStore;
 use golem_wasm_rpc::{Value, ValueAndType};
-use std::collections::HashSet;
+use std::collections::{BTreeMap, HashSet};
 use std::sync::{Arc, RwLock, Weak};
 use wasmtime::component::{Component, Instance, Linker};
 use wasmtime::{AsContextMut, Engine, ResourceLimiterAsync};
@@ -71,21 +71,24 @@ pub trait WorkerCtx:
     + InvocationHooks
     + ExternalOperations<Self>
     + ResourceStore
-    + IndexedResourceStore
     + UpdateManagement
     + FileSystemReading
     + DynamicLinking<Self>
     + InvocationContextManagement
+    + HasWasiConfigVars
     + Send
     + Sync
     + Sized
     + 'static
 {
-    /// PublicState is a subset of the worker context which is accessible outside the worker
+    /// PublicState is a subset of the worker context that is accessible outside the worker
     /// execution. This is useful to publish queues and similar objects to communicate with the
     /// executing worker from things like a request handler.
     type PublicState: PublicWorkerIo + HasWorker<Self> + HasOplog + Clone + Send + Sync;
 
+    /// Static log event behaviour configuration for workers
+    const LOG_EVENT_EMIT_BEHAVIOUR: LogEventEmitBehaviour;
+
     /// Creates a new worker context
     ///
     /// Arguments:
@@ -102,7 +105,7 @@ pub trait WorkerCtx:
     /// - `scheduler_service`: The scheduler implementation responsible for waking up suspended workers
     /// - `recovery_management`: The service for deciding if a worker should be recovered
     /// - `rpc`: The RPC implementation used for worker to worker communication
-    /// - `worker_proyx`: Access to the worker proxy above the worker executor cluster
+    /// - `worker_proxy`: Access to the worker proxy above the worker executor cluster
     /// - `extra_deps`: Extra dependencies that are required by this specific worker context
     /// - `config`: The shared worker configuration
     /// - `worker_config`: Configuration for this specific worker
@@ -110,6 +113,7 @@ pub trait WorkerCtx:
     /// - `file_loader`: The service for loading files and making them available to workers
     #[allow(clippy::too_many_arguments)]
     async fn create(
+        account_id: AccountId,
         owned_worker_id: OwnedWorkerId,
         promise_service: Arc<dyn PromiseService>,
         worker_service: Arc<dyn WorkerService>,
@@ -134,6 +138,8 @@ pub trait WorkerCtx:
         plugins: Arc<dyn Plugins>,
         worker_fork: Arc<dyn WorkerForkService>,
         resource_limits: Arc<dyn ResourceLimits>,
+        project_service: Arc<dyn ProjectService>,
+        agent_types_service: Arc<dyn AgentTypesService>,
     ) -> Result<Self, WorkerExecutorError>;
 
     fn as_wasi_view(&mut self) -> impl WasiView;
@@ -154,7 +160,10 @@ pub trait WorkerCtx:
     /// Get the owned worker ID associated with this worker context
     fn owned_worker_id(&self) -> &OwnedWorkerId;
 
-    fn component_metadata(&self) -> &ComponentMetadata;
+    /// Gets the account created this worker
+    fn created_by(&self) -> &AccountId;
+
+    fn component_metadata(&self) -> &golem_service_base::model::Component;
 
     /// The WASI exit API can use a special error to exit from the WASM execution. As this depends
     /// on the actual WASI implementation installed by the worker context, this function is used to
@@ -171,11 +180,6 @@ pub trait WorkerCtx:
     fn component_service(&self) -> Arc<dyn ComponentService>;
 
     fn worker_fork(&self) -> Arc<dyn WorkerForkService>;
-
-    async fn generate_unique_local_worker_id(
-        &mut self,
-        remote_worker_id: TargetWorkerId,
-    ) -> Result<WorkerId, WorkerExecutorError>;
 }
 
 /// The fuel management interface of a worker context is responsible for borrowing and returning
@@ -332,30 +336,6 @@ pub trait UpdateManagement {
     );
 }
 
-/// Stores resources created within the worker indexed by their constructor parameters
-///
-/// This is a secondary mapping on top of `ResourceStore`, which handles the mapping between
-/// resource identifiers to actual wasmtime `ResourceAny` instances.
-///
-/// Note that the parameters are passed as unparsed WAVE strings instead of their parsed `Value`
-/// representation - the string representation is easier to hash and allows us to reduce the number
-/// of times we need to parse the parameters.
-#[async_trait]
-pub trait IndexedResourceStore {
-    fn get_indexed_resource(
-        &self,
-        resource_name: &str,
-        resource_params: &[String],
-    ) -> Option<WorkerResourceId>;
-    async fn store_indexed_resource(
-        &mut self,
-        resource_name: &str,
-        resource_params: &[String],
-        resource: WorkerResourceId,
-    );
-    fn drop_indexed_resource(&mut self, resource_name: &str, resource_params: &[String]);
-}
-
 /// Operations not requiring an active worker context, but still depending on the
 /// worker context implementation.
 #[async_trait]
@@ -385,6 +365,7 @@ pub trait ExternalOperations<Ctx: WorkerCtx> {
     async fn resume_replay(
         store: &mut (impl AsContextMut<Data = Ctx> + Send),
         instance: &Instance,
+        refresh_replay_target: bool,
     ) -> Result<RetryDecision, WorkerExecutorError>;
 
     /// Prepares a wasmtime instance after it has been created, but before it can be invoked.
@@ -400,7 +381,7 @@ pub trait ExternalOperations<Ctx: WorkerCtx> {
     /// Records the last known resource limits of a worker without activating it
     async fn record_last_known_limits<T: HasAll<Ctx> + Send + Sync>(
         this: &T,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         last_known_limits: &CurrentResourceLimits,
     ) -> Result<(), WorkerExecutorError>;
 
@@ -418,6 +399,7 @@ pub trait ExternalOperations<Ctx: WorkerCtx> {
     /// Called when an update attempt has failed before the worker context has been created
     async fn on_worker_update_failed_to_start<T: HasAll<Ctx> + Send + Sync>(
         this: &T,
+        account_id: &AccountId,
         owned_worker_id: &OwnedWorkerId,
         target_version: ComponentVersion,
         details: Option<String>,
@@ -438,11 +420,10 @@ pub trait PublicWorkerIo {
 /// so not locking is needed in the implementation.
 #[async_trait]
 pub trait FileSystemReading {
-    // List the contents of a directory. Will return an error if the path is not a directory.
-    async fn list_directory(
+    async fn get_file_system_node(
         &self,
         path: &ComponentFilePath,
-    ) -> Result<ListDirectoryResult, WorkerExecutorError>;
+    ) -> Result<GetFileSystemNodeResult, WorkerExecutorError>;
     async fn read_file(
         &self,
         path: &ComponentFilePath,
@@ -474,6 +455,10 @@ pub trait InvocationContextManagement {
         key: &str,
         value: AttributeValue,
     ) -> Result<(), WorkerExecutorError>;
+
+    /// Clones every element of the stack belonging to the given current span id, and sets
+    /// the inherited flag to true on them, without changing the spans in this invocation context.
+    fn clone_as_inherited_stack(&self, current_span_id: &SpanId) -> InvocationContextStack;
 }
 
 #[async_trait]
@@ -483,6 +468,17 @@ pub trait DynamicLinking<Ctx: WorkerCtx> {
         engine: &Engine,
         linker: &mut Linker<Ctx>,
         component: &Component,
-        component_metadata: &ComponentMetadata,
+        component_metadata: &golem_service_base::model::Component,
     ) -> anyhow::Result<()>;
 }
+
+pub trait HasWasiConfigVars {
+    fn wasi_config_vars(&self) -> BTreeMap<String, String>;
+}
+
+pub enum LogEventEmitBehaviour {
+    /// Always emit all log event
+    Always,
+    /// Emit log events only during live mode
+    LiveOnly,
+}
diff --git a/golem-worker-executor/tests/api.rs b/golem-worker-executor/tests/api.rs
index 3e7a9626..f475f161 100644
--- a/golem-worker-executor/tests/api.rs
+++ b/golem-worker-executor/tests/api.rs
@@ -14,7 +14,7 @@
 
 use crate::common::{start, TestContext};
 use crate::compatibility::worker_recovery::save_recovery_golden_file;
-use crate::{Deps, LastUniqueId, Tracing};
+use crate::{LastUniqueId, Tracing, WorkerExecutorTestDependencies};
 use assert2::check;
 use axum::routing::get;
 use axum::Router;
@@ -23,10 +23,10 @@ use golem_api_grpc::proto::golem::workerexecutor::v1::CompletePromiseRequest;
 use golem_common::model::component_metadata::{
     DynamicLinkedInstance, DynamicLinkedWasmRpc, WasmRpcTarget,
 };
-use golem_common::model::oplog::{IndexedResourceKey, OplogIndex, WorkerResourceId};
+use golem_common::model::oplog::OplogIndex;
 use golem_common::model::{
     ComponentId, ComponentType, FilterComparator, IdempotencyKey, PromiseId, ScanCursor,
-    StringFilterComparator, TargetWorkerId, Timestamp, WorkerFilter, WorkerId, WorkerMetadata,
+    StringFilterComparator, Timestamp, WorkerFilter, WorkerId, WorkerMetadata,
     WorkerResourceDescription, WorkerStatus,
 };
 use golem_test_framework::config::TestDependencies;
@@ -35,8 +35,10 @@ use golem_test_framework::dsl::{
     worker_error_logs, worker_error_message, TestDslUnsafe,
 };
 use golem_wasm_ast::analysis::wit_parser::{SharedAnalysedTypeResolve, TypeName, TypeOwner};
-use golem_wasm_ast::analysis::{analysed_type, AnalysedType, TypeStr};
-use golem_wasm_rpc::IntoValue;
+use golem_wasm_ast::analysis::{
+    analysed_type, AnalysedResourceId, AnalysedResourceMode, AnalysedType, TypeHandle, TypeStr,
+};
+use golem_wasm_rpc::{IntoValue, Record};
 use golem_wasm_rpc::{IntoValueAndType, Value, ValueAndType};
 use redis::Commands;
 use std::collections::HashMap;
@@ -51,7 +53,7 @@ use test_r::{add_test, inherit_test_dep, test, test_gen, timeout};
 use tokio::time::sleep;
 use tracing::{debug, info, Instrument, Span};
 
-inherit_test_dep!(Deps);
+inherit_test_dep!(WorkerExecutorTestDependencies);
 inherit_test_dep!(LastUniqueId);
 inherit_test_dep!(Tracing);
 inherit_test_dep!(
@@ -62,9 +64,13 @@ inherit_test_dep!(
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn interruption(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn interruption(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("interruption").store().await;
     let worker_id = executor.start_worker(&component_id, "interruption-1").await;
@@ -74,7 +80,7 @@ async fn interruption(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tra
     let fiber = tokio::spawn(
         async move {
             executor_clone
-                .invoke_and_await(worker_id_clone, "run", vec![])
+                .invoke_and_await(&worker_id_clone, "run", vec![])
                 .await
         }
         .in_current_span(),
@@ -96,9 +102,13 @@ async fn interruption(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tra
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn simulated_crash(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn simulated_crash(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("interruption").store().await;
     let worker_id = executor
@@ -112,7 +122,7 @@ async fn simulated_crash(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &
     let fiber = tokio::spawn(
         async move {
             executor_clone
-                .invoke_and_await(worker_id_clone, "run", vec![])
+                .invoke_and_await(&worker_id_clone, "run", vec![])
                 .await
         }
         .in_current_span(),
@@ -135,9 +145,12 @@ async fn simulated_crash(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn shopping_cart_example(last_unique_id: &LastUniqueId, deps: &Deps) {
+async fn shopping_cart_example(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("shopping-cart").store().await;
     let worker_id = executor
@@ -159,12 +172,12 @@ async fn shopping_cart_example(last_unique_id: &LastUniqueId, deps: &Deps) {
         .invoke_and_await(
             &worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1000".into_value_and_type()),
                 ("name", "Golem T-Shirt M".into_value_and_type()),
                 ("price", 100.0f32.into_value_and_type()),
                 ("quantity", 5u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -173,12 +186,12 @@ async fn shopping_cart_example(last_unique_id: &LastUniqueId, deps: &Deps) {
         .invoke_and_await(
             &worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1001".into_value_and_type()),
                 ("name", "Golem Cloud Subscription 1y".into_value_and_type()),
                 ("price", 999999.0f32.into_value_and_type()),
                 ("quantity", 1u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -187,12 +200,12 @@ async fn shopping_cart_example(last_unique_id: &LastUniqueId, deps: &Deps) {
         .invoke_and_await(
             &worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1002".into_value_and_type()),
                 ("name", "Mud Golem".into_value_and_type()),
                 ("price", 11.0f32.into_value_and_type()),
                 ("quantity", 10u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -252,9 +265,12 @@ async fn shopping_cart_example(last_unique_id: &LastUniqueId, deps: &Deps) {
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn dynamic_worker_creation(last_unique_id: &LastUniqueId, deps: &Deps) {
+async fn dynamic_worker_creation(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("environment-service").store().await;
     let worker_id = WorkerId {
@@ -321,101 +337,25 @@ fn get_env_result(env: Vec<Value>) -> HashMap<String, String> {
     }
 }
 
-#[test]
-#[tracing::instrument]
-#[timeout(120_000)]
-async fn dynamic_worker_creation_without_name(last_unique_id: &LastUniqueId, deps: &Deps) {
-    let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
-
-    let component_id = executor.component("environment-service").store().await;
-    let worker_id = TargetWorkerId {
-        component_id: component_id.clone(),
-        worker_name: None,
-    };
-
-    let env1 = executor
-        .invoke_and_await(worker_id.clone(), "golem:it/api.{get-environment}", vec![])
-        .await
-        .unwrap();
-    let env2 = executor
-        .invoke_and_await(worker_id.clone(), "golem:it/api.{get-environment}", vec![])
-        .await
-        .unwrap();
-
-    drop(executor);
-
-    let env1 = get_env_result(env1);
-    let env2 = get_env_result(env2);
-
-    check!(env1.contains_key("GOLEM_WORKER_NAME"));
-    check!(env1.get("GOLEM_COMPONENT_ID") == Some(&component_id.to_string()));
-    check!(env1.get("GOLEM_COMPONENT_VERSION") == Some(&"0".to_string()));
-    check!(env2.contains_key("GOLEM_WORKER_NAME"));
-    check!(env2.get("GOLEM_COMPONENT_ID") == Some(&component_id.to_string()));
-    check!(env2.get("GOLEM_COMPONENT_VERSION") == Some(&"0".to_string()));
-    check!(env1.get("GOLEM_WORKER_NAME") != env2.get("GOLEM_WORKER_NAME"));
-}
-
-#[test]
-#[tracing::instrument]
-#[timeout(120_000)]
-async fn ephemeral_worker_creation_without_name(last_unique_id: &LastUniqueId, deps: &Deps) {
-    let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
-
-    let component_id = executor
-        .component("environment-service")
-        .ephemeral()
-        .store()
-        .await;
-    let worker_id = TargetWorkerId {
-        component_id: component_id.clone(),
-        worker_name: None,
-    };
-
-    let env1 = executor
-        .invoke_and_await(worker_id.clone(), "golem:it/api.{get-environment}", vec![])
-        .await
-        .unwrap();
-    let env2 = executor
-        .invoke_and_await(worker_id.clone(), "golem:it/api.{get-environment}", vec![])
-        .await
-        .unwrap();
-
-    drop(executor);
-
-    let env1 = get_env_result(env1);
-    let env2 = get_env_result(env2);
-
-    check!(env1.contains_key("GOLEM_WORKER_NAME"));
-    check!(env1.get("GOLEM_COMPONENT_ID") == Some(&component_id.to_string()));
-    check!(env1.get("GOLEM_COMPONENT_VERSION") == Some(&"0".to_string()));
-    check!(env2.contains_key("GOLEM_WORKER_NAME"));
-    check!(env2.get("GOLEM_COMPONENT_ID") == Some(&component_id.to_string()));
-    check!(env2.get("GOLEM_COMPONENT_VERSION") == Some(&"0".to_string()));
-    check!(env1.get("GOLEM_WORKER_NAME") != env2.get("GOLEM_WORKER_NAME"));
-}
-
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
 async fn ephemeral_worker_creation_with_name_is_not_persistent(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("counters").ephemeral().store().await;
-    let worker_id = TargetWorkerId {
+    let worker_id = WorkerId {
         component_id: component_id.clone(),
-        worker_name: Some("test".to_string()),
+        worker_name: "test".to_string(),
     };
 
     let _ = executor
         .invoke_and_await(
-            worker_id.clone(),
+            &worker_id,
             "rpc:counters-exports/api.{inc-global-by}",
             vec![2u64.into_value_and_type()],
         )
@@ -424,7 +364,7 @@ async fn ephemeral_worker_creation_with_name_is_not_persistent(
 
     let result = executor
         .invoke_and_await(
-            worker_id.clone(),
+            &worker_id,
             "rpc:counters-exports/api.{get-global-value}",
             vec![],
         )
@@ -439,9 +379,13 @@ async fn ephemeral_worker_creation_with_name_is_not_persistent(
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn promise(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn promise(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("promise").store().await;
     let worker_id = executor.start_worker(&component_id, "promise-1").await;
@@ -494,6 +438,7 @@ async fn promise(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing)
             ),
             data: vec![42],
             account_id: Some(executor.account_id.clone().into()),
+            project_id: Some(executor.default_project_id.clone().into()),
         })
         .await
         .unwrap();
@@ -522,11 +467,11 @@ async fn promise(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing)
 #[timeout(120_000)]
 async fn get_workers_from_worker(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     #[tagged_as("golem_host")] type_resolve: &SharedAnalysedTypeResolve,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("runtime-service").store().await;
 
@@ -547,14 +492,14 @@ async fn get_workers_from_worker(
     ) {
         let component_id_val_and_type = {
             let (high, low) = worker_id.component_id.0.as_u64_pair();
-            vec![(
+            Record(vec![(
                 "uuid",
-                vec![
+                Record(vec![
                     ("high-bits", high.into_value_and_type()),
                     ("low-bits", low.into_value_and_type()),
-                ]
+                ])
                 .into_value_and_type(),
-            )]
+            )])
             .into_value_and_type()
         };
 
@@ -572,7 +517,7 @@ async fn get_workers_from_worker(
 
         let result = executor
             .invoke_and_await(
-                worker_id.clone(),
+                worker_id,
                 "golem:it/api.{get-workers}",
                 vec![
                     component_id_val_and_type,
@@ -623,9 +568,12 @@ async fn get_workers_from_worker(
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn get_metadata_from_worker(last_unique_id: &LastUniqueId, deps: &Deps) {
+async fn get_metadata_from_worker(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("runtime-service").store().await;
 
@@ -657,11 +605,7 @@ async fn get_metadata_from_worker(last_unique_id: &LastUniqueId, deps: &Deps) {
         let worker_id_val1 = get_worker_id_val(worker_id1);
 
         let result = executor
-            .invoke_and_await(
-                worker_id1.clone(),
-                "golem:it/api.{get-self-metadata}",
-                vec![],
-            )
+            .invoke_and_await(worker_id1, "golem:it/api.{get-self-metadata}", vec![])
             .await
             .unwrap();
 
@@ -679,7 +623,7 @@ async fn get_metadata_from_worker(last_unique_id: &LastUniqueId, deps: &Deps) {
 
         let result = executor
             .invoke_and_await(
-                worker_id1.clone(),
+                worker_id1,
                 "golem:it/api.{get-worker-metadata}",
                 vec![ValueAndType {
                     value: worker_id_val2.clone(),
@@ -733,10 +677,10 @@ async fn get_metadata_from_worker(last_unique_id: &LastUniqueId, deps: &Deps) {
 #[timeout(120_000)]
 async fn invoking_with_same_idempotency_key_is_idempotent(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("shopping-cart").store().await;
     let worker_id = executor
@@ -749,12 +693,12 @@ async fn invoking_with_same_idempotency_key_is_idempotent(
             &worker_id,
             &idempotency_key,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1000".into_value_and_type()),
                 ("name", "Golem T-Shirt M".into_value_and_type()),
                 ("price", 100.0f32.into_value_and_type()),
                 ("quantity", 5u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await
@@ -765,12 +709,12 @@ async fn invoking_with_same_idempotency_key_is_idempotent(
             &worker_id,
             &idempotency_key,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1000".into_value_and_type()),
                 ("name", "Golem T-Shirt M".into_value_and_type()),
                 ("price", 100.0f32.into_value_and_type()),
                 ("quantity", 5u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await
@@ -800,10 +744,10 @@ async fn invoking_with_same_idempotency_key_is_idempotent(
 #[timeout(120_000)]
 async fn invoking_with_same_idempotency_key_is_idempotent_after_restart(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("shopping-cart").store().await;
     let worker_id = executor
@@ -816,31 +760,31 @@ async fn invoking_with_same_idempotency_key_is_idempotent_after_restart(
             &worker_id,
             &idempotency_key,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1000".into_value_and_type()),
                 ("name", "Golem T-Shirt M".into_value_and_type()),
                 ("price", 100.0f32.into_value_and_type()),
                 ("quantity", 5u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await
         .unwrap();
 
     drop(executor);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let _result2 = executor
         .invoke_and_await_with_key(
             &worker_id,
             &idempotency_key,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1000".into_value_and_type()),
                 ("name", "Golem T-Shirt M".into_value_and_type()),
                 ("price", 100.0f32.into_value_and_type()),
                 ("quantity", 5u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await
@@ -868,9 +812,12 @@ async fn invoking_with_same_idempotency_key_is_idempotent_after_restart(
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn component_env_variables(last_unique_id: &LastUniqueId, deps: &Deps) {
+async fn component_env_variables(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor
         .component("environment-service")
@@ -915,9 +862,12 @@ async fn component_env_variables(last_unique_id: &LastUniqueId, deps: &Deps) {
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn component_env_variables_update(last_unique_id: &LastUniqueId, deps: &Deps) {
+async fn component_env_variables_update(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor
         .component("environment-service")
@@ -962,9 +912,12 @@ async fn component_env_variables_update(last_unique_id: &LastUniqueId, deps: &De
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn component_env_and_worker_env_priority(last_unique_id: &LastUniqueId, deps: &Deps) {
+async fn component_env_and_worker_env_priority(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor
         .component("environment-service")
@@ -980,6 +933,7 @@ async fn component_env_and_worker_env_priority(last_unique_id: &LastUniqueId, de
             "component-env-variables-1",
             vec![],
             worker_env,
+            vec![],
         )
         .await;
 
@@ -993,9 +947,13 @@ async fn component_env_and_worker_env_priority(last_unique_id: &LastUniqueId, de
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn optional_parameters(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn optional_parameters(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("option-service").store().await;
     let worker_id = executor
@@ -1024,10 +982,10 @@ async fn optional_parameters(last_unique_id: &LastUniqueId, deps: &Deps, _tracin
         .invoke_and_await(
             &worker_id,
             "golem:it/api.{todo}",
-            vec![vec![
+            vec![Record(vec![
                 ("name", "todo".into_value_and_type()),
                 ("description", Some("description").into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await
@@ -1037,10 +995,10 @@ async fn optional_parameters(last_unique_id: &LastUniqueId, deps: &Deps, _tracin
         .invoke_and_await(
             &worker_id,
             "golem:it/api.{todo}",
-            vec![vec![
+            vec![Record(vec![
                 ("name", "todo".into_value_and_type()),
                 ("description", Some("description").into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await
@@ -1062,9 +1020,13 @@ async fn optional_parameters(last_unique_id: &LastUniqueId, deps: &Deps, _tracin
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn flags_parameters(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn flags_parameters(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("flags-service").store().await;
     let worker_id = executor
@@ -1075,7 +1037,7 @@ async fn flags_parameters(last_unique_id: &LastUniqueId, deps: &Deps, _tracing:
         .invoke_and_await(
             &worker_id,
             "golem:it/api.{create-task}",
-            vec![vec![
+            vec![Record(vec![
                 ("name", "t1".into_value_and_type()),
                 (
                     "permissions",
@@ -1084,7 +1046,7 @@ async fn flags_parameters(last_unique_id: &LastUniqueId, deps: &Deps, _tracing:
                         typ: analysed_type::flags(&["read", "write", "exec", "close"]),
                     },
                 ),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await
@@ -1122,9 +1084,12 @@ async fn flags_parameters(last_unique_id: &LastUniqueId, deps: &Deps, _tracing:
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn variants_with_no_payloads(last_unique_id: &LastUniqueId, deps: &Deps) {
+async fn variants_with_no_payloads(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("variant-service").store().await;
     let worker_id = executor
@@ -1143,9 +1108,13 @@ async fn variants_with_no_payloads(last_unique_id: &LastUniqueId, deps: &Deps) {
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn delete_worker(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn delete_worker(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("option-service").store().await;
     let worker_id = executor
@@ -1189,7 +1158,11 @@ async fn delete_worker(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tr
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn get_workers(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn get_workers(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     async fn get_check(
         component_id: &ComponentId,
         filter: Option<WorkerFilter>,
@@ -1207,7 +1180,7 @@ async fn get_workers(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Trac
     }
 
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("option-service").store().await;
 
@@ -1325,10 +1298,10 @@ async fn get_workers(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Trac
 #[timeout(120_000)]
 async fn error_handling_when_worker_is_invoked_with_fewer_than_expected_parameters(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("option-service").store().await;
     let worker_id = executor
@@ -1349,10 +1322,10 @@ async fn error_handling_when_worker_is_invoked_with_fewer_than_expected_paramete
 #[timeout(120_000)]
 async fn error_handling_when_worker_is_invoked_with_more_than_expected_parameters(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("option-service").store().await;
     let worker_id = executor
@@ -1379,9 +1352,13 @@ async fn error_handling_when_worker_is_invoked_with_more_than_expected_parameter
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn get_worker_metadata(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn get_worker_metadata(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("clock-service").store().await;
 
@@ -1433,7 +1410,7 @@ async fn get_worker_metadata(last_unique_id: &LastUniqueId, deps: &Deps, _tracin
     check!(metadata2.last_known_status.status == WorkerStatus::Idle);
     check!(metadata1.last_known_status.component_version == 0);
     check!(metadata1.worker_id == worker_id);
-    check!(metadata1.account_id == executor.account_id);
+    check!(metadata1.created_by == executor.account_id);
 
     check!(metadata2.last_known_status.component_size == expected_component_size);
     check!(metadata2.last_known_status.total_linear_memory_size == 1245184);
@@ -1442,9 +1419,12 @@ async fn get_worker_metadata(last_unique_id: &LastUniqueId, deps: &Deps, _tracin
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn create_invoke_delete_create_invoke(last_unique_id: &LastUniqueId, deps: &Deps) {
+async fn create_invoke_delete_create_invoke(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("shopping-cart").store().await;
     let worker_id = executor
@@ -1455,12 +1435,12 @@ async fn create_invoke_delete_create_invoke(last_unique_id: &LastUniqueId, deps:
         .invoke_and_await(
             &worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1000".into_value_and_type()),
                 ("name", "Golem T-Shirt M".into_value_and_type()),
                 ("price", 100.0f32.into_value_and_type()),
                 ("quantity", 5u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -1475,12 +1455,12 @@ async fn create_invoke_delete_create_invoke(last_unique_id: &LastUniqueId, deps:
         .invoke_and_await(
             &worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1000".into_value_and_type()),
                 ("name", "Golem T-Shirt M".into_value_and_type()),
                 ("price", 100.0f32.into_value_and_type()),
                 ("quantity", 5u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -1497,10 +1477,10 @@ async fn create_invoke_delete_create_invoke(last_unique_id: &LastUniqueId, deps:
 #[timeout(120_000)]
 async fn recovering_an_old_worker_after_updating_a_component(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("shopping-cart").unique().store().await;
     let worker_id = executor
@@ -1514,12 +1494,12 @@ async fn recovering_an_old_worker_after_updating_a_component(
         .invoke_and_await(
             &worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1000".into_value_and_type()),
                 ("name", "Golem T-Shirt M".into_value_and_type()),
                 ("price", 100.0f32.into_value_and_type()),
                 ("quantity", 5u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await
@@ -1549,7 +1529,7 @@ async fn recovering_an_old_worker_after_updating_a_component(
 
     // Restarting the server to force worker recovery
     drop(executor);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     // Call the first worker again to check if it is still working
     let r3 = executor
@@ -1581,10 +1561,10 @@ async fn recovering_an_old_worker_after_updating_a_component(
 #[timeout(120_000)]
 async fn recreating_a_worker_after_it_got_deleted_with_a_different_version(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("shopping-cart").unique().store().await;
     let worker_id = executor
@@ -1598,12 +1578,12 @@ async fn recreating_a_worker_after_it_got_deleted_with_a_different_version(
         .invoke_and_await(
             &worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1000".into_value_and_type()),
                 ("name", "Golem T-Shirt M".into_value_and_type()),
                 ("price", 100.0f32.into_value_and_type()),
                 ("quantity", 5u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await
@@ -1650,12 +1630,12 @@ async fn recreating_a_worker_after_it_got_deleted_with_a_different_version(
 #[timeout(120_000)]
 async fn trying_to_use_an_old_wasm_provides_good_error_message(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
 ) {
     let context = TestContext::new(last_unique_id);
     // case: WASM is an old version, rejected by protector
 
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor
         .component("old-component")
@@ -1682,11 +1662,11 @@ async fn trying_to_use_an_old_wasm_provides_good_error_message(
 #[timeout(120_000)]
 async fn trying_to_use_a_wasm_that_wasmtime_cannot_load_provides_good_error_message(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
 ) {
     let context = TestContext::new(last_unique_id);
-    // case: WASM can be parsed but wasmtime does not support it
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    // case: WASM can be parsed, but wasmtime does not support it
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
     let component_id = executor.component("write-stdout").store().await;
 
     let cwd = env::current_dir().expect("Failed to get current directory");
@@ -1728,15 +1708,16 @@ async fn trying_to_use_a_wasm_that_wasmtime_cannot_load_provides_good_error_mess
 #[timeout(120_000)]
 async fn trying_to_use_a_wasm_that_wasmtime_cannot_load_provides_good_error_message_after_recovery(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
     let component_id = executor.component("write-stdout").store().await;
 
     let worker_id = executor.start_worker(&component_id, "bad-wasm-2").await;
+    let project_id = executor.default_project().await;
 
-    // worker is idle. if we restart the server it will get recovered
+    // worker is idle. if we restart the server, it will get recovered
     drop(executor);
 
     // corrupting the uploaded WASM
@@ -1744,7 +1725,7 @@ async fn trying_to_use_a_wasm_that_wasmtime_cannot_load_provides_good_error_mess
     debug!("Current directory: {cwd:?}");
     let component_path = cwd.join(format!("data/components/wasms/{component_id}-0.wasm"));
     let compiled_component_path = cwd.join(Path::new(&format!(
-        "data/blobs/compilation_cache/{component_id}/0.cwasm"
+        "data/blobs/compilation_cache/{project_id}/{component_id}/0.cwasm"
     )));
 
     let span = Span::current();
@@ -1767,7 +1748,7 @@ async fn trying_to_use_a_wasm_that_wasmtime_cannot_load_provides_good_error_mess
     .await
     .unwrap();
 
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     debug!("Trying to invoke recovered worker");
 
@@ -1790,9 +1771,12 @@ async fn trying_to_use_a_wasm_that_wasmtime_cannot_load_provides_good_error_mess
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn long_running_poll_loop_works_as_expected(last_unique_id: &LastUniqueId, deps: &Deps) {
+async fn long_running_poll_loop_works_as_expected(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let response = Arc::new(Mutex::new("initial".to_string()));
     let response_clone = response.clone();
@@ -1822,7 +1806,7 @@ async fn long_running_poll_loop_works_as_expected(last_unique_id: &LastUniqueId,
     env.insert("RUST_BACKTRACE".to_string(), "1".to_string());
 
     let worker_id = executor
-        .start_worker_with(&component_id, "poll-loop-component-0", vec![], env)
+        .start_worker_with(&component_id, "poll-loop-component-0", vec![], env, vec![])
         .await;
 
     executor.log_output(&worker_id).await;
@@ -1859,10 +1843,10 @@ async fn long_running_poll_loop_works_as_expected(last_unique_id: &LastUniqueId,
 #[timeout(120_000)]
 async fn long_running_poll_loop_works_as_expected_async_http(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let response = Arc::new(Mutex::new("initial".to_string()));
     let response_clone = response.clone();
@@ -1892,7 +1876,7 @@ async fn long_running_poll_loop_works_as_expected_async_http(
     env.insert("RUST_BACKTRACE".to_string(), "1".to_string());
 
     let worker_id = executor
-        .start_worker_with(&component_id, "poll-loop-component-0", vec![], env)
+        .start_worker_with(&component_id, "poll-loop-component-0", vec![], env, vec![])
         .await;
 
     executor.log_output(&worker_id).await;
@@ -1929,10 +1913,10 @@ async fn long_running_poll_loop_works_as_expected_async_http(
 #[timeout(300_000)]
 async fn long_running_poll_loop_interrupting_and_resuming_by_second_invocation(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let response = Arc::new(Mutex::new("initial".to_string()));
     let response_clone = response.clone();
@@ -1960,7 +1944,7 @@ async fn long_running_poll_loop_interrupting_and_resuming_by_second_invocation(
     let mut env = HashMap::new();
     env.insert("PORT".to_string(), host_http_port.to_string());
     let worker_id = executor
-        .start_worker_with(&component_id, "poll-loop-component-1", vec![], env)
+        .start_worker_with(&component_id, "poll-loop-component-1", vec![], env, vec![])
         .await;
 
     executor.log_output(&worker_id).await;
@@ -2071,10 +2055,10 @@ async fn long_running_poll_loop_interrupting_and_resuming_by_second_invocation(
 #[timeout(120_000)]
 async fn long_running_poll_loop_connection_breaks_on_interrupt(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let response = Arc::new(Mutex::new("initial".to_string()));
     let response_clone = response.clone();
@@ -2102,7 +2086,7 @@ async fn long_running_poll_loop_connection_breaks_on_interrupt(
     let mut env = HashMap::new();
     env.insert("PORT".to_string(), host_http_port.to_string());
     let worker_id = executor
-        .start_worker_with(&component_id, "poll-loop-component-2", vec![], env)
+        .start_worker_with(&component_id, "poll-loop-component-2", vec![], env, vec![])
         .await;
 
     let mut rx = executor.capture_output_with_termination(&worker_id).await;
@@ -2153,10 +2137,10 @@ async fn long_running_poll_loop_connection_breaks_on_interrupt(
 #[timeout(120_000)]
 async fn long_running_poll_loop_connection_retry_does_not_resume_interrupted_worker(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let response = Arc::new(Mutex::new("initial".to_string()));
     let response_clone = response.clone();
@@ -2185,7 +2169,7 @@ async fn long_running_poll_loop_connection_retry_does_not_resume_interrupted_wor
     env.insert("PORT".to_string(), host_http_port.to_string());
 
     let worker_id = executor
-        .start_worker_with(&component_id, "poll-loop-component-3", vec![], env)
+        .start_worker_with(&component_id, "poll-loop-component-3", vec![], env, vec![])
         .await;
 
     let rx = executor.capture_output_with_termination(&worker_id).await;
@@ -2225,10 +2209,10 @@ async fn long_running_poll_loop_connection_retry_does_not_resume_interrupted_wor
 #[timeout(120_000)]
 async fn long_running_poll_loop_connection_can_be_restored_after_resume(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let response = Arc::new(Mutex::new("initial".to_string()));
     let response_clone = response.clone();
@@ -2257,7 +2241,7 @@ async fn long_running_poll_loop_connection_can_be_restored_after_resume(
     env.insert("PORT".to_string(), host_http_port.to_string());
 
     let worker_id = executor
-        .start_worker_with(&component_id, "poll-loop-component-4", vec![], env)
+        .start_worker_with(&component_id, "poll-loop-component-4", vec![], env, vec![])
         .await;
 
     let rx = executor.capture_output_with_termination(&worker_id).await;
@@ -2277,19 +2261,7 @@ async fn long_running_poll_loop_connection_can_be_restored_after_resume(
 
     executor.interrupt(&worker_id).await;
 
-    let mut found1 = false;
-    let mut found2 = false;
-    let previous_events = drain_connection(rx).await;
-    {
-        previous_events.into_iter().for_each(|event| {
-            let ev = event.unwrap();
-            if stdout_event_matching(&ev, "Calling the poll endpoint\n") {
-                found1 = true;
-            } else if stdout_event_matching(&ev, "Received initial\n") {
-                found2 = true;
-            }
-        });
-    }
+    let _ = drain_connection(rx).await;
     let (status2, _) = executor.get_worker_metadata(&worker_id).await.unwrap();
 
     executor.resume(&worker_id, false).await;
@@ -2300,6 +2272,8 @@ async fn long_running_poll_loop_connection_can_be_restored_after_resume(
 
     // wait for one loop to finish
     {
+        let mut found1 = false;
+        let mut found2 = false;
         while !(found1 && found2) {
             match rx.recv().await {
                 Some(Some(event)) => {
@@ -2364,10 +2338,10 @@ async fn long_running_poll_loop_connection_can_be_restored_after_resume(
 #[timeout(120_000)]
 async fn long_running_poll_loop_worker_can_be_deleted_after_interrupt(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let response = Arc::new(Mutex::new("initial".to_string()));
     let response_clone = response.clone();
@@ -2396,7 +2370,7 @@ async fn long_running_poll_loop_worker_can_be_deleted_after_interrupt(
     env.insert("PORT".to_string(), host_http_port.to_string());
 
     let worker_id = executor
-        .start_worker_with(&component_id, "poll-loop-component-5", vec![], env)
+        .start_worker_with(&component_id, "poll-loop-component-5", vec![], env, vec![])
         .await;
 
     let rx = executor.capture_output_with_termination(&worker_id).await;
@@ -2431,9 +2405,12 @@ async fn long_running_poll_loop_worker_can_be_deleted_after_interrupt(
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn shopping_cart_resource_example(last_unique_id: &LastUniqueId, deps: &Deps) {
+async fn shopping_cart_resource_example(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("shopping-cart-resource").store().await;
     let worker_id = executor
@@ -2459,12 +2436,12 @@ async fn shopping_cart_resource_example(last_unique_id: &LastUniqueId, deps: &De
                     value: cart[0].clone(),
                     typ: analysed_type::u64(),
                 },
-                vec![
+                Record(vec![
                     ("product-id", "G1000".into_value_and_type()),
                     ("name", "Golem T-Shirt M".into_value_and_type()),
                     ("price", 100.0f32.into_value_and_type()),
                     ("quantity", 5u32.into_value_and_type()),
-                ]
+                ])
                 .into_value_and_type(),
             ],
         )
@@ -2479,12 +2456,12 @@ async fn shopping_cart_resource_example(last_unique_id: &LastUniqueId, deps: &De
                     value: cart[0].clone(),
                     typ: analysed_type::u64(),
                 },
-                vec![
+                Record(vec![
                     ("product-id", "G1001".into_value_and_type()),
                     ("name", "Golem Cloud Subscription 1y".into_value_and_type()),
                     ("price", 999999.0f32.into_value_and_type()),
                     ("quantity", 1u32.into_value_and_type()),
-                ]
+                ])
                 .into_value_and_type(),
             ],
         )
@@ -2499,12 +2476,12 @@ async fn shopping_cart_resource_example(last_unique_id: &LastUniqueId, deps: &De
                     value: cart[0].clone(),
                     typ: analysed_type::u64(),
                 },
-                vec![
+                Record(vec![
                     ("product-id", "G1002".into_value_and_type()),
                     ("name", "Mud Golem".into_value_and_type()),
                     ("price", 11.0f32.into_value_and_type()),
                     ("quantity", 10u32.into_value_and_type()),
-                ]
+                ])
                 .into_value_and_type(),
             ],
         )
@@ -2577,9 +2554,12 @@ async fn shopping_cart_resource_example(last_unique_id: &LastUniqueId, deps: &De
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn counter_resource_test_1(last_unique_id: &LastUniqueId, deps: &Deps) {
+async fn counter_resource_test_1(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("counters").store().await;
     let worker_id = executor.start_worker(&component_id, "counters-1").await;
@@ -2659,7 +2639,7 @@ async fn counter_resource_test_1(last_unique_id: &LastUniqueId, deps: &Deps) {
         .iter()
         .map(|(k, v)| {
             (
-                *k,
+                k.to_string(),
                 WorkerResourceDescription {
                     created_at: ts,
                     ..v.clone()
@@ -2667,14 +2647,15 @@ async fn counter_resource_test_1(last_unique_id: &LastUniqueId, deps: &Deps) {
             )
         })
         .collect::<Vec<_>>();
-    resources1.sort_by_key(|(k, _v)| *k);
+    resources1.sort_by_key(|(k, _v)| k.clone());
     check!(
         resources1
             == vec![(
-                WorkerResourceId(0),
+                "0".to_string(),
                 WorkerResourceDescription {
                     created_at: ts,
-                    indexed_resource_key: None
+                    resource_owner: "rpc:counters-exports/api".to_string(),
+                    resource_name: "counter".to_string()
                 }
             ),]
     );
@@ -2685,7 +2666,7 @@ async fn counter_resource_test_1(last_unique_id: &LastUniqueId, deps: &Deps) {
         .iter()
         .map(|(k, v)| {
             (
-                *k,
+                k.to_string(),
                 WorkerResourceDescription {
                     created_at: ts,
                     ..v.clone()
@@ -2701,159 +2682,12 @@ async fn counter_resource_test_1(last_unique_id: &LastUniqueId, deps: &Deps) {
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn counter_resource_test_2(last_unique_id: &LastUniqueId, deps: &Deps) {
-    let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
-
-    let component_id = executor.component("counters").store().await;
-    let worker_id = executor.start_worker(&component_id, "counters-2").await;
-    executor.log_output(&worker_id).await;
-
-    let _ = executor
-        .invoke_and_await(
-            &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter1\").inc-by}",
-            vec![5u64.into_value_and_type()],
-        )
-        .await;
-
-    let _ = executor
-        .invoke_and_await(
-            &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter2\").inc-by}",
-            vec![1u64.into_value_and_type()],
-        )
-        .await;
-    let _ = executor
-        .invoke_and_await(
-            &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter2\").inc-by}",
-            vec![2u64.into_value_and_type()],
-        )
-        .await;
-
-    let result1 = executor
-        .invoke_and_await(
-            &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter1\").get-value}",
-            vec![],
-        )
-        .await;
-    let result2 = executor
-        .invoke_and_await(
-            &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter2\").get-value}",
-            vec![],
-        )
-        .await;
-
-    let (metadata1, _) = executor.get_worker_metadata(&worker_id).await.unwrap();
-
-    let _ = executor
-        .invoke_and_await(
-            &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter1\").drop}",
-            vec![],
-        )
-        .await;
-    let _ = executor
-        .invoke_and_await(
-            &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter2\").drop}",
-            vec![],
-        )
-        .await;
-
-    let result3 = executor
-        .invoke_and_await(
-            &worker_id,
-            "rpc:counters-exports/api.{get-all-dropped}",
-            vec![],
-        )
-        .await;
-
-    let (metadata2, _) = executor.get_worker_metadata(&worker_id).await.unwrap();
-
-    let _oplog = executor.get_oplog(&worker_id, OplogIndex::INITIAL).await;
-
-    drop(executor);
-
-    check!(result1 == Ok(vec![Value::U64(5)]));
-    check!(result2 == Ok(vec![Value::U64(3)]));
-    check!(
-        result3
-            == Ok(vec![Value::List(vec![
-                Value::Tuple(vec![Value::String("counter1".to_string()), Value::U64(5)]),
-                Value::Tuple(vec![Value::String("counter2".to_string()), Value::U64(3)])
-            ])])
-    );
-
-    let ts = Timestamp::now_utc();
-    let mut resources1 = metadata1
-        .last_known_status
-        .owned_resources
-        .iter()
-        .map(|(k, v)| {
-            (
-                *k,
-                WorkerResourceDescription {
-                    created_at: ts,
-                    ..v.clone()
-                },
-            )
-        })
-        .collect::<Vec<_>>();
-    resources1.sort_by_key(|(k, _v)| *k);
-    check!(
-        resources1
-            == vec![
-                (
-                    WorkerResourceId(0),
-                    WorkerResourceDescription {
-                        created_at: ts,
-                        indexed_resource_key: Some(IndexedResourceKey {
-                            resource_name: "counter".to_string(),
-                            resource_params: vec!["\"counter1\"".to_string()]
-                        })
-                    }
-                ),
-                (
-                    WorkerResourceId(1),
-                    WorkerResourceDescription {
-                        created_at: ts,
-                        indexed_resource_key: Some(IndexedResourceKey {
-                            resource_name: "counter".to_string(),
-                            resource_params: vec!["\"counter2\"".to_string()]
-                        })
-                    }
-                )
-            ]
-    );
-
-    let resources2 = metadata2
-        .last_known_status
-        .owned_resources
-        .iter()
-        .map(|(k, v)| {
-            (
-                *k,
-                WorkerResourceDescription {
-                    created_at: ts,
-                    ..v.clone()
-                },
-            )
-        })
-        .collect::<Vec<_>>();
-
-    check!(resources2 == vec![]);
-}
-
-#[test]
-#[tracing::instrument]
-#[timeout(120_000)]
-async fn reconstruct_interrupted_state(last_unique_id: &LastUniqueId, deps: &Deps) {
+async fn reconstruct_interrupted_state(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("interruption").store().await;
     let worker_id = executor.start_worker(&component_id, "interruption-1").await;
@@ -2907,9 +2741,12 @@ async fn reconstruct_interrupted_state(last_unique_id: &LastUniqueId, deps: &Dep
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn invocation_queue_is_persistent(last_unique_id: &LastUniqueId, deps: &Deps) {
+async fn invocation_queue_is_persistent(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let response = Arc::new(Mutex::new("initial".to_string()));
     let response_clone = response.clone();
@@ -2938,7 +2775,13 @@ async fn invocation_queue_is_persistent(last_unique_id: &LastUniqueId, deps: &De
     env.insert("PORT".to_string(), host_http_port.to_string());
 
     let worker_id = executor
-        .start_worker_with(&component_id, "invocation-queue-is-persistent", vec![], env)
+        .start_worker_with(
+            &component_id,
+            "invocation-queue-is-persistent",
+            vec![],
+            env,
+            vec![],
+        )
         .await;
 
     executor.log_output(&worker_id).await;
@@ -2980,7 +2823,7 @@ async fn invocation_queue_is_persistent(last_unique_id: &LastUniqueId, deps: &De
         .await;
 
     drop(executor);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     executor
         .invoke(&worker_id, "golem:it/api.{increment}", vec![])
@@ -3012,9 +2855,12 @@ async fn invocation_queue_is_persistent(last_unique_id: &LastUniqueId, deps: &De
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn invoke_with_non_existing_function(last_unique_id: &LastUniqueId, deps: &Deps) {
+async fn invoke_with_non_existing_function(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("option-service").store().await;
     let worker_id = executor
@@ -3047,9 +2893,12 @@ async fn invoke_with_non_existing_function(last_unique_id: &LastUniqueId, deps:
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn invoke_with_wrong_parameters(last_unique_id: &LastUniqueId, deps: &Deps) {
+async fn invoke_with_wrong_parameters(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("option-service").store().await;
     let worker_id = executor
@@ -3084,9 +2933,12 @@ async fn invoke_with_wrong_parameters(last_unique_id: &LastUniqueId, deps: &Deps
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn stderr_returned_for_failed_component(last_unique_id: &LastUniqueId, deps: &Deps) {
+async fn stderr_returned_for_failed_component(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("failing-component").store().await;
     let worker_id = executor
@@ -3158,9 +3010,12 @@ async fn stderr_returned_for_failed_component(last_unique_id: &LastUniqueId, dep
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn cancelling_pending_invocations(last_unique_id: &LastUniqueId, deps: &Deps) {
+async fn cancelling_pending_invocations(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("counters").store().await;
     let worker_id = executor
@@ -3172,12 +3027,28 @@ async fn cancelling_pending_invocations(last_unique_id: &LastUniqueId, deps: &De
     let ik3 = IdempotencyKey::fresh();
     let ik4 = IdempotencyKey::fresh();
 
+    let counter1 = executor
+        .invoke_and_await(
+            &worker_id,
+            "rpc:counters-exports/api.{[constructor]counter}",
+            vec!["counter1".into_value_and_type()],
+        )
+        .await
+        .unwrap();
+    let counter_handle_type = AnalysedType::Handle(TypeHandle {
+        name: None,
+        owner: None,
+        resource_id: AnalysedResourceId(0),
+        mode: AnalysedResourceMode::Borrowed,
+    });
+    let counter_ref = ValueAndType::new(counter1[0].clone(), counter_handle_type);
+
     let _ = executor
         .invoke_and_await_with_key(
             &worker_id,
             &ik1,
-            "rpc:counters-exports/api.{counter(\"counter1\").inc-by}",
-            vec![5u64.into_value_and_type()],
+            "rpc:counters-exports/api.{[method]counter.inc-by}",
+            vec![counter_ref.clone(), 5u64.into_value_and_type()],
         )
         .await
         .unwrap();
@@ -3185,8 +3056,8 @@ async fn cancelling_pending_invocations(last_unique_id: &LastUniqueId, deps: &De
     let promise_id = executor
         .invoke_and_await(
             &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter1\").create-promise}",
-            vec![],
+            "rpc:counters-exports/api.{[method]counter.create-promise}",
+            vec![counter_ref.clone()],
         )
         .await
         .unwrap();
@@ -3194,11 +3065,14 @@ async fn cancelling_pending_invocations(last_unique_id: &LastUniqueId, deps: &De
     executor
         .invoke(
             &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter1\").block-on-promise}",
-            vec![ValueAndType {
-                value: promise_id[0].clone(),
-                typ: PromiseId::get_type(),
-            }],
+            "rpc:counters-exports/api.{[method]counter.block-on-promise}",
+            vec![
+                counter_ref.clone(),
+                ValueAndType {
+                    value: promise_id[0].clone(),
+                    typ: PromiseId::get_type(),
+                },
+            ],
         )
         .await
         .unwrap();
@@ -3207,8 +3081,8 @@ async fn cancelling_pending_invocations(last_unique_id: &LastUniqueId, deps: &De
         .invoke_with_key(
             &worker_id,
             &ik2,
-            "rpc:counters-exports/api.{counter(\"counter1\").inc-by}",
-            vec![6u64.into_value_and_type()],
+            "rpc:counters-exports/api.{[method]counter.inc-by}",
+            vec![counter_ref.clone(), 6u64.into_value_and_type()],
         )
         .await
         .unwrap();
@@ -3217,8 +3091,8 @@ async fn cancelling_pending_invocations(last_unique_id: &LastUniqueId, deps: &De
         .invoke_with_key(
             &worker_id,
             &ik3,
-            "rpc:counters-exports/api.{counter(\"counter1\").inc-by}",
-            vec![7u64.into_value_and_type()],
+            "rpc:counters-exports/api.{[method]counter.inc-by}",
+            vec![counter_ref.clone(), 7u64.into_value_and_type()],
         )
         .await
         .unwrap();
@@ -3249,6 +3123,7 @@ async fn cancelling_pending_invocations(last_unique_id: &LastUniqueId, deps: &De
             ),
             data: vec![42],
             account_id: Some(executor.account_id.clone().into()),
+            project_id: Some(executor.default_project_id.clone().into()),
         })
         .await
         .unwrap();
@@ -3256,8 +3131,8 @@ async fn cancelling_pending_invocations(last_unique_id: &LastUniqueId, deps: &De
     let final_result = executor
         .invoke_and_await(
             &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter1\").get-value}",
-            vec![],
+            "rpc:counters-exports/api.{[method]counter.get-value}",
+            vec![counter_ref.clone()],
         )
         .await
         .unwrap();
@@ -3276,11 +3151,11 @@ async fn cancelling_pending_invocations(last_unique_id: &LastUniqueId, deps: &De
 #[timeout(120_000)]
 async fn resolve_components_from_name(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     // Make sure the name is unique
     let counter_component_id = executor
@@ -3337,11 +3212,11 @@ async fn scheduled_invocation_test(
     server_component_name: &str,
     client_component_name: &str,
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let server_component = executor.component(server_component_name).store().await;
 
@@ -3500,7 +3375,9 @@ async fn gen_scheduled_invocation_tests(r: &mut DynamicTestRegistration) {
             timeout: Some(Duration::from_secs(120)),
             ..Default::default()
         },
-        move |last_unique_id: &LastUniqueId, deps: &Deps, tracing: &Tracing| async {
+        move |last_unique_id: &LastUniqueId,
+              deps: &WorkerExecutorTestDependencies,
+              tracing: &Tracing| async {
             scheduled_invocation_test(
                 "it_scheduled_invocation_server",
                 "it_scheduled_invocation_client",
@@ -3518,7 +3395,9 @@ async fn gen_scheduled_invocation_tests(r: &mut DynamicTestRegistration) {
             timeout: Some(Duration::from_secs(120)),
             ..Default::default()
         },
-        move |last_unique_id: &LastUniqueId, deps: &Deps, tracing: &Tracing| async {
+        move |last_unique_id: &LastUniqueId,
+              deps: &WorkerExecutorTestDependencies,
+              tracing: &Tracing| async {
             scheduled_invocation_test(
                 "it_scheduled_invocation_server_stubless",
                 "it_scheduled_invocation_client_stubless",
@@ -3536,10 +3415,10 @@ async fn gen_scheduled_invocation_tests(r: &mut DynamicTestRegistration) {
 #[timeout(120_000)]
 async fn error_handling_when_worker_is_invoked_with_wrong_parameter_type(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("option-service").store().await;
     let worker_id = executor
diff --git a/golem-worker-executor/tests/blobstore.rs b/golem-worker-executor/tests/blobstore.rs
index ed0d33ce..eb074004 100644
--- a/golem-worker-executor/tests/blobstore.rs
+++ b/golem-worker-executor/tests/blobstore.rs
@@ -15,14 +15,13 @@
 use test_r::{inherit_test_dep, test};
 
 use crate::common::{start, TestContext};
-use crate::Deps;
-use crate::{LastUniqueId, Tracing};
+use crate::{LastUniqueId, Tracing, WorkerExecutorTestDependencies};
 use assert2::check;
 use golem_test_framework::config::TestDependencies;
 use golem_test_framework::dsl::TestDslUnsafe;
 use golem_wasm_rpc::{IntoValueAndType, Value};
 
-inherit_test_dep!(Deps);
+inherit_test_dep!(WorkerExecutorTestDependencies);
 inherit_test_dep!(LastUniqueId);
 inherit_test_dep!(Tracing);
 
@@ -30,11 +29,11 @@ inherit_test_dep!(Tracing);
 #[tracing::instrument]
 async fn blobstore_exists_return_true_if_the_container_was_created(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("blob-store-service").store().await;
     let worker_name = "blob-store-service-1";
@@ -69,11 +68,11 @@ async fn blobstore_exists_return_true_if_the_container_was_created(
 #[tracing::instrument]
 async fn blobstore_exists_return_false_if_the_container_was_not_created(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("blob-store-service").store().await;
     let worker_name = "blob-store-service-1";
diff --git a/golem-worker-executor/tests/common/mod.rs b/golem-worker-executor/tests/common/mod.rs
index 1f0e6f0e..461b5cd1 100644
--- a/golem-worker-executor/tests/common/mod.rs
+++ b/golem-worker-executor/tests/common/mod.rs
@@ -1,5 +1,4 @@
-use crate::Deps;
-use crate::{LastUniqueId, WorkerExecutorPerTestDependencies};
+use crate::{LastUniqueId, WorkerExecutorPerTestDependencies, WorkerExecutorTestDependencies};
 use anyhow::Error;
 use async_trait::async_trait;
 use golem_api_grpc::proto::golem::workerexecutor::v1::worker_executor_client::WorkerExecutorClient;
@@ -12,11 +11,10 @@ use golem_common::model::invocation_context::{
     AttributeValue, InvocationContextSpan, InvocationContextStack, SpanId,
 };
 use golem_common::model::oplog::UpdateDescription;
-use golem_common::model::oplog::WorkerResourceId;
 use golem_common::model::{
-    AccountId, ComponentFilePath, ComponentId, ComponentVersion, IdempotencyKey, OwnedWorkerId,
-    PluginInstallationId, RetryConfig, TargetWorkerId, WorkerFilter, WorkerId, WorkerMetadata,
-    WorkerStatus, WorkerStatusRecord,
+    AccountId, ComponentFilePath, ComponentId, ComponentVersion, GetFileSystemNodeResult,
+    IdempotencyKey, OwnedWorkerId, PluginInstallationId, ProjectId, RetryConfig, WorkerFilter,
+    WorkerId, WorkerMetadata, WorkerStatus, WorkerStatusRecord,
 };
 use golem_service_base::config::{BlobStorageConfig, LocalFileSystemBlobStorageConfig};
 use golem_service_base::error::worker_executor::{InterruptKind, WorkerExecutorError};
@@ -25,11 +23,7 @@ use golem_service_base::service::plugin_wasm_files::PluginWasmFilesService;
 use golem_service_base::storage::blob::BlobStorage;
 use golem_test_framework::components::cloud_service::CloudService;
 use golem_test_framework::components::component_compilation_service::ComponentCompilationService;
-use golem_test_framework::components::rdb::docker_mysql::DockerMysqlRdb;
-use golem_test_framework::components::rdb::docker_postgres::DockerPostgresRdb;
-use golem_test_framework::components::rdb::provided_mysql::ProvidedMysqlRdb;
-use golem_test_framework::components::rdb::provided_postgres::ProvidedPostgresRdb;
-use golem_test_framework::components::rdb::{DbInfo, MysqlInfo, PostgresInfo, Rdb, RdbConnection};
+use golem_test_framework::components::rdb::Rdb;
 use golem_test_framework::components::redis::Redis;
 use golem_test_framework::components::redis_monitor::RedisMonitor;
 use golem_test_framework::components::shard_manager::ShardManager;
@@ -38,37 +32,35 @@ use golem_test_framework::config::TestDependencies;
 use golem_test_framework::dsl::to_worker_metadata;
 use golem_wasm_rpc::golem_rpc_0_2_x::types::{FutureInvokeResult, WasmRpc};
 use golem_wasm_rpc::golem_rpc_0_2_x::types::{HostFutureInvokeResult, Pollable};
-use golem_wasm_rpc::wasmtime::ResourceStore;
+use golem_wasm_rpc::wasmtime::{ResourceStore, ResourceTypeId};
 use golem_wasm_rpc::{HostWasmRpc, RpcError, Uri, Value, ValueAndType, WitValue};
 use golem_worker_executor::durable_host::{
     DurableWorkerCtx, DurableWorkerCtxView, PublicDurableWorkerState,
 };
 use golem_worker_executor::model::{
-    CurrentResourceLimits, ExecutionStatus, LastError, ListDirectoryResult, ReadFileResult,
-    TrapType, WorkerConfig,
+    CurrentResourceLimits, ExecutionStatus, LastError, ReadFileResult, TrapType, WorkerConfig,
 };
 use golem_worker_executor::preview2::golem::durability;
-use golem_worker_executor::preview2::golem_api_1_x;
+use golem_worker_executor::preview2::{golem_agent, golem_api_1_x};
 use golem_worker_executor::services::active_workers::ActiveWorkers;
+use golem_worker_executor::services::agent_types::AgentTypesService;
 use golem_worker_executor::services::blob_store::BlobStoreService;
-use golem_worker_executor::services::component::{ComponentMetadata, ComponentService};
+use golem_worker_executor::services::component::ComponentService;
 use golem_worker_executor::services::events::Events;
 use golem_worker_executor::services::file_loader::FileLoader;
 use golem_worker_executor::services::golem_config::{
-    CompiledComponentServiceConfig, CompiledComponentServiceEnabledConfig, ComponentServiceConfig,
-    ComponentServiceLocalConfig, GolemConfig, IndexedStorageConfig,
-    IndexedStorageKVStoreRedisConfig, KeyValueStorageConfig, MemoryConfig, ProjectServiceConfig,
-    ProjectServiceDisabledConfig, RdbmsConfig, ShardManagerServiceConfig,
+    AgentTypesServiceConfig, AgentTypesServiceLocalConfig, CompiledComponentServiceConfig,
+    CompiledComponentServiceEnabledConfig, ComponentServiceConfig, ComponentServiceLocalConfig,
+    GolemConfig, IndexedStorageConfig, IndexedStorageKVStoreRedisConfig, KeyValueStorageConfig,
+    MemoryConfig, ProjectServiceConfig, ProjectServiceDisabledConfig, ShardManagerServiceConfig,
     ShardManagerServiceSingleShardConfig,
 };
 use golem_worker_executor::services::key_value::KeyValueService;
 use golem_worker_executor::services::oplog::plugin::OplogProcessorPlugin;
 use golem_worker_executor::services::oplog::{Oplog, OplogService};
 use golem_worker_executor::services::plugins::{Plugins, PluginsObservations};
+use golem_worker_executor::services::projects::ProjectService;
 use golem_worker_executor::services::promise::PromiseService;
-use golem_worker_executor::services::rdbms::mysql::{types as mysql_types, MysqlType};
-use golem_worker_executor::services::rdbms::postgres::{types as postgres_types, PostgresType};
-use golem_worker_executor::services::rdbms::Rdbms;
 use golem_worker_executor::services::resource_limits::ResourceLimits;
 use golem_worker_executor::services::rpc::{DirectWorkerInvocationRpc, RemoteInvocationRpc, Rpc};
 use golem_worker_executor::services::scheduler::SchedulerService;
@@ -88,14 +80,14 @@ use golem_worker_executor::services::{
 use golem_worker_executor::wasi_host::create_linker;
 use golem_worker_executor::worker::{RetryDecision, Worker};
 use golem_worker_executor::workerctx::{
-    DynamicLinking, ExternalOperations, FileSystemReading, FuelManagement, IndexedResourceStore,
-    InvocationContextManagement, InvocationHooks, InvocationManagement, StatusManagement,
-    UpdateManagement, WorkerCtx,
+    DynamicLinking, ExternalOperations, FileSystemReading, FuelManagement, HasWasiConfigVars,
+    InvocationContextManagement, InvocationHooks, InvocationManagement, LogEventEmitBehaviour,
+    StatusManagement, UpdateManagement, WorkerCtx,
 };
 use golem_worker_executor::{Bootstrap, RunDetails};
 use prometheus::Registry;
-use std::collections::HashSet;
-use std::env::var;
+use std::collections::{BTreeMap, HashSet};
+use std::future::Future;
 use std::path::Path;
 use std::sync::atomic::Ordering;
 use std::sync::{Arc, RwLock, Weak};
@@ -243,12 +235,15 @@ impl TestContext {
     }
 }
 
-pub async fn start(deps: &Deps, context: &TestContext) -> anyhow::Result<TestWorkerExecutor> {
+pub async fn start(
+    deps: &WorkerExecutorTestDependencies,
+    context: &TestContext,
+) -> anyhow::Result<TestWorkerExecutor> {
     start_customized(deps, context, None, None).await
 }
 
 pub async fn start_customized(
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     context: &TestContext,
     system_memory_override: Option<u64>,
     retry_override: Option<RetryConfig>,
@@ -260,6 +255,15 @@ pub async fn start_customized(
     info!("Using Redis on port {}", redis.public_port());
 
     let prometheus = golem_worker_executor::metrics::register_all();
+    let admin_account_id = deps.cloud_service.admin_account_id();
+    let admin_project_id = deps
+        .cloud_service
+        .get_default_project(&deps.cloud_service.admin_token())
+        .await?;
+    let admin_project_name = deps
+        .cloud_service
+        .get_project_name(&admin_project_id)
+        .await?;
     let mut config = GolemConfig {
         key_value_storage: KeyValueStorageConfig::Redis(RedisConfig {
             port: redis.public_port(),
@@ -285,7 +289,12 @@ pub async fn start_customized(
         component_service: ComponentServiceConfig::Local(ComponentServiceLocalConfig {
             root: Path::new("data/components").to_path_buf(),
         }),
-        project_service: ProjectServiceConfig::Disabled(ProjectServiceDisabledConfig {}),
+        project_service: ProjectServiceConfig::Disabled(ProjectServiceDisabledConfig {
+            account_id: admin_account_id,
+            project_id: admin_project_id,
+            project_name: admin_project_name,
+        }),
+        agent_types_service: AgentTypesServiceConfig::Local(AgentTypesServiceLocalConfig {}),
         ..Default::default()
     };
     if let Some(retry) = retry_override {
@@ -342,6 +351,28 @@ impl DurableWorkerCtxView<TestWorkerCtx> for TestWorkerCtx {
     }
 }
 
+impl HasWasiConfigVars for TestWorkerCtx {
+    fn wasi_config_vars(&self) -> BTreeMap<String, String> {
+        self.durable_ctx.wasi_config_vars()
+    }
+}
+
+impl wasmtime_wasi::p2::bindings::cli::environment::Host for TestWorkerCtx {
+    fn get_environment(
+        &mut self,
+    ) -> impl Future<Output = anyhow::Result<Vec<(String, String)>>> + Send {
+        wasmtime_wasi::p2::bindings::cli::environment::Host::get_environment(&mut self.durable_ctx)
+    }
+
+    fn get_arguments(&mut self) -> impl Future<Output = anyhow::Result<Vec<String>>> + Send {
+        wasmtime_wasi::p2::bindings::cli::environment::Host::get_arguments(&mut self.durable_ctx)
+    }
+
+    fn initial_cwd(&mut self) -> impl Future<Output = anyhow::Result<Option<String>>> + Send {
+        wasmtime_wasi::p2::bindings::cli::environment::Host::initial_cwd(&mut self.durable_ctx)
+    }
+}
+
 #[async_trait]
 impl FuelManagement for TestWorkerCtx {
     fn is_out_of_fuel(&self, _current_level: i64) -> bool {
@@ -359,34 +390,6 @@ impl FuelManagement for TestWorkerCtx {
     }
 }
 
-#[async_trait]
-impl IndexedResourceStore for TestWorkerCtx {
-    fn get_indexed_resource(
-        &self,
-        resource_name: &str,
-        resource_params: &[String],
-    ) -> Option<WorkerResourceId> {
-        self.durable_ctx
-            .get_indexed_resource(resource_name, resource_params)
-    }
-
-    async fn store_indexed_resource(
-        &mut self,
-        resource_name: &str,
-        resource_params: &[String],
-        resource: WorkerResourceId,
-    ) {
-        self.durable_ctx
-            .store_indexed_resource(resource_name, resource_params, resource)
-            .await
-    }
-
-    fn drop_indexed_resource(&mut self, resource_name: &str, resource_params: &[String]) {
-        self.durable_ctx
-            .drop_indexed_resource(resource_name, resource_params)
-    }
-}
-
 #[async_trait]
 impl ExternalOperations<TestWorkerCtx> for TestWorkerCtx {
     type ExtraDeps = ();
@@ -420,8 +423,10 @@ impl ExternalOperations<TestWorkerCtx> for TestWorkerCtx {
     async fn resume_replay(
         store: &mut (impl AsContextMut<Data = TestWorkerCtx> + Send),
         instance: &Instance,
+        refresh_replay_target: bool,
     ) -> Result<RetryDecision, WorkerExecutorError> {
-        DurableWorkerCtx::<TestWorkerCtx>::resume_replay(store, instance).await
+        DurableWorkerCtx::<TestWorkerCtx>::resume_replay(store, instance, refresh_replay_target)
+            .await
     }
 
     async fn prepare_instance(
@@ -434,12 +439,12 @@ impl ExternalOperations<TestWorkerCtx> for TestWorkerCtx {
 
     async fn record_last_known_limits<T: HasAll<TestWorkerCtx> + Send + Sync>(
         this: &T,
-        account_id: &AccountId,
+        project_id: &ProjectId,
         last_known_limits: &CurrentResourceLimits,
     ) -> Result<(), WorkerExecutorError> {
         DurableWorkerCtx::<TestWorkerCtx>::record_last_known_limits(
             this,
-            account_id,
+            project_id,
             last_known_limits,
         )
         .await
@@ -460,12 +465,14 @@ impl ExternalOperations<TestWorkerCtx> for TestWorkerCtx {
 
     async fn on_worker_update_failed_to_start<T: HasAll<TestWorkerCtx> + Send + Sync>(
         this: &T,
+        account_id: &AccountId,
         owned_worker_id: &OwnedWorkerId,
         target_version: ComponentVersion,
         details: Option<String>,
     ) -> Result<(), WorkerExecutorError> {
         DurableWorkerCtx::<TestWorkerCtx>::on_worker_update_failed_to_start(
             this,
+            account_id,
             owned_worker_id,
             target_version,
             details,
@@ -572,15 +579,15 @@ impl ResourceStore for TestWorkerCtx {
         self.durable_ctx.self_uri()
     }
 
-    async fn add(&mut self, resource: ResourceAny) -> u64 {
-        self.durable_ctx.add(resource).await
+    async fn add(&mut self, resource: ResourceAny, name: ResourceTypeId) -> u64 {
+        self.durable_ctx.add(resource, name).await
     }
 
-    async fn get(&mut self, resource_id: u64) -> Option<ResourceAny> {
+    async fn get(&mut self, resource_id: u64) -> Option<(ResourceTypeId, ResourceAny)> {
         ResourceStore::get(&mut self.durable_ctx, resource_id).await
     }
 
-    async fn borrow(&self, resource_id: u64) -> Option<ResourceAny> {
+    async fn borrow(&self, resource_id: u64) -> Option<(ResourceTypeId, ResourceAny)> {
         self.durable_ctx.borrow(resource_id).await
     }
 }
@@ -623,7 +630,10 @@ struct ServerBootstrap {}
 impl WorkerCtx for TestWorkerCtx {
     type PublicState = PublicDurableWorkerState<TestWorkerCtx>;
 
+    const LOG_EVENT_EMIT_BEHAVIOUR: LogEventEmitBehaviour = LogEventEmitBehaviour::LiveOnly;
+
     async fn create(
+        _account_id: AccountId,
         owned_worker_id: OwnedWorkerId,
         promise_service: Arc<dyn PromiseService>,
         worker_service: Arc<dyn WorkerService>,
@@ -648,6 +658,8 @@ impl WorkerCtx for TestWorkerCtx {
         plugins: Arc<dyn Plugins>,
         worker_fork: Arc<dyn WorkerForkService>,
         _resource_limits: Arc<dyn ResourceLimits>,
+        project_service: Arc<dyn ProjectService>,
+        agent_types_service: Arc<dyn AgentTypesService>,
     ) -> Result<Self, WorkerExecutorError> {
         let durable_ctx = DurableWorkerCtx::create(
             owned_worker_id,
@@ -671,6 +683,8 @@ impl WorkerCtx for TestWorkerCtx {
             file_loader,
             plugins,
             worker_fork,
+            project_service,
+            agent_types_service,
         )
         .await?;
         Ok(Self { durable_ctx })
@@ -700,7 +714,11 @@ impl WorkerCtx for TestWorkerCtx {
         self.durable_ctx.owned_worker_id()
     }
 
-    fn component_metadata(&self) -> &ComponentMetadata {
+    fn created_by(&self) -> &AccountId {
+        self.durable_ctx.created_by()
+    }
+
+    fn component_metadata(&self) -> &golem_service_base::model::Component {
         self.durable_ctx.component_metadata()
     }
 
@@ -723,15 +741,6 @@ impl WorkerCtx for TestWorkerCtx {
     fn worker_fork(&self) -> Arc<dyn WorkerForkService> {
         self.durable_ctx.worker_fork()
     }
-
-    async fn generate_unique_local_worker_id(
-        &mut self,
-        remote_worker_id: TargetWorkerId,
-    ) -> Result<WorkerId, WorkerExecutorError> {
-        self.durable_ctx
-            .generate_unique_local_worker_id(remote_worker_id)
-            .await
-    }
 }
 
 #[async_trait]
@@ -776,11 +785,11 @@ impl ResourceLimiterAsync for TestWorkerCtx {
 
 #[async_trait]
 impl FileSystemReading for TestWorkerCtx {
-    async fn list_directory(
+    async fn get_file_system_node(
         &self,
         path: &ComponentFilePath,
-    ) -> Result<ListDirectoryResult, WorkerExecutorError> {
-        self.durable_ctx.list_directory(path).await
+    ) -> Result<GetFileSystemNodeResult, WorkerExecutorError> {
+        self.durable_ctx.get_file_system_node(path).await
     }
 
     async fn read_file(
@@ -799,13 +808,6 @@ impl HostWasmRpc for TestWorkerCtx {
         self.durable_ctx.new(worker_id).await
     }
 
-    async fn ephemeral(
-        &mut self,
-        component_id: golem_wasm_rpc::ComponentId,
-    ) -> anyhow::Result<Resource<WasmRpc>> {
-        self.durable_ctx.ephemeral(component_id).await
-    }
-
     async fn invoke_and_await(
         &mut self,
         self_: Resource<WasmRpc>,
@@ -895,7 +897,7 @@ impl DynamicLinking<TestWorkerCtx> for TestWorkerCtx {
         engine: &Engine,
         linker: &mut Linker<TestWorkerCtx>,
         component: &Component,
-        component_metadata: &ComponentMetadata,
+        component_metadata: &golem_service_base::model::Component,
     ) -> anyhow::Result<()> {
         self.durable_ctx
             .link(engine, linker, component, component_metadata)
@@ -939,6 +941,10 @@ impl InvocationContextManagement for TestWorkerCtx {
             .set_span_attribute(span_id, key, value)
             .await
     }
+
+    fn clone_as_inherited_stack(&self, current_span_id: &SpanId) -> InvocationContextStack {
+        self.durable_ctx.clone_as_inherited_stack(current_span_id)
+    }
 }
 
 #[async_trait]
@@ -964,14 +970,15 @@ impl Bootstrap<TestWorkerCtx> for ServerBootstrap {
         golem_config: &GolemConfig,
         blob_storage: Arc<dyn BlobStorage>,
         plugin_observations: Arc<dyn PluginsObservations>,
+        project_service: Arc<dyn ProjectService>,
     ) -> Arc<dyn ComponentService> {
         golem_worker_executor::services::component::configured(
             &golem_config.component_service,
-            &golem_config.project_service,
             &golem_config.component_cache,
             &golem_config.compiled_component_service,
             blob_storage,
             plugin_observations,
+            project_service,
         )
     }
 
@@ -1000,6 +1007,8 @@ impl Bootstrap<TestWorkerCtx> for ServerBootstrap {
         file_loader: Arc<FileLoader>,
         plugins: Arc<dyn Plugins>,
         oplog_processor_plugin: Arc<dyn OplogProcessorPlugin>,
+        project_service: Arc<dyn ProjectService>,
+        agent_types_service: Arc<dyn AgentTypesService>,
     ) -> anyhow::Result<All<TestWorkerCtx>> {
         let resource_limits = resource_limits::configured(&golem_config.resource_limits);
         let worker_fork = Arc::new(DefaultWorkerFork::new(
@@ -1031,6 +1040,8 @@ impl Bootstrap<TestWorkerCtx> for ServerBootstrap {
             plugins.clone(),
             oplog_processor_plugin.clone(),
             resource_limits.clone(),
+            project_service.clone(),
+            agent_types_service.clone(),
             (),
         ));
 
@@ -1063,10 +1074,13 @@ impl Bootstrap<TestWorkerCtx> for ServerBootstrap {
             plugins.clone(),
             oplog_processor_plugin.clone(),
             resource_limits.clone(),
+            project_service.clone(),
+            agent_types_service.clone(),
             (),
         ));
         Ok(All::new(
             active_workers,
+            agent_types_service,
             engine,
             linker,
             runtime,
@@ -1092,6 +1106,7 @@ impl Bootstrap<TestWorkerCtx> for ServerBootstrap {
             plugins,
             oplog_processor_plugin,
             resource_limits,
+            project_service,
             (),
         ))
     }
@@ -1102,6 +1117,7 @@ impl Bootstrap<TestWorkerCtx> for ServerBootstrap {
         golem_api_1_x::oplog::add_to_linker_get_host(&mut linker, get_durable_ctx)?;
         golem_api_1_x::context::add_to_linker_get_host(&mut linker, get_durable_ctx)?;
         durability::durability::add_to_linker_get_host(&mut linker, get_durable_ctx)?;
+        golem_agent::host::add_to_linker_get_host(&mut linker, get_durable_ctx)?;
         golem_wasm_rpc::golem_rpc_0_2_x::types::add_to_linker_get_host(
             &mut linker,
             get_durable_ctx,
@@ -1113,419 +1129,3 @@ impl Bootstrap<TestWorkerCtx> for ServerBootstrap {
 fn get_durable_ctx(ctx: &mut TestWorkerCtx) -> &mut DurableWorkerCtx<TestWorkerCtx> {
     &mut ctx.durable_ctx
 }
-
-pub fn new_worker_id() -> WorkerId {
-    WorkerId {
-        component_id: ComponentId::new_v4(),
-        worker_name: "test".to_string(),
-    }
-}
-
-pub async fn postgres_host(
-    rdbms: Option<Arc<dyn Rdbms<PostgresType> + Send + Sync>>,
-) -> RdbPostgresHost {
-    let docker_active = var("GOLEM_DOCKER_SERVICES")
-        .map(|v| v == "true")
-        .unwrap_or(false);
-    let host = RdbPostgresHost {
-        rdbms: rdbms.unwrap_or_else(|| PostgresType::new_rdbms(RdbmsConfig::default())),
-        container: if docker_active {
-            Some(futures::executor::block_on(DockerPostgresRdb::new(
-                "test-net",
-            )))
-        } else {
-            None
-        },
-        provided: if !docker_active {
-            Some(ProvidedPostgresRdb::new(PostgresInfo {
-                public_host: "localhost".to_string(),
-                public_port: 5432,
-                private_host: "localhost".to_string(),
-                private_port: 5432,
-                database_name: "postgres".to_string(),
-                username: "postgres".to_string(),
-                password: "postgres".to_string(),
-            }))
-        } else {
-            None
-        },
-    };
-
-    host.reset().await;
-
-    host
-}
-
-pub async fn mysql_host(rdbms: Option<Arc<dyn Rdbms<MysqlType> + Send + Sync>>) -> RdbMysqlHost {
-    let docker_active = var("GOLEM_DOCKER_SERVICES")
-        .map(|v| v == "true")
-        .unwrap_or(false);
-    let host = RdbMysqlHost {
-        rdbms: rdbms.unwrap_or_else(|| MysqlType::new_rdbms(RdbmsConfig::default())),
-        container: if docker_active {
-            Some(futures::executor::block_on(DockerMysqlRdb::new("test-net")))
-        } else {
-            None
-        },
-        provided: if !docker_active {
-            Some(ProvidedMysqlRdb::new(MysqlInfo {
-                private_host: "localhost".to_string(),
-                private_port: 3306,
-                public_host: "localhost".to_string(),
-                public_port: 3306,
-                database_name: "mysql".to_string(),
-                username: "root".to_string(),
-                password: "mysql".to_string(),
-            }))
-        } else {
-            None
-        },
-    };
-
-    host.reset().await;
-
-    host
-}
-
-pub struct RdbPostgresHost {
-    container: Option<DockerPostgresRdb>,
-    provided: Option<ProvidedPostgresRdb>,
-    rdbms: Arc<dyn Rdbms<PostgresType> + Send + Sync>,
-}
-
-impl RdbPostgresHost {
-    pub fn public_connection_string_to_db(&self, db_name: &str) -> String {
-        if let Some(container) = self.container.as_ref() {
-            return container.public_connection_string_to_db(db_name);
-        }
-        if let Some(provided) = self.provided.as_ref() {
-            return provided.public_connection_string_to_db(db_name);
-        }
-        "".to_string()
-    }
-
-    pub async fn reset(&self) {
-        // Assumes public_connection_string() connects to a maintenance DB like 'postgres'
-        let admin_db_conn_string = self.public_connection_string();
-        let worker_id = new_worker_id();
-
-        match self.rdbms.create(&admin_db_conn_string, &worker_id).await {
-            Ok(admin_pool_key) => {
-                info!(
-                    "Connected to PostgreSQL admin interface {} for reset using pool key: {}",
-                    admin_db_conn_string,
-                    admin_pool_key.masked_address()
-                );
-
-                // Drop all user databases (excluding templates and 'postgres' itself)
-                // Cast datname to TEXT to ensure compatibility
-                let list_databases_sql = "SELECT datname::TEXT FROM pg_database WHERE datistemplate = false AND datname NOT IN ('template0', 'template1', 'postgres');";
-                match self
-                    .rdbms
-                    .query(&admin_pool_key, &worker_id, list_databases_sql, vec![])
-                    .await
-                {
-                    Ok(db_result) => {
-                        if db_result.rows.is_empty() {
-                            info!("No user databases found to drop (excluding template0, template1, postgres).");
-                        }
-                        for row in db_result.rows {
-                            let db_name_to_drop_opt: Option<String> =
-                                match row.values.first().cloned() {
-                                    Some(postgres_types::DbValue::Text(s)) => Some(s),
-                                    _ => None,
-                                };
-
-                            if let Some(db_name_to_drop) = db_name_to_drop_opt {
-                                info!("Attempting to drop database: {}", db_name_to_drop);
-
-                                // WITH (FORCE) is available in PostgreSQL 13+ and closes connections.
-                                let drop_db_sql = format!(
-                                    "DROP DATABASE IF EXISTS \"{}\" WITH (FORCE);",
-                                    db_name_to_drop
-                                );
-                                match self
-                                    .rdbms
-                                    .execute(&admin_pool_key, &worker_id, &drop_db_sql, vec![])
-                                    .await
-                                {
-                                    Ok(_) => {
-                                        info!("Successfully dropped database: {}", db_name_to_drop)
-                                    }
-                                    Err(e) => eprintln!(
-                                        "Failed to drop database {}: {:?}",
-                                        db_name_to_drop, e
-                                    ),
-                                }
-                            } else {
-                                eprintln!(
-                                    "Could not extract database name from row for dropping: {:?}",
-                                    row
-                                );
-                            }
-                        }
-                    }
-                    Err(e) => {
-                        eprintln!("Failed to query database list for reset: {:?}", e);
-                    }
-                }
-
-                // Clean public schema of the 'postgres' database (or the connected admin database)
-                let admin_db_name_for_schema_clean = "postgres"; // Or derive from admin_db_conn_string if more dynamic
-                let drop_schema_sql = "DROP SCHEMA IF EXISTS public CASCADE;";
-                match self.rdbms.execute(&admin_pool_key, &worker_id, drop_schema_sql, vec![]).await {
-                    Ok(_) => info!("Successfully dropped public schema in database {}", admin_db_name_for_schema_clean),
-                    Err(e) => eprintln!("Failed to drop public schema in database {}: {:?} (this may be ok if schema didn't exist)", admin_db_name_for_schema_clean, e),
-                }
-
-                let create_schema_sql = "CREATE SCHEMA public;";
-                match self
-                    .rdbms
-                    .execute(&admin_pool_key, &worker_id, create_schema_sql, vec![])
-                    .await
-                {
-                    Ok(_) => info!(
-                        "Successfully created public schema in database {}",
-                        admin_db_name_for_schema_clean
-                    ),
-                    Err(e) => eprintln!(
-                        "Failed to create public schema in database {}: {:?}",
-                        admin_db_name_for_schema_clean, e
-                    ),
-                }
-
-                if !self.rdbms.remove(&admin_pool_key, &worker_id) {
-                    eprintln!(
-                        "Failed to remove pool key for {} after cleaning",
-                        admin_pool_key.masked_address()
-                    );
-                }
-            }
-            Err(e) => {
-                eprintln!(
-                    "Failed to connect to PostgreSQL admin database {} for cleaning: {:?}",
-                    admin_db_conn_string, e
-                );
-            }
-        }
-    }
-}
-
-#[async_trait]
-impl Rdb for RdbPostgresHost {
-    fn info(&self) -> DbInfo {
-        if let Some(container) = self.container.as_ref() {
-            return container.info();
-        }
-        if let Some(provided) = self.provided.as_ref() {
-            return provided.info();
-        }
-        panic!("Postgres not configured")
-    }
-
-    async fn kill(&self) {
-        if let Some(container) = self.container.as_ref() {
-            container.kill().await;
-            return;
-        }
-        if let Some(provided) = self.provided.as_ref() {
-            provided.kill().await;
-            return;
-        }
-        panic!("Postgres not configured")
-    }
-}
-
-impl RdbConnection for RdbPostgresHost {
-    fn public_connection_string(&self) -> String {
-        if let Some(container) = self.container.as_ref() {
-            return container.public_connection_string();
-        }
-        if let Some(provided) = self.provided.as_ref() {
-            return provided.public_connection_string();
-        }
-        "".to_string()
-    }
-
-    fn private_connection_string(&self) -> String {
-        if let Some(container) = self.container.as_ref() {
-            return container.private_connection_string();
-        }
-        if let Some(provided) = self.provided.as_ref() {
-            return provided.private_connection_string();
-        }
-        "".to_string()
-    }
-}
-
-impl Drop for RdbPostgresHost {
-    fn drop(&mut self) {
-        if let Some(container) = self.container.as_ref() {
-            futures::executor::block_on(container.kill());
-        }
-    }
-}
-
-pub struct RdbMysqlHost {
-    container: Option<DockerMysqlRdb>,
-    provided: Option<ProvidedMysqlRdb>,
-    rdbms: Arc<dyn Rdbms<MysqlType> + Send + Sync>,
-}
-
-impl RdbMysqlHost {
-    pub fn public_connection_string_to_db(&self, db_name: &str) -> String {
-        if let Some(container) = self.container.as_ref() {
-            return container.public_connection_string_to_db(db_name);
-        }
-        if let Some(provided) = self.provided.as_ref() {
-            return provided.public_connection_string_to_db(db_name);
-        }
-        "".to_string()
-    }
-
-    pub async fn reset(&self) {
-        let admin_db_address = self.public_connection_string();
-
-        let worker_id = WorkerId {
-            component_id: ComponentId::new_v4(),
-            worker_name: "mysql-db-reset-worker".to_string(),
-        };
-
-        match self.rdbms.create(&admin_db_address, &worker_id).await {
-            Ok(pool_key) => {
-                info!(
-                    "Connected to MySQL admin interface {} for reset using pool key: {}",
-                    admin_db_address,
-                    pool_key.masked_address()
-                );
-
-                let query_databases = "SHOW DATABASES;";
-                let system_databases = [
-                    "information_schema",
-                    "mysql",
-                    "performance_schema",
-                    "sys",
-                    // Add any other system/default databases specific to your MySQL setup if needed
-                ];
-
-                match self
-                    .rdbms
-                    .query(&pool_key, &worker_id, query_databases, vec![])
-                    .await
-                {
-                    Ok(db_result) => {
-                        if db_result.rows.is_empty() {
-                            info!("No databases found to drop.");
-                        }
-                        for row in db_result.rows {
-                            let db_name_opt: Option<String> = match row.values.first().cloned() {
-                                Some(mysql_types::DbValue::Varchar(s)) => Some(s),
-                                Some(mysql_types::DbValue::Varbinary(bytes)) => {
-                                    String::from_utf8(bytes).ok()
-                                }
-                                _ => None,
-                            };
-
-                            if let Some(db_name) = db_name_opt {
-                                if system_databases.contains(&db_name.as_str()) {
-                                    info!("Skipping system database: {}", db_name);
-                                    continue;
-                                }
-                                info!("Attempting to drop database: {}", db_name);
-                                // MySQL uses backticks for identifiers and doesn't have a WITH (FORCE) equivalent
-                                // for DROP DATABASE in the same way PostgreSQL 13+ does.
-                                // Active connections might prevent dropping.
-                                let drop_db_sql = format!("DROP DATABASE IF EXISTS `{}`;", db_name);
-
-                                match self
-                                    .rdbms
-                                    .execute(&pool_key, &worker_id, &drop_db_sql, vec![])
-                                    .await
-                                {
-                                    Ok(_) => info!("Successfully dropped database: {}", db_name),
-                                    Err(e) => {
-                                        eprintln!("Failed to drop database {}: {:?}. This might be due to active connections or insufficient permissions.", db_name, e);
-                                    }
-                                }
-                            } else {
-                                eprintln!("Could not extract database name from row: {:?}", row);
-                            }
-                        }
-                    }
-                    Err(e) => {
-                        eprintln!("Failed to query database list for reset: {:?}", e);
-                    }
-                }
-
-                if !self.rdbms.remove(&pool_key, &worker_id) {
-                    eprintln!(
-                        "Failed to remove temporary pool key {} after reset",
-                        pool_key.masked_address()
-                    );
-                }
-            }
-            Err(e) => {
-                eprintln!(
-                    "Failed to create admin connection to {} for MySQL reset: {:?}",
-                    admin_db_address, e
-                );
-                eprintln!("Ensure RDBMS service default config matches target MySQL admin access.");
-            }
-        }
-    }
-}
-
-#[async_trait]
-impl Rdb for RdbMysqlHost {
-    fn info(&self) -> DbInfo {
-        if let Some(container) = self.container.as_ref() {
-            return container.info();
-        }
-        if let Some(provided) = self.provided.as_ref() {
-            return provided.info();
-        }
-        panic!("Mysql not configured")
-    }
-
-    async fn kill(&self) {
-        if let Some(container) = self.container.as_ref() {
-            container.kill().await;
-            return;
-        }
-        if let Some(provided) = self.provided.as_ref() {
-            provided.kill().await;
-            return;
-        }
-        panic!("Mysql not configured")
-    }
-}
-
-impl RdbConnection for RdbMysqlHost {
-    fn public_connection_string(&self) -> String {
-        if let Some(container) = self.container.as_ref() {
-            return container.public_connection_string();
-        }
-        if let Some(provided) = self.provided.as_ref() {
-            return provided.public_connection_string();
-        }
-        "".to_string()
-    }
-
-    fn private_connection_string(&self) -> String {
-        if let Some(container) = self.container.as_ref() {
-            return container.private_connection_string();
-        }
-        if let Some(provided) = self.provided.as_ref() {
-            return provided.private_connection_string();
-        }
-        "".to_string()
-    }
-}
-
-impl Drop for RdbMysqlHost {
-    fn drop(&mut self) {
-        if let Some(container) = self.container.as_ref() {
-            futures::executor::block_on(container.kill());
-        }
-    }
-}
diff --git a/golem-worker-executor/tests/compatibility/mod.rs b/golem-worker-executor/tests/compatibility/mod.rs
index c2732d15..f108ffa2 100644
--- a/golem-worker-executor/tests/compatibility/mod.rs
+++ b/golem-worker-executor/tests/compatibility/mod.rs
@@ -12,14 +12,15 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use crate::{Deps, LastUniqueId, Tracing};
+use crate::{LastUniqueId, Tracing, WorkerExecutorTestDependencies};
 use test_r::inherit_test_dep;
 
 pub mod v1;
 pub mod v1_1;
 pub mod v1_2;
+pub mod v1_3;
 pub mod worker_recovery;
 
-inherit_test_dep!(Deps);
+inherit_test_dep!(WorkerExecutorTestDependencies);
 inherit_test_dep!(LastUniqueId);
 inherit_test_dep!(Tracing);
diff --git a/golem-worker-executor/tests/compatibility/v1.rs b/golem-worker-executor/tests/compatibility/v1.rs
index 0c4f2ce3..6172731a 100644
--- a/golem-worker-executor/tests/compatibility/v1.rs
+++ b/golem-worker-executor/tests/compatibility/v1.rs
@@ -24,26 +24,19 @@ use goldenfile::differs::Differ;
 use goldenfile::Mint;
 use golem_common::model::invocation_context::InvocationContextStack;
 use golem_common::model::oplog::{
-    DurableFunctionType, IndexedResourceKey, LogLevel, OplogEntry, OplogIndex, OplogPayload,
-    PayloadId, TimestampedUpdateDescription, UpdateDescription, WorkerError, WorkerResourceId,
+    DurableFunctionType, LogLevel, OplogIndex, OplogPayload, PayloadId,
+    TimestampedUpdateDescription, UpdateDescription, WorkerError, WorkerResourceId,
 };
 use golem_common::model::regions::{DeletedRegions, OplogRegion};
 use golem_common::model::RetryConfig;
 use golem_common::model::{
-    AccountId, ComponentId, FailedUpdateRecord, IdempotencyKey, OwnedWorkerId, PromiseId,
-    ScheduledAction, ShardId, SuccessfulUpdateRecord, Timestamp, TimestampedWorkerInvocation,
-    WorkerId, WorkerInvocation, WorkerResourceDescription, WorkerStatus,
+    AccountId, ComponentId, FailedUpdateRecord, IdempotencyKey, PromiseId, ShardId,
+    SuccessfulUpdateRecord, Timestamp, TimestampedWorkerInvocation, WorkerId, WorkerInvocation,
+    WorkerStatus,
 };
 use golem_common::serialization::{deserialize, serialize};
 use golem_service_base::error::worker_executor::{InterruptKind, WorkerExecutorError};
-use golem_wasm_ast::analysis::{
-    AnalysedResourceId, AnalysedResourceMode, AnalysedType, NameOptionTypePair, NameTypePair,
-    TypeBool, TypeChr, TypeEnum, TypeF32, TypeF64, TypeFlags, TypeHandle, TypeList, TypeOption,
-    TypeRecord, TypeResult, TypeS16, TypeS32, TypeS64, TypeS8, TypeStr, TypeTuple, TypeU16,
-    TypeU32, TypeU64, TypeU8, TypeVariant,
-};
-use golem_wasm_rpc::protobuf::type_annotated_value::TypeAnnotatedValue;
-use golem_wasm_rpc::{TypeAnnotatedValueConstructors, Value, WitValue};
+use golem_wasm_rpc::{Value, WitValue};
 use golem_worker_executor::durable_host::http::serialized::{
     SerializableDnsErrorPayload, SerializableErrorCode, SerializableFieldSizePayload,
     SerializableResponse, SerializableResponseHeaders, SerializableTlsAlertReceivedPayload,
@@ -60,7 +53,7 @@ use golem_worker_executor::services::worker_proxy::WorkerProxyError;
 use std::collections::HashMap;
 use std::fmt::Debug;
 use std::io::Write;
-use std::path::{Path, PathBuf};
+use std::path::Path;
 use std::time::Duration;
 use test_r::test;
 use uuid::Uuid;
@@ -130,10 +123,7 @@ pub fn worker_status() {
     let ws6 = WorkerStatus::Failed;
     let ws7 = WorkerStatus::Exited;
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("worker_status_running", &mut mint, ws1);
     backward_compatible("worker_status_idle", &mut mint, ws2);
     backward_compatible("worker_status_suspended", &mut mint, ws3);
@@ -157,10 +147,7 @@ pub fn deleted_regions() {
         },
     ]);
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("deleted_regions_empty", &mut mint, dr1);
     backward_compatible("deleted_regions_nonempty", &mut mint, dr2);
 }
@@ -183,10 +170,7 @@ pub fn retry_config() {
         max_jitter_factor: Some(0.1),
     };
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("retry_config_default", &mut mint, rc1);
     backward_compatible("retry_config_custom1", &mut mint, rc2);
     backward_compatible("retry_config_custom2", &mut mint, rc3);
@@ -235,10 +219,7 @@ pub fn wasm_rpc_value() {
         resource_id: 123,
     };
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("wasm_rpc_value_bool", &mut mint, v1);
     backward_compatible("wasm_rpc_value_u8", &mut mint, v2);
     backward_compatible("wasm_rpc_value_u16", &mut mint, v3);
@@ -315,10 +296,7 @@ pub fn timestamped_worker_invocation() {
         },
     };
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible_custom(
         "timestamped_worker_invocation_exported_function",
         &mut mint,
@@ -350,10 +328,7 @@ pub fn timestamped_update_description() {
             payload: OplogPayload::Inline(vec![0, 1, 2, 3, 4]),
         },
     };
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("timestamped_update_description_automatic", &mut mint, tud1);
     backward_compatible(
         "timestamped_update_description_snapshot_based",
@@ -368,10 +343,7 @@ pub fn successful_update_record() {
         timestamp: Timestamp::from(1724701938466),
         target_version: 123,
     };
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("successful_update_record", &mut mint, sur1);
 }
 
@@ -387,38 +359,26 @@ pub fn failed_update_record() {
         target_version: 123,
         details: Some("details".to_string()),
     };
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("failed_update_record_no_details", &mut mint, fur1);
     backward_compatible("failed_update_record_with_details", &mut mint, fur2);
 }
 
 #[test]
 pub fn worker_resource_id() {
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("worker_resource_id", &mut mint, WorkerResourceId(1));
 }
 
 #[test]
 pub fn oplog_index() {
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("oplog_index", &mut mint, OplogIndex::from_u64(1));
 }
 
 #[test]
 pub fn idempotency_key() {
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible(
         "idempotency_key",
         &mut mint,
@@ -430,34 +390,10 @@ pub fn idempotency_key() {
 
 #[test]
 pub fn timestamp() {
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("timestamp", &mut mint, Timestamp::from(1724701938466));
 }
 
-#[test]
-pub fn worker_resource_description() {
-    let wrd1 = WorkerResourceDescription {
-        created_at: Timestamp::from(1724701938466),
-        indexed_resource_key: None,
-    };
-    let wrd2 = WorkerResourceDescription {
-        created_at: Timestamp::from(1724701938466),
-        indexed_resource_key: Some(IndexedResourceKey {
-            resource_name: "r1".to_string(),
-            resource_params: vec!["a".to_string(), "b".to_string()],
-        }),
-    };
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
-    backward_compatible("worker_resource_description", &mut mint, wrd1);
-    backward_compatible("worker_resource_description_indexed", &mut mint, wrd2);
-}
-
 #[test]
 pub fn oplog_payload() {
     let op1 = OplogPayload::Inline(vec![0, 1, 2, 3, 4]);
@@ -465,10 +401,7 @@ pub fn oplog_payload() {
         payload_id: PayloadId(Uuid::parse_str("4B29BF7C-13F6-4E37-AC03-830B81EAD478").unwrap()),
         md5_hash: vec![1, 2, 3, 4],
     };
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("oplog_payload_inline", &mut mint, op1);
     backward_compatible("oplog_payload_external", &mut mint, op2);
 }
@@ -478,10 +411,7 @@ pub fn redis_promise_state() {
     let s1 = RedisPromiseState::Pending;
     let s2 = RedisPromiseState::Complete(vec![]);
     let s3 = RedisPromiseState::Complete(vec![1, 2, 3, 4]);
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("redis_promise_state_pending", &mut mint, s1);
     backward_compatible("redis_promise_state_complete_empty", &mut mint, s2);
     backward_compatible("redis_promise_state_complete_nonempty", &mut mint, s3);
@@ -489,10 +419,7 @@ pub fn redis_promise_state() {
 
 #[test]
 pub fn account_id() {
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible(
         "account_id",
         &mut mint,
@@ -504,10 +431,7 @@ pub fn account_id() {
 
 #[test]
 pub fn component_id() {
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible(
         "component_id",
         &mut mint,
@@ -517,10 +441,7 @@ pub fn component_id() {
 
 #[test]
 pub fn worker_id() {
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible(
         "worker_id",
         &mut mint,
@@ -545,59 +466,13 @@ pub fn promise_id() {
         oplog_idx: OplogIndex::from_u64(100),
     };
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("promise_id", &mut mint, pid1);
 }
 
-#[test]
-pub fn scheduled_action() {
-    let sa1 = ScheduledAction::CompletePromise {
-        account_id: AccountId {
-            value: "account_id".to_string(),
-        },
-        promise_id: PromiseId {
-            worker_id: WorkerId {
-                component_id: ComponentId(
-                    Uuid::parse_str("4B29BF7C-13F6-4E37-AC03-830B81EAD478").unwrap(),
-                ),
-                worker_name: "worker_name".to_string(),
-            },
-            oplog_idx: OplogIndex::from_u64(100),
-        },
-    };
-    let sa2 = ScheduledAction::ArchiveOplog {
-        owned_worker_id: OwnedWorkerId {
-            account_id: AccountId {
-                value: "account_id".to_string(),
-            },
-            worker_id: WorkerId {
-                component_id: ComponentId(
-                    Uuid::parse_str("4B29BF7C-13F6-4E37-AC03-830B81EAD478").unwrap(),
-                ),
-                worker_name: "worker_name".to_string(),
-            },
-        },
-        last_oplog_index: OplogIndex::from_u64(100),
-        next_after: Duration::from_secs(10),
-    };
-
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
-    backward_compatible("scheduled_action_complete_promise", &mut mint, sa1);
-    backward_compatible("scheduled_action_archive_oplog", &mut mint, sa2);
-}
-
 #[test]
 pub fn wrapped_function_type() {
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible(
         "wrapped_function_type_read_local",
         &mut mint,
@@ -637,10 +512,7 @@ pub fn worker_error() {
     let we3 = WorkerError::StackOverflow;
     let we4 = WorkerError::Unknown("unknown".to_string());
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("worker_error_out_of_memory", &mut mint, we1);
     backward_compatible("worker_error_invalid_request", &mut mint, we2);
     backward_compatible("worker_error_stack_overflow", &mut mint, we3);
@@ -649,10 +521,7 @@ pub fn worker_error() {
 
 #[test]
 pub fn log_level() {
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("log_level_error", &mut mint, LogLevel::Error);
     backward_compatible("log_level_debug", &mut mint, LogLevel::Debug);
     backward_compatible("log_level_warn", &mut mint, LogLevel::Warn);
@@ -663,270 +532,6 @@ pub fn log_level() {
     backward_compatible("log_level_trace", &mut mint, LogLevel::Trace);
 }
 
-#[test]
-pub fn oplog_entry() {
-    // Special differ ignoring the invocation_context field
-    fn is_deserializable_ignoring_invocation_context(old: &Path, new: &Path) {
-        let old = std::fs::read(old).unwrap();
-        let new = std::fs::read(new).unwrap();
-
-        // Both the old and the latest binary can be deserialized
-        let mut old_decoded: OplogEntry = deserialize(&old).unwrap();
-        let new_decoded: OplogEntry = deserialize(&new).unwrap();
-
-        if let (
-            OplogEntry::PendingWorkerInvocation {
-                invocation:
-                    WorkerInvocation::ExportedFunction {
-                        invocation_context: old,
-                        ..
-                    },
-                ..
-            },
-            OplogEntry::PendingWorkerInvocation {
-                invocation:
-                    WorkerInvocation::ExportedFunction {
-                        invocation_context: new,
-                        ..
-                    },
-                ..
-            },
-        ) = (&mut old_decoded, &new_decoded)
-        {
-            *old = new.clone();
-        }
-
-        // And they represent the same value
-        assert_eq!(old_decoded, new_decoded);
-    }
-
-    let oe1a = OplogEntry::CreateV1 {
-        timestamp: Timestamp::from(1724701938466),
-        worker_id: WorkerId {
-            component_id: ComponentId(
-                Uuid::parse_str("4B29BF7C-13F6-4E37-AC03-830B81EAD478").unwrap(),
-            ),
-            worker_name: "worker_name".to_string(),
-        },
-        component_version: 0,
-        args: vec!["hello".to_string(), "world".to_string()],
-        env: vec![
-            ("key1".to_string(), "value1".to_string()),
-            ("key2".to_string(), "value2".to_string()),
-        ],
-        account_id: AccountId {
-            value: "account_id".to_string(),
-        },
-        parent: None,
-        component_size: 100_000_000,
-        initial_total_linear_memory_size: 100_000_000,
-    };
-    let oe1b = OplogEntry::CreateV1 {
-        timestamp: Timestamp::from(1724701938466),
-        worker_id: WorkerId {
-            component_id: ComponentId(
-                Uuid::parse_str("4B29BF7C-13F6-4E37-AC03-830B81EAD478").unwrap(),
-            ),
-            worker_name: "worker_name".to_string(),
-        },
-        component_version: 0,
-        args: vec!["hello".to_string(), "world".to_string()],
-        env: vec![
-            ("key1".to_string(), "value1".to_string()),
-            ("key2".to_string(), "value2".to_string()),
-        ],
-        account_id: AccountId {
-            value: "account_id".to_string(),
-        },
-        parent: Some(WorkerId {
-            component_id: ComponentId(
-                Uuid::parse_str("90BB3957-2C4E-4711-A488-902B7018100F").unwrap(),
-            ),
-            worker_name: "parent_worker_name".to_string(),
-        }),
-        component_size: 100_000_000,
-        initial_total_linear_memory_size: 100_000_000,
-    };
-
-    let oe2 = OplogEntry::ImportedFunctionInvokedV1 {
-        timestamp: Timestamp::from(1724701938466),
-        function_name: "test:pkg/iface.{fn}".to_string(),
-        response: OplogPayload::Inline(vec![0, 1, 2, 3, 4]),
-        wrapped_function_type: DurableFunctionType::ReadLocal,
-    };
-
-    let oe3 = OplogEntry::ExportedFunctionInvokedV1 {
-        timestamp: Timestamp::from(1724701938466),
-        function_name: "test:pkg/iface.{fn}".to_string(),
-        request: OplogPayload::Inline(vec![0, 1, 2, 3, 4]),
-        idempotency_key: IdempotencyKey {
-            value: "id1".to_string(),
-        },
-    };
-
-    let oe4 = OplogEntry::ExportedFunctionCompleted {
-        timestamp: Timestamp::from(1724701938466),
-        response: OplogPayload::Inline(vec![0, 1, 2, 3, 4]),
-        consumed_fuel: 12345678910,
-    };
-
-    let oe5 = OplogEntry::Suspend {
-        timestamp: Timestamp::from(1724701938466),
-    };
-
-    let oe6 = OplogEntry::Error {
-        timestamp: Timestamp::from(1724701938466),
-        error: WorkerError::OutOfMemory,
-    };
-
-    let oe7 = OplogEntry::NoOp {
-        timestamp: Timestamp::from(1724701938466),
-    };
-
-    let oe8 = OplogEntry::Jump {
-        timestamp: Timestamp::from(1724701938466),
-        jump: OplogRegion {
-            start: OplogIndex::from_u64(0),
-            end: OplogIndex::from_u64(10),
-        },
-    };
-
-    let oe9 = OplogEntry::Interrupted {
-        timestamp: Timestamp::from(1724701938466),
-    };
-
-    let oe10 = OplogEntry::Exited {
-        timestamp: Timestamp::from(1724701938466),
-    };
-
-    let oe11 = OplogEntry::ChangeRetryPolicy {
-        timestamp: Timestamp::from(1724701938466),
-        new_policy: RetryConfig::default(),
-    };
-
-    let oe12 = OplogEntry::BeginAtomicRegion {
-        timestamp: Timestamp::from(1724701938466),
-    };
-
-    let oe13 = OplogEntry::EndAtomicRegion {
-        timestamp: Timestamp::from(1724701938466),
-        begin_index: OplogIndex::from_u64(0),
-    };
-
-    let oe14 = OplogEntry::BeginRemoteWrite {
-        timestamp: Timestamp::from(1724701938466),
-    };
-
-    let oe15 = OplogEntry::EndRemoteWrite {
-        timestamp: Timestamp::from(1724701938466),
-        begin_index: OplogIndex::from_u64(0),
-    };
-
-    let oe16 = OplogEntry::PendingWorkerInvocation {
-        timestamp: Timestamp::from(1724701938466),
-        invocation: WorkerInvocation::ExportedFunction {
-            idempotency_key: IdempotencyKey {
-                value: "idempotency_key".to_string(),
-            },
-            full_function_name: "function-name".to_string(),
-            function_input: vec![Value::Bool(true)],
-            invocation_context: InvocationContextStack::fresh(),
-        },
-    };
-
-    let oe17 = OplogEntry::PendingUpdate {
-        timestamp: Timestamp::from(1724701938466),
-        description: UpdateDescription::Automatic {
-            target_version: 100,
-        },
-    };
-
-    let oe18 = OplogEntry::SuccessfulUpdateV1 {
-        timestamp: Timestamp::from(1724701938466),
-        target_version: 10,
-        new_component_size: 1234,
-    };
-
-    let oe19a = OplogEntry::FailedUpdate {
-        timestamp: Timestamp::from(1724701938466),
-        target_version: 10,
-        details: None,
-    };
-
-    let oe19b = OplogEntry::FailedUpdate {
-        timestamp: Timestamp::from(1724701938466),
-        target_version: 10,
-        details: Some("details".to_string()),
-    };
-
-    let oe20 = OplogEntry::GrowMemory {
-        timestamp: Timestamp::from(1724701938466),
-        delta: 100_000_000,
-    };
-
-    let oe21 = OplogEntry::CreateResource {
-        timestamp: Timestamp::from(1724701938466),
-        id: WorkerResourceId(1),
-    };
-
-    let oe22 = OplogEntry::DropResource {
-        timestamp: Timestamp::from(1724701938466),
-        id: WorkerResourceId(1),
-    };
-
-    let oe23 = OplogEntry::DescribeResource {
-        timestamp: Timestamp::from(1724701938466),
-        id: WorkerResourceId(1),
-        indexed_resource: IndexedResourceKey {
-            resource_name: "r1".to_string(),
-            resource_params: vec!["a".to_string(), "b".to_string()],
-        },
-    };
-
-    let oe24 = OplogEntry::Log {
-        timestamp: Timestamp::from(1724701938466),
-        level: LogLevel::Error,
-        context: "context".to_string(),
-        message: "message".to_string(),
-    };
-
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
-    backward_compatible("oplog_entry_create", &mut mint, oe1a);
-    backward_compatible("oplog_entry_create_with_parent", &mut mint, oe1b);
-    backward_compatible("oplog_entry_imported_function_invoked", &mut mint, oe2);
-    backward_compatible("oplog_entry_exported_function_invoked", &mut mint, oe3);
-    backward_compatible("oplog_entry_exported_function_completed", &mut mint, oe4);
-    backward_compatible("oplog_entry_suspend", &mut mint, oe5);
-    backward_compatible("oplog_entry_error", &mut mint, oe6);
-    backward_compatible("oplog_entry_no_op", &mut mint, oe7);
-    backward_compatible("oplog_entry_jump", &mut mint, oe8);
-    backward_compatible("oplog_entry_interrupted", &mut mint, oe9);
-    backward_compatible("oplog_entry_exited", &mut mint, oe10);
-    backward_compatible("oplog_entry_change_retry_policy", &mut mint, oe11);
-    backward_compatible("oplog_entry_begin_atomic_region", &mut mint, oe12);
-    backward_compatible("oplog_entry_end_atomic_region", &mut mint, oe13);
-    backward_compatible("oplog_entry_begin_remote_write", &mut mint, oe14);
-    backward_compatible("oplog_entry_end_remote_write", &mut mint, oe15);
-    backward_compatible_custom(
-        "oplog_entry_pending_worker_invocation",
-        &mut mint,
-        oe16,
-        Box::new(is_deserializable_ignoring_invocation_context),
-    );
-    backward_compatible("oplog_entry_pending_update", &mut mint, oe17);
-    backward_compatible("oplog_entry_successful_update", &mut mint, oe18);
-    backward_compatible("oplog_entry_failed_update_no_details", &mut mint, oe19a);
-    backward_compatible("oplog_entry_failed_update_with_details", &mut mint, oe19b);
-    backward_compatible("oplog_entry_grow_memory", &mut mint, oe20);
-    backward_compatible("oplog_entry_create_resource", &mut mint, oe21);
-    backward_compatible("oplog_entry_drop_resource", &mut mint, oe22);
-    backward_compatible("oplog_entry_describe_resource", &mut mint, oe23);
-    backward_compatible("oplog_entry_log", &mut mint, oe24);
-}
-
 #[test]
 pub fn blob_store_object_metadata() {
     let om1 = blob_store::ObjectMetadata {
@@ -936,19 +541,13 @@ pub fn blob_store_object_metadata() {
         size: 500_000_000,
     };
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("blob_store_object_metadata", &mut mint, om1);
 }
 
 #[test]
 pub fn interrupt_kind() {
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible(
         "interrupt_kind_interrupt",
         &mut mint,
@@ -961,10 +560,7 @@ pub fn interrupt_kind() {
 
 #[test]
 pub fn shard_id() {
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("shard_id", &mut mint, ShardId::new(1));
 }
 
@@ -1065,10 +661,7 @@ pub fn golem_error() {
         stderr: "stderr".to_string(),
     };
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("golem_error_invalid_request", &mut mint, g1);
     backward_compatible("golem_error_worker_already_exists", &mut mint, g2);
     backward_compatible("golem_error_worker_not_found", &mut mint, g3);
@@ -1120,10 +713,7 @@ pub fn rpc_error() {
         details: "not working".to_string(),
     };
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("rpc_error_protocol_error", &mut mint, rpc1);
     backward_compatible("rpc_error_denied", &mut mint, rpc2);
     backward_compatible("rpc_error_not_found", &mut mint, rpc3);
@@ -1139,10 +729,7 @@ pub fn worker_proxy_error() {
     let wpe5 = WorkerProxyError::AlreadyExists("already exists".to_string());
     let wpe6 = WorkerProxyError::InternalError(WorkerExecutorError::unknown("internal error"));
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("worker_proxy_error_bad_request", &mut mint, wpe1);
     backward_compatible("worker_proxy_error_unauthorized", &mut mint, wpe2);
     backward_compatible("worker_proxy_error_limit_exceeded", &mut mint, wpe3);
@@ -1172,10 +759,7 @@ pub fn serializable_error() {
         error: WorkerProxyError::AlreadyExists("already exists".to_string()),
     };
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("serializable_error_fs_error", &mut mint, se1);
     backward_compatible("serializable_error_generic", &mut mint, se2);
     backward_compatible("serializable_error_golem", &mut mint, se3);
@@ -1194,10 +778,7 @@ pub fn serializable_stream_error() {
         message: "hello world".to_string(),
     });
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("serializable_stream_error_closed", &mut mint, sse1);
     backward_compatible(
         "serializable_stream_error_last_operation_failed",
@@ -1216,10 +797,7 @@ pub fn serializable_ip_address() {
         address: [1, 2, 3, 4, 5, 6, 7, 8],
     };
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("serializable_ip_address_ipv4", &mut mint, sia1);
     backward_compatible("serializable_ip_address_ipv6", &mut mint, sia2);
 }
@@ -1230,10 +808,7 @@ pub fn serializable_ip_addresses() {
         address: [127, 0, 0, 1],
     }]);
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("serializable_ip_addresses", &mut mint, sia1);
 }
 
@@ -1284,10 +859,7 @@ pub fn wit_value() {
     }
     .into();
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible_wit_value("wit_value_bool", &mut mint, wv1);
     backward_compatible_wit_value("wit_value_u8", &mut mint, wv2);
     backward_compatible_wit_value("wit_value_u16", &mut mint, wv3);
@@ -1328,10 +900,7 @@ pub fn serializable_dns_error_payload() {
         info_code: None,
     };
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("serializable_dns_error_payload_some", &mut mint, sd1);
     backward_compatible("serializable_dns_error_payload_none", &mut mint, sd2);
 }
@@ -1347,10 +916,7 @@ pub fn serializable_tls_alert_received_payload() {
         alert_message: None,
     };
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible(
         "serializable_tls_alert_received_payload_some",
         &mut mint,
@@ -1374,20 +940,14 @@ pub fn serializable_field_size_payload() {
         field_name: None,
     };
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("serializable_field_size_payload_some", &mut mint, sf1);
     backward_compatible("serializable_field_size_payload_none", &mut mint, sf2);
 }
 
 #[test]
 pub fn serializable_error_code() {
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible(
         "serializable_error_code_dns_timeout",
         &mut mint,
@@ -1666,10 +1226,7 @@ pub fn serializable_response() {
         message: "hello world".to_string(),
     }));
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("serializable_response_pending", &mut mint, sr1);
     backward_compatible("serializable_response_headers_received", &mut mint, sr2);
     backward_compatible("serializable_response_http_error", &mut mint, sr3);
@@ -1689,10 +1246,7 @@ pub fn serializable_invoke_result() {
         details: "not now".to_string(),
     }));
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("serializable_invoke_result_pending", &mut mint, sir1);
     backward_compatible("serializable_invoke_result_failed", &mut mint, sir2);
     backward_compatible("serializable_invoke_result_completed_ok", &mut mint, sir3);
@@ -1716,10 +1270,7 @@ pub fn serializable_file_times() {
         data_modification_timestamp: None,
     };
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("serializable_file_times_some", &mut mint, sft1);
     backward_compatible("serializable_file_times_none", &mut mint, sft2);
 }
@@ -1776,10 +1327,7 @@ pub fn proto_val() {
     }
     .into();
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("proto_val_bool", &mut mint, pv1);
     backward_compatible("proto_val_u8", &mut mint, pv2);
     backward_compatible("proto_val_u16", &mut mint, pv3);
@@ -1808,217 +1356,3 @@ pub fn proto_val() {
     backward_compatible("proto_val_result_err_none", &mut mint, pv21d);
     backward_compatible("proto_val_handle", &mut mint, pv22);
 }
-
-#[test]
-pub fn type_annotated_value() {
-    let tav1 =
-        TypeAnnotatedValue::create(&Value::Bool(true), &AnalysedType::Bool(TypeBool)).unwrap();
-    let tav2 = TypeAnnotatedValue::create(&Value::U8(1), &AnalysedType::U8(TypeU8)).unwrap();
-    let tav3 = TypeAnnotatedValue::create(&Value::U16(12345), &AnalysedType::U16(TypeU16)).unwrap();
-    let tav4 =
-        TypeAnnotatedValue::create(&Value::U32(123456789), &AnalysedType::U32(TypeU32)).unwrap();
-    let tav5 = TypeAnnotatedValue::create(
-        &Value::U64(12345678901234567890),
-        &AnalysedType::U64(TypeU64),
-    )
-    .unwrap();
-    let tav6 = TypeAnnotatedValue::create(&Value::S8(-1), &AnalysedType::S8(TypeS8)).unwrap();
-    let tav7 =
-        TypeAnnotatedValue::create(&Value::S16(-12345), &AnalysedType::S16(TypeS16)).unwrap();
-    let tav8 =
-        TypeAnnotatedValue::create(&Value::S32(-123456789), &AnalysedType::S32(TypeS32)).unwrap();
-    let tav9 = TypeAnnotatedValue::create(
-        &Value::S64(-1234567890123456789),
-        &AnalysedType::S64(TypeS64),
-    )
-    .unwrap();
-    let tav10 =
-        TypeAnnotatedValue::create(&Value::F32(1.234), &AnalysedType::F32(TypeF32)).unwrap();
-    let tav11 = TypeAnnotatedValue::create(
-        &Value::F64(1.234_567_890_123_456_7),
-        &AnalysedType::F64(TypeF64),
-    )
-    .unwrap();
-    let tav12 = TypeAnnotatedValue::create(&Value::Char('a'), &AnalysedType::Chr(TypeChr)).unwrap();
-    let tav13 = TypeAnnotatedValue::create(
-        &Value::String("hello world".to_string()),
-        &AnalysedType::Str(TypeStr),
-    )
-    .unwrap();
-    let tav14 = TypeAnnotatedValue::create(
-        &Value::List(vec![Value::Bool(true), Value::Bool(false)]),
-        &AnalysedType::List(TypeList {
-            inner: Box::new(AnalysedType::Bool(TypeBool)),
-        }),
-    )
-    .unwrap();
-    let tav15 = TypeAnnotatedValue::create(
-        &Value::Tuple(vec![Value::Bool(true), Value::Char('x')]),
-        &AnalysedType::Tuple(TypeTuple {
-            items: vec![AnalysedType::Bool(TypeBool), AnalysedType::Chr(TypeChr)],
-        }),
-    )
-    .unwrap();
-    let tav16 = TypeAnnotatedValue::create(
-        &Value::Record(vec![
-            Value::Bool(true),
-            Value::Char('x'),
-            Value::List(vec![]),
-        ]),
-        &AnalysedType::Record(TypeRecord {
-            fields: vec![
-                NameTypePair {
-                    name: "a".to_string(),
-                    typ: AnalysedType::Bool(TypeBool),
-                },
-                NameTypePair {
-                    name: "b".to_string(),
-                    typ: AnalysedType::Chr(TypeChr),
-                },
-                NameTypePair {
-                    name: "c".to_string(),
-                    typ: AnalysedType::List(TypeList {
-                        inner: Box::new(AnalysedType::Bool(TypeBool)),
-                    }),
-                },
-            ],
-        }),
-    )
-    .unwrap();
-    let tav17a = TypeAnnotatedValue::create(
-        &Value::Variant {
-            case_idx: 0,
-            case_value: Some(Box::new(Value::Record(vec![Value::Option(None)]))),
-        },
-        &AnalysedType::Variant(TypeVariant {
-            cases: vec![NameOptionTypePair {
-                name: "a".to_string(),
-                typ: Some(AnalysedType::Record(TypeRecord {
-                    fields: vec![NameTypePair {
-                        name: "a".to_string(),
-                        typ: AnalysedType::Option(TypeOption {
-                            inner: Box::new(AnalysedType::Bool(TypeBool)),
-                        }),
-                    }],
-                })),
-            }],
-        }),
-    )
-    .unwrap();
-    let tav17b = TypeAnnotatedValue::create(
-        &Value::Variant {
-            case_idx: 0,
-            case_value: None,
-        },
-        &AnalysedType::Variant(TypeVariant {
-            cases: vec![NameOptionTypePair {
-                name: "a".to_string(),
-                typ: None,
-            }],
-        }),
-    )
-    .unwrap();
-    let tav18 = TypeAnnotatedValue::create(
-        &Value::Enum(1),
-        &AnalysedType::Enum(TypeEnum {
-            cases: vec!["a".to_string(), "b".to_string()],
-        }),
-    )
-    .unwrap();
-    let tav19 = TypeAnnotatedValue::create(
-        &Value::Flags(vec![true, false, true]),
-        &AnalysedType::Flags(TypeFlags {
-            names: vec!["a".to_string(), "b".to_string(), "c".to_string()],
-        }),
-    )
-    .unwrap();
-    let tav20a = TypeAnnotatedValue::create(
-        &Value::Option(Some(Box::new(Value::Bool(true)))),
-        &AnalysedType::Option(TypeOption {
-            inner: Box::new(AnalysedType::Bool(TypeBool)),
-        }),
-    )
-    .unwrap();
-    let tav20b = TypeAnnotatedValue::create(
-        &Value::Option(None),
-        &AnalysedType::Option(TypeOption {
-            inner: Box::new(AnalysedType::Bool(TypeBool)),
-        }),
-    )
-    .unwrap();
-    let tav21a = TypeAnnotatedValue::create(
-        &Value::Result(Ok(Some(Box::new(Value::Bool(true))))),
-        &AnalysedType::Result(TypeResult {
-            ok: Some(Box::new(AnalysedType::Bool(TypeBool))),
-            err: Some(Box::new(AnalysedType::Bool(TypeBool))),
-        }),
-    )
-    .unwrap();
-    let tav21b = TypeAnnotatedValue::create(
-        &Value::Result(Err(Some(Box::new(Value::Bool(true))))),
-        &AnalysedType::Result(TypeResult {
-            ok: Some(Box::new(AnalysedType::Bool(TypeBool))),
-            err: Some(Box::new(AnalysedType::Bool(TypeBool))),
-        }),
-    )
-    .unwrap();
-    let tav21c = TypeAnnotatedValue::create(
-        &Value::Result(Ok(None)),
-        &AnalysedType::Result(TypeResult {
-            ok: None,
-            err: None,
-        }),
-    )
-    .unwrap();
-    let tav21d = TypeAnnotatedValue::create(
-        &Value::Result(Err(None)),
-        &AnalysedType::Result(TypeResult {
-            ok: None,
-            err: None,
-        }),
-    )
-    .unwrap();
-    let tav22 = TypeAnnotatedValue::create(
-        &Value::Handle {
-            uri: "uri".to_string(),
-            resource_id: 123,
-        },
-        &AnalysedType::Handle(TypeHandle {
-            resource_id: AnalysedResourceId(1),
-            mode: AnalysedResourceMode::Borrowed,
-        }),
-    )
-    .unwrap();
-
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
-    backward_compatible("type_annotated_value_bool", &mut mint, tav1);
-    backward_compatible("type_annotated_value_u8", &mut mint, tav2);
-    backward_compatible("type_annotated_value_u16", &mut mint, tav3);
-    backward_compatible("type_annotated_value_u32", &mut mint, tav4);
-    backward_compatible("type_annotated_value_u64", &mut mint, tav5);
-    backward_compatible("type_annotated_value_s8", &mut mint, tav6);
-    backward_compatible("type_annotated_value_s16", &mut mint, tav7);
-    backward_compatible("type_annotated_value_s32", &mut mint, tav8);
-    backward_compatible("type_annotated_value_s64", &mut mint, tav9);
-    backward_compatible("type_annotated_value_f32", &mut mint, tav10);
-    backward_compatible("type_annotated_value_f64", &mut mint, tav11);
-    backward_compatible("type_annotated_value_char", &mut mint, tav12);
-    backward_compatible("type_annotated_value_string", &mut mint, tav13);
-    backward_compatible("type_annotated_value_list", &mut mint, tav14);
-    backward_compatible("type_annotated_value_tuple", &mut mint, tav15);
-    backward_compatible("type_annotated_value_record", &mut mint, tav16);
-    backward_compatible("type_annotated_value_variant_some", &mut mint, tav17a);
-    backward_compatible("type_annotated_value_variant_none", &mut mint, tav17b);
-    backward_compatible("type_annotated_value_enum", &mut mint, tav18);
-    backward_compatible("type_annotated_value_flags", &mut mint, tav19);
-    backward_compatible("type_annotated_value_option_some", &mut mint, tav20a);
-    backward_compatible("type_annotated_value_option_none", &mut mint, tav20b);
-    backward_compatible("type_annotated_value_result_ok_some", &mut mint, tav21a);
-    backward_compatible("type_annotated_value_result_err_some", &mut mint, tav21b);
-    backward_compatible("type_annotated_value_result_ok_none", &mut mint, tav21c);
-    backward_compatible("type_annotated_value_result_err_none", &mut mint, tav21d);
-    backward_compatible("type_annotated_value_handle", &mut mint, tav22);
-}
diff --git a/golem-worker-executor/tests/compatibility/v1_1.rs b/golem-worker-executor/tests/compatibility/v1_1.rs
index dd6e6f90..a2b47daf 100644
--- a/golem-worker-executor/tests/compatibility/v1_1.rs
+++ b/golem-worker-executor/tests/compatibility/v1_1.rs
@@ -14,132 +14,22 @@
 
 use crate::compatibility::v1::backward_compatible;
 use goldenfile::Mint;
-use golem_common::model::oplog::{DurableFunctionType, OplogEntry, OplogPayload};
-use golem_common::model::{AccountId, ComponentId, PluginInstallationId, Timestamp, WorkerId};
 use golem_service_base::error::worker_executor::WorkerExecutorError;
 use golem_wasm_ast::analysis::analysed_type::bool;
 use golem_wasm_rpc::{Value, ValueAndType};
 use golem_worker_executor::durable_host::serialized::SerializableError;
 use golem_worker_executor::durable_host::wasm_rpc::serialized::SerializableInvokeResult;
 use golem_worker_executor::services::rpc::RpcError;
-use std::collections::HashSet;
-use std::path::PathBuf;
 use test_r::test;
-use uuid::Uuid;
 
 #[test]
 pub fn golem_error() {
     let g1 = WorkerExecutorError::ShardingNotReady;
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("golem_error_sharding_not_ready", &mut mint, g1);
 }
 
-#[test]
-pub fn oplog_entry() {
-    let oe25 = OplogEntry::Restart {
-        timestamp: Timestamp::from(1724701938466),
-    };
-    let oe26 = OplogEntry::ImportedFunctionInvoked {
-        timestamp: Timestamp::from(1724701938466),
-        function_name: "test:pkg/iface.{fn}".to_string(),
-        request: OplogPayload::Inline(vec![5, 6, 7, 8, 9]),
-        response: OplogPayload::Inline(vec![0, 1, 2, 3, 4]),
-        wrapped_function_type: DurableFunctionType::ReadLocal,
-    };
-    let oe27a = OplogEntry::Create {
-        timestamp: Timestamp::from(1724701938466),
-        worker_id: WorkerId {
-            component_id: ComponentId(
-                Uuid::parse_str("4B29BF7C-13F6-4E37-AC03-830B81EAD478").unwrap(),
-            ),
-            worker_name: "worker_name".to_string(),
-        },
-        component_version: 0,
-        args: vec!["hello".to_string(), "world".to_string()],
-        env: vec![
-            ("key1".to_string(), "value1".to_string()),
-            ("key2".to_string(), "value2".to_string()),
-        ],
-        account_id: AccountId {
-            value: "account_id".to_string(),
-        },
-        parent: None,
-        component_size: 100_000_000,
-        initial_total_linear_memory_size: 100_000_000,
-        initial_active_plugins: HashSet::from_iter(vec![
-            PluginInstallationId(Uuid::parse_str("E7AA7893-B8F8-4DC7-B3AC-3A9E3472EA18").unwrap()),
-            PluginInstallationId(Uuid::parse_str("339ED9E3-9D93-440C-BC07-377F56642ABB").unwrap()),
-        ]),
-    };
-    let oe27b = OplogEntry::Create {
-        timestamp: Timestamp::from(1724701938466),
-        worker_id: WorkerId {
-            component_id: ComponentId(
-                Uuid::parse_str("4B29BF7C-13F6-4E37-AC03-830B81EAD478").unwrap(),
-            ),
-            worker_name: "worker_name".to_string(),
-        },
-        component_version: 0,
-        args: vec!["hello".to_string(), "world".to_string()],
-        env: vec![
-            ("key1".to_string(), "value1".to_string()),
-            ("key2".to_string(), "value2".to_string()),
-        ],
-        account_id: AccountId {
-            value: "account_id".to_string(),
-        },
-        parent: Some(WorkerId {
-            component_id: ComponentId(
-                Uuid::parse_str("90BB3957-2C4E-4711-A488-902B7018100F").unwrap(),
-            ),
-            worker_name: "parent_worker_name".to_string(),
-        }),
-        component_size: 100_000_000,
-        initial_total_linear_memory_size: 100_000_000,
-        initial_active_plugins: HashSet::from_iter(vec![
-            PluginInstallationId(Uuid::parse_str("E7AA7893-B8F8-4DC7-B3AC-3A9E3472EA18").unwrap()),
-            PluginInstallationId(Uuid::parse_str("339ED9E3-9D93-440C-BC07-377F56642ABB").unwrap()),
-        ]),
-    };
-    let oe28 = OplogEntry::SuccessfulUpdate {
-        timestamp: Timestamp::from(1724701938466),
-        target_version: 10,
-        new_component_size: 1234,
-        new_active_plugins: HashSet::from_iter(vec![
-            PluginInstallationId(Uuid::parse_str("E7AA7893-B8F8-4DC7-B3AC-3A9E3472EA18").unwrap()),
-            PluginInstallationId(Uuid::parse_str("339ED9E3-9D93-440C-BC07-377F56642ABB").unwrap()),
-        ]),
-    };
-    let oe29 = OplogEntry::ActivatePlugin {
-        timestamp: Timestamp::from(1724701938466),
-        plugin: PluginInstallationId(
-            Uuid::parse_str("E7AA7893-B8F8-4DC7-B3AC-3A9E3472EA18").unwrap(),
-        ),
-    };
-    let oe30 = OplogEntry::DeactivatePlugin {
-        timestamp: Timestamp::from(1724701938466),
-        plugin: PluginInstallationId(
-            Uuid::parse_str("E7AA7893-B8F8-4DC7-B3AC-3A9E3472EA18").unwrap(),
-        ),
-    };
-
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
-    backward_compatible("oplog_entry_restart", &mut mint, oe25);
-    backward_compatible("oplog_entry_import_function_invoked_v11", &mut mint, oe26);
-    backward_compatible("oplog_entry_create_v11a", &mut mint, oe27a);
-    backward_compatible("oplog_entry_create_v11b", &mut mint, oe27b);
-    backward_compatible("oplog_entry_successful_update_v11", &mut mint, oe28);
-    backward_compatible("oplog_entry_activate_plugin_v11", &mut mint, oe29);
-    backward_compatible("oplog_entry_deactivate_plugin_v11", &mut mint, oe30);
-}
-
 #[test]
 #[ignore] // compatibility has been broken in 1.3
 pub fn serializable_invoke_result() {
@@ -155,10 +45,7 @@ pub fn serializable_invoke_result() {
         details: "not now".to_string(),
     }));
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible("serializable_invoke_result_v11_pending", &mut mint, sir1);
     backward_compatible("serializable_invoke_result_v11_failed", &mut mint, sir2);
     backward_compatible(
diff --git a/golem-worker-executor/tests/compatibility/v1_2.rs b/golem-worker-executor/tests/compatibility/v1_2.rs
index c9f1371e..2adc8470 100644
--- a/golem-worker-executor/tests/compatibility/v1_2.rs
+++ b/golem-worker-executor/tests/compatibility/v1_2.rs
@@ -17,103 +17,13 @@ use goldenfile::Mint;
 use golem_common::model::invocation_context::{
     AttributeValue, InvocationContextSpan, InvocationContextStack, SpanId, TraceId,
 };
-use golem_common::model::oplog::{OplogEntry, OplogPayload, SpanData};
-use golem_common::model::regions::OplogRegion;
 use golem_common::model::{
-    IdempotencyKey, OplogIndex, Timestamp, TimestampedWorkerInvocation, WorkerInvocation,
+    IdempotencyKey, Timestamp, TimestampedWorkerInvocation, WorkerInvocation,
 };
 use golem_wasm_rpc::Value;
-use std::collections::HashMap;
 use std::num::{NonZeroU128, NonZeroU64};
-use std::path::PathBuf;
 use test_r::test;
 
-#[test]
-pub fn oplog_entry() {
-    let oe31 = OplogEntry::Revert {
-        timestamp: Timestamp::from(1724701938466),
-        dropped_region: OplogRegion {
-            start: OplogIndex::from_u64(3),
-            end: OplogIndex::from_u64(10),
-        },
-    };
-
-    let oe32 = OplogEntry::CancelPendingInvocation {
-        timestamp: Timestamp::from(1724701938466),
-        idempotency_key: IdempotencyKey {
-            value: "idempotency_key".to_string(),
-        },
-    };
-
-    let oe33 = OplogEntry::ExportedFunctionInvoked {
-        timestamp: Timestamp::from(1724701938466),
-        function_name: "test:pkg/iface.{fn}".to_string(),
-        request: OplogPayload::Inline(vec![0, 1, 2, 3, 4]),
-        idempotency_key: IdempotencyKey {
-            value: "id1".to_string(),
-        },
-        trace_id: TraceId::from_string("4bf92f3577b34da6a3ce929d0e0e4736").unwrap(),
-        trace_states: vec!["a=1".to_string(), "b=2".to_string()],
-        invocation_context: vec![
-            SpanData::LocalSpan {
-                span_id: SpanId::from_string("cddd89c618fb7bf3").unwrap(),
-                start: Timestamp::from(1724701938466),
-                parent_id: Some(SpanId::from_string("00f067aa0ba902b7").unwrap()),
-                linked_context: Some(vec![SpanData::LocalSpan {
-                    span_id: SpanId::from_string("d0fa4a9110f2dcab").unwrap(),
-                    start: Timestamp::from(1724701938466),
-                    parent_id: None,
-                    linked_context: None,
-                    attributes: HashMap::new(),
-                    inherited: true,
-                }]),
-                attributes: HashMap::from_iter(vec![(
-                    "key".to_string(),
-                    AttributeValue::String("value".to_string()),
-                )]),
-                inherited: false,
-            },
-            SpanData::ExternalSpan {
-                span_id: SpanId::from_string("00f067aa0ba902b7").unwrap(),
-            },
-        ],
-    };
-
-    let oe34 = OplogEntry::StartSpan {
-        timestamp: Timestamp::from(1724701938466),
-        span_id: SpanId::from_string("cddd89c618fb7bf3").unwrap(),
-        parent_id: Some(SpanId::from_string("00f067aa0ba902b7").unwrap()),
-        linked_context_id: Some(SpanId::from_string("d0fa4a9110f2dcab").unwrap()),
-        attributes: HashMap::from_iter(vec![(
-            "key".to_string(),
-            AttributeValue::String("value".to_string()),
-        )]),
-    };
-
-    let oe35 = OplogEntry::FinishSpan {
-        timestamp: Timestamp::from(1724701938466),
-        span_id: SpanId::from_string("cddd89c618fb7bf3").unwrap(),
-    };
-
-    let oe36 = OplogEntry::SetSpanAttribute {
-        timestamp: Timestamp::from(1724701938466),
-        span_id: SpanId::from_string("cddd89c618fb7bf3").unwrap(),
-        key: "key".to_string(),
-        value: AttributeValue::String("value".to_string()),
-    };
-
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
-    backward_compatible("oplog_entry_revert", &mut mint, oe31);
-    backward_compatible("oplog_entry_cancel_pending_invocation", &mut mint, oe32);
-    backward_compatible("oplog_entry_exported_function_invoked_v12", &mut mint, oe33);
-    backward_compatible("oplog_entry_start_span", &mut mint, oe34);
-    backward_compatible("oplog_entry_finish_span", &mut mint, oe35);
-    backward_compatible("oplog_entry_set_span_attribute", &mut mint, oe36);
-}
-
 #[test]
 #[test_r::non_flaky(100)]
 pub async fn timestamped_worker_invocation() {
@@ -144,10 +54,7 @@ pub async fn timestamped_worker_invocation() {
         },
     };
 
-    let mut mint = Mint::new(PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-    ]));
+    let mut mint = Mint::new("tests/goldenfiles");
     backward_compatible(
         "timestamped_worker_invocation_exported_function_v1_2",
         &mut mint,
diff --git a/golem-worker-executor/tests/compatibility/worker_recovery.rs b/golem-worker-executor/tests/compatibility/worker_recovery.rs
index c4c9d9c5..72bac495 100644
--- a/golem-worker-executor/tests/compatibility/worker_recovery.rs
+++ b/golem-worker-executor/tests/compatibility/worker_recovery.rs
@@ -13,32 +13,32 @@
 // limitations under the License.
 
 use crate::common::{start, TestContext, TestWorkerExecutor};
-use crate::Deps;
-use crate::{LastUniqueId, Tracing};
+use crate::{LastUniqueId, Tracing, WorkerExecutorTestDependencies};
 use golem_common::model::{WorkerId, WorkerStatus};
 use golem_common::serialization::{deserialize, serialize};
 use golem_test_framework::config::{TestDependencies, TestDependenciesDsl};
 use golem_test_framework::dsl::TestDslUnsafe;
 use redis::AsyncCommands;
 use std::collections::BTreeMap;
-use std::path::PathBuf;
+use std::path::Path;
 use std::time::Duration;
 use test_r::{inherit_test_dep, test};
 use tracing::info;
 
-inherit_test_dep!(Deps);
+inherit_test_dep!(WorkerExecutorTestDependencies);
 inherit_test_dep!(LastUniqueId);
 inherit_test_dep!(Tracing);
 
 #[test]
 #[tracing::instrument]
+#[ignore] // TODO: 1.3 breaks worker recovery compatibility. to be regenerated once 1.3 is final
 async fn recover_shopping_cart_example(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let worker_id = restore_from_recovery_golden_file(
         &executor,
@@ -57,13 +57,14 @@ async fn recover_shopping_cart_example(
 
 #[test]
 #[tracing::instrument]
+#[ignore] // TODO: 1.3 breaks worker recovery compatibility. to be regenerated once 1.3 is final
 async fn recover_shopping_cart_resource_example(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let worker_id = restore_from_recovery_golden_file(
         &executor,
@@ -82,13 +83,14 @@ async fn recover_shopping_cart_resource_example(
 
 #[test]
 #[tracing::instrument]
+#[ignore] // TODO: 1.3 breaks worker recovery compatibility. to be regenerated once 1.3 is final
 async fn recover_environment_example(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let worker_id = restore_from_recovery_golden_file(
         &executor,
@@ -107,9 +109,14 @@ async fn recover_environment_example(
 
 #[test]
 #[tracing::instrument]
-async fn recover_read_stdin(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+#[ignore] // TODO: 1.3 breaks worker recovery compatibility. to be regenerated once 1.3 is final
+async fn recover_read_stdin(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let worker_id =
         restore_from_recovery_golden_file(&executor, &context, "read_stdin_fails", &["read-stdin"])
@@ -124,9 +131,14 @@ async fn recover_read_stdin(last_unique_id: &LastUniqueId, deps: &Deps, _tracing
 
 #[test]
 #[tracing::instrument]
-async fn recover_jump(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+#[ignore] // TODO: 1.3 breaks worker recovery compatibility. to be regenerated once 1.3 is final
+async fn recover_jump(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let worker_id =
         restore_from_recovery_golden_file(&executor, &context, "jump", &["runtime-service"]).await;
@@ -140,9 +152,14 @@ async fn recover_jump(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tra
 
 #[test]
 #[tracing::instrument]
-async fn recover_js_example_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+#[ignore] // TODO: 1.3 breaks worker recovery compatibility. to be regenerated once 1.3 is final
+async fn recover_js_example_1(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let worker_id =
         restore_from_recovery_golden_file(&executor, &context, "js_example_1", &["js-1"]).await;
@@ -156,13 +173,14 @@ async fn recover_js_example_1(last_unique_id: &LastUniqueId, deps: &Deps, _traci
 
 #[test]
 #[tracing::instrument]
+#[ignore] // TODO: 1.3 breaks worker recovery compatibility. to be regenerated once 1.3 is final
 async fn recover_auto_update_on_running(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let worker_id = restore_from_recovery_golden_file(
         &executor,
@@ -181,13 +199,14 @@ async fn recover_auto_update_on_running(
 
 #[test]
 #[tracing::instrument]
+#[ignore] // TODO: 1.3 breaks worker recovery compatibility. to be regenerated once 1.3 is final
 async fn recover_counter_resource_test_2(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let caller_worker_id = restore_from_recovery_golden_file(
         &executor,
@@ -218,16 +237,10 @@ async fn restore_from_recovery_golden_file(
     name: &str,
     component_names: &[&str],
 ) -> WorkerId {
-    let worker_id_path = PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-        format!("worker_recovery_{name}.worker_id.bin").as_str(),
-    ]);
-    let oplog_path = PathBuf::from_iter([
-        env!("CARGO_MANIFEST_DIR"),
-        "tests/goldenfiles",
-        format!("worker_recovery_{name}.oplog.bin").as_str(),
-    ]);
+    let worker_id_path =
+        Path::new("tests/goldenfiles").join(format!("worker_recovery_{name}.worker_id.bin"));
+    let oplog_path =
+        Path::new("tests/goldenfiles").join(format!("worker_recovery_{name}.oplog.bin"));
 
     let worker_id = tokio::fs::read(&worker_id_path).await.unwrap();
     let worker_id: WorkerId = deserialize(&worker_id).unwrap();
@@ -301,16 +314,10 @@ pub async fn save_recovery_golden_file(
             .await
             .unwrap();
 
-        let worker_id_path = PathBuf::from_iter([
-            env!("CARGO_MANIFEST_DIR"),
-            "tests/goldenfiles",
-            format!("worker_recovery_{name}.worker_id.bin").as_str(),
-        ]);
-        let oplog_path = PathBuf::from_iter([
-            env!("CARGO_MANIFEST_DIR"),
-            "tests/goldenfiles",
-            format!("worker_recovery_{name}.oplog.bin").as_str(),
-        ]);
+        let oplog_path =
+            Path::new("tests/goldenfiles").join(format!("worker_recovery_{name}.oplog.bin"));
+        let worker_id_path =
+            Path::new("tests/goldenfiles").join(format!("worker_recovery_{name}.worker_id.bin"));
 
         let encoded_oplog = serialize(&entries).unwrap();
         let encoded_worker_id = serialize(&worker_id).unwrap();
diff --git a/golem-worker-executor/tests/durability.rs b/golem-worker-executor/tests/durability.rs
index d28fa2f7..146267cb 100644
--- a/golem-worker-executor/tests/durability.rs
+++ b/golem-worker-executor/tests/durability.rs
@@ -13,17 +13,19 @@
 // limitations under the License.
 
 use crate::common::{start, TestContext};
-use crate::Deps;
-use crate::{LastUniqueId, Tracing};
+use crate::{LastUniqueId, Tracing, WorkerExecutorTestDependencies};
 use axum::extract::Query;
 use axum::response::Response;
 use axum::routing::get;
 use axum::{BoxError, Router};
 use bytes::Bytes;
-use futures_util::{stream, StreamExt};
+use futures::{stream, StreamExt};
 use golem_test_framework::config::TestDependencies;
 use golem_test_framework::dsl::TestDslUnsafe;
-use golem_wasm_rpc::{IntoValueAndType, Value};
+use golem_wasm_ast::analysis::{
+    AnalysedResourceId, AnalysedResourceMode, AnalysedType, TypeHandle,
+};
+use golem_wasm_rpc::{IntoValueAndType, Value, ValueAndType};
 use http::StatusCode;
 use serde::Deserialize;
 use std::collections::HashMap;
@@ -33,15 +35,19 @@ use test_r::{inherit_test_dep, test};
 use tokio::sync::Mutex;
 use tracing::Instrument;
 
-inherit_test_dep!(Deps);
+inherit_test_dep!(WorkerExecutorTestDependencies);
 inherit_test_dep!(LastUniqueId);
 inherit_test_dep!(Tracing);
 
 #[test]
 #[tracing::instrument]
-async fn custom_durability_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn custom_durability_1(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let response = Arc::new(AtomicU32::new(0));
     let response_clone = response.clone();
@@ -80,7 +86,7 @@ async fn custom_durability_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracin
     env.insert("PORT".to_string(), host_http_port.to_string());
 
     let worker_id = executor
-        .start_worker_with(&component_id, "custom-durability-1", vec![], env)
+        .start_worker_with(&component_id, "custom-durability-1", vec![], env, vec![])
         .await;
 
     let result1 = executor
@@ -96,7 +102,7 @@ async fn custom_durability_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracin
 
     drop(executor);
 
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let result2 = executor
         .invoke_and_await(
@@ -118,9 +124,13 @@ async fn custom_durability_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracin
 
 #[test]
 #[tracing::instrument]
-async fn lazy_pollable(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn lazy_pollable(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let listener = tokio::net::TcpListener::bind("0.0.0.0:0").await.unwrap();
 
@@ -171,16 +181,32 @@ async fn lazy_pollable(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tr
     env.insert("PORT".to_string(), host_http_port.to_string());
 
     let worker_id = executor
-        .start_worker_with(&component_id, "custom-durability-1", vec![], env)
+        .start_worker_with(&component_id, "custom-durability-1", vec![], env, vec![])
         .await;
 
     signal_tx.send(()).unwrap();
 
+    let res1 = executor
+        .invoke_and_await(
+            &worker_id,
+            "golem:it-exports/golem-it-api.{[constructor]lazy-pollable-test}",
+            vec![],
+        )
+        .await
+        .unwrap();
+    let res_handle_type = AnalysedType::Handle(TypeHandle {
+        name: None,
+        owner: None,
+        resource_id: AnalysedResourceId(0),
+        mode: AnalysedResourceMode::Borrowed,
+    });
+    let res = ValueAndType::new(res1[0].clone(), res_handle_type);
+
     let s1 = executor
         .invoke_and_await(
             &worker_id,
-            "golem:it-exports/golem-it-api.{lazy-pollable-test().test}",
-            vec![1u32.into_value_and_type()],
+            "golem:it-exports/golem-it-api.{[method]lazy-pollable-test.test}",
+            vec![res.clone(), 1u32.into_value_and_type()],
         )
         .await
         .unwrap();
@@ -190,8 +216,8 @@ async fn lazy_pollable(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tr
     let s2 = executor
         .invoke_and_await(
             &worker_id,
-            "golem:it-exports/golem-it-api.{lazy-pollable-test().test}",
-            vec![2u32.into_value_and_type()],
+            "golem:it-exports/golem-it-api.{[method]lazy-pollable-test.test}",
+            vec![res.clone(), 2u32.into_value_and_type()],
         )
         .await
         .unwrap();
@@ -201,8 +227,8 @@ async fn lazy_pollable(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tr
     let s3 = executor
         .invoke_and_await(
             &worker_id,
-            "golem:it-exports/golem-it-api.{lazy-pollable-test().test}",
-            vec![3u32.into_value_and_type()],
+            "golem:it-exports/golem-it-api.{[method]lazy-pollable-test.test}",
+            vec![res.clone(), 3u32.into_value_and_type()],
         )
         .await
         .unwrap();
@@ -210,15 +236,15 @@ async fn lazy_pollable(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tr
     signal_tx.send(()).unwrap();
 
     drop(executor);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     signal_tx.send(()).unwrap();
 
     let s4 = executor
         .invoke_and_await(
             &worker_id,
-            "golem:it-exports/golem-it-api.{lazy-pollable-test().test}",
-            vec![3u32.into_value_and_type()],
+            "golem:it-exports/golem-it-api.{[method]lazy-pollable-test.test}",
+            vec![res.clone(), 3u32.into_value_and_type()],
         )
         .await
         .unwrap();
diff --git a/golem-worker-executor/tests/hot_update.rs b/golem-worker-executor/tests/hot_update.rs
index fcb046f2..dc82a4bf 100644
--- a/golem-worker-executor/tests/hot_update.rs
+++ b/golem-worker-executor/tests/hot_update.rs
@@ -12,8 +12,7 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use crate::Deps;
-use crate::{common, LastUniqueId, Tracing};
+use crate::{common, LastUniqueId, Tracing, WorkerExecutorTestDependencies};
 use assert2::check;
 use async_mutex::Mutex;
 use axum::routing::post;
@@ -31,7 +30,7 @@ use tokio::spawn;
 use tokio::task::JoinHandle;
 use tracing::{debug, Instrument};
 
-inherit_test_dep!(Deps);
+inherit_test_dep!(WorkerExecutorTestDependencies);
 inherit_test_dep!(LastUniqueId);
 inherit_test_dep!(Tracing);
 
@@ -137,9 +136,17 @@ impl TestHttpServer {
 
 #[test]
 #[tracing::instrument]
-async fn auto_update_on_running(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn auto_update_on_running(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = common::TestContext::new(last_unique_id);
-    let executor = common::start(deps, &context).await.unwrap().into_admin();
+    let executor = common::start(deps, &context)
+        .await
+        .unwrap()
+        .into_admin()
+        .await;
 
     let mut http_server = TestHttpServer::start().await;
     let mut env = HashMap::new();
@@ -147,7 +154,7 @@ async fn auto_update_on_running(last_unique_id: &LastUniqueId, deps: &Deps, _tra
 
     let component_id = executor.component("update-test-v1").unique().store().await;
     let worker_id = executor
-        .start_worker_with(&component_id, "auto_update_on_running", vec![], env)
+        .start_worker_with(&component_id, "auto_update_on_running", vec![], env, vec![])
         .await;
     let _ = executor.log_output(&worker_id).await;
 
@@ -211,9 +218,17 @@ async fn auto_update_on_running(last_unique_id: &LastUniqueId, deps: &Deps, _tra
 
 #[test]
 #[tracing::instrument]
-async fn auto_update_on_idle(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn auto_update_on_idle(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = common::TestContext::new(last_unique_id);
-    let executor = common::start(deps, &context).await.unwrap().into_admin();
+    let executor = common::start(deps, &context)
+        .await
+        .unwrap()
+        .into_admin()
+        .await;
 
     let component_id = executor.component("update-test-v1").unique().store().await;
     let worker_id = executor
@@ -254,11 +269,15 @@ async fn auto_update_on_idle(last_unique_id: &LastUniqueId, deps: &Deps, _tracin
 #[flaky(10)] // TODO: remove when the test is stabilized
 async fn failing_auto_update_on_idle(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = common::TestContext::new(last_unique_id);
-    let executor = common::start(deps, &context).await.unwrap().into_admin();
+    let executor = common::start(deps, &context)
+        .await
+        .unwrap()
+        .into_admin()
+        .await;
 
     let http_server = TestHttpServer::start().await;
     let mut env = HashMap::new();
@@ -267,7 +286,13 @@ async fn failing_auto_update_on_idle(
 
     let component_id = executor.component("update-test-v1").unique().store().await;
     let worker_id = executor
-        .start_worker_with(&component_id, "failing_auto_update_on_idle", vec![], env)
+        .start_worker_with(
+            &component_id,
+            "failing_auto_update_on_idle",
+            vec![],
+            env,
+            vec![],
+        )
         .await;
     let _ = executor.log_output(&worker_id).await;
 
@@ -317,11 +342,15 @@ async fn failing_auto_update_on_idle(
 #[tracing::instrument]
 async fn auto_update_on_idle_with_non_diverging_history(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = common::TestContext::new(last_unique_id);
-    let executor = common::start(deps, &context).await.unwrap().into_admin();
+    let executor = common::start(deps, &context)
+        .await
+        .unwrap()
+        .into_admin()
+        .await;
 
     let component_id = executor.component("update-test-v1").unique().store().await;
     let worker_id = executor
@@ -374,11 +403,15 @@ async fn auto_update_on_idle_with_non_diverging_history(
 #[tracing::instrument]
 async fn failing_auto_update_on_running(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = common::TestContext::new(last_unique_id);
-    let executor = common::start(deps, &context).await.unwrap().into_admin();
+    let executor = common::start(deps, &context)
+        .await
+        .unwrap()
+        .into_admin()
+        .await;
 
     let mut http_server = TestHttpServer::start().await;
     let mut env = HashMap::new();
@@ -386,7 +419,13 @@ async fn failing_auto_update_on_running(
 
     let component_id = executor.component("update-test-v1").unique().store().await;
     let worker_id = executor
-        .start_worker_with(&component_id, "failing_auto_update_on_running", vec![], env)
+        .start_worker_with(
+            &component_id,
+            "failing_auto_update_on_running",
+            vec![],
+            env,
+            vec![],
+        )
         .await;
     let _ = executor.log_output(&worker_id).await;
 
@@ -457,9 +496,17 @@ async fn failing_auto_update_on_running(
 
 #[test]
 #[tracing::instrument]
-async fn manual_update_on_idle(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn manual_update_on_idle(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = common::TestContext::new(last_unique_id);
-    let executor = common::start(deps, &context).await.unwrap().into_admin();
+    let executor = common::start(deps, &context)
+        .await
+        .unwrap()
+        .into_admin()
+        .await;
 
     let http_server = TestHttpServer::start().await;
     let mut env = HashMap::new();
@@ -467,7 +514,7 @@ async fn manual_update_on_idle(last_unique_id: &LastUniqueId, deps: &Deps, _trac
 
     let component_id = executor.component("update-test-v2").unique().store().await;
     let worker_id = executor
-        .start_worker_with(&component_id, "manual_update_on_idle", vec![], env)
+        .start_worker_with(&component_id, "manual_update_on_idle", vec![], env, vec![])
         .await;
     let _ = executor.log_output(&worker_id).await;
 
@@ -521,11 +568,15 @@ async fn manual_update_on_idle(last_unique_id: &LastUniqueId, deps: &Deps, _trac
 #[tracing::instrument]
 async fn manual_update_on_idle_without_save_snapshot(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = common::TestContext::new(last_unique_id);
-    let executor = common::start(deps, &context).await.unwrap().into_admin();
+    let executor = common::start(deps, &context)
+        .await
+        .unwrap()
+        .into_admin()
+        .await;
 
     let http_server = TestHttpServer::start().await;
     let mut env = HashMap::new();
@@ -538,6 +589,7 @@ async fn manual_update_on_idle_without_save_snapshot(
             "manual_update_on_idle_without_save_snapshot",
             vec![],
             env,
+            vec![],
         )
         .await;
     let _ = executor.log_output(&worker_id).await;
@@ -586,11 +638,15 @@ async fn manual_update_on_idle_without_save_snapshot(
 #[tracing::instrument]
 async fn auto_update_on_running_followed_by_manual(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = common::TestContext::new(last_unique_id);
-    let executor = common::start(deps, &context).await.unwrap().into_admin();
+    let executor = common::start(deps, &context)
+        .await
+        .unwrap()
+        .into_admin()
+        .await;
 
     let mut http_server = TestHttpServer::start().await;
     let mut env = HashMap::new();
@@ -603,6 +659,7 @@ async fn auto_update_on_running_followed_by_manual(
             "auto_update_on_running_followed_by_manual",
             vec![],
             env,
+            vec![],
         )
         .await;
     let _ = executor.log_output(&worker_id).await;
@@ -682,11 +739,15 @@ async fn auto_update_on_running_followed_by_manual(
 #[tracing::instrument]
 async fn manual_update_on_idle_with_failing_load(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = common::TestContext::new(last_unique_id);
-    let executor = common::start(deps, &context).await.unwrap().into_admin();
+    let executor = common::start(deps, &context)
+        .await
+        .unwrap()
+        .into_admin()
+        .await;
 
     let http_server = TestHttpServer::start().await;
     let mut env = HashMap::new();
@@ -699,6 +760,7 @@ async fn manual_update_on_idle_with_failing_load(
             "manual_update_on_idle_with_failing_load",
             vec![],
             env,
+            vec![],
         )
         .await;
     let _ = executor.log_output(&worker_id).await;
@@ -746,11 +808,15 @@ async fn manual_update_on_idle_with_failing_load(
 #[tracing::instrument]
 async fn manual_update_on_idle_using_v11(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = common::TestContext::new(last_unique_id);
-    let executor = common::start(deps, &context).await.unwrap().into_admin();
+    let executor = common::start(deps, &context)
+        .await
+        .unwrap()
+        .into_admin()
+        .await;
 
     let http_server = TestHttpServer::start().await;
     let mut env = HashMap::new();
@@ -767,6 +833,7 @@ async fn manual_update_on_idle_using_v11(
             "manual_update_on_idle_using_v11",
             vec![],
             env,
+            vec![],
         )
         .await;
     let _ = executor.log_output(&worker_id).await;
@@ -821,11 +888,15 @@ async fn manual_update_on_idle_using_v11(
 #[tracing::instrument]
 async fn manual_update_on_idle_using_golem_rust_sdk(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = common::TestContext::new(last_unique_id);
-    let executor = common::start(deps, &context).await.unwrap().into_admin();
+    let executor = common::start(deps, &context)
+        .await
+        .unwrap()
+        .into_admin()
+        .await;
 
     let http_server = TestHttpServer::start().await;
     let mut env = HashMap::new();
@@ -842,6 +913,7 @@ async fn manual_update_on_idle_using_golem_rust_sdk(
             "manual_update_on_idle_using_golem_rust_sdk",
             vec![],
             env,
+            vec![],
         )
         .await;
     let _ = executor.log_output(&worker_id).await;
@@ -896,11 +968,15 @@ async fn manual_update_on_idle_using_golem_rust_sdk(
 #[tracing::instrument]
 async fn auto_update_on_idle_to_non_existing(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = common::TestContext::new(last_unique_id);
-    let executor = common::start(deps, &context).await.unwrap().into_admin();
+    let executor = common::start(deps, &context)
+        .await
+        .unwrap()
+        .into_admin()
+        .await;
 
     let component_id = executor.component("update-test-v1").unique().store().await;
     let worker_id = executor
@@ -953,11 +1029,15 @@ async fn auto_update_on_idle_to_non_existing(
 #[tracing::instrument]
 async fn update_component_version_environment_variable(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = common::TestContext::new(last_unique_id);
-    let executor = common::start(deps, &context).await.unwrap().into_admin();
+    let executor = common::start(deps, &context)
+        .await
+        .unwrap()
+        .into_admin()
+        .await;
 
     let component_id = executor.component("update-test-env-var").store().await;
 
diff --git a/golem-worker-executor/tests/http.rs b/golem-worker-executor/tests/http.rs
index 69a55903..7ae6ce65 100644
--- a/golem-worker-executor/tests/http.rs
+++ b/golem-worker-executor/tests/http.rs
@@ -13,8 +13,7 @@
 // limitations under the License.
 
 use crate::common::{start, start_customized, TestContext};
-use crate::Deps;
-use crate::{LastUniqueId, Tracing};
+use crate::{LastUniqueId, Tracing, WorkerExecutorTestDependencies};
 use assert2::{check, let_assert};
 use axum::routing::post;
 use axum::Router;
@@ -31,15 +30,19 @@ use test_r::{inherit_test_dep, test};
 use tokio::spawn;
 use tracing::Instrument;
 
-inherit_test_dep!(Deps);
+inherit_test_dep!(WorkerExecutorTestDependencies);
 inherit_test_dep!(LastUniqueId);
 inherit_test_dep!(Tracing);
 
 #[test]
 #[tracing::instrument]
-async fn http_client(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn http_client(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let listener = tokio::net::TcpListener::bind("0.0.0.0:0").await.unwrap();
     let host_http_port = listener.local_addr().unwrap().port();
@@ -66,7 +69,7 @@ async fn http_client(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Trac
     env.insert("RUST_BACKTRACE".to_string(), "full".to_string());
 
     let worker_id = executor
-        .start_worker_with(&component_id, "http-client-1", vec![], env)
+        .start_worker_with(&component_id, "http-client-1", vec![], env, vec![])
         .await;
     let rx = executor.capture_output(&worker_id).await;
 
@@ -90,9 +93,13 @@ async fn http_client(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Trac
 
 #[test]
 #[tracing::instrument]
-async fn http_client_using_reqwest(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn http_client_using_reqwest(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
     let captured_body: Arc<Mutex<Option<String>>> = Arc::new(Mutex::new(None));
     let captured_body_clone = captured_body.clone();
 
@@ -129,7 +136,7 @@ async fn http_client_using_reqwest(last_unique_id: &LastUniqueId, deps: &Deps, _
     env.insert("PORT".to_string(), host_http_port.to_string());
 
     let worker_id = executor
-        .start_worker_with(&component_id, "http-client-reqwest-1", vec![], env)
+        .start_worker_with(&component_id, "http-client-reqwest-1", vec![], env, vec![])
         .await;
 
     let result = executor
@@ -155,11 +162,11 @@ async fn http_client_using_reqwest(last_unique_id: &LastUniqueId, deps: &Deps, _
 #[tracing::instrument]
 async fn http_client_using_reqwest_async(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
     let captured_body: Arc<Mutex<Option<String>>> = Arc::new(Mutex::new(None));
     let captured_body_clone = captured_body.clone();
 
@@ -196,7 +203,13 @@ async fn http_client_using_reqwest_async(
     env.insert("PORT".to_string(), host_http_port.to_string());
 
     let worker_id = executor
-        .start_worker_with(&component_id, "http-client-reqwest-async-1", vec![], env)
+        .start_worker_with(
+            &component_id,
+            "http-client-reqwest-async-1",
+            vec![],
+            env,
+            vec![],
+        )
         .await;
 
     let result = executor
@@ -222,11 +235,11 @@ async fn http_client_using_reqwest_async(
 #[tracing::instrument]
 async fn http_client_using_reqwest_async_parallel(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
     let captured_body: Arc<Mutex<Vec<String>>> = Arc::new(Mutex::new(Vec::new()));
     let captured_body_clone = captured_body.clone();
 
@@ -263,7 +276,13 @@ async fn http_client_using_reqwest_async_parallel(
     env.insert("PORT".to_string(), host_http_port.to_string());
 
     let worker_id = executor
-        .start_worker_with(&component_id, "http-client-reqwest-async-2", vec![], env)
+        .start_worker_with(
+            &component_id,
+            "http-client-reqwest-async-2",
+            vec![],
+            env,
+            vec![],
+        )
         .await;
 
     let result = executor
@@ -327,11 +346,11 @@ async fn http_client_using_reqwest_async_parallel(
 #[tracing::instrument]
 async fn outgoing_http_contains_idempotency_key(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let listener = tokio::net::TcpListener::bind("0.0.0.0:0").await.unwrap();
     let host_http_port = listener.local_addr().unwrap().port();
@@ -368,6 +387,7 @@ async fn outgoing_http_contains_idempotency_key(
             "outgoing-http-contains-idempotency-key",
             vec![],
             env,
+            vec![],
         )
         .await;
 
@@ -394,21 +414,22 @@ async fn outgoing_http_contains_idempotency_key(
 #[test]
 async fn http_response_request_chaining(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
     let executor = start_customized(deps, &context, None, Some(RetryConfig::no_retries()))
         .await
         .unwrap()
-        .into_admin();
+        .into_admin()
+        .await;
 
     let component_id = executor.component("fetch").store().await;
     let mut env = HashMap::new();
     env.insert("RUST_BACKTRACE".to_string(), "full".to_string());
 
     let worker_id = executor
-        .start_worker_with(&component_id, "fetch-test-4", vec![], env)
+        .start_worker_with(&component_id, "fetch-test-4", vec![], env, vec![])
         .await;
     let rx = executor.capture_output(&worker_id).await;
 
diff --git a/golem-worker-executor/tests/indexed_storage.rs b/golem-worker-executor/tests/indexed_storage.rs
index e5bf0bee..649a7e81 100644
--- a/golem-worker-executor/tests/indexed_storage.rs
+++ b/golem-worker-executor/tests/indexed_storage.rs
@@ -12,7 +12,7 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use crate::Deps;
+use crate::WorkerExecutorTestDependencies;
 use assert2::check;
 use async_trait::async_trait;
 use golem_common::config::RedisConfig;
@@ -53,7 +53,9 @@ impl GetIndexedStorage for InMemoryIndexedStorageWrapper {
 }
 
 #[test_dep(tagged_as = "in_memory")]
-async fn in_memory_storage(_deps: &Deps) -> Arc<dyn GetIndexedStorage + Send + Sync> {
+async fn in_memory_storage(
+    _deps: &WorkerExecutorTestDependencies,
+) -> Arc<dyn GetIndexedStorage + Send + Sync> {
     Arc::new(InMemoryIndexedStorageWrapper)
 }
 
@@ -90,7 +92,9 @@ impl GetIndexedStorage for RedisIndexedStorageWrapper {
 }
 
 #[test_dep(tagged_as = "redis")]
-async fn redis_storage(deps: &Deps) -> Arc<dyn GetIndexedStorage + Send + Sync> {
+async fn redis_storage(
+    deps: &WorkerExecutorTestDependencies,
+) -> Arc<dyn GetIndexedStorage + Send + Sync> {
     let redis = deps.redis.clone();
     let redis_monitor = deps.redis_monitor.clone();
     redis.assert_valid();
@@ -122,7 +126,9 @@ impl GetIndexedStorage for SqliteIndexedStorageWrapper {
 }
 
 #[test_dep(tagged_as = "sqlite")]
-async fn sqlite_storage(_deps: &Deps) -> Arc<dyn GetIndexedStorage + Send + Sync> {
+async fn sqlite_storage(
+    _deps: &WorkerExecutorTestDependencies,
+) -> Arc<dyn GetIndexedStorage + Send + Sync> {
     Arc::new(SqliteIndexedStorageWrapper)
 }
 
@@ -136,14 +142,14 @@ fn ns2() -> IndexedStorageNamespace {
     IndexedStorageNamespace::CompressedOpLog { level: 1 }
 }
 
-inherit_test_dep!(Deps);
+inherit_test_dep!(WorkerExecutorTestDependencies);
 
 define_matrix_dimension!(is: Arc<dyn GetIndexedStorage + Send + Sync> -> "in_memory", "redis", "sqlite");
 
 #[test]
 #[tracing::instrument]
 async fn exists_append(
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     #[dimension(is)] is: &Arc<dyn GetIndexedStorage + Send + Sync>,
     #[tagged_as("ns1")] ns: &IndexedStorageNamespace,
     #[tagged_as("ns2")] ns2: &IndexedStorageNamespace,
@@ -166,7 +172,7 @@ async fn exists_append(
 #[test]
 #[tracing::instrument]
 async fn namespaces_are_separate(
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     #[dimension(is)] is: &Arc<dyn GetIndexedStorage + Send + Sync>,
     #[tagged_as("ns1")] ns1: &IndexedStorageNamespace,
     #[tagged_as("ns2")] ns2: &IndexedStorageNamespace,
@@ -187,7 +193,7 @@ async fn namespaces_are_separate(
 #[test]
 #[tracing::instrument]
 async fn can_append_and_get(
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     #[dimension(is)] is: &Arc<dyn GetIndexedStorage + Send + Sync>,
     #[tagged_as("ns1")] ns: &IndexedStorageNamespace,
     #[tagged_as("ns2")] ns2: &IndexedStorageNamespace,
@@ -220,7 +226,7 @@ async fn can_append_and_get(
 #[test]
 #[tracing::instrument]
 async fn append_cannot_overwrite(
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     #[dimension(is)] is: &Arc<dyn GetIndexedStorage + Send + Sync>,
     #[tagged_as("ns1")] ns: &IndexedStorageNamespace,
     #[tagged_as("ns2")] ns2: &IndexedStorageNamespace,
@@ -244,7 +250,7 @@ async fn append_cannot_overwrite(
 #[test]
 #[tracing::instrument]
 async fn append_can_skip(
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     #[dimension(is)] is: &Arc<dyn GetIndexedStorage + Send + Sync>,
     #[tagged_as("ns1")] ns: &IndexedStorageNamespace,
     #[tagged_as("ns2")] ns2: &IndexedStorageNamespace,
@@ -273,7 +279,7 @@ async fn append_can_skip(
 #[test]
 #[tracing::instrument]
 async fn length(
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     #[dimension(is)] is: &Arc<dyn GetIndexedStorage + Send + Sync>,
     #[tagged_as("ns1")] ns: &IndexedStorageNamespace,
     #[tagged_as("ns2")] ns2: &IndexedStorageNamespace,
@@ -302,7 +308,7 @@ async fn length(
 #[test]
 #[tracing::instrument]
 async fn scan_empty(
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     #[dimension(is)] is: &Arc<dyn GetIndexedStorage + Send + Sync>,
     #[tagged_as("ns1")] ns: &IndexedStorageNamespace,
     #[tagged_as("ns2")] ns2: &IndexedStorageNamespace,
@@ -329,7 +335,7 @@ async fn scan_empty(
 #[test]
 #[tracing::instrument]
 async fn scan_with_no_pattern_single_paged(
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     #[dimension(is)] is: &Arc<dyn GetIndexedStorage + Send + Sync>,
     #[tagged_as("ns1")] ns: &IndexedStorageNamespace,
     #[tagged_as("ns2")] ns2: &IndexedStorageNamespace,
@@ -369,7 +375,7 @@ async fn scan_with_no_pattern_single_paged(
 #[test]
 #[tracing::instrument]
 async fn scan_with_no_pattern_paginated(
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     #[dimension(is)] is: &Arc<dyn GetIndexedStorage + Send + Sync>,
     #[tagged_as("ns1")] ns: &IndexedStorageNamespace,
     #[tagged_as("ns2")] ns2: &IndexedStorageNamespace,
@@ -434,7 +440,7 @@ async fn scan_with_no_pattern_paginated(
 #[test]
 #[tracing::instrument]
 async fn scan_with_prefix_pattern_single_paged(
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     #[dimension(is)] is: &Arc<dyn GetIndexedStorage + Send + Sync>,
     #[tagged_as("ns1")] ns: &IndexedStorageNamespace,
     #[tagged_as("ns2")] ns2: &IndexedStorageNamespace,
@@ -479,7 +485,7 @@ async fn scan_with_prefix_pattern_single_paged(
 #[test]
 #[tracing::instrument]
 async fn scan_with_prefix_pattern_paginated(
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     #[dimension(is)] is: &Arc<dyn GetIndexedStorage + Send + Sync>,
     #[tagged_as("ns1")] ns: &IndexedStorageNamespace,
     #[tagged_as("ns2")] ns2: &IndexedStorageNamespace,
@@ -546,7 +552,7 @@ async fn scan_with_prefix_pattern_paginated(
 #[test]
 #[tracing::instrument]
 async fn exists_append_delete(
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     #[dimension(is)] is: &Arc<dyn GetIndexedStorage + Send + Sync>,
     #[tagged_as("ns1")] ns: &IndexedStorageNamespace,
     #[tagged_as("ns2")] ns2: &IndexedStorageNamespace,
@@ -570,7 +576,7 @@ async fn exists_append_delete(
 #[test]
 #[tracing::instrument]
 async fn delete_is_per_namespace(
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     #[dimension(is)] is: &Arc<dyn GetIndexedStorage + Send + Sync>,
     #[tagged_as("ns1")] ns1: &IndexedStorageNamespace,
     #[tagged_as("ns2")] ns2: &IndexedStorageNamespace,
@@ -592,7 +598,7 @@ async fn delete_is_per_namespace(
 #[test]
 #[tracing::instrument]
 async fn delete_non_existing(
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     #[dimension(is)] is: &Arc<dyn GetIndexedStorage + Send + Sync>,
     #[tagged_as("ns1")] ns: &IndexedStorageNamespace,
     #[tagged_as("ns2")] ns2: &IndexedStorageNamespace,
@@ -609,7 +615,7 @@ async fn delete_non_existing(
 #[test]
 #[tracing::instrument]
 async fn first(
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     #[dimension(is)] is: &Arc<dyn GetIndexedStorage + Send + Sync>,
     #[tagged_as("ns1")] ns: &IndexedStorageNamespace,
     #[tagged_as("ns2")] ns2: &IndexedStorageNamespace,
@@ -642,7 +648,7 @@ async fn first(
 #[test]
 #[tracing::instrument]
 async fn last(
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     #[dimension(is)] is: &Arc<dyn GetIndexedStorage + Send + Sync>,
     #[tagged_as("ns1")] ns: &IndexedStorageNamespace,
     #[tagged_as("ns2")] ns2: &IndexedStorageNamespace,
@@ -675,7 +681,7 @@ async fn last(
 #[test]
 #[tracing::instrument]
 async fn closest_low(
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     #[dimension(is)] is: &Arc<dyn GetIndexedStorage + Send + Sync>,
     #[tagged_as("ns1")] ns: &IndexedStorageNamespace,
     #[tagged_as("ns2")] ns2: &IndexedStorageNamespace,
@@ -708,7 +714,7 @@ async fn closest_low(
 #[test]
 #[tracing::instrument]
 async fn closest_match(
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     #[dimension(is)] is: &Arc<dyn GetIndexedStorage + Send + Sync>,
     #[tagged_as("ns1")] ns: &IndexedStorageNamespace,
     #[tagged_as("ns2")] ns2: &IndexedStorageNamespace,
@@ -741,7 +747,7 @@ async fn closest_match(
 #[test]
 #[tracing::instrument]
 async fn closest_mid(
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     #[dimension(is)] is: &Arc<dyn GetIndexedStorage + Send + Sync>,
     #[tagged_as("ns1")] ns: &IndexedStorageNamespace,
     #[tagged_as("ns2")] ns2: &IndexedStorageNamespace,
@@ -774,7 +780,7 @@ async fn closest_mid(
 #[test]
 #[tracing::instrument]
 async fn closest_high(
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     #[dimension(is)] is: &Arc<dyn GetIndexedStorage + Send + Sync>,
     #[tagged_as("ns1")] ns: &IndexedStorageNamespace,
     #[tagged_as("ns2")] ns2: &IndexedStorageNamespace,
@@ -807,7 +813,7 @@ async fn closest_high(
 #[test]
 #[tracing::instrument]
 async fn drop_prefix_no_match(
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     #[dimension(is)] is: &Arc<dyn GetIndexedStorage + Send + Sync>,
     #[tagged_as("ns1")] ns: &IndexedStorageNamespace,
     #[tagged_as("ns2")] ns2: &IndexedStorageNamespace,
@@ -850,7 +856,7 @@ async fn drop_prefix_no_match(
 #[test]
 #[tracing::instrument]
 async fn drop_prefix_partial(
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     #[dimension(is)] is: &Arc<dyn GetIndexedStorage + Send + Sync>,
     #[tagged_as("ns1")] ns: &IndexedStorageNamespace,
     #[tagged_as("ns2")] ns2: &IndexedStorageNamespace,
@@ -886,7 +892,7 @@ async fn drop_prefix_partial(
 #[test]
 #[tracing::instrument]
 async fn drop_prefix_full(
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     #[dimension(is)] is: &Arc<dyn GetIndexedStorage + Send + Sync>,
     #[tagged_as("ns1")] ns: &IndexedStorageNamespace,
     #[tagged_as("ns2")] ns2: &IndexedStorageNamespace,
diff --git a/golem-worker-executor/tests/key_value_storage.rs b/golem-worker-executor/tests/key_value_storage.rs
index e5503fd7..ce454f09 100644
--- a/golem-worker-executor/tests/key_value_storage.rs
+++ b/golem-worker-executor/tests/key_value_storage.rs
@@ -12,10 +12,10 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use crate::Deps;
+use crate::WorkerExecutorTestDependencies;
 use async_trait::async_trait;
+use golem_common::base_model::ProjectId;
 use golem_common::config::RedisConfig;
-use golem_common::model::AccountId;
 use golem_common::redis::RedisPool;
 use golem_service_base::db::sqlite::SqlitePool;
 use golem_test_framework::components::redis::Redis;
@@ -50,7 +50,9 @@ impl GetKeyValueStorage for InMemoryKeyValueStorageWrapper {
 }
 
 #[test_dep(tagged_as = "in_memory")]
-async fn in_memory_storage(_deps: &Deps) -> Arc<dyn GetKeyValueStorage + Send + Sync> {
+async fn in_memory_storage(
+    _deps: &WorkerExecutorTestDependencies,
+) -> Arc<dyn GetKeyValueStorage + Send + Sync> {
     Arc::new(InMemoryKeyValueStorageWrapper)
 }
 
@@ -87,7 +89,9 @@ impl GetKeyValueStorage for RedisKeyValueStorageWrapper {
 }
 
 #[test_dep(tagged_as = "redis")]
-async fn redis_storage(deps: &Deps) -> Arc<dyn GetKeyValueStorage + Send + Sync> {
+async fn redis_storage(
+    deps: &WorkerExecutorTestDependencies,
+) -> Arc<dyn GetKeyValueStorage + Send + Sync> {
     let redis = deps.redis.clone();
     let redis_monitor = deps.redis_monitor.clone();
     redis.assert_valid();
@@ -119,7 +123,9 @@ impl GetKeyValueStorage for SqliteKeyValueStorageWrapper {
 }
 
 #[test_dep(tagged_as = "sqlite")]
-async fn sqlite_storage(_deps: &Deps) -> Arc<dyn GetKeyValueStorage + Send + Sync> {
+async fn sqlite_storage(
+    _deps: &WorkerExecutorTestDependencies,
+) -> Arc<dyn GetKeyValueStorage + Send + Sync> {
     Arc::new(SqliteKeyValueStorageWrapper)
 }
 
@@ -134,7 +140,7 @@ fn ns() -> Namespaces {
     Namespaces {
         ns: KeyValueStorageNamespace::Worker,
         ns2: KeyValueStorageNamespace::UserDefined {
-            account_id: AccountId::generate(),
+            project_id: ProjectId(Uuid::parse_str("296aa41a-ff44-4882-8f34-08b7fe431aa4").unwrap()),
             bucket: "test-bucket".to_string(),
         },
     }
@@ -144,14 +150,14 @@ fn ns() -> Namespaces {
 fn ns2() -> Namespaces {
     Namespaces {
         ns: KeyValueStorageNamespace::UserDefined {
-            account_id: AccountId::generate(),
+            project_id: ProjectId(Uuid::parse_str("296aa41a-ff44-4882-8f34-08b7fe431aa4").unwrap()),
             bucket: "test-bucket".to_string(),
         },
         ns2: KeyValueStorageNamespace::Worker,
     }
 }
 
-inherit_test_dep!(Deps);
+inherit_test_dep!(WorkerExecutorTestDependencies);
 
 define_matrix_dimension!(kvs: Arc<dyn GetKeyValueStorage + Send + Sync> -> "in_memory", "redis", "sqlite");
 define_matrix_dimension!(nss: Namespaces -> "ns1", "ns2");
@@ -159,7 +165,7 @@ define_matrix_dimension!(nss: Namespaces -> "ns1", "ns2");
 #[test]
 #[tracing::instrument]
 async fn get_set_get(
-    _deps: &Deps,
+    _deps: &WorkerExecutorTestDependencies,
     #[dimension(kvs)] kvs: &Arc<dyn GetKeyValueStorage + Send + Sync>,
     #[dimension(nss)] nss: &Namespaces,
 ) {
@@ -184,7 +190,7 @@ async fn get_set_get(
 #[test]
 #[tracing::instrument]
 async fn namespaces_are_separate(
-    _deps: &Deps,
+    _deps: &WorkerExecutorTestDependencies,
     #[dimension(kvs)] kvs: &Arc<dyn GetKeyValueStorage + Send + Sync>,
     #[dimension(nss)] nss: &Namespaces,
 ) {
@@ -221,7 +227,7 @@ async fn namespaces_are_separate(
 #[test]
 #[tracing::instrument]
 async fn get_set_get_many(
-    _deps: &Deps,
+    _deps: &WorkerExecutorTestDependencies,
     #[dimension(kvs)] kvs: &Arc<dyn GetKeyValueStorage + Send + Sync>,
     #[dimension(nss)] nss: &Namespaces,
 ) {
@@ -273,7 +279,7 @@ async fn get_set_get_many(
 #[test]
 #[tracing::instrument]
 async fn set_if_not_exists(
-    _deps: &Deps,
+    _deps: &WorkerExecutorTestDependencies,
     #[dimension(kvs)] kvs: &Arc<dyn GetKeyValueStorage + Send + Sync>,
     #[dimension(nss)] nss: &Namespaces,
 ) {
@@ -301,7 +307,7 @@ async fn set_if_not_exists(
 #[test]
 #[tracing::instrument]
 async fn del(
-    _deps: &Deps,
+    _deps: &WorkerExecutorTestDependencies,
     #[dimension(kvs)] kvs: &Arc<dyn GetKeyValueStorage + Send + Sync>,
     #[dimension(nss)] nss: &Namespaces,
 ) {
@@ -329,7 +335,7 @@ async fn del(
 #[test]
 #[tracing::instrument]
 async fn del_many(
-    _deps: &Deps,
+    _deps: &WorkerExecutorTestDependencies,
     #[dimension(kvs)] kvs: &Arc<dyn GetKeyValueStorage + Send + Sync>,
     #[dimension(nss)] nss: &Namespaces,
 ) {
@@ -389,7 +395,7 @@ async fn del_many(
 #[test]
 #[tracing::instrument]
 async fn exists_set_exists(
-    _deps: &Deps,
+    _deps: &WorkerExecutorTestDependencies,
     #[dimension(kvs)] kvs: &Arc<dyn GetKeyValueStorage + Send + Sync>,
     #[dimension(nss)] nss: &Namespaces,
 ) {
@@ -411,7 +417,7 @@ async fn exists_set_exists(
 #[test]
 #[tracing::instrument]
 async fn exists_is_per_namespace(
-    _deps: &Deps,
+    _deps: &WorkerExecutorTestDependencies,
     #[dimension(kvs)] kvs: &Arc<dyn GetKeyValueStorage + Send + Sync>,
     #[dimension(nss)] nss: &Namespaces,
 ) {
@@ -436,7 +442,7 @@ async fn exists_is_per_namespace(
 #[test]
 #[tracing::instrument]
 async fn keys(
-    _deps: &Deps,
+    _deps: &WorkerExecutorTestDependencies,
     #[dimension(kvs)] kvs: &Arc<dyn GetKeyValueStorage + Send + Sync>,
     #[dimension(nss)] nss: &Namespaces,
 ) {
@@ -483,7 +489,7 @@ async fn keys(
 #[test]
 #[tracing::instrument]
 async fn sets(
-    _deps: &Deps,
+    _deps: &WorkerExecutorTestDependencies,
     #[dimension(kvs)] kvs: &Arc<dyn GetKeyValueStorage + Send + Sync>,
     #[dimension(nss)] nss: &Namespaces,
 ) {
@@ -588,7 +594,7 @@ async fn sets(
 #[test]
 #[tracing::instrument]
 async fn sorted_sets(
-    _deps: &Deps,
+    _deps: &WorkerExecutorTestDependencies,
     #[dimension(kvs)] kvs: &Arc<dyn GetKeyValueStorage + Send + Sync>,
     #[dimension(nss)] nss: &Namespaces,
 ) {
@@ -709,7 +715,7 @@ async fn sorted_sets(
 #[test]
 #[tracing::instrument]
 async fn add_to_sorted_set_updates_score(
-    _deps: &Deps,
+    _deps: &WorkerExecutorTestDependencies,
     #[dimension(kvs)] kvs: &Arc<dyn GetKeyValueStorage + Send + Sync>,
     #[dimension(nss)] nss: &Namespaces,
 ) {
@@ -742,7 +748,7 @@ async fn add_to_sorted_set_updates_score(
 #[test]
 #[tracing::instrument]
 async fn query_sorted_set(
-    _deps: &Deps,
+    _deps: &WorkerExecutorTestDependencies,
     #[dimension(kvs)] kvs: &Arc<dyn GetKeyValueStorage + Send + Sync>,
     #[dimension(nss)] nss: &Namespaces,
 ) {
diff --git a/golem-worker-executor/tests/keyvalue.rs b/golem-worker-executor/tests/keyvalue.rs
index 7708b599..975e0a00 100644
--- a/golem-worker-executor/tests/keyvalue.rs
+++ b/golem-worker-executor/tests/keyvalue.rs
@@ -13,15 +13,14 @@
 // limitations under the License.
 
 use crate::common::{start, TestContext};
-use crate::Deps;
-use crate::{LastUniqueId, Tracing};
+use crate::{LastUniqueId, Tracing, WorkerExecutorTestDependencies};
 use assert2::check;
 use golem_test_framework::config::TestDependencies;
 use golem_test_framework::dsl::TestDslUnsafe;
 use golem_wasm_rpc::{IntoValueAndType, Value};
 use test_r::{inherit_test_dep, test};
 
-inherit_test_dep!(Deps);
+inherit_test_dep!(WorkerExecutorTestDependencies);
 inherit_test_dep!(LastUniqueId);
 inherit_test_dep!(Tracing);
 
@@ -29,11 +28,11 @@ inherit_test_dep!(Tracing);
 #[tracing::instrument]
 async fn readwrite_get_returns_the_value_that_was_set(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("key-value-service").store().await;
     let worker_name = "key-value-service-1";
@@ -82,11 +81,11 @@ async fn readwrite_get_returns_the_value_that_was_set(
 #[tracing::instrument]
 async fn readwrite_get_fails_if_the_value_was_not_set(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("key-value-service").store().await;
     let worker_name = "key-value-service-2";
@@ -115,11 +114,11 @@ async fn readwrite_get_fails_if_the_value_was_not_set(
 #[tracing::instrument]
 async fn readwrite_set_replaces_the_value_if_it_was_already_set(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("key-value-service").store().await;
     let worker_name = "key-value-service-3";
@@ -181,11 +180,11 @@ async fn readwrite_set_replaces_the_value_if_it_was_already_set(
 #[tracing::instrument]
 async fn readwrite_delete_removes_the_value_if_it_was_already_set(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("key-value-service").store().await;
     let worker_name = "key-value-service-4";
@@ -239,11 +238,11 @@ async fn readwrite_delete_removes_the_value_if_it_was_already_set(
 #[tracing::instrument]
 async fn readwrite_exists_returns_true_if_the_value_was_set(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("key-value-service").store().await;
     let worker_name = "key-value-service-5";
@@ -285,11 +284,11 @@ async fn readwrite_exists_returns_true_if_the_value_was_set(
 #[tracing::instrument]
 async fn readwrite_exists_returns_false_if_the_value_was_not_set(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("key-value-service").store().await;
     let worker_name = "key-value-service-6";
@@ -318,11 +317,11 @@ async fn readwrite_exists_returns_false_if_the_value_was_not_set(
 #[tracing::instrument]
 async fn readwrite_buckets_can_be_shared_between_workers(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("key-value-service").store().await;
     let worker_id_1 = executor
@@ -376,11 +375,11 @@ async fn readwrite_buckets_can_be_shared_between_workers(
 #[tracing::instrument]
 async fn batch_get_many_gets_multiple_values(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("key-value-service").store().await;
     let worker_name = "key-value-service-9";
@@ -455,11 +454,11 @@ async fn batch_get_many_gets_multiple_values(
 #[tracing::instrument]
 async fn batch_get_many_fails_if_any_value_was_not_set(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("key-value-service").store().await;
     let worker_name = "key-value-service-10";
@@ -514,11 +513,11 @@ async fn batch_get_many_fails_if_any_value_was_not_set(
 #[tracing::instrument]
 async fn batch_set_many_sets_multiple_values(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("key-value-service").store().await;
     let worker_name = "key-value-service-11";
@@ -611,11 +610,11 @@ async fn batch_set_many_sets_multiple_values(
 #[tracing::instrument]
 async fn batch_delete_many_deletes_multiple_values(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("key-value-service").store().await;
     let worker_name = "key-value-service-12";
@@ -721,11 +720,11 @@ async fn batch_delete_many_deletes_multiple_values(
 #[tracing::instrument]
 async fn batch_get_keys_returns_multiple_keys(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("key-value-service").store().await;
     let worker_name = "key-value-service-13";
diff --git a/golem-worker-executor/tests/lib.rs b/golem-worker-executor/tests/lib.rs
index 63c5d3aa..249a20dc 100644
--- a/golem-worker-executor/tests/lib.rs
+++ b/golem-worker-executor/tests/lib.rs
@@ -22,34 +22,31 @@ use golem_test_framework::components::cloud_service::{AdminOnlyStubCloudService,
 use golem_test_framework::components::component_service::filesystem::FileSystemComponentService;
 use golem_test_framework::components::component_service::ComponentService;
 use golem_test_framework::components::redis::provided::ProvidedRedis;
+use golem_test_framework::components::redis::spawned::SpawnedRedis;
 use golem_test_framework::components::redis::Redis;
+use golem_test_framework::components::redis_monitor::spawned::SpawnedRedisMonitor;
 use golem_test_framework::components::redis_monitor::RedisMonitor;
 use golem_test_framework::components::worker_executor::provided::ProvidedWorkerExecutor;
 use golem_test_framework::components::worker_executor::WorkerExecutor;
 use golem_test_framework::components::worker_service::forwarding::ForwardingWorkerService;
 use golem_test_framework::components::worker_service::WorkerService;
-use golem_test_framework::config::{
-    EnvBasedTestDependencies, EnvBasedTestDependenciesConfig, TestDependencies, TestDependenciesDsl,
-};
 use golem_wasm_ast::analysis::wit_parser::{AnalysedTypeResolve, SharedAnalysedTypeResolve};
 use std::fmt::{Debug, Formatter};
-use std::ops::Deref;
 use std::path::{Path, PathBuf};
 use std::sync::atomic::AtomicU16;
 use std::sync::Arc;
 use tempfile::TempDir;
 use test_r::{tag_suite, test_dep};
+use tracing::Level;
 use uuid::Uuid;
 
 mod common;
 
+pub mod agent;
 pub mod api;
 pub mod blobstore;
 pub mod compatibility;
 pub mod durability;
-pub mod guest_languages1;
-pub mod guest_languages2;
-pub mod guest_languages3;
 pub mod hot_update;
 pub mod http;
 pub mod indexed_storage;
@@ -74,46 +71,26 @@ tag_suite!(api, group1);
 tag_suite!(blobstore, group1);
 tag_suite!(keyvalue, group1);
 tag_suite!(http, group1);
-
 tag_suite!(rdbms, group1);
+tag_suite!(agent, group1);
 
-tag_suite!(guest_languages1, group2);
-
-tag_suite!(transactions, group3);
-tag_suite!(wasi, group3);
-tag_suite!(revert, group3);
-tag_suite!(durability, group3);
-
-tag_suite!(scalability, group4);
-tag_suite!(hot_update, group4);
-tag_suite!(rust_rpc, group4);
-tag_suite!(rust_rpc_stubless, group4);
-
-tag_suite!(guest_languages2, group5);
+tag_suite!(transactions, group2);
+tag_suite!(wasi, group2);
+tag_suite!(revert, group2);
+tag_suite!(durability, group2);
 
-tag_suite!(ts_rpc1, group6);
-tag_suite!(ts_rpc1_stubless, group6);
+tag_suite!(scalability, group3);
+tag_suite!(hot_update, group3);
+tag_suite!(rust_rpc, group3);
+tag_suite!(rust_rpc_stubless, group3);
 
-tag_suite!(guest_languages3, group7);
-
-tag_suite!(ts_rpc2, group8);
-tag_suite!(ts_rpc2_stubless, group8);
-
-pub struct Deps(pub TestDependenciesDsl<WorkerExecutorTestDependencies>);
-
-impl std::fmt::Debug for Deps {
-    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
-        f.debug_struct("Deps").finish_non_exhaustive()
-    }
-}
+tag_suite!(ts_rpc1, group4);
+tag_suite!(ts_rpc1_stubless, group4);
 
-impl Deref for Deps {
-    type Target = WorkerExecutorTestDependencies;
+tag_suite!(ts_rpc2, group5);
+tag_suite!(ts_rpc2_stubless, group5);
 
-    fn deref(&self) -> &Self::Target {
-        &self.0.deps
-    }
-}
+tag_suite!(rdbms_service, rdbms_service);
 
 #[derive(Clone)]
 pub struct WorkerExecutorPerTestDependencies {
@@ -150,11 +127,17 @@ impl Debug for WorkerExecutorTestDependencies {
 
 impl WorkerExecutorTestDependencies {
     pub async fn new() -> Self {
-        let env_config = EnvBasedTestDependenciesConfig::new();
-        let env = EnvBasedTestDependencies::new(env_config).await;
-
-        let redis: Arc<dyn Redis + Send + Sync + 'static> = env.redis();
-        let redis_monitor: Arc<dyn RedisMonitor + Send + Sync + 'static> = env.redis_monitor();
+        let redis: Arc<dyn Redis> = Arc::new(SpawnedRedis::new(
+            6379,
+            "".to_string(),
+            Level::INFO,
+            Level::ERROR,
+        ));
+        let redis_monitor: Arc<dyn RedisMonitor> = Arc::new(SpawnedRedisMonitor::new(
+            redis.clone(),
+            Level::TRACE,
+            Level::ERROR,
+        ));
 
         let blob_storage = Arc::new(
             FileSystemBlobStorage::new(Path::new("data/blobs"))
@@ -169,6 +152,7 @@ impl WorkerExecutorTestDependencies {
         let component_directory = Path::new("../test-components").to_path_buf();
         let account_id = AccountId::generate();
         let project_id = ProjectId::new_v4();
+        let project_name = "default".to_string();
         let token = Uuid::new_v4();
         let component_service: Arc<dyn ComponentService> = Arc::new(
             FileSystemComponentService::new(
@@ -181,7 +165,10 @@ impl WorkerExecutorTestDependencies {
         );
 
         let cloud_service = Arc::new(AdminOnlyStubCloudService::new(
-            account_id, token, project_id,
+            account_id,
+            token,
+            project_id,
+            project_name,
         ));
 
         Self {
@@ -251,19 +238,8 @@ pub fn tracing() -> Tracing {
 }
 
 #[test_dep]
-pub async fn test_dependencies(_tracing: &Tracing) -> Deps {
-    let deps = WorkerExecutorTestDependencies::new().await;
-
-    let deps2 = TestDependenciesDsl {
-        deps,
-        account_id: AccountId {
-            value: "".to_string(),
-        },
-        account_email: "".to_string(),
-        token: Default::default(),
-    };
-
-    Deps(deps2)
+pub async fn test_dependencies(_tracing: &Tracing) -> WorkerExecutorTestDependencies {
+    WorkerExecutorTestDependencies::new().await
 }
 
 #[derive(Debug)]
diff --git a/golem-worker-executor/tests/measure_test_component_mem.rs b/golem-worker-executor/tests/measure_test_component_mem.rs
index 6c62a834..9849561e 100644
--- a/golem-worker-executor/tests/measure_test_component_mem.rs
+++ b/golem-worker-executor/tests/measure_test_component_mem.rs
@@ -1,8 +1,7 @@
 use test_r::{inherit_test_dep, test};
 
 use crate::common::{start, TestContext, TestWorkerExecutor};
-use crate::Deps;
-use crate::{LastUniqueId, Tracing};
+use crate::{LastUniqueId, Tracing, WorkerExecutorTestDependencies};
 use anyhow::anyhow;
 use golem_common::model::ComponentType;
 use golem_test_framework::config::{TestDependencies, TestDependenciesDsl};
@@ -19,16 +18,20 @@ use std::path::Path;
 use sysinfo::{Pid, ProcessesToUpdate, System};
 use tracing::{error, info};
 
-inherit_test_dep!(Deps);
+inherit_test_dep!(WorkerExecutorTestDependencies);
 inherit_test_dep!(LastUniqueId);
 inherit_test_dep!(Tracing);
 
 #[test]
 #[ignore]
-async fn measure(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn measure(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let mut system = System::new_all();
     let ctx = TestContext::new(last_unique_id);
-    let executor = start(deps, &ctx).await.unwrap().into_admin();
+    let executor = start(deps, &ctx).await.unwrap().into_admin().await;
 
     // collect
     let mut paths = Vec::new();
diff --git a/golem-worker-executor/tests/observability.rs b/golem-worker-executor/tests/observability.rs
index cc7b4851..43f2f9e9 100644
--- a/golem-worker-executor/tests/observability.rs
+++ b/golem-worker-executor/tests/observability.rs
@@ -13,8 +13,7 @@
 // limitations under the License.
 
 use crate::common::{start, TestContext};
-use crate::Deps;
-use crate::{LastUniqueId, Tracing};
+use crate::{LastUniqueId, Tracing, WorkerExecutorTestDependencies};
 use assert2::check;
 use axum::routing::post;
 use axum::{Json, Router};
@@ -26,7 +25,7 @@ use golem_common::model::public_oplog::{ExportedFunctionInvokedParameters, Publi
 use golem_common::model::{ComponentType, IdempotencyKey, WorkerId};
 use golem_test_framework::config::TestDependencies;
 use golem_test_framework::dsl::TestDslUnsafe;
-use golem_wasm_rpc::{IntoValueAndType, Value};
+use golem_wasm_rpc::{IntoValueAndType, Record, Value};
 use http::HeaderMap;
 use log::info;
 use std::collections::HashMap;
@@ -34,15 +33,19 @@ use std::sync::{Arc, Mutex};
 use test_r::{inherit_test_dep, test};
 use tracing::Instrument;
 
-inherit_test_dep!(Deps);
+inherit_test_dep!(WorkerExecutorTestDependencies);
 inherit_test_dep!(LastUniqueId);
 inherit_test_dep!(Tracing);
 
 #[test]
 #[tracing::instrument]
-async fn get_oplog_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn get_oplog_1(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("runtime-service").store().await;
 
@@ -56,7 +59,7 @@ async fn get_oplog_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Trac
 
     let _ = executor
         .invoke_and_await(
-            worker_id.clone(),
+            &worker_id,
             "golem:it/api.{generate-idempotency-keys}",
             vec![],
         )
@@ -64,7 +67,7 @@ async fn get_oplog_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Trac
         .unwrap();
     let _ = executor
         .invoke_and_await_with_key(
-            worker_id.clone(),
+            &worker_id,
             &idempotency_key1,
             "golem:it/api.{generate-idempotency-keys}",
             vec![],
@@ -73,7 +76,7 @@ async fn get_oplog_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Trac
         .unwrap();
     let _ = executor
         .invoke_and_await_with_key(
-            worker_id.clone(),
+            &worker_id,
             &idempotency_key2,
             "golem:it/api.{generate-idempotency-keys}",
             vec![],
@@ -111,9 +114,13 @@ async fn get_oplog_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Trac
 
 #[test]
 #[tracing::instrument]
-async fn search_oplog_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn search_oplog_1(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("shopping-cart").store().await;
 
@@ -134,12 +141,12 @@ async fn search_oplog_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &T
         .invoke_and_await(
             &worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1000".into_value_and_type()),
                 ("name", "Golem T-Shirt M".into_value_and_type()),
                 ("price", 100.0f32.into_value_and_type()),
                 ("quantity", 5u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -148,12 +155,12 @@ async fn search_oplog_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &T
         .invoke_and_await(
             &worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1001".into_value_and_type()),
                 ("name", "Golem Cloud Subscription 1y".into_value_and_type()),
                 ("price", 999999.0f32.into_value_and_type()),
                 ("quantity", 1u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -162,12 +169,12 @@ async fn search_oplog_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &T
         .invoke_and_await(
             &worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1002".into_value_and_type()),
                 ("name", "Mud Golem".into_value_and_type()),
                 ("price", 11.0f32.into_value_and_type()),
                 ("quantity", 10u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -209,11 +216,11 @@ async fn search_oplog_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &T
 #[tracing::instrument]
 async fn get_oplog_with_api_changing_updates(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("update-test-v1").unique().store().await;
     let worker_id = executor
@@ -259,11 +266,11 @@ async fn get_oplog_with_api_changing_updates(
 #[tracing::instrument]
 async fn get_oplog_starting_with_updated_component(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("update-test-v1").unique().store().await;
     let target_version = executor
@@ -288,9 +295,13 @@ async fn get_oplog_starting_with_updated_component(
 #[test]
 #[tracing::instrument]
 #[allow(clippy::await_holding_lock)]
-async fn invocation_context_test(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn invocation_context_test(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let listener = tokio::net::TcpListener::bind("0.0.0.0:0").await.unwrap();
     let host_http_port = listener.local_addr().unwrap().port();
@@ -343,7 +354,7 @@ async fn invocation_context_test(last_unique_id: &LastUniqueId, deps: &Deps, _tr
         .store()
         .await;
     let worker_id = executor
-        .start_worker_with(&component_id, "w1", vec![], env.clone())
+        .start_worker_with(&component_id, "w1", vec![], env.clone(), vec![])
         .await;
 
     let result = executor
diff --git a/golem-worker-executor/tests/rdbms.rs b/golem-worker-executor/tests/rdbms.rs
index 49d5375c..8b732f1a 100644
--- a/golem-worker-executor/tests/rdbms.rs
+++ b/golem-worker-executor/tests/rdbms.rs
@@ -12,15 +12,8 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use std::collections::HashMap;
-use std::fmt::Display;
-use std::time::Duration;
-use test_r::{inherit_test_dep, test, timeout};
-use tracing::Instrument;
-
-use crate::common::{mysql_host, postgres_host, start, TestContext};
-use crate::Deps;
-use crate::{LastUniqueId, Tracing};
+use crate::common::{start, TestContext};
+use crate::{LastUniqueId, Tracing, WorkerExecutorTestDependencies};
 use assert2::check;
 use golem_api_grpc::proto::golem::worker::v1::worker_error::Error;
 use golem_common::model::public_oplog::{
@@ -29,7 +22,8 @@ use golem_common::model::public_oplog::{
 };
 use golem_common::model::{ComponentId, IdempotencyKey, OplogIndex, WorkerId, WorkerStatus};
 use golem_service_base::model::PublicOplogEntryWithIndex;
-use golem_test_framework::components::rdb::RdbConnection;
+use golem_test_framework::components::rdb::docker_mysql::DockerMysqlRdb;
+use golem_test_framework::components::rdb::docker_postgres::DockerPostgresRdb;
 use golem_test_framework::config::TestDependencies;
 use golem_test_framework::dsl::TestDslUnsafe;
 use golem_wasm_ast::analysis::analysed_type;
@@ -38,14 +32,31 @@ use golem_worker_executor::services::rdbms::mysql::MysqlType;
 use golem_worker_executor::services::rdbms::postgres::PostgresType;
 use golem_worker_executor::services::rdbms::RdbmsType;
 use serde_json::json;
+use std::collections::HashMap;
+use std::fmt::Display;
+use std::time::Duration;
+use test_r::{inherit_test_dep, test, test_dep};
 use tokio::task::JoinSet;
+use tracing::Instrument;
 use try_match::try_match;
 use uuid::Uuid;
 
-inherit_test_dep!(Deps);
+inherit_test_dep!(WorkerExecutorTestDependencies);
 inherit_test_dep!(LastUniqueId);
 inherit_test_dep!(Tracing);
 
+#[test_dep]
+async fn postgres() -> DockerPostgresRdb {
+    let unique_network_id = Uuid::new_v4().to_string();
+    DockerPostgresRdb::new(&unique_network_id).await
+}
+
+#[test_dep]
+async fn mysql() -> DockerMysqlRdb {
+    let unique_network_id = Uuid::new_v4().to_string();
+    DockerMysqlRdb::new(&unique_network_id).await
+}
+
 #[repr(u8)]
 #[derive(Clone, Copy, Eq, PartialEq, Debug)]
 enum StatementAction {
@@ -168,17 +179,21 @@ impl RdbmsTest {
 }
 
 #[test]
-#[timeout(300_000)]
 #[tracing::instrument]
-async fn rdbms_postgres_crud(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
-    let postgres = postgres_host(None).await;
+async fn rdbms_postgres_crud(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    postgres: &DockerPostgresRdb,
+    _tracing: &Tracing,
+) {
     let db_address = postgres.public_connection_string();
 
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
     let component_id = executor.component("rdbms-service").store().await;
 
     let worker_ids1 = start_workers::<PostgresType>(&executor, &component_id, &db_address, 1).await;
+
     let worker_ids3 = start_workers::<PostgresType>(&executor, &component_id, &db_address, 3).await;
 
     let create_table_statement = r#"
@@ -305,18 +320,17 @@ async fn rdbms_postgres_crud(last_unique_id: &LastUniqueId, deps: &Deps, _tracin
 }
 
 #[test]
-#[timeout(300_000)]
 #[tracing::instrument]
 async fn rdbms_postgres_idempotency(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
+    postgres: &DockerPostgresRdb,
     _tracing: &Tracing,
 ) {
-    let postgres = postgres_host(None).await;
     let db_address = postgres.public_connection_string();
 
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
     let component_id = executor.component("rdbms-service").store().await;
 
     let worker_ids = start_workers::<PostgresType>(&executor, &component_id, &db_address, 1).await;
@@ -512,10 +526,13 @@ fn postgres_get_expected(expected_values: Vec<(Uuid, String, String)>) -> serde_
 }
 
 #[test]
-#[timeout(300_000)]
 #[tracing::instrument]
-async fn rdbms_postgres_select1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
-    let postgres = postgres_host(None).await;
+async fn rdbms_postgres_select1(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    postgres: &DockerPostgresRdb,
+    _tracing: &Tracing,
+) {
     let test1 = StatementTest::execute_test("SELECT 1", vec![], Some(1));
 
     let expected_rows: Vec<serde_json::Value> = vec![json!({
@@ -548,14 +565,17 @@ async fn rdbms_postgres_select1(last_unique_id: &LastUniqueId, deps: &Deps, _tra
 }
 
 #[test]
-#[timeout(300_000)]
 #[tracing::instrument]
-async fn rdbms_mysql_crud(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
-    let mysql = mysql_host(None).await;
+async fn rdbms_mysql_crud(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    mysql: &DockerMysqlRdb,
+    _tracing: &Tracing,
+) {
     let db_address = mysql.public_connection_string();
 
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
     let component_id = executor.component("rdbms-service").store().await;
 
     let worker_ids1 = start_workers::<MysqlType>(&executor, &component_id, &db_address, 1).await;
@@ -688,14 +708,17 @@ async fn rdbms_mysql_crud(last_unique_id: &LastUniqueId, deps: &Deps, _tracing:
 }
 
 #[test]
-#[timeout(300_000)]
 #[tracing::instrument]
-async fn rdbms_mysql_idempotency(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
-    let mysql = mysql_host(None).await;
+async fn rdbms_mysql_idempotency(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    mysql: &DockerMysqlRdb,
+    _tracing: &Tracing,
+) {
     let db_address = mysql.public_connection_string();
 
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
     let component_id = executor.component("rdbms-service").store().await;
 
     let worker_ids = start_workers::<MysqlType>(&executor, &component_id, &db_address, 1).await;
@@ -873,10 +896,13 @@ fn mysql_get_expected(expected_values: Vec<(String, String)>) -> serde_json::Val
 }
 
 #[test]
-#[timeout(300_000)]
 #[tracing::instrument]
-async fn rdbms_mysql_select1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
-    let mysql = mysql_host(None).await;
+async fn rdbms_mysql_select1(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    mysql: &DockerMysqlRdb,
+    _tracing: &Tracing,
+) {
     let test1 = StatementTest::execute_test("SELECT 1", vec![], Some(0));
 
     let expected_rows: Vec<serde_json::Value> = vec![json!({
@@ -910,13 +936,13 @@ async fn rdbms_mysql_select1(last_unique_id: &LastUniqueId, deps: &Deps, _tracin
 
 async fn rdbms_component_test<T: RdbmsType>(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     db_address: &str,
     test: RdbmsTest,
     n_workers: u8,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
     let component_id = executor.component("rdbms-service").store().await;
     let worker_ids = start_workers::<T>(&executor, &component_id, db_address, n_workers).await;
 
@@ -1085,7 +1111,7 @@ async fn start_workers<T: RdbmsType>(
     for _ in 0..n_workers {
         let worker_name = format!("rdbms-service-{}-{}", db_type, Uuid::new_v4());
         let worker_id = executor
-            .start_worker_with(component_id, &worker_name, vec![], env.clone())
+            .start_worker_with(component_id, &worker_name, vec![], env.clone(), vec![])
             .await;
         worker_ids.push(worker_id.clone());
         let _result = executor
@@ -1214,7 +1240,7 @@ fn check_transaction_oplog_entries<T: RdbmsType>(entries: Vec<PublicOplogEntryWi
                     || v.function_name.starts_with(fn_prefix3.as_str())
             );
             check!(
-                v.wrapped_function_type
+                v.durable_function_type
                     == PublicDurableFunctionType::WriteRemoteBatched(
                         WriteRemoteBatchedParameters {
                             index: Some(end_entry.begin_index)
diff --git a/golem-worker-executor/tests/rdbms_service.rs b/golem-worker-executor/tests/rdbms_service.rs
index b5c1b3b0..a1c3f91a 100644
--- a/golem-worker-executor/tests/rdbms_service.rs
+++ b/golem-worker-executor/tests/rdbms_service.rs
@@ -12,12 +12,12 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use crate::common::{mysql_host, new_worker_id, postgres_host};
 use assert2::check;
 use bigdecimal::BigDecimal;
 use bit_vec::BitVec;
-use golem_common::model::WorkerId;
-use golem_test_framework::components::rdb::RdbConnection;
+use golem_common::model::{ComponentId, WorkerId};
+use golem_test_framework::components::rdb::docker_mysql::DockerMysqlRdb;
+use golem_test_framework::components::rdb::docker_postgres::DockerPostgresRdb;
 use golem_worker_executor::services::golem_config::{RdbmsConfig, RdbmsPoolConfig};
 use golem_worker_executor::services::rdbms::mysql::{types as mysql_types, MysqlType};
 use golem_worker_executor::services::rdbms::postgres::{types as postgres_types, PostgresType};
@@ -31,11 +31,23 @@ use std::fmt::Debug;
 use std::net::{IpAddr, Ipv4Addr, Ipv6Addr};
 use std::str::FromStr;
 use std::sync::Arc;
-use test_r::{test, test_dep, timeout};
+use test_r::{test, test_dep};
 use tokio::task::JoinSet;
 use tracing::{info, Instrument};
 use uuid::Uuid;
 
+#[test_dep]
+async fn postgres() -> DockerPostgresRdb {
+    let unique_network_id = Uuid::new_v4().to_string();
+    DockerPostgresRdb::new(&unique_network_id).await
+}
+
+#[test_dep]
+async fn mysql() -> DockerMysqlRdb {
+    let unique_network_id = Uuid::new_v4().to_string();
+    DockerMysqlRdb::new(&unique_network_id).await
+}
+
 #[test_dep]
 fn rdbms_service() -> RdbmsServiceDefault {
     RdbmsServiceDefault::new(RdbmsConfig {
@@ -194,9 +206,10 @@ impl<T: RdbmsType + Clone> RdbmsTest<T> {
 }
 
 #[test]
-#[timeout(300_000)]
-async fn postgres_transaction_tests(rdbms_service: &RdbmsServiceDefault) {
-    let postgres = postgres_host(Some(rdbms_service.postgres().clone())).await;
+async fn postgres_transaction_tests(
+    postgres: &DockerPostgresRdb,
+    rdbms_service: &RdbmsServiceDefault,
+) {
     let db_address = postgres.public_connection_string();
     let rdbms = rdbms_service.postgres();
 
@@ -313,9 +326,10 @@ async fn postgres_transaction_tests(rdbms_service: &RdbmsServiceDefault) {
 }
 
 #[test]
-#[timeout(300_000)]
-async fn postgres_create_insert_select_test(rdbms_service: &RdbmsServiceDefault) {
-    let postgres = postgres_host(Some(rdbms_service.postgres().clone())).await;
+async fn postgres_create_insert_select_test(
+    postgres: &DockerPostgresRdb,
+    rdbms_service: &RdbmsServiceDefault,
+) {
     let db_address = postgres.public_connection_string();
     let rdbms = rdbms_service.postgres();
 
@@ -968,9 +982,10 @@ async fn postgres_create_insert_select_test(rdbms_service: &RdbmsServiceDefault)
 }
 
 #[test]
-#[timeout(300_000)]
-async fn postgres_create_insert_select_array_test(rdbms_service: &RdbmsServiceDefault) {
-    let postgres = postgres_host(Some(rdbms_service.postgres().clone())).await;
+async fn postgres_create_insert_select_array_test(
+    postgres: &DockerPostgresRdb,
+    rdbms_service: &RdbmsServiceDefault,
+) {
     let db_address = postgres.public_connection_string();
     let rdbms = rdbms_service.postgres();
 
@@ -1839,9 +1854,7 @@ async fn postgres_create_insert_select_array_test(rdbms_service: &RdbmsServiceDe
 }
 
 #[test]
-#[timeout(300_000)]
-async fn postgres_schema_test(rdbms_service: &RdbmsServiceDefault) {
-    let postgres = postgres_host(Some(rdbms_service.postgres().clone())).await;
+async fn postgres_schema_test(postgres: &DockerPostgresRdb, rdbms_service: &RdbmsServiceDefault) {
     let rdbms = rdbms_service.postgres();
     let db_address = postgres.public_connection_string();
 
@@ -1874,9 +1887,7 @@ async fn postgres_schema_test(rdbms_service: &RdbmsServiceDefault) {
 }
 
 #[test]
-#[timeout(300_000)]
-async fn mysql_transaction_tests(rdbms_service: &RdbmsServiceDefault) {
-    let mysql = mysql_host(Some(rdbms_service.mysql().clone())).await;
+async fn mysql_transaction_tests(mysql: &DockerMysqlRdb, rdbms_service: &RdbmsServiceDefault) {
     let db_address = mysql.public_connection_string();
     let rdbms = rdbms_service.mysql();
 
@@ -1989,9 +2000,10 @@ async fn mysql_transaction_tests(rdbms_service: &RdbmsServiceDefault) {
 }
 
 #[test]
-#[timeout(300_000)]
-async fn mysql_create_insert_select_test(rdbms_service: &RdbmsServiceDefault) {
-    let mysql = mysql_host(Some(rdbms_service.mysql().clone())).await;
+async fn mysql_create_insert_select_test(
+    mysql: &DockerMysqlRdb,
+    rdbms_service: &RdbmsServiceDefault,
+) {
     let db_address = mysql.public_connection_string();
     let rdbms = rdbms_service.mysql();
     let create_table_statement = r#"
@@ -2584,7 +2596,6 @@ fn check_test_results<T: RdbmsType + Clone>(
 }
 
 #[test]
-#[timeout(300_000)]
 async fn postgres_connection_err_test(rdbms_service: &RdbmsServiceDefault) {
     rdbms_connection_err_test(
         rdbms_service.postgres(),
@@ -2602,9 +2613,10 @@ async fn postgres_connection_err_test(rdbms_service: &RdbmsServiceDefault) {
 }
 
 #[test]
-#[timeout(300_000)]
-async fn postgres_query_err_test(rdbms_service: &RdbmsServiceDefault) {
-    let postgres = postgres_host(Some(rdbms_service.postgres().clone())).await;
+async fn postgres_query_err_test(
+    postgres: &DockerPostgresRdb,
+    rdbms_service: &RdbmsServiceDefault,
+) {
     let db_address = postgres.public_connection_string();
     let rdbms = rdbms_service.postgres();
 
@@ -2643,9 +2655,10 @@ async fn postgres_query_err_test(rdbms_service: &RdbmsServiceDefault) {
 }
 
 #[test]
-#[timeout(300_000)]
-async fn postgres_execute_err_test(rdbms_service: &RdbmsServiceDefault) {
-    let postgres = postgres_host(Some(rdbms_service.postgres().clone())).await;
+async fn postgres_execute_err_test(
+    postgres: &DockerPostgresRdb,
+    rdbms_service: &RdbmsServiceDefault,
+) {
     let db_address = postgres.public_connection_string();
     let rdbms = rdbms_service.postgres();
 
@@ -2676,9 +2689,7 @@ async fn postgres_execute_err_test(rdbms_service: &RdbmsServiceDefault) {
 }
 
 #[test]
-#[timeout(300_000)]
-async fn mysql_query_err_test(rdbms_service: &RdbmsServiceDefault) {
-    let mysql = mysql_host(Some(rdbms_service.mysql().clone())).await;
+async fn mysql_query_err_test(mysql: &DockerMysqlRdb, rdbms_service: &RdbmsServiceDefault) {
     let db_address = mysql.public_connection_string();
     let rdbms = rdbms_service.mysql();
 
@@ -2705,9 +2716,7 @@ async fn mysql_query_err_test(rdbms_service: &RdbmsServiceDefault) {
 }
 
 #[test]
-#[timeout(300_000)]
-async fn mysql_execute_err_test(rdbms_service: &RdbmsServiceDefault) {
-    let mysql = mysql_host(Some(rdbms_service.mysql().clone())).await;
+async fn mysql_execute_err_test(mysql: &DockerMysqlRdb, rdbms_service: &RdbmsServiceDefault) {
     let db_address = mysql.public_connection_string();
     let rdbms = rdbms_service.mysql();
 
@@ -2725,7 +2734,6 @@ async fn mysql_execute_err_test(rdbms_service: &RdbmsServiceDefault) {
 }
 
 #[test]
-#[timeout(300_000)]
 async fn mysql_connection_err_test(rdbms_service: &RdbmsServiceDefault) {
     rdbms_connection_err_test(
         rdbms_service.mysql(),
@@ -2826,8 +2834,7 @@ async fn rdbms_execute_err_test<T: RdbmsType>(
 }
 
 #[test]
-#[timeout(300_000)]
-async fn test_rdbms_pool_key_masked_address() {
+fn test_rdbms_pool_key_masked_address() {
     let key = RdbmsPoolKey::from("mysql://user:password@localhost:3306").unwrap();
     check!(key.masked_address() == "mysql://user:*****@localhost:3306");
     let key = RdbmsPoolKey::from("mysql://user@localhost:3306").unwrap();
@@ -2843,9 +2850,7 @@ async fn test_rdbms_pool_key_masked_address() {
 }
 
 #[test]
-#[timeout(300_000)]
-async fn mysql_par_test(rdbms_service: &RdbmsServiceDefault) {
-    let mysql = mysql_host(Some(rdbms_service.mysql().clone())).await;
+async fn mysql_par_test(mysql: &DockerMysqlRdb, rdbms_service: &RdbmsServiceDefault) {
     let db_address = mysql.public_connection_string();
     let rdbms = rdbms_service.mysql();
     let mut db_addresses = create_test_databases(rdbms.clone(), &db_address, 3, |db_name| {
@@ -2867,9 +2872,7 @@ async fn mysql_par_test(rdbms_service: &RdbmsServiceDefault) {
 }
 
 #[test]
-#[timeout(60_000)]
-async fn postgres_par_test(rdbms_service: &RdbmsServiceDefault) {
-    let postgres = postgres_host(Some(rdbms_service.postgres().clone())).await;
+async fn postgres_par_test(postgres: &DockerPostgresRdb, rdbms_service: &RdbmsServiceDefault) {
     let db_address = postgres.public_connection_string();
     let rdbms = rdbms_service.postgres();
     let mut db_addresses = create_test_databases(rdbms.clone(), &db_address, 3, |db_name| {
@@ -2989,3 +2992,10 @@ async fn rdbms_par_test<T: RdbmsType + Clone + 'static>(
         check_test_results(&worker_id, test.clone(), result);
     }
 }
+
+fn new_worker_id() -> WorkerId {
+    WorkerId {
+        component_id: ComponentId::new_v4(),
+        worker_name: "test".to_string(),
+    }
+}
diff --git a/golem-worker-executor/tests/revert.rs b/golem-worker-executor/tests/revert.rs
index 8642c4a4..cd4ff891 100644
--- a/golem-worker-executor/tests/revert.rs
+++ b/golem-worker-executor/tests/revert.rs
@@ -13,19 +13,21 @@
 // limitations under the License.
 
 use crate::common::{start, TestContext};
-use crate::Deps;
-use crate::{LastUniqueId, Tracing};
+use crate::{LastUniqueId, Tracing, WorkerExecutorTestDependencies};
 use assert2::check;
 use golem_common::model::OplogIndex;
 use golem_service_base::model::{RevertLastInvocations, RevertToOplogIndex, RevertWorkerTarget};
 use golem_test_framework::config::TestDependencies;
 use golem_test_framework::dsl::TestDslUnsafe;
-use golem_wasm_rpc::{IntoValue, IntoValueAndType};
+use golem_wasm_ast::analysis::{
+    AnalysedResourceId, AnalysedResourceMode, AnalysedType, TypeHandle,
+};
+use golem_wasm_rpc::{IntoValue, IntoValueAndType, ValueAndType};
 use log::info;
 use std::collections::HashMap;
 use test_r::{inherit_test_dep, test};
 
-inherit_test_dep!(Deps);
+inherit_test_dep!(WorkerExecutorTestDependencies);
 inherit_test_dep!(LastUniqueId);
 inherit_test_dep!(Tracing);
 
@@ -33,11 +35,11 @@ inherit_test_dep!(Tracing);
 #[tracing::instrument]
 async fn revert_successful_invocations(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("counters").store().await;
     let worker_id = executor
@@ -45,11 +47,36 @@ async fn revert_successful_invocations(
         .await;
     executor.log_output(&worker_id).await;
 
+    let counter1 = executor
+        .invoke_and_await(
+            &worker_id,
+            "rpc:counters-exports/api.{[constructor]counter}",
+            vec!["counter1".into_value_and_type()],
+        )
+        .await
+        .unwrap();
+    let counter2 = executor
+        .invoke_and_await(
+            &worker_id,
+            "rpc:counters-exports/api.{[constructor]counter}",
+            vec!["counter2".into_value_and_type()],
+        )
+        .await
+        .unwrap();
+    let counter_handle_type = AnalysedType::Handle(TypeHandle {
+        name: None,
+        owner: None,
+        resource_id: AnalysedResourceId(0),
+        mode: AnalysedResourceMode::Borrowed,
+    });
+    let counter_ref1 = ValueAndType::new(counter1[0].clone(), counter_handle_type.clone());
+    let counter_ref2 = ValueAndType::new(counter2[0].clone(), counter_handle_type);
+
     let _ = executor
         .invoke_and_await(
             &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter1\").inc-by}",
-            vec![5u64.into_value_and_type()],
+            "rpc:counters-exports/api.{[method]counter.inc-by}",
+            vec![counter_ref1.clone(), 5u64.into_value_and_type()],
         )
         .await
         .unwrap();
@@ -57,16 +84,16 @@ async fn revert_successful_invocations(
     let _ = executor
         .invoke_and_await(
             &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter2\").inc-by}",
-            vec![1u64.into_value_and_type()],
+            "rpc:counters-exports/api.{[method]counter.inc-by}",
+            vec![counter_ref2.clone(), 1u64.into_value_and_type()],
         )
         .await
         .unwrap();
     let _ = executor
         .invoke_and_await(
             &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter2\").inc-by}",
-            vec![2u64.into_value_and_type()],
+            "rpc:counters-exports/api.{[method]counter.inc-by}",
+            vec![counter_ref2.clone(), 2u64.into_value_and_type()],
         )
         .await
         .unwrap();
@@ -74,16 +101,16 @@ async fn revert_successful_invocations(
     let result1 = executor
         .invoke_and_await(
             &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter1\").get-value}",
-            vec![],
+            "rpc:counters-exports/api.{[method]counter.get-value}",
+            vec![counter_ref1.clone()],
         )
         .await
         .unwrap();
     let result2 = executor
         .invoke_and_await(
             &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter2\").get-value}",
-            vec![],
+            "rpc:counters-exports/api.{[method]counter.get-value}",
+            vec![counter_ref2.clone()],
         )
         .await
         .unwrap();
@@ -100,16 +127,16 @@ async fn revert_successful_invocations(
     let result3 = executor
         .invoke_and_await(
             &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter1\").get-value}",
-            vec![],
+            "rpc:counters-exports/api.{[method]counter.get-value}",
+            vec![counter_ref1.clone()],
         )
         .await
         .unwrap();
     let result4 = executor
         .invoke_and_await(
             &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter2\").get-value}",
-            vec![],
+            "rpc:counters-exports/api.{[method]counter.get-value}",
+            vec![counter_ref2.clone()],
         )
         .await
         .unwrap();
@@ -126,9 +153,13 @@ async fn revert_successful_invocations(
 
 #[test]
 #[tracing::instrument]
-async fn revert_failed_worker(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn revert_failed_worker(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("failing-component").store().await;
     let worker_id = executor
@@ -180,9 +211,13 @@ async fn revert_failed_worker(last_unique_id: &LastUniqueId, deps: &Deps, _traci
 
 #[test]
 #[tracing::instrument]
-async fn revert_auto_update(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn revert_auto_update(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("update-test-v1").unique().store().await;
     let worker_id = executor
@@ -191,7 +226,7 @@ async fn revert_auto_update(last_unique_id: &LastUniqueId, deps: &Deps, _tracing
     let _ = executor.log_output(&worker_id).await;
 
     let target_version = executor
-        .update_component(&component_id, "update-test-v2")
+        .update_component(&component_id, "update-test-v2-11")
         .await;
     info!("Updated component to version {target_version}");
 
@@ -236,22 +271,30 @@ async fn revert_auto_update(last_unique_id: &LastUniqueId, deps: &Deps, _tracing
 
 #[test]
 #[tracing::instrument]
-async fn revert_manual_update(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn revert_manual_update(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let http_server = crate::hot_update::TestHttpServer::start().await;
     let mut env = HashMap::new();
     env.insert("PORT".to_string(), http_server.port().to_string());
 
-    let component_id = executor.component("update-test-v2").unique().store().await;
+    let component_id = executor
+        .component("update-test-v2-11")
+        .unique()
+        .store()
+        .await;
     let worker_id = executor
-        .start_worker_with(&component_id, "revert_manual_update", vec![], env)
+        .start_worker_with(&component_id, "revert_manual_update", vec![], env, vec![])
         .await;
     let _ = executor.log_output(&worker_id).await;
 
     let target_version = executor
-        .update_component(&component_id, "update-test-v3")
+        .update_component(&component_id, "update-test-v3-11")
         .await;
     info!("Updated component to version {target_version}");
 
diff --git a/golem-worker-executor/tests/rust_rpc.rs b/golem-worker-executor/tests/rust_rpc.rs
index 1cc26fe9..a2b714e0 100644
--- a/golem-worker-executor/tests/rust_rpc.rs
+++ b/golem-worker-executor/tests/rust_rpc.rs
@@ -13,11 +13,10 @@
 // limitations under the License.
 
 use crate::common::{start, TestContext};
-use crate::Deps;
-use crate::{LastUniqueId, Tracing};
+use crate::{LastUniqueId, Tracing, WorkerExecutorTestDependencies};
 use assert2::check;
 use golem_test_framework::config::TestDependencies;
-use golem_test_framework::dsl::{worker_error_logs, TestDslUnsafe};
+use golem_test_framework::dsl::TestDslUnsafe;
 use golem_wasm_ast::analysis::analysed_type;
 use golem_wasm_rpc::{IntoValueAndType, Value, ValueAndType};
 use std::collections::HashMap;
@@ -25,15 +24,19 @@ use std::time::SystemTime;
 use test_r::{inherit_test_dep, test};
 use tracing::info;
 
-inherit_test_dep!(Deps);
+inherit_test_dep!(WorkerExecutorTestDependencies);
 inherit_test_dep!(LastUniqueId);
 inherit_test_dep!(Tracing);
 
 #[test]
 #[tracing::instrument]
-async fn auction_example_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn auction_example_1(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let registry_component_id = executor
         .component("auction_registry_composed")
@@ -47,7 +50,13 @@ async fn auction_example_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing:
         auction_component_id.to_string(),
     );
     let registry_worker_id = executor
-        .start_worker_with(&registry_component_id, "auction-registry-1", vec![], env)
+        .start_worker_with(
+            &registry_component_id,
+            "auction-registry-1",
+            vec![],
+            env,
+            vec![],
+        )
         .await;
 
     let _ = executor.log_output(&registry_worker_id).await;
@@ -101,9 +110,13 @@ async fn auction_example_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing:
 
 #[test]
 #[tracing::instrument]
-async fn auction_example_2(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn auction_example_2(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let registry_component_id = executor
         .component("auction_registry_composed")
@@ -117,7 +130,13 @@ async fn auction_example_2(last_unique_id: &LastUniqueId, deps: &Deps, _tracing:
         auction_component_id.to_string(),
     );
     let registry_worker_id = executor
-        .start_worker_with(&registry_component_id, "auction-registry-2", vec![], env)
+        .start_worker_with(
+            &registry_component_id,
+            "auction-registry-2",
+            vec![],
+            env,
+            vec![],
+        )
         .await;
 
     let _ = executor.log_output(&registry_worker_id).await;
@@ -171,9 +190,13 @@ async fn auction_example_2(last_unique_id: &LastUniqueId, deps: &Deps, _tracing:
 
 #[test]
 #[tracing::instrument]
-async fn counter_resource_test_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn counter_resource_test_1(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let counters_component_id = executor.component("counters").store().await;
     let caller_component_id = executor.component("caller_composed").store().await;
@@ -184,7 +207,7 @@ async fn counter_resource_test_1(last_unique_id: &LastUniqueId, deps: &Deps, _tr
         counters_component_id.to_string(),
     );
     let caller_worker_id = executor
-        .start_worker_with(&caller_component_id, "rpc-counters-1", vec![], env)
+        .start_worker_with(&caller_component_id, "rpc-counters-1", vec![], env, vec![])
         .await;
 
     let result = executor
@@ -211,9 +234,13 @@ async fn counter_resource_test_1(last_unique_id: &LastUniqueId, deps: &Deps, _tr
 
 #[test]
 #[tracing::instrument]
-async fn counter_resource_test_2(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn counter_resource_test_2(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let counters_component_id = executor.component("counters").store().await;
     let caller_component_id = executor.component("caller_composed").store().await;
@@ -224,7 +251,7 @@ async fn counter_resource_test_2(last_unique_id: &LastUniqueId, deps: &Deps, _tr
         counters_component_id.to_string(),
     );
     let caller_worker_id = executor
-        .start_worker_with(&caller_component_id, "rpc-counters-2", vec![], env)
+        .start_worker_with(&caller_component_id, "rpc-counters-2", vec![], env, vec![])
         .await;
 
     let result1 = executor
@@ -254,11 +281,11 @@ async fn counter_resource_test_2(last_unique_id: &LastUniqueId, deps: &Deps, _tr
 #[tracing::instrument]
 async fn counter_resource_test_2_with_restart(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let counters_component_id = executor.component("counters").store().await;
     let caller_component_id = executor.component("caller_composed").store().await;
@@ -269,7 +296,7 @@ async fn counter_resource_test_2_with_restart(
         counters_component_id.to_string(),
     );
     let caller_worker_id = executor
-        .start_worker_with(&caller_component_id, "rpc-counters-2r", vec![], env)
+        .start_worker_with(&caller_component_id, "rpc-counters-2r", vec![], env, vec![])
         .await;
 
     let result1 = executor
@@ -281,7 +308,7 @@ async fn counter_resource_test_2_with_restart(
         .await;
 
     drop(executor);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let result2 = executor
         .invoke_and_await(
@@ -301,9 +328,13 @@ async fn counter_resource_test_2_with_restart(
 
 #[test]
 #[tracing::instrument]
-async fn counter_resource_test_3(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn counter_resource_test_3(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let counters_component_id = executor.component("counters").store().await;
     let caller_component_id = executor.component("caller_composed").store().await;
@@ -314,7 +345,7 @@ async fn counter_resource_test_3(last_unique_id: &LastUniqueId, deps: &Deps, _tr
         counters_component_id.to_string(),
     );
     let caller_worker_id = executor
-        .start_worker_with(&caller_component_id, "rpc-counters-3", vec![], env)
+        .start_worker_with(&caller_component_id, "rpc-counters-3", vec![], env, vec![])
         .await;
 
     let result1 = executor
@@ -344,11 +375,11 @@ async fn counter_resource_test_3(last_unique_id: &LastUniqueId, deps: &Deps, _tr
 #[tracing::instrument]
 async fn counter_resource_test_3_with_restart(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let counters_component_id = executor.component("counters").store().await;
     let caller_component_id = executor.component("caller_composed").store().await;
@@ -359,7 +390,7 @@ async fn counter_resource_test_3_with_restart(
         counters_component_id.to_string(),
     );
     let caller_worker_id = executor
-        .start_worker_with(&caller_component_id, "rpc-counters-3r", vec![], env)
+        .start_worker_with(&caller_component_id, "rpc-counters-3r", vec![], env, vec![])
         .await;
 
     let result1 = executor
@@ -371,7 +402,7 @@ async fn counter_resource_test_3_with_restart(
         .await;
 
     drop(executor);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let result2 = executor
         .invoke_and_await(
@@ -391,9 +422,13 @@ async fn counter_resource_test_3_with_restart(
 
 #[test]
 #[tracing::instrument]
-async fn context_inheritance(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn context_inheritance(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let counters_component_id = executor.component("counters").store().await;
     let caller_component_id = executor.component("caller_composed").store().await;
@@ -410,6 +445,7 @@ async fn context_inheritance(last_unique_id: &LastUniqueId, deps: &Deps, _tracin
             "rpc-counters-4",
             vec!["a".to_string(), "b".to_string(), "c".to_string()],
             env,
+            vec![],
         )
         .await;
 
@@ -479,9 +515,13 @@ async fn context_inheritance(last_unique_id: &LastUniqueId, deps: &Deps, _tracin
 
 #[test]
 #[tracing::instrument]
-async fn counter_resource_test_5(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn counter_resource_test_5(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let counters_component_id = executor.component("counters").store().await;
     let caller_component_id = executor.component("caller_composed").store().await;
@@ -492,7 +532,7 @@ async fn counter_resource_test_5(last_unique_id: &LastUniqueId, deps: &Deps, _tr
         counters_component_id.to_string(),
     );
     let caller_worker_id = executor
-        .start_worker_with(&caller_component_id, "rpc-counters-5", vec![], env)
+        .start_worker_with(&caller_component_id, "rpc-counters-5", vec![], env, vec![])
         .await;
 
     executor.log_output(&caller_worker_id).await;
@@ -523,11 +563,11 @@ async fn counter_resource_test_5(last_unique_id: &LastUniqueId, deps: &Deps, _tr
 #[tracing::instrument]
 async fn counter_resource_test_5_with_restart(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     // using store_unique_component to avoid collision with counter_resource_test_5
     let counters_component_id = executor.component("counters").unique().store().await;
@@ -539,7 +579,7 @@ async fn counter_resource_test_5_with_restart(
         counters_component_id.to_string(),
     );
     let caller_worker_id = executor
-        .start_worker_with(&caller_component_id, "rpc-counters-5r", vec![], env)
+        .start_worker_with(&caller_component_id, "rpc-counters-5r", vec![], env, vec![])
         .await;
 
     executor.log_output(&caller_worker_id).await;
@@ -554,7 +594,7 @@ async fn counter_resource_test_5_with_restart(
 
     drop(executor);
 
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let result2 = executor
         .invoke_and_await(
@@ -589,9 +629,13 @@ async fn counter_resource_test_5_with_restart(
 
 #[test]
 #[tracing::instrument]
-async fn wasm_rpc_bug_32_test(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn wasm_rpc_bug_32_test(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let counters_component_id = executor.component("counters").store().await;
     let caller_component_id = executor.component("caller_composed").store().await;
@@ -602,7 +646,13 @@ async fn wasm_rpc_bug_32_test(last_unique_id: &LastUniqueId, deps: &Deps, _traci
         counters_component_id.to_string(),
     );
     let caller_worker_id = executor
-        .start_worker_with(&caller_component_id, "rpc-counters-bug32", vec![], env)
+        .start_worker_with(
+            &caller_component_id,
+            "rpc-counters-bug32",
+            vec![],
+            env,
+            vec![],
+        )
         .await;
 
     let result = executor
@@ -636,11 +686,11 @@ async fn wasm_rpc_bug_32_test(last_unique_id: &LastUniqueId, deps: &Deps, _traci
 #[tracing::instrument]
 async fn error_message_non_existing_target_component(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let registry_component_id = executor
         .component("auction_registry_composed")
@@ -658,6 +708,7 @@ async fn error_message_non_existing_target_component(
             "auction-registry-non-existing-target",
             vec![],
             env,
+            vec![],
         )
         .await;
 
@@ -684,20 +735,19 @@ async fn error_message_non_existing_target_component(
 
     drop(executor);
 
-    assert!(
-        matches!(worker_error_logs(&create_auction_result.err().unwrap()), Some(logs) if logs.contains("Could not find any component with the given id"))
-    );
+    assert!(format!("{:?}", create_auction_result.err().unwrap())
+        .contains("Could not find any component with the given id"));
 }
 
 #[test]
 #[tracing::instrument]
 async fn ephemeral_worker_invocation_via_rpc1(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let ephemeral_component_id = executor.component("ephemeral").ephemeral().store().await;
     let caller_component_id = executor.component("caller_composed").store().await;
@@ -708,7 +758,7 @@ async fn ephemeral_worker_invocation_via_rpc1(
         ephemeral_component_id.to_string(),
     );
     let caller_worker_id = executor
-        .start_worker_with(&caller_component_id, "rpc-ephemeral-1", vec![], env)
+        .start_worker_with(&caller_component_id, "rpc-ephemeral-1", vec![], env, vec![])
         .await;
 
     let result = executor
diff --git a/golem-worker-executor/tests/rust_rpc_stubless.rs b/golem-worker-executor/tests/rust_rpc_stubless.rs
index 2bddd934..0f6412b7 100644
--- a/golem-worker-executor/tests/rust_rpc_stubless.rs
+++ b/golem-worker-executor/tests/rust_rpc_stubless.rs
@@ -15,8 +15,7 @@
 use test_r::{inherit_test_dep, test};
 
 use crate::common::{start, TestContext};
-use crate::Deps;
-use crate::{LastUniqueId, Tracing};
+use crate::{LastUniqueId, Tracing, WorkerExecutorTestDependencies};
 use assert2::check;
 use golem_common::model::component_metadata::{
     DynamicLinkedInstance, DynamicLinkedWasmRpc, WasmRpcTarget,
@@ -31,15 +30,19 @@ use std::collections::HashMap;
 use std::time::SystemTime;
 use tracing::info;
 
-inherit_test_dep!(Deps);
+inherit_test_dep!(WorkerExecutorTestDependencies);
 inherit_test_dep!(LastUniqueId);
 inherit_test_dep!(Tracing);
 
 #[test]
 #[tracing::instrument]
-async fn auction_example_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn auction_example_1(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let registry_component_id = executor
         .component("auction_registry")
@@ -76,7 +79,13 @@ async fn auction_example_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing:
         auction_component_id.to_string(),
     );
     let registry_worker_id = executor
-        .start_worker_with(&registry_component_id, "auction-registry-1", vec![], env)
+        .start_worker_with(
+            &registry_component_id,
+            "auction-registry-1",
+            vec![],
+            env,
+            vec![],
+        )
         .await;
 
     let _ = executor.log_output(&registry_worker_id).await;
@@ -130,9 +139,13 @@ async fn auction_example_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing:
 
 #[test]
 #[tracing::instrument]
-async fn auction_example_2(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn auction_example_2(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let registry_component_id = executor
         .component("auction_registry")
@@ -169,7 +182,13 @@ async fn auction_example_2(last_unique_id: &LastUniqueId, deps: &Deps, _tracing:
         auction_component_id.to_string(),
     );
     let registry_worker_id = executor
-        .start_worker_with(&registry_component_id, "auction-registry-2", vec![], env)
+        .start_worker_with(
+            &registry_component_id,
+            "auction-registry-2",
+            vec![],
+            env,
+            vec![],
+        )
         .await;
 
     let _ = executor.log_output(&registry_worker_id).await;
@@ -223,9 +242,13 @@ async fn auction_example_2(last_unique_id: &LastUniqueId, deps: &Deps, _tracing:
 
 #[test]
 #[tracing::instrument]
-async fn counter_resource_test_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn counter_resource_test_1(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let counters_component_id = executor.component("counters").store().await;
     let caller_component_id = executor
@@ -277,7 +300,7 @@ async fn counter_resource_test_1(last_unique_id: &LastUniqueId, deps: &Deps, _tr
         counters_component_id.to_string(),
     );
     let caller_worker_id = executor
-        .start_worker_with(&caller_component_id, "rpc-counters-1", vec![], env)
+        .start_worker_with(&caller_component_id, "rpc-counters-1", vec![], env, vec![])
         .await;
 
     let result = executor
@@ -304,9 +327,13 @@ async fn counter_resource_test_1(last_unique_id: &LastUniqueId, deps: &Deps, _tr
 
 #[test]
 #[tracing::instrument]
-async fn counter_resource_test_2(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn counter_resource_test_2(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let counters_component_id = executor.component("counters").store().await;
     let caller_component_id = executor
@@ -358,7 +385,7 @@ async fn counter_resource_test_2(last_unique_id: &LastUniqueId, deps: &Deps, _tr
         counters_component_id.to_string(),
     );
     let caller_worker_id = executor
-        .start_worker_with(&caller_component_id, "rpc-counters-2", vec![], env)
+        .start_worker_with(&caller_component_id, "rpc-counters-2", vec![], env, vec![])
         .await;
 
     let result1 = executor
@@ -388,11 +415,11 @@ async fn counter_resource_test_2(last_unique_id: &LastUniqueId, deps: &Deps, _tr
 #[tracing::instrument]
 async fn counter_resource_test_2_with_restart(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let counters_component_id = executor.component("counters").store().await;
     let caller_component_id = executor
@@ -444,7 +471,7 @@ async fn counter_resource_test_2_with_restart(
         counters_component_id.to_string(),
     );
     let caller_worker_id = executor
-        .start_worker_with(&caller_component_id, "rpc-counters-2r", vec![], env)
+        .start_worker_with(&caller_component_id, "rpc-counters-2r", vec![], env, vec![])
         .await;
 
     let result1 = executor
@@ -456,7 +483,7 @@ async fn counter_resource_test_2_with_restart(
         .await;
 
     drop(executor);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let result2 = executor
         .invoke_and_await(
@@ -476,9 +503,13 @@ async fn counter_resource_test_2_with_restart(
 
 #[test]
 #[tracing::instrument]
-async fn counter_resource_test_3(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn counter_resource_test_3(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let counters_component_id = executor.component("counters").store().await;
     let caller_component_id = executor
@@ -530,7 +561,7 @@ async fn counter_resource_test_3(last_unique_id: &LastUniqueId, deps: &Deps, _tr
         counters_component_id.to_string(),
     );
     let caller_worker_id = executor
-        .start_worker_with(&caller_component_id, "rpc-counters-3", vec![], env)
+        .start_worker_with(&caller_component_id, "rpc-counters-3", vec![], env, vec![])
         .await;
 
     let result1 = executor
@@ -560,11 +591,11 @@ async fn counter_resource_test_3(last_unique_id: &LastUniqueId, deps: &Deps, _tr
 #[tracing::instrument]
 async fn counter_resource_test_3_with_restart(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let counters_component_id = executor.component("counters").store().await;
     let caller_component_id = executor
@@ -616,7 +647,7 @@ async fn counter_resource_test_3_with_restart(
         counters_component_id.to_string(),
     );
     let caller_worker_id = executor
-        .start_worker_with(&caller_component_id, "rpc-counters-3r", vec![], env)
+        .start_worker_with(&caller_component_id, "rpc-counters-3r", vec![], env, vec![])
         .await;
 
     let result1 = executor
@@ -628,7 +659,7 @@ async fn counter_resource_test_3_with_restart(
         .await;
 
     drop(executor);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let result2 = executor
         .invoke_and_await(
@@ -648,9 +679,13 @@ async fn counter_resource_test_3_with_restart(
 
 #[test]
 #[tracing::instrument]
-async fn context_inheritance(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn context_inheritance(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let counters_component_id = executor.component("counters").store().await;
     let caller_component_id = executor
@@ -708,6 +743,7 @@ async fn context_inheritance(last_unique_id: &LastUniqueId, deps: &Deps, _tracin
             "rpc-counters-4",
             vec!["a".to_string(), "b".to_string(), "c".to_string()],
             env,
+            vec![],
         )
         .await;
 
@@ -777,9 +813,13 @@ async fn context_inheritance(last_unique_id: &LastUniqueId, deps: &Deps, _tracin
 
 #[test]
 #[tracing::instrument]
-async fn counter_resource_test_5(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn counter_resource_test_5(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let counters_component_id = executor.component("counters").store().await;
     let caller_component_id = executor
@@ -831,7 +871,7 @@ async fn counter_resource_test_5(last_unique_id: &LastUniqueId, deps: &Deps, _tr
         counters_component_id.to_string(),
     );
     let caller_worker_id = executor
-        .start_worker_with(&caller_component_id, "rpc-counters-5", vec![], env)
+        .start_worker_with(&caller_component_id, "rpc-counters-5", vec![], env, vec![])
         .await;
 
     executor.log_output(&caller_worker_id).await;
@@ -862,11 +902,11 @@ async fn counter_resource_test_5(last_unique_id: &LastUniqueId, deps: &Deps, _tr
 #[tracing::instrument]
 async fn counter_resource_test_5_with_restart(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     // using store_unique_component to avoid collision with counter_resource_test_5
     let counters_component_id = executor.component("counters").unique().store().await;
@@ -920,7 +960,7 @@ async fn counter_resource_test_5_with_restart(
         counters_component_id.to_string(),
     );
     let caller_worker_id = executor
-        .start_worker_with(&caller_component_id, "rpc-counters-5r", vec![], env)
+        .start_worker_with(&caller_component_id, "rpc-counters-5r", vec![], env, vec![])
         .await;
 
     executor.log_output(&caller_worker_id).await;
@@ -935,7 +975,7 @@ async fn counter_resource_test_5_with_restart(
 
     drop(executor);
 
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let result2 = executor
         .invoke_and_await(
@@ -970,9 +1010,13 @@ async fn counter_resource_test_5_with_restart(
 
 #[test]
 #[tracing::instrument]
-async fn wasm_rpc_bug_32_test(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn wasm_rpc_bug_32_test(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let counters_component_id = executor.component("counters").store().await;
     let caller_component_id = executor
@@ -1024,7 +1068,13 @@ async fn wasm_rpc_bug_32_test(last_unique_id: &LastUniqueId, deps: &Deps, _traci
         counters_component_id.to_string(),
     );
     let caller_worker_id = executor
-        .start_worker_with(&caller_component_id, "rpc-counters-bug32", vec![], env)
+        .start_worker_with(
+            &caller_component_id,
+            "rpc-counters-bug32",
+            vec![],
+            env,
+            vec![],
+        )
         .await;
 
     let result = executor
@@ -1058,11 +1108,11 @@ async fn wasm_rpc_bug_32_test(last_unique_id: &LastUniqueId, deps: &Deps, _traci
 #[tracing::instrument]
 async fn error_message_non_existing_target_component(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let registry_component_id = executor
         .component("auction_registry")
@@ -1103,6 +1153,7 @@ async fn error_message_non_existing_target_component(
             "auction-registry-non-existing-target",
             vec![],
             env,
+            vec![],
         )
         .await;
 
@@ -1138,11 +1189,11 @@ async fn error_message_non_existing_target_component(
 #[tracing::instrument]
 async fn ephemeral_worker_invocation_via_rpc1(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let ephemeral_component_id = executor.component("ephemeral").ephemeral().store().await;
     let caller_component_id = executor
@@ -1194,7 +1245,7 @@ async fn ephemeral_worker_invocation_via_rpc1(
         ephemeral_component_id.to_string(),
     );
     let caller_worker_id = executor
-        .start_worker_with(&caller_component_id, "rpc-ephemeral-1", vec![], env)
+        .start_worker_with(&caller_component_id, "rpc-ephemeral-1", vec![], env, vec![])
         .await;
 
     let result = executor
@@ -1251,9 +1302,13 @@ async fn ephemeral_worker_invocation_via_rpc1(
 
 #[test]
 #[tracing::instrument]
-async fn golem_bug_1265_test(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn golem_bug_1265_test(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let counters_component_id = executor.component("counters").store().await;
     let caller_component_id = executor
@@ -1305,7 +1360,13 @@ async fn golem_bug_1265_test(last_unique_id: &LastUniqueId, deps: &Deps, _tracin
         counters_component_id.to_string(),
     );
     let caller_worker_id = executor
-        .start_worker_with(&caller_component_id, "rpc-counters-bug1265", vec![], env)
+        .start_worker_with(
+            &caller_component_id,
+            "rpc-counters-bug1265",
+            vec![],
+            env,
+            vec![],
+        )
         .await;
 
     let result = executor
diff --git a/golem-worker-executor/tests/scalability.rs b/golem-worker-executor/tests/scalability.rs
index 04ad0412..2b9d759c 100644
--- a/golem-worker-executor/tests/scalability.rs
+++ b/golem-worker-executor/tests/scalability.rs
@@ -13,11 +13,10 @@
 // limitations under the License.
 
 use crate::common::{start, start_customized, TestContext};
-use crate::Deps;
-use crate::{LastUniqueId, Tracing};
+use crate::{LastUniqueId, Tracing, WorkerExecutorTestDependencies};
 use assert2::check;
-use futures_util::stream::FuturesUnordered;
-use futures_util::StreamExt;
+use futures::stream::FuturesUnordered;
+use futures::StreamExt;
 use golem_test_framework::config::TestDependencies;
 use golem_test_framework::dsl::TestDslUnsafe;
 use golem_wasm_rpc::{IntoValueAndType, Value};
@@ -28,7 +27,7 @@ use tokio::spawn;
 use tokio::task::JoinSet;
 use tracing::{info, Instrument};
 
-inherit_test_dep!(Deps);
+inherit_test_dep!(WorkerExecutorTestDependencies);
 inherit_test_dep!(LastUniqueId);
 inherit_test_dep!(Tracing);
 
@@ -36,7 +35,7 @@ inherit_test_dep!(Tracing);
 #[tracing::instrument]
 async fn spawning_many_workers_that_sleep(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
@@ -54,7 +53,7 @@ async fn spawning_many_workers_that_sleep(
         (result, duration)
     }
 
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
     let component_id = executor.component("clocks").store().await;
 
     let warmup_worker = executor.start_worker(&component_id, &worker_name(0)).await;
@@ -128,7 +127,7 @@ async fn spawning_many_workers_that_sleep(
 #[tracing::instrument]
 async fn spawning_many_workers_that_sleep_long_enough_to_get_suspended(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
@@ -146,7 +145,7 @@ async fn spawning_many_workers_that_sleep_long_enough_to_get_suspended(
         (result, duration)
     }
 
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
     let component_id = executor.component("clocks").store().await;
 
     let warmup_worker = executor.start_worker(&component_id, &worker_name(0)).await;
@@ -245,14 +244,15 @@ async fn spawning_many_workers_that_sleep_long_enough_to_get_suspended(
 #[allow(clippy::needless_range_loop)]
 async fn initial_large_memory_allocation(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
     let executor = start_customized(deps, &context, Some(768 * 1024 * 1024), None)
         .await
         .unwrap()
-        .into_admin();
+        .into_admin()
+        .await;
     let component_id = executor.component("large-initial-memory").store().await;
 
     let mut handles = JoinSet::new();
@@ -291,14 +291,15 @@ async fn initial_large_memory_allocation(
 #[allow(clippy::needless_range_loop)]
 async fn dynamic_large_memory_allocation(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
     let executor = start_customized(deps, &context, Some(768 * 1024 * 1024), None)
         .await
         .unwrap()
-        .into_admin();
+        .into_admin()
+        .await;
     let component_id = executor.component("large-dynamic-memory").store().await;
 
     let mut handles = JoinSet::new();
diff --git a/golem-worker-executor/tests/transactions.rs b/golem-worker-executor/tests/transactions.rs
index 5915853e..a41dcffa 100644
--- a/golem-worker-executor/tests/transactions.rs
+++ b/golem-worker-executor/tests/transactions.rs
@@ -13,15 +13,14 @@
 // limitations under the License.
 
 use crate::common::{start, TestContext};
-use crate::Deps;
-use crate::{LastUniqueId, Tracing};
+use crate::{LastUniqueId, Tracing, WorkerExecutorTestDependencies};
 use assert2::check;
 use axum::extract::Path;
 use axum::routing::{delete, get, post};
 use axum::Router;
 use bytes::Bytes;
 use golem_common::model::oplog::WorkerError;
-use golem_common::model::{IdempotencyKey, TargetWorkerId};
+use golem_common::model::{IdempotencyKey, WorkerId};
 use golem_test_framework::config::TestDependencies;
 use golem_test_framework::dsl::{
     drain_connection, stdout_event_starting_with, stdout_events, worker_error_logs,
@@ -36,7 +35,7 @@ use tokio::task::JoinHandle;
 use tracing::info;
 use tracing::{debug, instrument, Instrument};
 
-inherit_test_dep!(Deps);
+inherit_test_dep!(WorkerExecutorTestDependencies);
 inherit_test_dep!(LastUniqueId);
 inherit_test_dep!(Tracing);
 
@@ -133,9 +132,13 @@ impl TestHttpServer {
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn jump(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn jump(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let http_server = TestHttpServer::start(1).await;
 
@@ -145,7 +148,7 @@ async fn jump(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
     env.insert("PORT".to_string(), http_server.port().to_string());
 
     let worker_id = executor
-        .start_worker_with(&component_id, "runtime-service-jump", vec![], env)
+        .start_worker_with(&component_id, "runtime-service-jump", vec![], env, vec![])
         .await;
 
     let (rx, abort_capture) = executor.capture_output_forever(&worker_id).await;
@@ -192,9 +195,13 @@ async fn jump(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
 
 #[test]
 #[instrument]
-async fn explicit_oplog_commit(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn explicit_oplog_commit(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("runtime-service").store().await;
 
@@ -221,9 +228,13 @@ async fn explicit_oplog_commit(last_unique_id: &LastUniqueId, deps: &Deps, _trac
 
 #[test]
 #[instrument]
-async fn set_retry_policy(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn set_retry_policy(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("runtime-service").store().await;
     let worker_id = executor
@@ -278,9 +289,13 @@ async fn set_retry_policy(last_unique_id: &LastUniqueId, deps: &Deps, _tracing:
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn atomic_region(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn atomic_region(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let http_server = TestHttpServer::start(2).await;
     let component_id = executor.component("runtime-service").store().await;
@@ -289,7 +304,7 @@ async fn atomic_region(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tr
     env.insert("PORT".to_string(), http_server.port().to_string());
 
     let worker_id = executor
-        .start_worker_with(&component_id, "atomic-region", vec![], env)
+        .start_worker_with(&component_id, "atomic-region", vec![], env, vec![])
         .await;
 
     let _ = executor
@@ -311,9 +326,13 @@ async fn atomic_region(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tr
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn idempotence_on(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn idempotence_on(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let http_server = TestHttpServer::start(1).await;
 
@@ -323,7 +342,7 @@ async fn idempotence_on(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &T
     env.insert("PORT".to_string(), http_server.port().to_string());
 
     let worker_id = executor
-        .start_worker_with(&component_id, "idempotence-flag", vec![], env)
+        .start_worker_with(&component_id, "idempotence-flag", vec![], env, vec![])
         .await;
 
     let _ = executor
@@ -349,9 +368,13 @@ async fn idempotence_on(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &T
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn idempotence_off(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn idempotence_off(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let http_server = TestHttpServer::start(1).await;
 
@@ -361,7 +384,7 @@ async fn idempotence_off(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &
     env.insert("PORT".to_string(), http_server.port().to_string());
 
     let worker_id = executor
-        .start_worker_with(&component_id, "idempotence-flag", vec![], env)
+        .start_worker_with(&component_id, "idempotence-flag", vec![], env, vec![])
         .await;
 
     let result = executor
@@ -388,9 +411,13 @@ async fn idempotence_off(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn persist_nothing(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn persist_nothing(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let http_server = TestHttpServer::start(2).await;
 
@@ -400,7 +427,7 @@ async fn persist_nothing(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &
     env.insert("PORT".to_string(), http_server.port().to_string());
 
     let worker_id = executor
-        .start_worker_with(&component_id, "persist-nothing", vec![], env)
+        .start_worker_with(&component_id, "persist-nothing", vec![], env, vec![])
         .await;
 
     let result = executor
@@ -426,11 +453,11 @@ async fn persist_nothing(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &
 #[instrument]
 async fn golem_rust_explicit_oplog_commit(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("golem-rust-tests").store().await;
 
@@ -459,11 +486,11 @@ async fn golem_rust_explicit_oplog_commit(
 #[instrument]
 async fn golem_rust_set_retry_policy(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("golem-rust-tests").store().await;
     let worker_id = executor
@@ -517,9 +544,13 @@ async fn golem_rust_set_retry_policy(
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn golem_rust_atomic_region(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn golem_rust_atomic_region(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let http_server = TestHttpServer::start(2).await;
     let component_id = executor.component("golem-rust-tests").store().await;
@@ -528,7 +559,13 @@ async fn golem_rust_atomic_region(last_unique_id: &LastUniqueId, deps: &Deps, _t
     env.insert("PORT".to_string(), http_server.port().to_string());
 
     let worker_id = executor
-        .start_worker_with(&component_id, "golem-rust-tests-atomic-region", vec![], env)
+        .start_worker_with(
+            &component_id,
+            "golem-rust-tests-atomic-region",
+            vec![],
+            env,
+            vec![],
+        )
         .await;
 
     let _ = executor
@@ -550,9 +587,13 @@ async fn golem_rust_atomic_region(last_unique_id: &LastUniqueId, deps: &Deps, _t
 #[test]
 #[tracing::instrument]
 #[timeout(120_000)]
-async fn golem_rust_idempotence_on(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn golem_rust_idempotence_on(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let http_server = TestHttpServer::start(1).await;
 
@@ -567,6 +608,7 @@ async fn golem_rust_idempotence_on(last_unique_id: &LastUniqueId, deps: &Deps, _
             "golem-rust-tests-idempotence-flag-on",
             vec![],
             env,
+            vec![],
         )
         .await;
 
@@ -595,11 +637,11 @@ async fn golem_rust_idempotence_on(last_unique_id: &LastUniqueId, deps: &Deps, _
 #[timeout(120_000)]
 async fn golem_rust_idempotence_off(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let http_server = TestHttpServer::start(1).await;
 
@@ -614,6 +656,7 @@ async fn golem_rust_idempotence_off(
             "golem-rust-tests-idempotence-flag-off",
             vec![],
             env,
+            vec![],
         )
         .await;
 
@@ -643,11 +686,11 @@ async fn golem_rust_idempotence_off(
 #[timeout(120_000)]
 async fn golem_rust_persist_nothing(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let http_server = TestHttpServer::start(2).await;
 
@@ -662,6 +705,7 @@ async fn golem_rust_persist_nothing(
             "golem-rust-tests-persist-nothing",
             vec![],
             env,
+            vec![],
         )
         .await;
 
@@ -687,11 +731,11 @@ async fn golem_rust_persist_nothing(
 #[timeout(120_000)]
 async fn golem_rust_fallible_transaction(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let http_server = TestHttpServer::start_custom(
         Arc::new(|step| match step {
@@ -712,6 +756,7 @@ async fn golem_rust_fallible_transaction(
             "golem-rust-tests-fallible-transaction",
             vec![],
             env,
+            vec![],
         )
         .await;
 
@@ -751,11 +796,11 @@ async fn golem_rust_fallible_transaction(
 #[timeout(120_000)]
 async fn golem_rust_infallible_transaction(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let http_server = TestHttpServer::start_custom(
         Arc::new(|step| match step {
@@ -776,6 +821,7 @@ async fn golem_rust_infallible_transaction(
             "golem-rust-tests-infallible-transaction",
             vec![],
             env,
+            vec![],
         )
         .await;
 
@@ -816,11 +862,11 @@ async fn golem_rust_infallible_transaction(
 #[timeout(120_000)]
 async fn idempotency_keys_in_ephemeral_workers(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor
         .component("runtime-service")
@@ -828,9 +874,9 @@ async fn idempotency_keys_in_ephemeral_workers(
         .store()
         .await;
 
-    let target_worker_id = TargetWorkerId {
+    let target_worker_id = WorkerId {
         component_id,
-        worker_name: None,
+        worker_name: "ephemeral".to_string(),
     };
 
     let idempotency_key1 = IdempotencyKey::fresh();
@@ -838,7 +884,7 @@ async fn idempotency_keys_in_ephemeral_workers(
 
     let result11 = executor
         .invoke_and_await(
-            target_worker_id.clone(),
+            &target_worker_id,
             "golem:it/api.{generate-idempotency-keys}",
             vec![],
         )
@@ -846,7 +892,7 @@ async fn idempotency_keys_in_ephemeral_workers(
         .unwrap();
     let result21 = executor
         .invoke_and_await_with_key(
-            target_worker_id.clone(),
+            &target_worker_id,
             &idempotency_key1,
             "golem:it/api.{generate-idempotency-keys}",
             vec![],
@@ -855,7 +901,7 @@ async fn idempotency_keys_in_ephemeral_workers(
         .unwrap();
     let result31 = executor
         .invoke_and_await_with_key(
-            target_worker_id.clone(),
+            &target_worker_id,
             &idempotency_key2,
             "golem:it/api.{generate-idempotency-keys}",
             vec![],
@@ -864,7 +910,7 @@ async fn idempotency_keys_in_ephemeral_workers(
         .unwrap();
     let result12 = executor
         .invoke_and_await(
-            target_worker_id.clone(),
+            &target_worker_id,
             "golem:it/api.{generate-idempotency-keys}",
             vec![],
         )
@@ -872,7 +918,7 @@ async fn idempotency_keys_in_ephemeral_workers(
         .unwrap();
     let result22 = executor
         .invoke_and_await_with_key(
-            target_worker_id.clone(),
+            &target_worker_id,
             &idempotency_key1,
             "golem:it/api.{generate-idempotency-keys}",
             vec![],
@@ -881,7 +927,7 @@ async fn idempotency_keys_in_ephemeral_workers(
         .unwrap();
     let result32 = executor
         .invoke_and_await_with_key(
-            target_worker_id.clone(),
+            &target_worker_id,
             &idempotency_key2,
             "golem:it/api.{generate-idempotency-keys}",
             vec![],
diff --git a/golem-worker-executor/tests/ts_rpc1_stubless.rs b/golem-worker-executor/tests/ts_rpc1_stubless.rs
index d7c1c127..1c95f294 100644
--- a/golem-worker-executor/tests/ts_rpc1_stubless.rs
+++ b/golem-worker-executor/tests/ts_rpc1_stubless.rs
@@ -12,8 +12,7 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use crate::Deps;
-use crate::{common, LastUniqueId, Tracing};
+use crate::{common, LastUniqueId, Tracing, WorkerExecutorTestDependencies};
 use assert2::check;
 use golem_common::model::component_metadata::{
     DynamicLinkedInstance, DynamicLinkedWasmRpc, WasmRpcTarget,
@@ -25,7 +24,7 @@ use golem_wasm_rpc::Value;
 use std::collections::HashMap;
 use test_r::{inherit_test_dep, test};
 
-inherit_test_dep!(Deps);
+inherit_test_dep!(WorkerExecutorTestDependencies);
 inherit_test_dep!(LastUniqueId);
 inherit_test_dep!(Tracing);
 
@@ -34,9 +33,17 @@ static CALLER_COMPONENT_NAME: &str = "caller-ts";
 
 #[test]
 #[tracing::instrument]
-async fn counter_resource_test_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn counter_resource_test_1(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = common::TestContext::new(last_unique_id);
-    let executor = common::start(deps, &context).await.unwrap().into_admin();
+    let executor = common::start(deps, &context)
+        .await
+        .unwrap()
+        .into_admin()
+        .await;
 
     let counters_component_id = executor.component(COUNTER_COMPONENT_NAME).store().await;
     let caller_component_id = executor
@@ -73,7 +80,7 @@ async fn counter_resource_test_1(last_unique_id: &LastUniqueId, deps: &Deps, _tr
         counters_component_id.to_string(),
     );
     let caller_worker_id = executor
-        .start_worker_with(&caller_component_id, "rpc-counters-1", vec![], env)
+        .start_worker_with(&caller_component_id, "rpc-counters-1", vec![], env, vec![])
         .await;
 
     let result1 = executor
@@ -103,11 +110,15 @@ async fn counter_resource_test_1(last_unique_id: &LastUniqueId, deps: &Deps, _tr
 #[tracing::instrument]
 async fn counter_resource_test_1_with_restart(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = common::TestContext::new(last_unique_id);
-    let executor = common::start(deps, &context).await.unwrap().into_admin();
+    let executor = common::start(deps, &context)
+        .await
+        .unwrap()
+        .into_admin()
+        .await;
 
     let counters_component_id = executor.component(COUNTER_COMPONENT_NAME).store().await;
     let caller_component_id = executor
@@ -144,7 +155,7 @@ async fn counter_resource_test_1_with_restart(
         counters_component_id.to_string(),
     );
     let caller_worker_id = executor
-        .start_worker_with(&caller_component_id, "rpc-counters-1r", vec![], env)
+        .start_worker_with(&caller_component_id, "rpc-counters-1r", vec![], env, vec![])
         .await;
 
     let result1 = executor
@@ -156,7 +167,11 @@ async fn counter_resource_test_1_with_restart(
         .await;
 
     drop(executor);
-    let executor = common::start(deps, &context).await.unwrap().into_admin();
+    let executor = common::start(deps, &context)
+        .await
+        .unwrap()
+        .into_admin()
+        .await;
 
     let result2 = executor
         .invoke_and_await(
@@ -176,9 +191,17 @@ async fn counter_resource_test_1_with_restart(
 
 #[test]
 #[tracing::instrument]
-async fn context_inheritance(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn context_inheritance(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = common::TestContext::new(last_unique_id);
-    let executor = common::start(deps, &context).await.unwrap().into_admin();
+    let executor = common::start(deps, &context)
+        .await
+        .unwrap()
+        .into_admin()
+        .await;
 
     let counters_component_id = executor.component(COUNTER_COMPONENT_NAME).store().await;
     let caller_component_id = executor
@@ -221,6 +244,7 @@ async fn context_inheritance(last_unique_id: &LastUniqueId, deps: &Deps, _tracin
             "rpc-counters-4",
             vec!["a".to_string(), "b".to_string(), "c".to_string()],
             env,
+            vec![],
         )
         .await;
 
diff --git a/golem-worker-executor/tests/ts_rpc2_stubless.rs b/golem-worker-executor/tests/ts_rpc2_stubless.rs
index 4c8ed23a..d4aad32b 100644
--- a/golem-worker-executor/tests/ts_rpc2_stubless.rs
+++ b/golem-worker-executor/tests/ts_rpc2_stubless.rs
@@ -12,8 +12,7 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use crate::Deps;
-use crate::{common, LastUniqueId, Tracing};
+use crate::{common, LastUniqueId, Tracing, WorkerExecutorTestDependencies};
 use assert2::check;
 use golem_common::model::component_metadata::{
     DynamicLinkedInstance, DynamicLinkedWasmRpc, WasmRpcTarget,
@@ -25,7 +24,7 @@ use golem_wasm_rpc::Value;
 use std::collections::HashMap;
 use test_r::{inherit_test_dep, test};
 
-inherit_test_dep!(Deps);
+inherit_test_dep!(WorkerExecutorTestDependencies);
 inherit_test_dep!(LastUniqueId);
 inherit_test_dep!(Tracing);
 
@@ -34,9 +33,17 @@ static CALLER_COMPONENT_NAME: &str = "caller-ts";
 
 #[test]
 #[tracing::instrument]
-async fn counter_resource_test_2(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn counter_resource_test_2(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = common::TestContext::new(last_unique_id);
-    let executor = common::start(deps, &context).await.unwrap().into_admin();
+    let executor = common::start(deps, &context)
+        .await
+        .unwrap()
+        .into_admin()
+        .await;
 
     let counters_component_id = executor.component(COUNTER_COMPONENT_NAME).store().await;
     let caller_component_id = executor
@@ -73,7 +80,7 @@ async fn counter_resource_test_2(last_unique_id: &LastUniqueId, deps: &Deps, _tr
         counters_component_id.to_string(),
     );
     let caller_worker_id = executor
-        .start_worker_with(&caller_component_id, "rpc-counters-2", vec![], env)
+        .start_worker_with(&caller_component_id, "rpc-counters-2", vec![], env, vec![])
         .await;
 
     let result1 = executor
@@ -103,11 +110,15 @@ async fn counter_resource_test_2(last_unique_id: &LastUniqueId, deps: &Deps, _tr
 #[tracing::instrument]
 async fn counter_resource_test_2_with_restart(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = common::TestContext::new(last_unique_id);
-    let executor = common::start(deps, &context).await.unwrap().into_admin();
+    let executor = common::start(deps, &context)
+        .await
+        .unwrap()
+        .into_admin()
+        .await;
 
     let counters_component_id = executor.component(COUNTER_COMPONENT_NAME).store().await;
     let caller_component_id = executor
@@ -144,7 +155,7 @@ async fn counter_resource_test_2_with_restart(
         counters_component_id.to_string(),
     );
     let caller_worker_id = executor
-        .start_worker_with(&caller_component_id, "rpc-counters-2r", vec![], env)
+        .start_worker_with(&caller_component_id, "rpc-counters-2r", vec![], env, vec![])
         .await;
 
     let result1 = executor
@@ -156,7 +167,11 @@ async fn counter_resource_test_2_with_restart(
         .await;
 
     drop(executor);
-    let executor = common::start(deps, &context).await.unwrap().into_admin();
+    let executor = common::start(deps, &context)
+        .await
+        .unwrap()
+        .into_admin()
+        .await;
 
     let result2 = executor
         .invoke_and_await(
diff --git a/golem-worker-executor/tests/wasi.rs b/golem-worker-executor/tests/wasi.rs
index d33ac5f5..5a4667a3 100644
--- a/golem-worker-executor/tests/wasi.rs
+++ b/golem-worker-executor/tests/wasi.rs
@@ -12,22 +12,21 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use crate::common::{start, TestContext, TestWorkerExecutor};
-use crate::Deps;
-use crate::{LastUniqueId, Tracing};
+use crate::common::{start, TestContext};
+use crate::{LastUniqueId, Tracing, WorkerExecutorTestDependencies};
 use assert2::{assert, check};
 use axum::response::Response;
 use axum::routing::{get, post};
 use axum::{BoxError, Router};
 use bytes::Bytes;
-use futures_util::stream;
+use futures::stream;
 use golem_common::model::oplog::WorkerError;
 use golem_common::model::{
     ComponentFilePermissions, ComponentFileSystemNode, ComponentFileSystemNodeDetails,
     IdempotencyKey, WorkerStatus,
 };
 use golem_common::virtual_exports::http_incoming_handler::IncomingHttpRequest;
-use golem_test_framework::config::{TestDependencies, TestDependenciesDsl};
+use golem_test_framework::config::TestDependencies;
 use golem_test_framework::dsl::{
     drain_connection, stderr_events, stdout_events, worker_error_logs, worker_error_message,
     worker_error_underlying_error, TestDslUnsafe,
@@ -44,20 +43,19 @@ use tokio::time::Instant;
 use tokio_stream::StreamExt;
 use tracing::{info, Instrument};
 
-inherit_test_dep!(Deps);
+inherit_test_dep!(WorkerExecutorTestDependencies);
 inherit_test_dep!(LastUniqueId);
 inherit_test_dep!(Tracing);
 
-#[cfg(windows)]
-const LINE_ENDING: &str = "\r\n";
-#[cfg(not(windows))]
-const LINE_ENDING: &str = "\n";
-
 #[test]
 #[tracing::instrument]
-async fn write_stdout(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn write_stdout(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("write-stdout").store().await;
     let worker_id = executor.start_worker(&component_id, "write-stdout-1").await;
@@ -85,9 +83,13 @@ async fn write_stdout(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tra
 
 #[test]
 #[tracing::instrument]
-async fn write_stderr(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn write_stderr(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("write-stderr").store().await;
     let worker_id = executor.start_worker(&component_id, "write-stderr-1").await;
@@ -115,9 +117,13 @@ async fn write_stderr(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tra
 
 #[test]
 #[tracing::instrument]
-async fn read_stdin(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn read_stdin(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("read-stdin").store().await;
     let worker_id = executor.start_worker(&component_id, "read-stdin-1").await;
@@ -133,9 +139,13 @@ async fn read_stdin(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Traci
 
 #[test]
 #[tracing::instrument]
-async fn clocks(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn clocks(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("clocks").store().await;
     let worker_id = executor.start_worker(&component_id, "clocks-1").await;
@@ -181,15 +191,25 @@ async fn clocks(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing)
 
 #[test]
 #[tracing::instrument]
-async fn file_write_read_delete(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn file_write_read_delete(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("file-write-read-delete").store().await;
     let mut env = HashMap::new();
     env.insert("RUST_BACKTRACE".to_string(), "full".to_string());
     let worker_id = executor
-        .start_worker_with(&component_id, "file-write-read-delete-1", vec![], env)
+        .start_worker_with(
+            &component_id,
+            "file-write-read-delete-1",
+            vec![],
+            env,
+            vec![],
+        )
         .await;
 
     let result = executor
@@ -213,9 +233,13 @@ async fn file_write_read_delete(last_unique_id: &LastUniqueId, deps: &Deps, _tra
 
 #[test]
 #[tracing::instrument]
-async fn initial_file_read_write(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn initial_file_read_write(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_files = executor
         .add_initial_component_files(&[
@@ -241,7 +265,13 @@ async fn initial_file_read_write(last_unique_id: &LastUniqueId, deps: &Deps, _tr
     let mut env = HashMap::new();
     env.insert("RUST_BACKTRACE".to_string(), "full".to_string());
     let worker_id = executor
-        .start_worker_with(&component_id, "initial-file-read-write-1", vec![], env)
+        .start_worker_with(
+            &component_id,
+            "initial-file-read-write-1",
+            vec![],
+            env,
+            vec![],
+        )
         .await;
 
     let result = executor
@@ -253,41 +283,27 @@ async fn initial_file_read_write(last_unique_id: &LastUniqueId, deps: &Deps, _tr
 
     drop(executor);
 
-    let foo_data = format!("foo{}", LINE_ENDING);
-    let baz_data = format!("baz{}", LINE_ENDING);
-
     check!(
         result
             == vec![Value::Tuple(vec![
-                Value::Option(Some(Box::new(Value::String(foo_data)))),
+                Value::Option(Some(Box::new(Value::String("foo\n".to_string())))),
                 Value::Option(None),
                 Value::Option(None),
-                Value::Option(Some(Box::new(Value::String(baz_data)))),
+                Value::Option(Some(Box::new(Value::String("baz\n".to_string())))),
                 Value::Option(Some(Box::new(Value::String("hello world".to_string())))),
             ])]
     );
 }
 
-async fn get_file_size(executor: &TestDependenciesDsl<TestWorkerExecutor>, path: &str) -> u64 {
-    let source_path = executor.deps.component_directory().join(path);
-    let meta = tokio::fs::metadata(source_path);
-
-    let size = meta.await.unwrap().len();
-    size
-}
-
 #[test]
 #[tracing::instrument]
 async fn initial_file_listing_through_api(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
-
-    let foo_file_size = get_file_size(&executor, "initial-file-read-write/files/foo.txt").await;
-    let baz_file_size = get_file_size(&executor, "initial-file-read-write/files/baz.txt").await;
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_files = executor
         .add_initial_component_files(&[
@@ -315,13 +331,12 @@ async fn initial_file_listing_through_api(
         .with_files(&component_files)
         .store()
         .await;
-    let mut env = HashMap::new();
-    env.insert("RUST_BACKTRACE".to_string(), "full".to_string());
+
     let worker_id = executor
-        .start_worker_with(&component_id, "initial-file-read-write-2", vec![], env)
+        .start_worker(&component_id, "initial-file-read-write-1")
         .await;
 
-    let result = executor.list_directory(&worker_id, "/").await;
+    let result = executor.get_file_system_node(&worker_id, "/").await;
 
     let mut result = result
         .into_iter()
@@ -333,10 +348,6 @@ async fn initial_file_listing_through_api(
 
     result.sort_by_key(|e| e.name.clone());
 
-    executor.check_oplog_is_queryable(&worker_id).await;
-
-    drop(executor);
-
     check!(
         result
             == vec![
@@ -350,7 +361,7 @@ async fn initial_file_listing_through_api(
                     last_modified: SystemTime::UNIX_EPOCH,
                     details: ComponentFileSystemNodeDetails::File {
                         permissions: ComponentFilePermissions::ReadWrite,
-                        size: baz_file_size,
+                        size: 4,
                     }
                 },
                 ComponentFileSystemNode {
@@ -358,22 +369,74 @@ async fn initial_file_listing_through_api(
                     last_modified: SystemTime::UNIX_EPOCH,
                     details: ComponentFileSystemNodeDetails::File {
                         permissions: ComponentFilePermissions::ReadOnly,
-                        size: foo_file_size,
+                        size: 4,
                     }
                 },
             ]
     );
+
+    let result = executor.get_file_system_node(&worker_id, "/bar").await;
+
+    let mut result = result
+        .into_iter()
+        .map(|e| ComponentFileSystemNode {
+            last_modified: SystemTime::UNIX_EPOCH,
+            ..e
+        })
+        .collect::<Vec<_>>();
+
+    result.sort_by_key(|e| e.name.clone());
+
+    check!(
+        result
+            == vec![ComponentFileSystemNode {
+                name: "baz.txt".to_string(),
+                last_modified: SystemTime::UNIX_EPOCH,
+                details: ComponentFileSystemNodeDetails::File {
+                    permissions: ComponentFilePermissions::ReadWrite,
+                    size: 4,
+                }
+            },]
+    );
+
+    let result = executor.get_file_system_node(&worker_id, "/baz.txt").await;
+
+    let mut result = result
+        .into_iter()
+        .map(|e| ComponentFileSystemNode {
+            last_modified: SystemTime::UNIX_EPOCH,
+            ..e
+        })
+        .collect::<Vec<_>>();
+
+    result.sort_by_key(|e| e.name.clone());
+
+    check!(
+        result
+            == vec![ComponentFileSystemNode {
+                name: "baz.txt".to_string(),
+                last_modified: SystemTime::UNIX_EPOCH,
+                details: ComponentFileSystemNodeDetails::File {
+                    permissions: ComponentFilePermissions::ReadWrite,
+                    size: 4,
+                }
+            },]
+    );
+
+    executor.check_oplog_is_queryable(&worker_id).await;
+
+    drop(executor);
 }
 
 #[test]
 #[tracing::instrument]
 async fn initial_file_reading_through_api(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_files = executor
         .add_initial_component_files(&[
@@ -399,7 +462,13 @@ async fn initial_file_reading_through_api(
     let mut env = HashMap::new();
     env.insert("RUST_BACKTRACE".to_string(), "full".to_string());
     let worker_id = executor
-        .start_worker_with(&component_id, "initial-file-read-write-3", vec![], env)
+        .start_worker_with(
+            &component_id,
+            "initial-file-read-write-3",
+            vec![],
+            env,
+            vec![],
+        )
         .await;
 
     // run the worker so it can update the files.
@@ -418,17 +487,19 @@ async fn initial_file_reading_through_api(
 
     drop(executor);
 
-    let foo_data = format!("foo{}", LINE_ENDING);
-
-    check!(result1 == foo_data);
+    check!(result1 == "foo\n");
     check!(result2 == "hello world");
 }
 
 #[test]
 #[tracing::instrument]
-async fn directories(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn directories(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("directories").store().await;
     let worker_id = executor.start_worker(&component_id, "directories-1").await;
@@ -482,9 +553,13 @@ async fn directories(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Trac
 
 #[test]
 #[tracing::instrument]
-async fn directories_replay(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn directories_replay(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("directories").store().await;
     let worker_id = executor.start_worker(&component_id, "directories-1").await;
@@ -497,7 +572,7 @@ async fn directories_replay(last_unique_id: &LastUniqueId, deps: &Deps, _tracing
     executor.check_oplog_is_queryable(&worker_id).await;
 
     drop(executor);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     // NOTE: if the directory listing would not be stable, replay would fail with divergence error
 
@@ -547,9 +622,13 @@ async fn directories_replay(last_unique_id: &LastUniqueId, deps: &Deps, _tracing
 
 #[test]
 #[tracing::instrument]
-async fn file_write_read(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn file_write_read(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("file-service").store().await;
     let worker_id = executor.start_worker(&component_id, "file-service-1").await;
@@ -569,7 +648,7 @@ async fn file_write_read(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &
     executor.check_oplog_is_queryable(&worker_id).await;
 
     drop(executor);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let result = executor
         .invoke_and_await(
@@ -590,13 +669,13 @@ async fn file_write_read(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &
 
 #[test]
 #[tracing::instrument]
-async fn file_update_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn file_update_1(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
-
-    let foo_data = format!("foo{}", LINE_ENDING);
-    let bar_data = format!("bar{}", LINE_ENDING);
-    let baz_data = format!("baz{}", LINE_ENDING);
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = {
         let component_files = executor
@@ -636,7 +715,7 @@ async fn file_update_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tr
             .await
             .unwrap();
 
-        check!(content_before_update[0] == Value::String(foo_data.to_string()));
+        check!(content_before_update[0] == Value::String("foo\n".to_string()));
     }
 
     {
@@ -671,7 +750,7 @@ async fn file_update_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tr
             .await
             .unwrap();
 
-        check!(content_after_update[0] == Value::String(foo_data.to_string()));
+        check!(content_after_update[0] == Value::String("foo\n".to_string()));
     }
 
     executor.simulated_crash(&worker_id).await;
@@ -686,7 +765,7 @@ async fn file_update_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tr
             .await
             .unwrap();
 
-        check!(content_after_crash[0] == Value::String(foo_data.to_string()));
+        check!(content_after_crash[0] == Value::String("foo\n".to_string()));
     }
 
     executor
@@ -708,7 +787,7 @@ async fn file_update_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tr
             .await
             .unwrap();
 
-        check!(content_after_reload[0] == Value::String(bar_data.to_string()));
+        check!(content_after_reload[0] == Value::String("bar\n".to_string()));
     }
 
     executor.simulated_crash(&worker_id).await;
@@ -723,7 +802,7 @@ async fn file_update_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tr
             .await
             .unwrap();
 
-        check!(content_after_crash[0] == Value::String(bar_data.to_string()));
+        check!(content_after_crash[0] == Value::String("bar\n".to_string()));
     }
 
     {
@@ -780,22 +859,22 @@ async fn file_update_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tr
             .await
             .unwrap();
 
-        check!(content_after_reload[0] == Value::String(baz_data.to_string()));
+        check!(content_after_reload[0] == Value::String("baz\n".to_string()));
     }
 
     executor.simulated_crash(&worker_id).await;
 
     {
-        // after manual update oplog fails and worker cannot be restarted
         let content_after_crash = executor
             .invoke_and_await(
                 &worker_id,
                 "golem-it:ifs-update-exports/golem-it-ifs-update-api.{get-file-content}",
                 vec![],
             )
-            .await;
+            .await
+            .unwrap();
 
-        check!(content_after_crash.is_err());
+        check!(content_after_crash[0] == Value::String("baz\n".to_string()));
     }
 }
 
@@ -803,11 +882,11 @@ async fn file_update_1(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tr
 #[tracing::instrument]
 async fn file_update_in_the_middle_of_exported_function(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let (sender, mut latch) = tokio::sync::mpsc::channel::<()>(1);
     let listener = tokio::net::TcpListener::bind("0.0.0.0:0").await.unwrap();
@@ -898,9 +977,6 @@ async fn file_update_in_the_middle_of_exported_function(
     };
 
     {
-        let foo_data = format!("foo{}", LINE_ENDING);
-        let bar_data = format!("bar{}", LINE_ENDING);
-
         let result = executor
             .invoke_and_await_with_key(
                 &worker_id,
@@ -914,8 +990,8 @@ async fn file_update_in_the_middle_of_exported_function(
         check!(
             result[0]
                 == Value::Tuple(vec![
-                    Value::String(foo_data.to_string()),
-                    Value::String(bar_data.to_string())
+                    Value::String("foo\n".to_string()),
+                    Value::String("bar\n".to_string())
                 ])
         );
     }
@@ -925,16 +1001,20 @@ async fn file_update_in_the_middle_of_exported_function(
 
 #[test]
 #[tracing::instrument]
-async fn environment_service(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn environment_service(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("environment-service").store().await;
     let args = vec!["test-arg".to_string()];
     let mut env = HashMap::new();
     env.insert("TEST_ENV".to_string(), "test-value".to_string());
     let worker_id = executor
-        .start_worker_with(&component_id, "environment-service-1", args, env)
+        .start_worker_with(&component_id, "environment-service-1", args, env, vec![])
         .await;
 
     let args_result = executor
@@ -984,11 +1064,11 @@ async fn environment_service(last_unique_id: &LastUniqueId, deps: &Deps, _tracin
 #[tracing::instrument]
 async fn http_client_response_persisted_between_invocations(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let listener = tokio::net::TcpListener::bind("0.0.0.0:0").await.unwrap();
     let host_http_port = listener.local_addr().unwrap().port();
@@ -1020,7 +1100,7 @@ async fn http_client_response_persisted_between_invocations(
     env.insert("PORT".to_string(), host_http_port.to_string());
 
     let worker_id = executor
-        .start_worker_with(&component_id, "http-client-2", vec![], env)
+        .start_worker_with(&component_id, "http-client-2", vec![], env, vec![])
         .await;
     let rx = executor.capture_output(&worker_id).await;
 
@@ -1034,7 +1114,7 @@ async fn http_client_response_persisted_between_invocations(
     drop(executor);
     drop(rx);
 
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
     let _rx = executor.capture_output(&worker_id).await;
 
     let result = executor
@@ -1055,11 +1135,11 @@ async fn http_client_response_persisted_between_invocations(
 #[tracing::instrument]
 async fn http_client_interrupting_response_stream(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let listener = tokio::net::TcpListener::bind("0.0.0.0:0").await.unwrap();
     let host_http_port = listener.local_addr().unwrap().port();
@@ -1107,7 +1187,7 @@ async fn http_client_interrupting_response_stream(
     env.insert("PORT".to_string(), host_http_port.to_string());
 
     let worker_id = executor
-        .start_worker_with(&component_id, "http-client-2", vec![], env)
+        .start_worker_with(&component_id, "http-client-2", vec![], env, vec![])
         .await;
     let rx = executor.capture_output_with_termination(&worker_id).await;
 
@@ -1164,11 +1244,11 @@ async fn http_client_interrupting_response_stream(
 #[tracing::instrument]
 async fn http_client_interrupting_response_stream_async(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let listener = tokio::net::TcpListener::bind("0.0.0.0:0").await.unwrap();
     let host_http_port = listener.local_addr().unwrap().port();
@@ -1216,7 +1296,7 @@ async fn http_client_interrupting_response_stream_async(
     env.insert("PORT".to_string(), host_http_port.to_string());
 
     let worker_id = executor
-        .start_worker_with(&component_id, "http-client-2-async", vec![], env)
+        .start_worker_with(&component_id, "http-client-2-async", vec![], env, vec![])
         .await;
     let rx = executor.capture_output_with_termination(&worker_id).await;
 
@@ -1271,9 +1351,13 @@ async fn http_client_interrupting_response_stream_async(
 
 #[test]
 #[tracing::instrument]
-async fn sleep(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn sleep(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("clock-service").store().await;
     let worker_id = executor
@@ -1292,7 +1376,7 @@ async fn sleep(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
     executor.check_oplog_is_queryable(&worker_id).await;
 
     drop(executor);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let start = Instant::now();
     let _ = executor
@@ -1310,9 +1394,13 @@ async fn sleep(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
 
 #[test]
 #[tracing::instrument]
-async fn resuming_sleep(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn resuming_sleep(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("clock-service").store().await;
     let worker_id = executor
@@ -1344,7 +1432,7 @@ async fn resuming_sleep(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &T
 
     info!("Restarting worker...");
 
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     info!("Worker restarted");
 
@@ -1365,9 +1453,13 @@ async fn resuming_sleep(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &T
 
 #[test]
 #[tracing::instrument]
-async fn failing_worker(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn failing_worker(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("failing-component").store().await;
     let worker_id = executor
@@ -1421,9 +1513,13 @@ async fn failing_worker(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &T
 
 #[test]
 #[tracing::instrument]
-async fn file_service_write_direct(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn file_service_write_direct(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("file-service").store().await;
     let worker_id = executor.start_worker(&component_id, "file-service-2").await;
@@ -1443,7 +1539,7 @@ async fn file_service_write_direct(last_unique_id: &LastUniqueId, deps: &Deps, _
     executor.check_oplog_is_queryable(&worker_id).await;
 
     drop(executor);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let result = executor
         .invoke_and_await(
@@ -1466,11 +1562,11 @@ async fn file_service_write_direct(last_unique_id: &LastUniqueId, deps: &Deps, _
 #[tracing::instrument]
 async fn filesystem_write_replay_restores_file_times(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("file-service").store().await;
     let worker_id = executor.start_worker(&component_id, "file-service-3").await;
@@ -1498,7 +1594,7 @@ async fn filesystem_write_replay_restores_file_times(
     executor.check_oplog_is_queryable(&worker_id).await;
 
     drop(executor);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let times2 = executor
         .invoke_and_await(
@@ -1516,11 +1612,11 @@ async fn filesystem_write_replay_restores_file_times(
 #[tracing::instrument]
 async fn filesystem_create_dir_replay_restores_file_times(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("file-service").store().await;
     let worker_id = executor.start_worker(&component_id, "file-service-4").await;
@@ -1545,7 +1641,7 @@ async fn filesystem_create_dir_replay_restores_file_times(
     executor.check_oplog_is_queryable(&worker_id).await;
 
     drop(executor);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let times2 = executor
         .invoke_and_await(
@@ -1561,9 +1657,13 @@ async fn filesystem_create_dir_replay_restores_file_times(
 
 #[test]
 #[tracing::instrument]
-async fn file_hard_link(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn file_hard_link(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("file-service").store().await;
     let worker_id = executor.start_worker(&component_id, "file-service-5").await;
@@ -1613,11 +1713,11 @@ async fn file_hard_link(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &T
 #[tracing::instrument]
 async fn filesystem_link_replay_restores_file_times(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("file-service").store().await;
     let worker_id = executor.start_worker(&component_id, "file-service-6").await;
@@ -1681,7 +1781,7 @@ async fn filesystem_link_replay_restores_file_times(
     executor.check_oplog_is_queryable(&worker_id).await;
 
     drop(executor);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let times_dir_2 = executor
         .invoke_and_await(
@@ -1708,11 +1808,11 @@ async fn filesystem_link_replay_restores_file_times(
 #[tracing::instrument]
 async fn filesystem_remove_dir_replay_restores_file_times(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("file-service").store().await;
     let worker_id = executor.start_worker(&component_id, "file-service-7").await;
@@ -1753,7 +1853,7 @@ async fn filesystem_remove_dir_replay_restores_file_times(
     executor.check_oplog_is_queryable(&worker_id).await;
 
     drop(executor);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let times2 = executor
         .invoke_and_await(
@@ -1771,11 +1871,11 @@ async fn filesystem_remove_dir_replay_restores_file_times(
 #[tracing::instrument]
 async fn filesystem_symlink_replay_restores_file_times(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("file-service").store().await;
     let worker_id = executor.start_worker(&component_id, "file-service-8").await;
@@ -1838,7 +1938,7 @@ async fn filesystem_symlink_replay_restores_file_times(
 
     drop(executor);
 
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let times_dir_2 = executor
         .invoke_and_await(
@@ -1869,11 +1969,11 @@ async fn filesystem_symlink_replay_restores_file_times(
 #[tracing::instrument]
 async fn filesystem_rename_replay_restores_file_times(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("file-service").store().await;
     let worker_id = executor.start_worker(&component_id, "file-service-9").await;
@@ -1943,7 +2043,7 @@ async fn filesystem_rename_replay_restores_file_times(
         .unwrap();
 
     drop(executor);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let times_srcdir_2 = executor
         .invoke_and_await(
@@ -1982,11 +2082,11 @@ async fn filesystem_rename_replay_restores_file_times(
 #[tracing::instrument]
 async fn filesystem_remove_file_replay_restores_file_times(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("file-service").store().await;
     let worker_id = executor
@@ -2030,7 +2130,7 @@ async fn filesystem_remove_file_replay_restores_file_times(
         .unwrap();
 
     drop(executor);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let times2 = executor
         .invoke_and_await(
@@ -2051,11 +2151,11 @@ async fn filesystem_remove_file_replay_restores_file_times(
 #[tracing::instrument]
 async fn filesystem_write_via_stream_replay_restores_file_times(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("file-service").store().await;
     let worker_id = executor.start_worker(&component_id, "file-service-3").await;
@@ -2081,7 +2181,7 @@ async fn filesystem_write_via_stream_replay_restores_file_times(
         .unwrap();
 
     drop(executor);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let times2 = executor
         .invoke_and_await(
@@ -2101,9 +2201,13 @@ async fn filesystem_write_via_stream_replay_restores_file_times(
 
 #[test]
 #[tracing::instrument]
-async fn filesystem_metadata_hash(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn filesystem_metadata_hash(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("file-service").store().await;
     let worker_id = executor.start_worker(&component_id, "file-service-3").await;
@@ -2129,7 +2233,7 @@ async fn filesystem_metadata_hash(last_unique_id: &LastUniqueId, deps: &Deps, _t
         .unwrap();
 
     drop(executor);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let hash2 = executor
         .invoke_and_await(
@@ -2149,9 +2253,13 @@ async fn filesystem_metadata_hash(last_unique_id: &LastUniqueId, deps: &Deps, _t
 
 #[test]
 #[tracing::instrument]
-async fn ip_address_resolve(last_unique_id: &LastUniqueId, deps: &Deps, _tracing: &Tracing) {
+async fn ip_address_resolve(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor.component("networking").store().await;
     let worker_id = executor
@@ -2164,7 +2272,7 @@ async fn ip_address_resolve(last_unique_id: &LastUniqueId, deps: &Deps, _tracing
         .unwrap();
 
     drop(executor);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     // If the recovery succeeds, that means that the replayed IP address resolution produced the same result as expected
 
@@ -2187,11 +2295,11 @@ async fn ip_address_resolve(last_unique_id: &LastUniqueId, deps: &Deps, _tracing
 #[tracing::instrument]
 async fn wasi_incoming_request_handler(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor
         .component("wasi-http-incoming-request-handler")
@@ -2247,11 +2355,11 @@ async fn wasi_incoming_request_handler(
 #[tracing::instrument]
 async fn wasi_incoming_request_handler_echo(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor
         .component("wasi-http-incoming-request-handler-echo")
@@ -2392,11 +2500,11 @@ async fn wasi_incoming_request_handler_echo(
 #[tracing::instrument]
 async fn wasi_incoming_request_handler_state(
     last_unique_id: &LastUniqueId,
-    deps: &Deps,
+    deps: &WorkerExecutorTestDependencies,
     _tracing: &Tracing,
 ) {
     let context = TestContext::new(last_unique_id);
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let component_id = executor
         .component("wasi-http-incoming-request-handler-state")
@@ -2502,7 +2610,7 @@ async fn wasi_incoming_request_handler_state(
     );
 
     // restart executor and check whether we are restoring the state
-    let executor = start(deps, &context).await.unwrap().into_admin();
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
 
     let result3 = executor
         .invoke_and_await(
@@ -2536,3 +2644,91 @@ async fn wasi_incoming_request_handler_state(
             ])
     );
 }
+
+#[test]
+#[tracing::instrument]
+async fn wasi_config_initial_worker_config(
+    last_unique_id: &LastUniqueId,
+    deps: &WorkerExecutorTestDependencies,
+    _tracing: &Tracing,
+) {
+    let context = TestContext::new(last_unique_id);
+    let executor = start(deps, &context).await.unwrap().into_admin().await;
+
+    let component_id = executor.component("golem_it_wasi_config").store().await;
+
+    let worker_id = executor
+        .start_worker_with(
+            &component_id,
+            "worker-1",
+            Vec::new(),
+            HashMap::new(),
+            vec![
+                ("k1".to_string(), "v1".to_string()),
+                ("k2".to_string(), "v2".to_string()),
+            ],
+        )
+        .await;
+
+    {
+        // get existing key
+
+        let result = executor
+            .invoke_and_await(
+                &worker_id,
+                "golem-it:wasi-config-exports/golem-it-wasi-config-api.{get}",
+                vec!["k1".into_value_and_type()],
+            )
+            .await
+            .unwrap();
+
+        assert_eq!(
+            result,
+            vec![Value::Option(Some(Box::new(Value::String(
+                "v1".to_string()
+            ))))]
+        )
+    }
+
+    {
+        // get non-existent key
+
+        let result = executor
+            .invoke_and_await(
+                &worker_id,
+                "golem-it:wasi-config-exports/golem-it-wasi-config-api.{get}",
+                vec!["k3".into_value_and_type()],
+            )
+            .await
+            .unwrap();
+
+        assert_eq!(result, vec![Value::Option(None)])
+    }
+
+    {
+        // get all keys
+
+        let result = executor
+            .invoke_and_await(
+                &worker_id,
+                "golem-it:wasi-config-exports/golem-it-wasi-config-api.{get-all}",
+                vec![],
+            )
+            .await
+            .unwrap();
+
+        assert_eq!(
+            result,
+            vec![Value::List(vec![
+                Value::Tuple(vec![
+                    Value::String("k1".to_string()),
+                    Value::String("v1".to_string())
+                ]),
+                Value::Tuple(vec![
+                    Value::String("k2".to_string()),
+                    Value::String("v2".to_string())
+                ])
+            ])]
+        )
+    }
+}
diff --git a/golem-worker-service/src/api/api_definition.rs b/golem-worker-service/src/api/api_definition.rs
index 27c4ba90..d13c6e6e 100644
--- a/golem-worker-service/src/api/api_definition.rs
+++ b/golem-worker-service/src/api/api_definition.rs
@@ -15,12 +15,13 @@
 use super::dto::HttpApiDefinitionRequest;
 use super::dto::HttpApiDefinitionResponseData;
 use crate::api::common::ApiEndpointError;
+use crate::gateway_api_definition::http::api_oas_convert::OpenApiHttpApiDefinitionResponse;
 use crate::gateway_api_definition::http::HttpApiDefinitionRequest as CoreHttpApiDefinitionRequest;
 use crate::gateway_api_definition::http::OpenApiHttpApiDefinition;
 use crate::gateway_api_definition::{ApiDefinitionId, ApiVersion};
 use crate::service::auth::AuthService;
 use crate::service::gateway::api_definition::ApiDefinitionService;
-use futures_util::future::try_join_all;
+use futures::future::try_join_all;
 use golem_common::json_yaml::JsonOrYaml;
 use golem_common::model::auth::AuthCtx;
 use golem_common::model::auth::ProjectAction;
@@ -434,4 +435,72 @@ impl ApiDefinitionApi {
 
         record.result(response)
     }
+
+    /// Export an API definition in OpenAPI format
+    ///
+    /// Exports an API definition by its API definition ID and version in OpenAPI format.
+    #[oai(
+        path = "/:project_id/:id/:version/export",
+        method = "get",
+        operation_id = "export_definition"
+    )]
+    async fn export(
+        &self,
+        project_id: Path<ProjectId>,
+        id: Path<ApiDefinitionId>,
+        version: Path<ApiVersion>,
+        token: GolemSecurityScheme,
+    ) -> Result<Json<OpenApiHttpApiDefinitionResponse>, ApiEndpointError> {
+        let record = recorded_http_api_request!(
+            "export_definition",
+            api_definition_id = id.0.to_string(),
+            version = version.0.to_string(),
+            project_id = project_id.0.to_string()
+        );
+
+        let response = self
+            .export_internal(project_id.0, id.0, version.0, token)
+            .instrument(record.span.clone())
+            .await;
+        record.result(response)
+    }
+
+    async fn export_internal(
+        &self,
+        project_id: ProjectId,
+        api_definition_id: ApiDefinitionId,
+        api_version: ApiVersion,
+        token: GolemSecurityScheme,
+    ) -> Result<Json<OpenApiHttpApiDefinitionResponse>, ApiEndpointError> {
+        let auth_ctx = AuthCtx::new(token.secret());
+        let namespace = self
+            .auth_service
+            .authorize_project_action(&project_id, ProjectAction::ExportApiDefinition, &auth_ctx)
+            .await?;
+
+        let data = self
+            .definition_service
+            .get(&api_definition_id, &api_version, &namespace, &auth_ctx)
+            .await?;
+
+        let compiled_definition = data.ok_or(ApiEndpointError::not_found(safe(format!(
+            "Can't find api definition with id {api_definition_id}, and version {api_version} in project {project_id}"
+        ))))?;
+
+        let conversion_context = self
+            .definition_service
+            .conversion_context(&namespace, &auth_ctx);
+
+        let response = OpenApiHttpApiDefinitionResponse::from_compiled_http_api_definition(
+            &compiled_definition,
+            &conversion_context,
+        )
+        .await
+        .map_err(|e| {
+            error!("Failed to convert to OpenAPI: {}", e);
+            ApiEndpointError::internal(safe(e.to_string()))
+        })?;
+
+        Ok(Json(response))
+    }
 }
diff --git a/golem-worker-service/src/api/common.rs b/golem-worker-service/src/api/common.rs
index fc972f4b..658facee 100644
--- a/golem-worker-service/src/api/common.rs
+++ b/golem-worker-service/src/api/common.rs
@@ -159,6 +159,7 @@ impl From<WorkerServiceError> for ApiEndpointError {
 
             WorkerServiceError::GolemError(inner) => inner.into(),
             WorkerServiceError::Component(inner) => inner.into(),
+            WorkerServiceError::Project(inner) => inner.into(),
             WorkerServiceError::InternalCallError(inner) => inner.into(),
             WorkerServiceError::LimitError(inner) => inner.into(),
         }
diff --git a/golem-worker-service/src/api/worker.rs b/golem-worker-service/src/api/worker.rs
index 914024e9..de38a7ed 100644
--- a/golem-worker-service/src/api/worker.rs
+++ b/golem-worker-service/src/api/worker.rs
@@ -19,15 +19,16 @@ use crate::service::component::ComponentService;
 use crate::service::worker::{proxy_worker_connection, InvocationParameters};
 use crate::service::worker::{ConnectWorkerStream, WorkerService};
 use futures::StreamExt;
-use futures_util::TryStreamExt;
+use futures::TryStreamExt;
 use golem_common::model::auth::AuthCtx;
 use golem_common::model::auth::{ProjectAction, TokenSecret};
 use golem_common::model::error::{ErrorBody, ErrorsBody};
 use golem_common::model::oplog::OplogIndex;
 use golem_common::model::public_oplog::OplogCursor;
+use golem_common::model::worker::WorkerCreationRequest;
 use golem_common::model::{
-    ComponentFilePath, ComponentId, IdempotencyKey, PluginInstallationId, ScanCursor,
-    TargetWorkerId, WorkerFilter, WorkerId,
+    ComponentFilePath, ComponentId, IdempotencyKey, PluginInstallationId, ScanCursor, WorkerFilter,
+    WorkerId,
 };
 use golem_common::recorded_http_api_request;
 use golem_service_base::api_tags::ApiTags;
@@ -123,7 +124,12 @@ impl WorkerApi {
                 }))
             })?;
 
-        let WorkerCreationRequest { name, args, env } = request;
+        let WorkerCreationRequest {
+            name,
+            args,
+            env,
+            wasi_config_vars,
+        } = request;
 
         let worker_id = validated_worker_id(component_id, name)?;
 
@@ -139,6 +145,8 @@ impl WorkerApi {
                 latest_component.versioned_component_id.version,
                 args,
                 env,
+                wasi_config_vars.into(),
+                false,
                 namespace,
             )
             .await?;
@@ -218,7 +226,7 @@ impl WorkerApi {
 
         let response = self
             .invoke_and_await_function_internal(
-                worker_id.into_target_worker_id(),
+                worker_id,
                 idempotency_key.0,
                 function.0,
                 params.0,
@@ -232,7 +240,7 @@ impl WorkerApi {
 
     async fn invoke_and_await_function_internal(
         &self,
-        target_worker_id: TargetWorkerId,
+        target_worker_id: WorkerId,
         idempotency_key: Option<IdempotencyKey>,
         function: String,
         params: InvokeParameters,
@@ -280,46 +288,6 @@ impl WorkerApi {
         Ok(Json(InvokeResult { result }))
     }
 
-    /// Invoke a function and await its resolution on a new worker with a random generated name
-    ///
-    /// Ideal for invoking ephemeral components, but works with durable ones as well.
-    /// Supply the parameters in the request body as JSON.
-    #[oai(
-        path = "/:component_id/invoke-and-await",
-        method = "post",
-        operation_id = "invoke_and_await_function_without_name"
-    )]
-    async fn invoke_and_await_function_without_name(
-        &self,
-        component_id: Path<ComponentId>,
-        #[oai(name = "Idempotency-Key")] idempotency_key: Header<Option<IdempotencyKey>>,
-        function: Query<String>,
-        params: Json<InvokeParameters>,
-        token: GolemSecurityScheme,
-    ) -> Result<Json<InvokeResult>> {
-        let target_worker_id = make_target_worker_id(component_id.0, None)?;
-
-        let record = recorded_http_api_request!(
-            "invoke_and_await_function_without_name",
-            worker_id = target_worker_id.to_string(),
-            idempotency_key = idempotency_key.0.as_ref().map(|v| v.value.clone()),
-            function = function.0
-        );
-
-        let response = self
-            .invoke_and_await_function_internal(
-                target_worker_id,
-                idempotency_key.0,
-                function.0,
-                params.0,
-                token,
-            )
-            .instrument(record.span.clone())
-            .await;
-
-        record.result(response)
-    }
-
     /// Invoke a function
     ///
     /// A simpler version of the previously defined invoke and await endpoint just triggers the execution of a function and immediately returns.
@@ -348,13 +316,7 @@ impl WorkerApi {
         );
 
         let response = self
-            .invoke_function_internal(
-                worker_id.into_target_worker_id(),
-                idempotency_key.0,
-                function.0,
-                params.0,
-                token,
-            )
+            .invoke_function_internal(worker_id, idempotency_key.0, function.0, params.0, token)
             .instrument(record.span.clone())
             .await;
 
@@ -363,7 +325,7 @@ impl WorkerApi {
 
     async fn invoke_function_internal(
         &self,
-        target_worker_id: TargetWorkerId,
+        target_worker_id: WorkerId,
         idempotency_key: Option<IdempotencyKey>,
         function: String,
         params: InvokeParameters,
@@ -405,47 +367,6 @@ impl WorkerApi {
         Ok(Json(InvokeResponse {}))
     }
 
-    /// Invoke a function on a new worker with a random generated name
-    ///
-    /// Ideal for invoking ephemeral components, but works with durable ones as well.
-    /// A simpler version of the previously defined invoke and await endpoint just triggers the execution of a function and immediately returns.
-    #[oai(
-        path = "/:component_id/invoke",
-        method = "post",
-        operation_id = "invoke_function_without_name"
-    )]
-    async fn invoke_function_without_name(
-        &self,
-        component_id: Path<ComponentId>,
-        #[oai(name = "Idempotency-Key")] idempotency_key: Header<Option<IdempotencyKey>>,
-        /// name of the exported function to be invoked
-        function: Query<String>,
-        params: Json<InvokeParameters>,
-        token: GolemSecurityScheme,
-    ) -> Result<Json<InvokeResponse>> {
-        let target_worker_id = make_target_worker_id(component_id.0, None)?;
-
-        let record = recorded_http_api_request!(
-            "invoke_function_without_name",
-            worker_id = target_worker_id.to_string(),
-            idempotency_key = idempotency_key.0.as_ref().map(|v| v.value.clone()),
-            function = function.0
-        );
-
-        let response = self
-            .invoke_function_internal(
-                target_worker_id,
-                idempotency_key.0,
-                function.0,
-                params.0,
-                token,
-            )
-            .instrument(record.span.clone())
-            .await;
-
-        record.result(response)
-    }
-
     /// Complete a promise
     ///
     /// Completes a promise with a given custom array of bytes.
@@ -674,7 +595,7 @@ impl WorkerApi {
         count: Option<u64>,
         precise: Option<bool>,
         token: GolemSecurityScheme,
-    ) -> Result<Json<crate::model::WorkersMetadataResponse>> {
+    ) -> Result<Json<model::WorkersMetadataResponse>> {
         let auth = AuthCtx::new(token.secret());
         let namespace = self
             .worker_auth_service
@@ -710,10 +631,7 @@ impl WorkerApi {
             )
             .await?;
 
-        Ok(Json(crate::model::WorkersMetadataResponse {
-            workers,
-            cursor,
-        }))
+        Ok(Json(model::WorkersMetadataResponse { workers, cursor }))
     }
 
     /// Advanced search for workers
@@ -747,7 +665,7 @@ impl WorkerApi {
         component_id: Path<ComponentId>,
         params: Json<WorkersMetadataRequest>,
         token: GolemSecurityScheme,
-    ) -> Result<Json<crate::model::WorkersMetadataResponse>> {
+    ) -> Result<Json<model::WorkersMetadataResponse>> {
         let record = recorded_http_api_request!(
             "find_workers_metadata",
             component_id = component_id.0.to_string()
@@ -766,7 +684,7 @@ impl WorkerApi {
         component_id: ComponentId,
         params: WorkersMetadataRequest,
         token: GolemSecurityScheme,
-    ) -> Result<Json<crate::model::WorkersMetadataResponse>> {
+    ) -> Result<Json<model::WorkersMetadataResponse>> {
         let auth = AuthCtx::new(token.secret());
         let namespace = self
             .worker_auth_service
@@ -784,10 +702,7 @@ impl WorkerApi {
             )
             .await?;
 
-        Ok(Json(crate::model::WorkersMetadataResponse {
-            workers,
-            cursor,
-        }))
+        Ok(Json(model::WorkersMetadataResponse { workers, cursor }))
     }
 
     /// Resume a worker
@@ -1001,7 +916,7 @@ impl WorkerApi {
 
         let nodes = self
             .worker_service
-            .list_directory(&worker_id.into_target_worker_id(), path, namespace)
+            .get_file_system_node(&worker_id, path, namespace)
             .await?;
 
         Ok(Json(GetFilesResponse {
@@ -1049,7 +964,7 @@ impl WorkerApi {
 
         let bytes = self
             .worker_service
-            .get_file_contents(&worker_id.into_target_worker_id(), path, namespace)
+            .get_file_contents(&worker_id, path, namespace)
             .await?;
 
         Ok(Binary(Body::from_bytes_stream(
@@ -1339,25 +1254,6 @@ fn validated_worker_id(component_id: ComponentId, worker_name: String) -> Result
     })
 }
 
-// TODO: should be in a base library
-fn make_target_worker_id(
-    component_id: ComponentId,
-    worker_name: Option<String>,
-) -> Result<TargetWorkerId> {
-    if let Some(worker_name) = &worker_name {
-        WorkerId::validate_worker_name(worker_name).map_err(|error| {
-            ApiEndpointError::BadRequest(Json(ErrorsBody {
-                errors: vec![format!("Invalid worker name: {error}")],
-            }))
-        })?;
-    }
-
-    Ok(TargetWorkerId {
-        component_id,
-        worker_name,
-    })
-}
-
 // TODO: should be in a base library
 fn make_component_file_path(name: String) -> Result<ComponentFilePath> {
     ComponentFilePath::from_rel_str(&name).map_err(|error| {
diff --git a/golem-worker-service/src/config.rs b/golem-worker-service/src/config.rs
index 54a7e135..3014e403 100644
--- a/golem-worker-service/src/config.rs
+++ b/golem-worker-service/src/config.rs
@@ -18,12 +18,13 @@ use golem_common::config::{ConfigExample, ConfigLoader, HasConfigExamples};
 use golem_common::config::{DbConfig, DbSqliteConfig};
 use golem_common::model::RetryConfig;
 use golem_common::tracing::TracingConfig;
+use golem_common::SafeDisplay;
 use golem_service_base::clients::RemoteServiceConfig;
 use golem_service_base::config::BlobStorageConfig;
 use golem_service_base::service::routing_table::RoutingTableConfig;
 use http::Uri;
 use serde::{Deserialize, Serialize};
-use std::fmt::Debug;
+use std::fmt::{Debug, Write};
 use std::path::PathBuf;
 use std::time::Duration;
 use url::Url;
@@ -55,6 +56,76 @@ impl WorkerServiceConfig {
     }
 }
 
+impl SafeDisplay for WorkerServiceConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "environment: {}", self.environment);
+        let _ = writeln!(&mut result, "tracing:");
+        let _ = writeln!(&mut result, "{}", self.tracing.to_safe_string_indented());
+        let _ = writeln!(&mut result, "gateway session storage:");
+        let _ = writeln!(
+            result,
+            "{}",
+            self.gateway_session_storage.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "db:");
+        let _ = writeln!(&mut result, "{}", self.db.to_safe_string_indented());
+        let _ = writeln!(&mut result, "component service:");
+        let _ = writeln!(
+            result,
+            "{}",
+            self.component_service.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "HTTP port: {}", self.port);
+        let _ = writeln!(
+            &mut result,
+            "Custom request port: {}",
+            self.custom_request_port
+        );
+        let _ = writeln!(&mut result, "gRPC port: {}", self.worker_grpc_port);
+        let _ = writeln!(&mut result, "routing table:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.routing_table.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "worker executor retries:");
+        let _ = writeln!(
+            result,
+            "{}",
+            self.worker_executor_retries.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "blob storage:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.blob_storage.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "API definition service:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.api_definition.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "workspace: {}", self.workspace);
+        let _ = writeln!(&mut result, "domain records:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.domain_records.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "cloud service:");
+        let _ = writeln!(
+            &mut result,
+            "{}",
+            self.cloud_service.to_safe_string_indented()
+        );
+        let _ = writeln!(&mut result, "CORS origin regex: {}", self.cors_origin_regex);
+
+        result
+    }
+}
+
 impl Default for WorkerServiceConfig {
     fn default() -> Self {
         Self {
@@ -116,6 +187,23 @@ pub enum GatewaySessionStorageConfig {
     Sqlite(DbSqliteConfig),
 }
 
+impl SafeDisplay for GatewaySessionStorageConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        match self {
+            GatewaySessionStorageConfig::Redis(redis) => {
+                let _ = writeln!(&mut result, "redis:");
+                let _ = writeln!(&mut result, "{}", redis.to_safe_string_indented());
+            }
+            GatewaySessionStorageConfig::Sqlite(sqlite) => {
+                let _ = writeln!(&mut result, "sqlite:");
+                let _ = writeln!(&mut result, "{}", sqlite.to_safe_string_indented());
+            }
+        }
+        result
+    }
+}
+
 impl Default for GatewaySessionStorageConfig {
     fn default() -> Self {
         Self::default_redis()
@@ -153,6 +241,19 @@ impl ComponentServiceConfig {
     }
 }
 
+impl SafeDisplay for ComponentServiceConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(&mut result, "host: {}", self.host);
+        let _ = writeln!(&mut result, "port: {}", self.port);
+        let _ = writeln!(&mut result, "access token: ****");
+        let _ = writeln!(&mut result, "connect timeout: {:?}", self.connect_timeout);
+        let _ = writeln!(&mut result, "retries:");
+        let _ = writeln!(&mut result, "{}", self.retries.to_safe_string_indented());
+        result
+    }
+}
+
 impl Default for ComponentServiceConfig {
     fn default() -> Self {
         Self {
@@ -173,6 +274,28 @@ pub struct DomainRecordsConfig {
     pub register_domain_black_list: Vec<String>,
 }
 
+impl SafeDisplay for DomainRecordsConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(
+            &mut result,
+            "subdomain black list: {}",
+            self.subdomain_black_list.join(", ")
+        );
+        let _ = writeln!(
+            &mut result,
+            "domain allow list: {}",
+            self.domain_allow_list.join(", ")
+        );
+        let _ = writeln!(
+            &mut result,
+            "register domain black list: {}",
+            self.register_domain_black_list.join(", ")
+        );
+        result
+    }
+}
+
 impl Default for DomainRecordsConfig {
     fn default() -> Self {
         Self {
@@ -251,8 +374,6 @@ pub fn make_worker_service_config_loader() -> ConfigLoader<WorkerServiceConfig>
 
 #[cfg(test)]
 mod tests {
-    use std::env;
-    use std::path::PathBuf;
     use test_r::test;
 
     use super::make_worker_service_config_loader;
@@ -260,9 +381,6 @@ mod tests {
 
     #[test]
     pub fn config_is_loadable() {
-        env::set_current_dir(PathBuf::from(env!("CARGO_MANIFEST_DIR")))
-            .expect("Failed to set current directory");
-
         make_worker_service_config_loader()
             .load_or_dump_config()
             .expect("Failed to load config");
diff --git a/golem-worker-service/src/gateway_api_definition/http/api_definition.rs b/golem-worker-service/src/gateway_api_definition/http/api_definition.rs
index 826c8c79..96f8c4ee 100644
--- a/golem-worker-service/src/gateway_api_definition/http/api_definition.rs
+++ b/golem-worker-service/src/gateway_api_definition/http/api_definition.rs
@@ -13,9 +13,12 @@
 // limitations under the License.
 
 use crate::gateway_api_definition::http::path_pattern_parser::parse_path_pattern;
-use crate::gateway_api_definition::http::{HttpApiDefinitionRequest, RouteRequest};
+use crate::gateway_api_definition::http::{
+    HttpApiDefinitionRequest, OpenApiHttpApiDefinition, RouteRequest,
+};
 use crate::gateway_api_definition::{ApiDefinitionId, ApiVersion, HasGolemBindings};
 use crate::gateway_api_definition_transformer::transform_http_api_definition;
+use crate::gateway_binding::SwaggerUiBinding;
 use crate::gateway_binding::{
     FileServerBindingCompiled, GatewayBinding, GatewayBindingCompiled, IdempotencyKeyCompiled,
     InvocationContextCompiled, ResponseMappingCompiled, StaticBinding, WorkerNameCompiled,
@@ -28,9 +31,8 @@ use crate::gateway_security::SecuritySchemeReference;
 use crate::service::gateway::api_definition::ApiDefinitionError;
 use crate::service::gateway::api_definition_validator::ValidationErrors;
 use crate::service::gateway::security_scheme::SecuritySchemeService;
+use crate::service::gateway::BoxConversionContext;
 use bincode::{Decode, Encode};
-use golem_api_grpc::proto::golem::apidefinition as grpc_apidefinition;
-use golem_api_grpc::proto::golem::apidefinition::HttpRoute;
 use golem_common::model::auth::Namespace;
 use golem_common::model::component::VersionedComponentId;
 use golem_service_base::model::Component;
@@ -45,7 +47,6 @@ use std::fmt::{Debug, Display, Formatter};
 use std::ops::Deref;
 use std::str::FromStr;
 use std::sync::Arc;
-use std::time::SystemTime;
 use Iterator;
 
 #[derive(Debug, Clone, PartialEq)]
@@ -186,64 +187,6 @@ impl From<CompiledHttpApiDefinition> for HttpApiDefinition {
     }
 }
 
-impl TryFrom<grpc_apidefinition::ApiDefinition> for HttpApiDefinition {
-    type Error = String;
-    fn try_from(value: grpc_apidefinition::ApiDefinition) -> Result<Self, Self::Error> {
-        let routes = match value.definition.ok_or("definition is missing")? {
-            grpc_apidefinition::api_definition::Definition::Http(http) => http
-                .routes
-                .into_iter()
-                .map(crate::gateway_api_definition::http::Route::try_from)
-                .collect::<Result<Vec<crate::gateway_api_definition::http::Route>, String>>()?,
-        };
-        let id = value.id.ok_or("Api Definition ID is missing")?;
-        let created_at = value
-            .created_at
-            .ok_or("Created At is missing")
-            .and_then(|t| SystemTime::try_from(t).map_err(|_| "Failed to convert timestamp"))?;
-        let result = crate::gateway_api_definition::http::HttpApiDefinition {
-            id: ApiDefinitionId(id.value),
-            version: ApiVersion(value.version),
-            routes,
-            draft: value.draft,
-            created_at: created_at.into(),
-        };
-        Ok(result)
-    }
-}
-
-impl TryFrom<HttpApiDefinition> for grpc_apidefinition::ApiDefinition {
-    type Error = String;
-
-    fn try_from(
-        value: crate::gateway_api_definition::http::HttpApiDefinition,
-    ) -> Result<Self, Self::Error> {
-        let routes = value
-            .routes
-            .into_iter()
-            .map(grpc_apidefinition::HttpRoute::try_from)
-            .collect::<Result<Vec<grpc_apidefinition::HttpRoute>, String>>()?;
-
-        let id = value.id.0;
-
-        let definition = grpc_apidefinition::HttpApiDefinition { routes };
-
-        let created_at = prost_types::Timestamp::from(SystemTime::from(value.created_at));
-
-        let result = grpc_apidefinition::ApiDefinition {
-            id: Some(grpc_apidefinition::ApiDefinitionId { value: id }),
-            version: value.version.0,
-            definition: Some(grpc_apidefinition::api_definition::Definition::Http(
-                definition,
-            )),
-            draft: value.draft,
-            created_at: Some(created_at),
-        };
-
-        Ok(result)
-    }
-}
-
 // The Rib Expressions that exists in various parts of HttpApiDefinition (mainly in Routes)
 // are compiled to form CompiledHttpApiDefinition.
 // The Compilation happens during API definition registration,
@@ -290,6 +233,7 @@ impl CompiledHttpApiDefinition {
         http_api_definition: &HttpApiDefinition,
         metadata_dictionary: &ComponentMetadataDictionary,
         namespace: &Namespace,
+        conversion_context: &BoxConversionContext<'_>,
     ) -> Result<Self, RouteCompilationErrors> {
         let mut compiled_routes = vec![];
 
@@ -298,14 +242,45 @@ impl CompiledHttpApiDefinition {
             compiled_routes.push(compiled_route);
         }
 
-        Ok(CompiledHttpApiDefinition {
+        let mut result = CompiledHttpApiDefinition {
             id: http_api_definition.id.clone(),
             version: http_api_definition.version.clone(),
             routes: compiled_routes,
             draft: http_api_definition.draft,
             created_at: http_api_definition.created_at,
             namespace: namespace.clone(),
-        })
+        };
+        // Update SwaggerUI routes with actual OpenAPI spec
+        result.update_swagger_ui_openapi_specs(conversion_context);
+        Ok(result)
+    }
+
+    pub fn update_swagger_ui_openapi_specs(
+        &mut self,
+        conversion_context: &BoxConversionContext<'_>,
+    ) {
+        let openapi_spec_json = self.generate_openapi_spec_json(conversion_context).ok();
+
+        // Update all SwaggerUI routes with the actual OpenAPI spec
+        for route in &mut self.routes {
+            if let crate::gateway_binding::GatewayBindingCompiled::SwaggerUi(swagger_binding) =
+                &mut route.binding
+            {
+                swagger_binding.openapi_spec_json = openapi_spec_json.clone();
+            }
+        }
+    }
+
+    /// Generates the OpenAPI specification JSON for this compiled API definition
+    fn generate_openapi_spec_json(
+        &self,
+        conversion_context: &BoxConversionContext<'_>,
+    ) -> Result<String, String> {
+        let openapi = futures::executor::block_on(
+            OpenApiHttpApiDefinition::from_compiled_http_api_definition(self, conversion_context),
+        )?;
+        serde_json::to_string_pretty(&openapi.0)
+            .map_err(|e| format!("Failed to serialize OpenAPI to JSON: {e}"))
     }
 }
 
@@ -449,22 +424,6 @@ impl<'de> Deserialize<'de> for MethodPattern {
     }
 }
 
-impl From<MethodPattern> for grpc_apidefinition::HttpMethod {
-    fn from(value: MethodPattern) -> Self {
-        match value {
-            MethodPattern::Get => grpc_apidefinition::HttpMethod::Get,
-            MethodPattern::Post => grpc_apidefinition::HttpMethod::Post,
-            MethodPattern::Put => grpc_apidefinition::HttpMethod::Put,
-            MethodPattern::Delete => grpc_apidefinition::HttpMethod::Delete,
-            MethodPattern::Patch => grpc_apidefinition::HttpMethod::Patch,
-            MethodPattern::Head => grpc_apidefinition::HttpMethod::Head,
-            MethodPattern::Options => grpc_apidefinition::HttpMethod::Options,
-            MethodPattern::Trace => grpc_apidefinition::HttpMethod::Trace,
-            MethodPattern::Connect => grpc_apidefinition::HttpMethod::Connect,
-        }
-    }
-}
-
 #[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize, Encode, Decode)]
 pub struct LiteralInfo(pub String);
 
@@ -614,48 +573,6 @@ impl Route {
     }
 }
 
-impl TryFrom<HttpRoute> for Route {
-    type Error = String;
-
-    fn try_from(http_route: HttpRoute) -> Result<Self, Self::Error> {
-        let binding = http_route.binding.ok_or("Missing binding")?;
-        let middlewares = http_route
-            .middleware
-            .map(HttpMiddlewares::try_from)
-            .transpose()?;
-
-        Ok(Route {
-            method: MethodPattern::try_from(http_route.method)?,
-            path: AllPathPatterns::from_str(http_route.path.as_str())?,
-            binding: GatewayBinding::try_from(binding)?,
-            middlewares,
-        })
-    }
-}
-
-impl TryFrom<Route> for grpc_apidefinition::HttpRoute {
-    type Error = String;
-
-    fn try_from(value: crate::gateway_api_definition::http::Route) -> Result<Self, Self::Error> {
-        let path = value.path.to_string();
-        let binding = grpc_apidefinition::GatewayBinding::try_from(value.binding)?;
-        let method: grpc_apidefinition::HttpMethod = value.method.into();
-        let middlewares = value.middlewares.clone();
-        let middleware_proto = middlewares
-            .map(golem_api_grpc::proto::golem::apidefinition::Middleware::try_from)
-            .transpose()?;
-
-        let result = grpc_apidefinition::HttpRoute {
-            method: method as i32,
-            path,
-            binding: Some(binding),
-            middleware: middleware_proto,
-        };
-
-        Ok(result)
-    }
-}
-
 #[derive(Debug, Clone, PartialEq)]
 pub struct CompiledRoute {
     pub method: MethodPattern,
@@ -763,13 +680,13 @@ impl ComponentMetadataDictionary {
             let component_info = ComponentDependencyKey {
                 component_name: component.component_name.0.clone(),
                 component_id: component.versioned_component_id.component_id.0,
-                root_package_name: component.metadata.root_package_name.clone(),
-                root_package_version: component.metadata.root_package_version.clone(),
+                root_package_name: component.metadata.root_package_name().clone(),
+                root_package_version: component.metadata.root_package_version().clone(),
             };
 
             let component_details = ComponentDetails {
                 component_info,
-                metadata: component.metadata.exports.clone(),
+                metadata: component.metadata.exports().to_vec(),
             };
 
             metadata.insert(component.versioned_component_id.clone(), component_details);
@@ -903,6 +820,16 @@ impl CompiledRoute {
                 binding: GatewayBindingCompiled::Static(static_binding.clone()),
                 middlewares: route.middlewares.clone(),
             }),
+
+            GatewayBinding::SwaggerUi(_) => {
+                // SwaggerUI binding starts with None - will be populated after full compilation
+                Ok(CompiledRoute {
+                    method: route.method.clone(),
+                    path: route.path.clone(),
+                    binding: GatewayBindingCompiled::SwaggerUi(SwaggerUiBinding::new()),
+                    middlewares: route.middlewares.clone(),
+                })
+            }
         }
     }
 
@@ -1119,18 +1046,7 @@ impl From<CompiledRoute> for Route {
 mod tests {
     use super::*;
 
-    use crate::service::gateway::{ComponentView, ConversionContext};
-    use async_trait::async_trait;
-    use golem_common::model::{AccountId, ComponentId, ProjectId};
-    use golem_service_base::model::ComponentName;
-
-    use crate::gateway_security::{
-        SecurityScheme, SecuritySchemeIdentifier, SecuritySchemeWithProviderMetadata,
-    };
-    use crate::service::gateway::security_scheme::SecuritySchemeServiceError;
-    use chrono::{DateTime, Utc};
     use test_r::test;
-    use uuid::uuid;
 
     #[test]
     fn split_path_works_with_single_value() {
@@ -1308,136 +1224,4 @@ mod tests {
     fn expr_worker_response() {
         test_string_expr_parse_and_encode("worker.response");
     }
-
-    fn get_api_spec(
-        path_pattern: &str,
-        worker_id: &str,
-        response_mapping: &str,
-    ) -> serde_yaml::Value {
-        let yaml_string = format!(
-            r#"
-          id: users-api
-          version: 0.0.1
-          projectId: '15d70aa5-2e23-4ee3-b65c-4e1d702836a3'
-          createdAt: 2024-08-21T07:42:15.696Z
-          routes:
-          - method: Get
-            path: {path_pattern}
-            binding:
-              component:
-                version: 0
-                name: 'foobar'
-              workerName: '{worker_id}'
-              response: '{response_mapping}'
-
-        "#
-        );
-
-        let de = serde_yaml::Deserializer::from_str(yaml_string.as_str());
-        serde_yaml::Value::deserialize(de).unwrap()
-    }
-
-    struct TestConversionContext;
-
-    #[async_trait]
-    impl ConversionContext for TestConversionContext {
-        async fn component_by_name(&self, name: &ComponentName) -> Result<ComponentView, String> {
-            if name.0 == "foobar" {
-                Ok(ComponentView {
-                    name: ComponentName("foobar".to_string()),
-                    id: ComponentId(uuid!("15d70aa5-2e23-4ee3-b65c-4e1d702836a3")),
-                    latest_version: 0,
-                })
-            } else {
-                Err("unknown component name".to_string())
-            }
-        }
-        async fn component_by_id(
-            &self,
-            _component_id: &ComponentId,
-        ) -> Result<ComponentView, String> {
-            unimplemented!()
-        }
-    }
-
-    struct TestSecuritySchemeService;
-
-    #[async_trait]
-    impl SecuritySchemeService for TestSecuritySchemeService {
-        async fn get(
-            &self,
-            _security_scheme_name: &SecuritySchemeIdentifier,
-            _namespace: &Namespace,
-        ) -> Result<SecuritySchemeWithProviderMetadata, SecuritySchemeServiceError> {
-            Err(SecuritySchemeServiceError::InternalError(
-                "Not implemented".to_string(),
-            ))
-        }
-
-        async fn create(
-            &self,
-            _namespace: &Namespace,
-            _security_scheme: &SecurityScheme,
-        ) -> Result<SecuritySchemeWithProviderMetadata, SecuritySchemeServiceError> {
-            Err(SecuritySchemeServiceError::InternalError(
-                "Not implemented".to_string(),
-            ))
-        }
-    }
-
-    #[test]
-    async fn test_api_spec_proto_conversion() {
-        async fn test_encode_decode(path_pattern: &str, worker_id: &str, response_mapping: &str) {
-            let security_scheme_service: Arc<dyn SecuritySchemeService> =
-                Arc::new(TestSecuritySchemeService);
-
-            let yaml = get_api_spec(path_pattern, worker_id, response_mapping);
-            let api_http_definition_request: crate::api::dto::HttpApiDefinitionRequest =
-                serde_yaml::from_value(yaml.clone()).unwrap();
-
-            let core_http_definition_request: HttpApiDefinitionRequest =
-                api_http_definition_request
-                    .into_core(&TestConversionContext.boxed())
-                    .await
-                    .unwrap();
-            let timestamp: DateTime<Utc> = "2024-08-21T07:42:15.696Z".parse().unwrap();
-            let core_http_definition = HttpApiDefinition::from_http_api_definition_request(
-                &Namespace {
-                    account_id: AccountId {
-                        value: uuid!("15d70aa5-2e23-4ee3-b65c-4e1d702836a3").to_string(),
-                    },
-                    project_id: ProjectId(uuid!("017beaf5-43db-4acc-9c6e-8b90e35ef063")),
-                },
-                core_http_definition_request,
-                timestamp,
-                &security_scheme_service,
-            )
-            .await
-            .unwrap();
-            let proto: grpc_apidefinition::ApiDefinition =
-                core_http_definition.clone().try_into().unwrap();
-            let decoded: HttpApiDefinition = proto.try_into().unwrap();
-            assert_eq!(core_http_definition, decoded);
-        }
-        test_encode_decode(
-            "/foo/{user-id}",
-            "let x: string = request.path.user-id; \"shopping-cart-${if x>100 then 0 else 1}\"",
-            "${ let result = golem:it/api.{do-something}(request.body); {status: if result.user == \"admin\" then 401 else 200 } }",
-        ).await;
-        test_encode_decode(
-            "/foo/{user-id}",
-            "let x: string = request.path.user-id; \"shopping-cart-${if x>100 then 0 else 1}\"",
-            "${ let result = golem:it/api.{do-something}(request.body.foo); {status: if result.user == \"admin\" then 401 else 200 } }",
-        ).await;
-        test_encode_decode(
-            "/foo/{user-id}",
-            "let x: string = request.path.user-id; \"shopping-cart-${if x>100 then 0 else 1}\"",
-            "${ let result = golem:it/api.{do-something}(request.path.user-id); {status: if result.user == \"admin\" then 401 else 200 } }",
-        ).await;
-        test_encode_decode(
-            "/foo",
-            "let x: string = request.body.user-id; \"shopping-cart-${if x>100 then 0 else 1}\"",
-            "${ let result = golem:it/api.{do-something}(\"foo\"); {status: if result.user == \"admin\" then 401 else 200 } }",
-        ).await;
-    }
 }
diff --git a/golem-worker-service/src/gateway_api_definition/http/oas_api_definition.rs b/golem-worker-service/src/gateway_api_definition/http/oas_api_definition.rs
index c349701d..7e6c24a0 100644
--- a/golem-worker-service/src/gateway_api_definition/http/oas_api_definition.rs
+++ b/golem-worker-service/src/gateway_api_definition/http/oas_api_definition.rs
@@ -18,10 +18,12 @@ use crate::service::gateway::BoxConversionContext;
 use internal::*;
 use openapiv3::OpenAPI;
 use poem_openapi::registry::{MetaSchema, MetaSchemaRef};
-use poem_openapi::types::{ParseError, ParseFromJSON, ParseFromYAML, ParseResult};
+use poem_openapi::types::{ParseError, ParseFromJSON, ParseFromYAML, ParseResult, ToJSON};
+use serde::Serialize;
 use serde_json::Value;
 use std::borrow::Cow;
 
+#[derive(Serialize)]
 pub struct OpenApiHttpApiDefinition(pub OpenAPI);
 
 impl OpenApiHttpApiDefinition {
@@ -118,12 +120,19 @@ impl poem_openapi::types::Type for OpenApiHttpApiDefinition {
     }
 }
 
+impl ToJSON for OpenApiHttpApiDefinition {
+    fn to_json(&self) -> Option<serde_json::Value> {
+        serde_json::to_value(&self.0).ok()
+    }
+}
+
 mod internal {
 
     use crate::gateway_api_definition::http::{AllPathPatterns, MethodPattern, RouteRequest};
 
     use crate::gateway_binding::{
-        GatewayBinding, HttpHandlerBinding, ResponseMapping, StaticBinding, WorkerBinding,
+        GatewayBinding, HttpHandlerBinding, ResponseMapping, StaticBinding, SwaggerUiBinding,
+        WorkerBinding,
     };
     use crate::gateway_middleware::{CorsPreflightExpr, HttpCors};
     use crate::gateway_security::{SecuritySchemeIdentifier, SecuritySchemeReference};
@@ -277,6 +286,14 @@ mod internal {
                             security,
                         })
                     }
+                    (GatewayBindingType::SwaggerUi, _) => {
+                        Ok(RouteRequest {
+                            path: path_pattern.clone(),
+                            method,
+                            binding: GatewayBinding::SwaggerUi(SwaggerUiBinding::default()),
+                            security,
+                        })
+                    }
                     (GatewayBindingType::CorsPreflight, method) => {
                         Err(format!("cors-preflight binding type is supported only for 'options' method, but found method '{method}'"))
                     }
diff --git a/golem-worker-service/src/gateway_binding/gateway_binding_compiled.rs b/golem-worker-service/src/gateway_binding/gateway_binding_compiled.rs
index d87ef175..051d7225 100644
--- a/golem-worker-service/src/gateway_binding/gateway_binding_compiled.rs
+++ b/golem-worker-service/src/gateway_binding/gateway_binding_compiled.rs
@@ -24,6 +24,31 @@ use rib::RibOutputTypeInfo;
 use super::http_handler_binding::HttpHandlerBindingCompiled;
 use super::HttpHandlerBinding;
 
+#[derive(Debug, Clone, PartialEq)]
+pub struct SwaggerUiBinding {
+    pub openapi_spec_json: Option<String>,
+}
+
+impl Default for SwaggerUiBinding {
+    fn default() -> Self {
+        Self::new()
+    }
+}
+
+impl SwaggerUiBinding {
+    pub fn new() -> Self {
+        Self {
+            openapi_spec_json: None,
+        }
+    }
+
+    pub fn update_openapi_spec(openapi_spec_json: String) -> Self {
+        Self {
+            openapi_spec_json: Some(openapi_spec_json),
+        }
+    }
+}
+
 // A compiled binding is a binding with all existence of Rib Expr
 // get replaced with their compiled form - RibByteCode.
 #[derive(Debug, Clone, PartialEq)]
@@ -32,6 +57,7 @@ pub enum GatewayBindingCompiled {
     Static(StaticBinding),
     FileServer(Box<FileServerBindingCompiled>),
     HttpHandler(Box<HttpHandlerBindingCompiled>),
+    SwaggerUi(SwaggerUiBinding),
 }
 
 impl GatewayBindingCompiled {
@@ -40,6 +66,7 @@ impl GatewayBindingCompiled {
             GatewayBindingCompiled::Worker(_) => false,
             GatewayBindingCompiled::FileServer(_) => false,
             GatewayBindingCompiled::HttpHandler(_) => false,
+            GatewayBindingCompiled::SwaggerUi(_) => false,
             GatewayBindingCompiled::Static(static_binding) => match static_binding {
                 StaticBinding::HttpCorsPreflight(_) => false,
                 StaticBinding::HttpAuthCallBack(_) => true,
@@ -75,6 +102,9 @@ impl From<GatewayBindingCompiled> for GatewayBinding {
 
                 GatewayBinding::HttpHandler(Box::new(worker_binding))
             }
+            GatewayBindingCompiled::SwaggerUi(swagger_binding) => {
+                GatewayBinding::SwaggerUi(swagger_binding)
+            }
         }
     }
 }
@@ -135,9 +165,33 @@ impl TryFrom<GatewayBindingCompiled>
                         invocation_context: None,
                         compiled_invocation_context_expr: None,
                         invocation_context_rib_input: None,
+                        openapi_spec_json: None,
                     },
                 )
             }
+
+            GatewayBindingCompiled::SwaggerUi(swagger_binding) => Ok(
+                golem_api_grpc::proto::golem::apidefinition::CompiledGatewayBinding {
+                    component: None,
+                    worker_name: None,
+                    compiled_worker_name_expr: None,
+                    worker_name_rib_input: None,
+                    idempotency_key: None,
+                    compiled_idempotency_key_expr: None,
+                    idempotency_key_rib_input: None,
+                    response: None,
+                    compiled_response_expr: None,
+                    response_rib_input: None,
+                    worker_functions_in_response: None,
+                    binding_type: Some(ProtoGatewayBindingType::SwaggerUi.into()),
+                    static_binding: None,
+                    response_rib_output: None,
+                    invocation_context: None,
+                    compiled_invocation_context_expr: None,
+                    invocation_context_rib_input: None,
+                    openapi_spec_json: swagger_binding.openapi_spec_json.clone(),
+                },
+            ),
         }
     }
 }
@@ -323,6 +377,11 @@ impl TryFrom<golem_api_grpc::proto::golem::apidefinition::CompiledGatewayBinding
 
                 Ok(GatewayBindingCompiled::Static(static_binding.try_into()?))
             }
+            ProtoGatewayBindingType::SwaggerUi => {
+                Ok(GatewayBindingCompiled::SwaggerUi(SwaggerUiBinding {
+                    openapi_spec_json: value.openapi_spec_json,
+                }))
+            }
         }
     }
 }
@@ -400,6 +459,7 @@ mod internal {
             GatewayBindingType::FileServer => 1,
             GatewayBindingType::CorsPreflight => 2,
             GatewayBindingType::HttpHandler => 4,
+            GatewayBindingType::SwaggerUi => 5,
         };
 
         Ok(
@@ -421,6 +481,7 @@ mod internal {
                 invocation_context,
                 compiled_invocation_context_expr,
                 invocation_context_rib_input,
+                openapi_spec_json: None,
             },
         )
     }
@@ -478,6 +539,7 @@ mod internal {
             GatewayBindingType::FileServer => 1,
             GatewayBindingType::CorsPreflight => 2,
             GatewayBindingType::HttpHandler => 4,
+            GatewayBindingType::SwaggerUi => 5,
         };
 
         Ok(
@@ -499,6 +561,7 @@ mod internal {
                 invocation_context,
                 compiled_invocation_context_expr,
                 invocation_context_rib_input,
+                openapi_spec_json: None,
             },
         )
     }
@@ -534,6 +597,7 @@ mod internal {
             GatewayBindingType::FileServer => 1,
             GatewayBindingType::CorsPreflight => 2,
             GatewayBindingType::HttpHandler => 4,
+            GatewayBindingType::SwaggerUi => 5,
         };
 
         Ok(
@@ -555,6 +619,7 @@ mod internal {
                 invocation_context: None,
                 compiled_invocation_context_expr: None,
                 invocation_context_rib_input: None,
+                openapi_spec_json: None,
             },
         )
     }
diff --git a/golem-worker-service/src/gateway_execution/file_server_binding_handler.rs b/golem-worker-service/src/gateway_execution/file_server_binding_handler.rs
index 1d226b2b..10072abe 100644
--- a/golem-worker-service/src/gateway_execution/file_server_binding_handler.rs
+++ b/golem-worker-service/src/gateway_execution/file_server_binding_handler.rs
@@ -18,9 +18,9 @@ use crate::service::worker::{WorkerService, WorkerServiceError};
 use async_trait::async_trait;
 use bytes::Bytes;
 use futures::Stream;
-use futures_util::TryStreamExt;
+use futures::TryStreamExt;
 use golem_common::model::auth::{AuthCtx, Namespace};
-use golem_common::model::{ComponentFilePath, ComponentId, TargetWorkerId, WorkerId};
+use golem_common::model::{ComponentFilePath, ComponentId, WorkerId};
 use golem_common::SafeDisplay;
 use golem_service_base::model::Component;
 use golem_service_base::service::initial_component_files::InitialComponentFilesService;
@@ -38,7 +38,7 @@ pub trait FileServerBindingHandler: Send + Sync {
     async fn handle_file_server_binding_result(
         &self,
         namespace: Namespace,
-        worker_name: Option<&str>,
+        worker_name: &str,
         component_id: &ComponentId,
         original_result: RibResult,
     ) -> FileServerBindingResult;
@@ -199,14 +199,14 @@ impl DefaultFileServerBindingHandler {
     async fn get_component_metadata(
         &self,
         namespace: &Namespace,
-        worker_name: Option<&str>,
+        worker_name: &str,
         component_id: &ComponentId,
     ) -> Result<Component, FileServerBindingError> {
         // Two cases, we either have an existing worker or not (either not configured or not existing).
         // If there is no worker we need use the lastest component version, if there is none we need to use the exact component version
         // the worker is using. Not doing that would make the blob_storage optimization for read-only files visible to users.
 
-        let component_version = if let Some(worker_name) = worker_name {
+        let component_version = {
             let worker_metadata = self
                 .worker_service
                 .get_metadata(
@@ -223,8 +223,6 @@ impl DefaultFileServerBindingHandler {
                 Err(WorkerServiceError::WorkerNotFound(_)) => None,
                 Err(other) => Err(other)?,
             }
-        } else {
-            None
         };
 
         let component_metadata = if let Some(component_version) = component_version {
@@ -248,7 +246,7 @@ impl FileServerBindingHandler for DefaultFileServerBindingHandler {
     async fn handle_file_server_binding_result(
         &self,
         namespace: Namespace,
-        worker_name: Option<&str>,
+        worker_name: &str,
         component_id: &ComponentId,
         original_result: RibResult,
     ) -> FileServerBindingResult {
@@ -268,7 +266,7 @@ impl FileServerBindingHandler for DefaultFileServerBindingHandler {
         if let Some(file) = matching_ro_file {
             let data = self
                 .initial_component_files_service
-                .get(&namespace.account_id, &file.key)
+                .get(&namespace.project_id, &file.key)
                 .await
                 .map_err(|e| {
                     FileServerBindingError::InternalError(format!(
@@ -291,19 +289,15 @@ impl FileServerBindingHandler for DefaultFileServerBindingHandler {
         } else {
             // Read write files need to be fetched from a running worker.
             // Ask the worker service to get the file contents. If no worker is running, one will be started.
-            let worker_name_opt_validated = worker_name
-                .as_ref()
-                .map(|&w| WorkerId::validate_worker_name(w).map(|_| w.to_string()))
-                .transpose()
-                .map_err(|e| {
-                    FileServerBindingError::InternalError(format!("Invalid worker name: {e}"))
-                })?;
+            WorkerId::validate_worker_name(worker_name).map_err(|e| {
+                FileServerBindingError::InternalError(format!("Invalid worker name: {e}"))
+            })?;
 
             let component_id = component_id.clone();
 
-            let worker_id = TargetWorkerId {
+            let worker_id = WorkerId {
                 component_id,
-                worker_name: worker_name_opt_validated.map(|w| w.to_string()),
+                worker_name: worker_name.to_string(),
             };
 
             let stream = self
diff --git a/golem-worker-service/src/gateway_execution/gateway_http_input_executor.rs b/golem-worker-service/src/gateway_execution/gateway_http_input_executor.rs
index afce34e9..02dc9d8a 100644
--- a/golem-worker-service/src/gateway_execution/gateway_http_input_executor.rs
+++ b/golem-worker-service/src/gateway_execution/gateway_http_input_executor.rs
@@ -13,11 +13,12 @@
 // limitations under the License.
 
 use super::auth_call_back_binding_handler::AuthorisationSuccess;
-use super::file_server_binding_handler::FileServerBindingSuccess;
+use super::file_server_binding_handler::{FileServerBindingError, FileServerBindingSuccess};
 use super::http_handler_binding_handler::{HttpHandlerBindingHandler, HttpHandlerBindingResult};
 use super::request::{
     authority_from_request, split_resolved_route_entry, RichRequest, SplitResolvedRouteEntryResult,
 };
+use super::swagger_binding_handler::SwaggerBindingHandler;
 use super::to_response::GatewayHttpResult;
 use super::WorkerDetails;
 use crate::gateway_api_deployment::ApiSiteString;
@@ -48,9 +49,9 @@ use golem_common::model::invocation_context::{
 use golem_common::model::IdempotencyKey;
 use golem_common::SafeDisplay;
 use golem_service_base::headers::TraceContextHeaders;
-use golem_wasm_ast::analysis::{AnalysedType, NameTypePair, TypeRecord};
-use golem_wasm_rpc::json::TypeAnnotatedValueJsonExtensions;
-use golem_wasm_rpc::protobuf::type_annotated_value::TypeAnnotatedValue;
+use golem_wasm_ast::analysis::analysed_type::record;
+use golem_wasm_ast::analysis::{AnalysedType, NameTypePair};
+use golem_wasm_rpc::json::ValueAndTypeJsonExtensions;
 use golem_wasm_rpc::{IntoValue, IntoValueAndType, ValueAndType};
 use http::StatusCode;
 use poem::Body;
@@ -70,6 +71,7 @@ pub struct DefaultGatewayInputExecutor {
     pub file_server_binding_handler: Arc<dyn FileServerBindingHandler>,
     pub auth_call_back_binding_handler: Arc<dyn AuthCallBackBindingHandler>,
     pub http_handler_binding_handler: Arc<dyn HttpHandlerBindingHandler>,
+    pub swagger_binding_handler: Arc<dyn SwaggerBindingHandler + Sync + Send>,
     pub api_definition_lookup_service: Arc<dyn HttpApiDefinitionsLookup>,
     pub gateway_session_store: GatewaySessionStore,
     pub identity_provider: Arc<dyn IdentityProvider>,
@@ -81,6 +83,7 @@ impl DefaultGatewayInputExecutor {
         file_server_binding_handler: Arc<dyn FileServerBindingHandler>,
         auth_call_back_binding_handler: Arc<dyn AuthCallBackBindingHandler>,
         http_handler_binding_handler: Arc<dyn HttpHandlerBindingHandler>,
+        swagger_binding_handler: Arc<dyn SwaggerBindingHandler + Sync + Send>,
         api_definition_lookup_service: Arc<dyn HttpApiDefinitionsLookup>,
         gateway_session_store: GatewaySessionStore,
         identity_provider: Arc<dyn IdentityProvider>,
@@ -90,6 +93,7 @@ impl DefaultGatewayInputExecutor {
             file_server_binding_handler,
             auth_call_back_binding_handler,
             http_handler_binding_handler,
+            swagger_binding_handler,
             api_definition_lookup_service,
             gateway_session_store,
             identity_provider,
@@ -190,8 +194,15 @@ impl DefaultGatewayInputExecutor {
             )
             .await?;
 
-        let worker_name = worker_detail.worker_name.clone();
-        let worker_name = worker_name.as_deref();
+        let worker_name = worker_detail
+            .worker_name
+            .as_ref()
+            .ok_or_else(|| {
+                GatewayHttpError::FileServerBindingError(FileServerBindingError::InternalError(
+                    "Missing worker name".to_string(),
+                ))
+            })?
+            .clone();
 
         let response_script_result = self
             .execute_response_mapping_script(
@@ -205,7 +216,7 @@ impl DefaultGatewayInputExecutor {
         self.file_server_binding_handler
             .handle_file_server_binding_result(
                 namespace,
-                worker_name,
+                &worker_name,
                 &component_id,
                 response_script_result,
             )
@@ -651,6 +662,19 @@ impl GatewayHttpInputExecutor for DefaultGatewayInputExecutor {
 
                 maybe_apply_middlewares_out(response, &middlewares).await
             }
+
+            GatewayBindingCompiled::SwaggerUi(swagger_binding) => {
+                let result = self
+                    .swagger_binding_handler
+                    .handle_swagger_binding_request(&authority, &swagger_binding)
+                    .await;
+
+                let response = result
+                    .to_response(&rich_request, &self.gateway_session_store)
+                    .await;
+
+                maybe_apply_middlewares_out(response, &middlewares).await
+            }
         }
     }
 }
@@ -682,8 +706,8 @@ async fn resolve_rib_input(
                             ))
                         })?;
 
-                        let body_value = TypeAnnotatedValue::parse_with_type(body, &record.typ)
-                            .map_err(|err| {
+                        let body_value =
+                            ValueAndType::parse_with_type(body, &record.typ).map_err(|err| {
                                 GatewayHttpError::BadRequest(format!(
                                     "invalid http request body\n{}\nexpected request body: {}",
                                     err.join("\n"),
@@ -693,15 +717,7 @@ async fn resolve_rib_input(
                                 ))
                             })?;
 
-                        let converted_value =
-                            ValueAndType::try_from(body_value).map_err(|err| {
-                                error!("internal value conversion error: {}", err);
-                                GatewayHttpError::InternalError(
-                                    "internal value conversion error".to_string(),
-                                )
-                            })?;
-
-                        values.push(converted_value.value);
+                        values.push(body_value.value);
                     }
                     "headers" | "header" => {
                         let header_values = get_wasm_rpc_value_for_primitives(
@@ -772,28 +788,18 @@ async fn resolve_rib_input(
                                     "missing auth data".to_string(),
                                 ))?;
 
-                        let auth_value =
-                            TypeAnnotatedValue::parse_with_type(auth_data, &record.typ).map_err(
-                                |err| {
-                                    GatewayHttpError::BadRequest(format!(
-                                        "invalid auth data\n{}\nexpected auth: {}",
-                                        err.join("\n"),
-                                        TypeName::try_from(record.typ.clone())
-                                            .map(|x| x.to_string())
-                                            .unwrap_or_else(|_| format!("{:?}", &record.typ))
-                                    ))
-                                },
-                            )?;
-
-                        let converted_value =
-                            ValueAndType::try_from(auth_value).map_err(|err| {
-                                error!("internal value conversion error: {}", err);
-                                GatewayHttpError::InternalError(
-                                    "internal value conversion error".to_string(),
-                                )
+                        let auth_value = ValueAndType::parse_with_type(auth_data, &record.typ)
+                            .map_err(|err| {
+                                GatewayHttpError::BadRequest(format!(
+                                    "invalid auth data\n{}\nexpected auth: {}",
+                                    err.join("\n"),
+                                    TypeName::try_from(record.typ.clone())
+                                        .map(|x| x.to_string())
+                                        .unwrap_or_else(|_| format!("{:?}", &record.typ))
+                                ))
                             })?;
 
-                        values.push(converted_value.value);
+                        values.push(auth_value.value);
                     }
                     field_name => {
                         // This is already type checked during API registration,
@@ -810,10 +816,7 @@ async fn resolve_rib_input(
 
             result_map.insert(
                 "request".to_string(),
-                ValueAndType::new(
-                    golem_wasm_rpc::Value::Record(values),
-                    AnalysedType::Record(TypeRecord { fields: types }),
-                ),
+                ValueAndType::new(golem_wasm_rpc::Value::Record(values), record(types)),
             );
 
             Ok(RibInput { input: result_map })
@@ -882,7 +885,7 @@ fn get_status_code_from_api_lookup_error(error: &ApiDefinitionLookupError) -> St
 /// Map against the required types and get `wasm_rpc::Value` from http request
 /// # Parameters
 /// - `analysed_type: &AnalysedType`
-///   - RibInput requirement follows a pseudo form like `{request : {headers: record-type, query: record-type, path: record-type, body: analysed-type}}`).
+///   - RibInput requirement follows a pseudo form like `{request : {headers: record-type, query: record-type, path: record-type, body: analysed-type}}`.
 ///   - The `analysed_type` here is the type of headers, query, or path (and not body). i.e, `record-type` in the above pseudo form.
 ///   - This `record-type` is expected to have primitive field types. Example for a Rib `request.path.user-id` `user-id` is some primitive and `path` should be hence a record.
 ///   - This analysed doesn't handle (or shouldn't correspond to) the `body` field because it can be anything and not a record of primitives
diff --git a/golem-worker-service/src/gateway_execution/http_content_type_mapper.rs b/golem-worker-service/src/gateway_execution/http_content_type_mapper.rs
index d02e2196..6450b915 100644
--- a/golem-worker-service/src/gateway_execution/http_content_type_mapper.rs
+++ b/golem-worker-service/src/gateway_execution/http_content_type_mapper.rs
@@ -13,7 +13,7 @@
 // limitations under the License.
 
 use golem_wasm_ast::analysis::AnalysedType;
-use golem_wasm_rpc::protobuf::type_annotated_value::TypeAnnotatedValue;
+use golem_wasm_rpc::ValueAndType;
 use mime::Mime;
 use poem::web::headers::ContentType;
 use poem::web::WithContentType;
@@ -114,7 +114,7 @@ impl ContentTypeHeaders {
     }
 }
 
-impl HttpContentTypeResponseMapper for TypeAnnotatedValue {
+impl HttpContentTypeResponseMapper for ValueAndType {
     fn to_http_resp_with_content_type(
         &self,
         content_type_headers: ContentTypeHeaders,
@@ -179,154 +179,151 @@ mod internal {
     use crate::gateway_execution::http_content_type_mapper::{
         AcceptHeaders, ContentTypeHeaderExt, ContentTypeMapError,
     };
-    use golem_wasm_ast::analysis::analysed_type::{
-        bool, chr, f32, f64, s16, s32, s64, s8, u16, u32, u64, u8,
-    };
-    use golem_wasm_ast::analysis::AnalysedType;
-    use golem_wasm_rpc::json::TypeAnnotatedValueJsonExtensions;
-    use golem_wasm_rpc::protobuf::type_annotated_value::TypeAnnotatedValue;
-    use golem_wasm_rpc::protobuf::{PrimitiveType, TypedEnum, TypedList};
+    use golem_wasm_ast::analysis::{AnalysedType, TypeEnum, TypeList, TypeOption, TypeRecord};
+    use golem_wasm_rpc::json::ValueAndTypeJsonExtensions;
+    use golem_wasm_rpc::{Value, ValueAndType};
     use poem::web::headers::ContentType;
     use poem::web::WithContentType;
     use poem::{Body, IntoResponse};
     use std::fmt::Display;
 
     pub(crate) fn get_response_body_based_on_content_type<A: ContentTypeHeaderExt + Display>(
-        type_annotated_value: &TypeAnnotatedValue,
+        value_and_type: &ValueAndType,
         content_header: &A,
     ) -> Result<WithContentType<Body>, ContentTypeMapError> {
-        match type_annotated_value {
-            TypeAnnotatedValue::Record { .. } => {
-                handle_record(type_annotated_value, content_header)
+        match (&value_and_type.typ, &value_and_type.value) {
+            (AnalysedType::Record(_record), Value::Record(_values)) => {
+                handle_record(value_and_type, content_header)
             }
-            TypeAnnotatedValue::List(ref typed_list) => {
-                let typ = typed_list
-                    .typ
-                    .clone()
-                    .ok_or(ContentTypeMapError::internal("Failed to fetch list type"))?;
-                let analysed_type = AnalysedType::try_from(&typ).map_err(|_| {
-                    ContentTypeMapError::internal("Failed to convert type to analysed type")
-                })?;
-                let vec = typed_list
-                    .values
-                    .iter()
-                    .filter_map(|v| v.type_annotated_value.clone())
-                    .collect::<Vec<_>>();
-                handle_list(type_annotated_value, &vec, &analysed_type, content_header)
+            (AnalysedType::Variant(_variant), Value::Variant { .. }) => {
+                handle_record(value_and_type, content_header)
             }
-            TypeAnnotatedValue::Bool(value) => handle_primitive(value, &bool(), content_header),
-            TypeAnnotatedValue::S8(value) => handle_primitive(value, &s8(), content_header),
-            TypeAnnotatedValue::U8(value) => handle_primitive(value, &u8(), content_header),
-            TypeAnnotatedValue::S16(value) => handle_primitive(value, &s16(), content_header),
-            TypeAnnotatedValue::U16(value) => handle_primitive(value, &u16(), content_header),
-            TypeAnnotatedValue::S32(value) => handle_primitive(value, &s32(), content_header),
-            TypeAnnotatedValue::U32(value) => handle_primitive(value, &u32(), content_header),
-            TypeAnnotatedValue::S64(value) => handle_primitive(value, &s64(), content_header),
-            TypeAnnotatedValue::U64(value) => handle_primitive(value, &u64(), content_header),
-            TypeAnnotatedValue::F32(value) => handle_primitive(value, &f32(), content_header),
-            TypeAnnotatedValue::F64(value) => handle_primitive(value, &f64(), content_header),
-            TypeAnnotatedValue::Char(value) => handle_primitive(value, &chr(), content_header),
-            TypeAnnotatedValue::Str(string) => handle_string(string, content_header),
-
-            TypeAnnotatedValue::Tuple { .. } => {
-                handle_complex(type_annotated_value, content_header)
+            (AnalysedType::List(TypeList { inner, .. }), Value::List(values)) => {
+                handle_list(value_and_type, values, inner, content_header)
             }
-            TypeAnnotatedValue::Flags { .. } => {
-                handle_complex(type_annotated_value, content_header)
+            (AnalysedType::Bool(_), Value::Bool(value)) => {
+                handle_primitive(value, &value_and_type.typ, content_header)
             }
-            TypeAnnotatedValue::Variant { .. } => {
-                handle_record(type_annotated_value, content_header)
+            (AnalysedType::S8(_), Value::S8(value)) => {
+                handle_primitive(value, &value_and_type.typ, content_header)
             }
-            TypeAnnotatedValue::Enum(TypedEnum { value, .. }) => {
-                handle_string(value, content_header)
+            (AnalysedType::U8(_), Value::U8(value)) => {
+                handle_primitive(value, &value_and_type.typ, content_header)
             }
-
-            TypeAnnotatedValue::Option(typed_option) => match &typed_option.value {
+            (AnalysedType::S16(_), Value::S16(value)) => {
+                handle_primitive(value, &value_and_type.typ, content_header)
+            }
+            (AnalysedType::U16(_), Value::U16(value)) => {
+                handle_primitive(value, &value_and_type.typ, content_header)
+            }
+            (AnalysedType::S32(_), Value::S32(value)) => {
+                handle_primitive(value, &value_and_type.typ, content_header)
+            }
+            (AnalysedType::U32(_), Value::U32(value)) => {
+                handle_primitive(value, &value_and_type.typ, content_header)
+            }
+            (AnalysedType::S64(_), Value::S64(value)) => {
+                handle_primitive(value, &value_and_type.typ, content_header)
+            }
+            (AnalysedType::U64(_), Value::U64(value)) => {
+                handle_primitive(value, &value_and_type.typ, content_header)
+            }
+            (AnalysedType::F32(_), Value::F32(value)) => {
+                handle_primitive(value, &value_and_type.typ, content_header)
+            }
+            (AnalysedType::F64(_), Value::F64(value)) => {
+                handle_primitive(value, &value_and_type.typ, content_header)
+            }
+            (AnalysedType::Chr(_), Value::Char(value)) => {
+                handle_primitive(value, &value_and_type.typ, content_header)
+            }
+            (AnalysedType::Str(_), Value::String(string)) => handle_string(string, content_header),
+            (AnalysedType::Tuple(_), Value::Tuple(_)) => {
+                handle_complex(value_and_type, content_header)
+            }
+            (AnalysedType::Flags(_), Value::Flags(_)) => {
+                handle_complex(value_and_type, content_header)
+            }
+            // Can be considered as a record
+            (AnalysedType::Result(_), Value::Result(_)) => {
+                handle_complex(value_and_type, content_header)
+            }
+            (AnalysedType::Handle(_), Value::Handle { .. }) => {
+                handle_complex(value_and_type, content_header)
+            }
+            (AnalysedType::Enum(TypeEnum { cases, .. }), Value::Enum(name_idx)) => {
+                let name = cases
+                    .get(*name_idx as usize)
+                    .ok_or(ContentTypeMapError::internal("Invalid enum index"))?;
+                handle_string(name, content_header)
+            }
+            (AnalysedType::Option(TypeOption { inner, .. }), Value::Option(value)) => match value {
                 Some(value) => {
-                    let value = value.type_annotated_value.as_ref().ok_or(
-                        ContentTypeMapError::internal("Failed to fetch option value"),
-                    )?;
-                    get_response_body_based_on_content_type(value, content_header)
+                    let value_and_type = ValueAndType::new((**value).clone(), (**inner).clone());
+                    get_response_body_based_on_content_type(&value_and_type, content_header)
                 }
                 None => {
                     if content_header.has_application_json() {
                         get_json_null()
                     } else {
-                        let typ = AnalysedType::try_from(type_annotated_value).map_err(|_| {
-                            ContentTypeMapError::internal("Failed to resolve type of data")
-                        })?;
+                        let typ = value_and_type.typ.clone();
                         Err(ContentTypeMapError::illegal_mapping(&typ, content_header))
                     }
                 }
             },
-            // Can be considered as a record
-            TypeAnnotatedValue::Result { .. } => {
-                handle_complex(type_annotated_value, content_header)
-            }
-            TypeAnnotatedValue::Handle { .. } => {
-                handle_complex(type_annotated_value, content_header)
-            }
+            _ => Err(ContentTypeMapError::InternalError(
+                "Value and type mismatch".to_string(),
+            )),
         }
     }
 
     pub(crate) fn get_response_body(
-        type_annotated_value: &TypeAnnotatedValue,
+        value_and_type: &ValueAndType,
     ) -> Result<WithContentType<Body>, ContentTypeMapError> {
-        match type_annotated_value {
-            TypeAnnotatedValue::Record { .. } => get_json(type_annotated_value),
-            TypeAnnotatedValue::List(TypedList { values, typ }) => {
-                match typ.clone().and_then(|v| v.r#type) {
-                    Some(golem_wasm_rpc::protobuf::r#type::Type::Primitive(primitive)) => {
-                        match PrimitiveType::try_from(primitive.primitive) {
-                            Ok(PrimitiveType::U8) => {
-                                let values = values
-                                    .iter()
-                                    .filter_map(|v| v.type_annotated_value.clone())
-                                    .collect::<Vec<_>>();
-                                get_byte_stream_body(&values)
-                            }
-                            _ => get_json(type_annotated_value),
-                        }
-                    }
-                    _ => get_json(type_annotated_value),
-                }
+        match (&value_and_type.typ, &value_and_type.value) {
+            (AnalysedType::Record(TypeRecord { .. }), Value::Record { .. }) => {
+                get_json(value_and_type)
             }
-
-            TypeAnnotatedValue::Str(string) => Ok(Body::from_string(string.to_string())
-                .with_content_type(ContentType::json().to_string())),
-
-            TypeAnnotatedValue::Enum(TypedEnum { value, .. }) => {
-                Ok(Body::from_string(value.to_string())
+            (AnalysedType::List(TypeList { inner, .. }), Value::List(values)) => match &**inner {
+                AnalysedType::U8(_) => get_byte_stream_body(values),
+                _ => get_json(value_and_type),
+            },
+            (AnalysedType::Str(_), Value::String(string)) => {
+                Ok(Body::from_string(string.to_string())
                     .with_content_type(ContentType::json().to_string()))
             }
-
-            TypeAnnotatedValue::Bool(bool) => get_json_of(bool),
-            TypeAnnotatedValue::S8(s8) => get_json_of(s8),
-            TypeAnnotatedValue::U8(u8) => get_json_of(u8),
-            TypeAnnotatedValue::S16(s16) => get_json_of(s16),
-            TypeAnnotatedValue::U16(u16) => get_json_of(u16),
-            TypeAnnotatedValue::S32(s32) => get_json_of(s32),
-            TypeAnnotatedValue::U32(u32) => get_json_of(u32),
-            TypeAnnotatedValue::S64(s64) => get_json_of(s64),
-            TypeAnnotatedValue::U64(u64) => get_json_of(u64),
-            TypeAnnotatedValue::F32(f32) => get_json_of(f32),
-            TypeAnnotatedValue::F64(f64) => get_json_of(f64),
-            TypeAnnotatedValue::Char(char) => get_json_of(char),
-            TypeAnnotatedValue::Tuple { .. } => get_json(type_annotated_value),
-            TypeAnnotatedValue::Flags { .. } => get_json(type_annotated_value),
-            TypeAnnotatedValue::Variant { .. } => get_json(type_annotated_value),
-            TypeAnnotatedValue::Option(typed_option) => match &typed_option.value {
+            (AnalysedType::Enum(TypeEnum { cases, .. }), Value::Enum(case_idx)) => {
+                let case_name = cases
+                    .get(*case_idx as usize)
+                    .ok_or(ContentTypeMapError::internal("Invalid enum index"))?;
+                Ok(Body::from_string(case_name.to_string())
+                    .with_content_type(ContentType::json().to_string()))
+            }
+            (AnalysedType::Bool(_), Value::Bool(bool)) => get_json_of(bool),
+            (AnalysedType::S8(_), Value::S8(s8)) => get_json_of(s8),
+            (AnalysedType::U8(_), Value::U8(u8)) => get_json_of(u8),
+            (AnalysedType::S16(_), Value::S16(s16)) => get_json_of(s16),
+            (AnalysedType::U16(_), Value::U16(u16)) => get_json_of(u16),
+            (AnalysedType::S32(_), Value::S32(s32)) => get_json_of(s32),
+            (AnalysedType::U32(_), Value::U32(u32)) => get_json_of(u32),
+            (AnalysedType::S64(_), Value::S64(s64)) => get_json_of(s64),
+            (AnalysedType::U64(_), Value::U64(u64)) => get_json_of(u64),
+            (AnalysedType::F32(_), Value::F32(f32)) => get_json_of(f32),
+            (AnalysedType::F64(_), Value::F64(f64)) => get_json_of(f64),
+            (AnalysedType::Chr(_), Value::Char(char)) => get_json_of(char),
+            (AnalysedType::Tuple(_), Value::Tuple(_)) => get_json(value_and_type),
+            (AnalysedType::Flags(_), Value::Flags(_)) => get_json(value_and_type),
+            (AnalysedType::Variant(_), Value::Variant { .. }) => get_json(value_and_type),
+            (AnalysedType::Result(_), Value::Result { .. }) => get_json(value_and_type),
+            (AnalysedType::Handle(_), Value::Handle { .. }) => get_json(value_and_type),
+            (AnalysedType::Option(TypeOption { inner, .. }), Value::Option(value)) => match value {
                 Some(value) => {
-                    let value = value.type_annotated_value.as_ref().ok_or(
-                        ContentTypeMapError::internal("Failed to fetch option value"),
-                    )?;
-                    get_response_body(value)
+                    let value = ValueAndType::new((**value).clone(), (**inner).clone());
+                    get_response_body(&value)
                 }
                 None => get_json_null(),
             },
-            // Can be considered as a record
-            TypeAnnotatedValue::Result { .. } => get_json(type_annotated_value),
-            TypeAnnotatedValue::Handle { .. } => get_json(type_annotated_value),
+            _ => Err(ContentTypeMapError::internal("Value and type mismatch")),
         }
     }
 
@@ -362,11 +359,11 @@ mod internal {
         }
     }
 
-    fn get_byte_stream(values: &[TypeAnnotatedValue]) -> Result<Vec<u8>, ContentTypeMapError> {
+    fn get_byte_stream(values: &[Value]) -> Result<Vec<u8>, ContentTypeMapError> {
         let bytes = values
             .iter()
             .map(|v| match v {
-                TypeAnnotatedValue::U8(u8) => Ok(*u8 as u8),
+                Value::U8(u8) => Ok(*u8),
                 _ => Err(ContentTypeMapError::internal(
                     "The analysed type is a binary stream however unable to fetch vec<u8>",
                 )),
@@ -377,7 +374,7 @@ mod internal {
     }
 
     fn get_byte_stream_body(
-        values: &[TypeAnnotatedValue],
+        values: &[Value],
     ) -> Result<WithContentType<Body>, ContentTypeMapError> {
         let bytes = get_byte_stream(values)?;
         Ok(Body::from_bytes(bytes::Bytes::from(bytes))
@@ -385,9 +382,11 @@ mod internal {
     }
 
     fn get_json(
-        type_annotated_value: &TypeAnnotatedValue,
+        value_and_type: &ValueAndType,
     ) -> Result<WithContentType<Body>, ContentTypeMapError> {
-        let json = type_annotated_value.to_json_value();
+        let json = value_and_type.to_json_value().map_err(|err| {
+            ContentTypeMapError::internal(format!("Failed to encode value as JSON: {err}"))
+        })?;
         Body::from_json(json)
             .map(|body| body.with_content_type(ContentType::json().to_string()))
             .map_err(|_| ContentTypeMapError::internal("Failed to convert to json body"))
@@ -412,26 +411,24 @@ mod internal {
     }
 
     fn handle_complex<A: ContentTypeHeaderExt + Display>(
-        complex: &TypeAnnotatedValue,
+        complex: &ValueAndType,
         content_header: &A,
     ) -> Result<WithContentType<Body>, ContentTypeMapError> {
         if content_header.has_application_json() {
             get_json(complex)
         } else {
-            let typ = AnalysedType::try_from(complex)
-                .map_err(|_| ContentTypeMapError::internal("Failed to resolve type of data"))?;
-
+            let typ = complex.typ.clone();
             Err(ContentTypeMapError::illegal_mapping(&typ, content_header))
         }
     }
 
     fn handle_list<A: ContentTypeHeaderExt + Display>(
-        original: &TypeAnnotatedValue,
-        inner_values: &[TypeAnnotatedValue],
-        list_type: &AnalysedType,
+        original: &ValueAndType,
+        inner_values: &[Value],
+        elem_type: &AnalysedType,
         content_header: &A,
     ) -> Result<WithContentType<Body>, ContentTypeMapError> {
-        match list_type {
+        match elem_type {
             AnalysedType::U8(_) => {
                 let byte_stream = get_byte_stream(inner_values)?;
                 let body = Body::from_bytes(bytes::Bytes::from(byte_stream));
@@ -443,7 +440,7 @@ mod internal {
                     get_json(original)
                 } else {
                     Err(ContentTypeMapError::illegal_mapping(
-                        list_type,
+                        elem_type,
                         content_header,
                     ))
                 }
@@ -474,15 +471,14 @@ mod internal {
     }
 
     fn handle_record<A: ContentTypeHeaderExt + Display>(
-        record: &TypeAnnotatedValue,
+        value_and_type: &ValueAndType,
         content_header: &A,
     ) -> Result<WithContentType<Body>, ContentTypeMapError> {
         // if record, we prioritise JSON
         if content_header.has_application_json() {
-            get_json(record)
+            get_json(value_and_type)
         } else {
-            let typ = AnalysedType::try_from(record)
-                .map_err(|_| ContentTypeMapError::internal("Failed to resolve type of data"))?;
+            let typ = value_and_type.typ.clone();
             // There is no way a Record can be properly serialised into any other formats to satisfy any other headers, therefore fail
             Err(ContentTypeMapError::illegal_mapping(&typ, content_header))
         }
@@ -507,66 +503,32 @@ mod internal {
 #[cfg(test)]
 mod tests {
     use super::*;
-    use golem_wasm_ast::analysis::analysed_type::str;
-    use golem_wasm_rpc::protobuf::{NameTypePair, NameValuePair, TypedList, TypedRecord};
+    use golem_wasm_ast::analysis::analysed_type::{field, list, record, str};
+    use golem_wasm_rpc::{IntoValue, Value};
     use poem::web::headers::ContentType;
     use poem::IntoResponse;
-    use serde_json::Value;
-
-    fn sample_record() -> TypeAnnotatedValue {
-        TypeAnnotatedValue::Record(TypedRecord {
-            typ: vec![NameTypePair {
-                name: "name".to_string(),
-                typ: Some((&str()).into()),
-            }],
-            value: vec![NameValuePair {
-                name: "name".to_string(),
-                value: Some(golem_wasm_rpc::protobuf::TypeAnnotatedValue {
-                    type_annotated_value: Some(TypeAnnotatedValue::Str("Hello".to_string())),
-                }),
-            }],
-        })
-    }
 
-    fn create_list(
-        vec: Vec<TypeAnnotatedValue>,
-        analysed_type: &AnalysedType,
-    ) -> TypeAnnotatedValue {
-        TypeAnnotatedValue::List(TypedList {
-            values: vec
-                .into_iter()
-                .map(|v| golem_wasm_rpc::protobuf::TypeAnnotatedValue {
-                    type_annotated_value: Some(v),
-                })
-                .collect(),
-            typ: Some(analysed_type.into()),
-        })
+    fn sample_record() -> ValueAndType {
+        ValueAndType::new(
+            Value::Record(vec!["Hello".into_value()]),
+            record(vec![field("name", str())]),
+        )
     }
 
-    fn create_record(values: Vec<(String, TypeAnnotatedValue)>) -> TypeAnnotatedValue {
-        let mut name_type_pairs = vec![];
-        let mut name_value_pairs = vec![];
-
-        for (key, value) in values.iter() {
-            let typ = golem_wasm_rpc::protobuf::Type::try_from(value).unwrap();
-
-            name_type_pairs.push(NameTypePair {
-                name: key.to_string(),
-                typ: Some(typ),
-            });
-
-            name_value_pairs.push(NameValuePair {
-                name: key.to_string(),
-                value: Some(golem_wasm_rpc::protobuf::TypeAnnotatedValue {
-                    type_annotated_value: Some(value.clone()),
-                }),
-            });
-        }
+    fn create_list(vec: Vec<Value>, analysed_type: AnalysedType) -> ValueAndType {
+        ValueAndType::new(Value::List(vec), list(analysed_type))
+    }
 
-        TypeAnnotatedValue::Record(TypedRecord {
-            typ: name_type_pairs,
-            value: name_value_pairs,
-        })
+    fn create_record(values: Vec<(&str, ValueAndType)>) -> ValueAndType {
+        ValueAndType::new(
+            Value::Record(values.iter().map(|(_, v)| v.value.clone()).collect()),
+            record(
+                values
+                    .iter()
+                    .map(|(name, value)| field(name, value.typ.clone()))
+                    .collect(),
+            ),
+        )
     }
 
     #[cfg(test)]
@@ -575,8 +537,9 @@ mod tests {
 
         use super::*;
         use golem_wasm_ast::analysis::analysed_type::{u16, u8};
+        use golem_wasm_rpc::IntoValueAndType;
 
-        fn get_content_type_and_body(input: &TypeAnnotatedValue) -> (Option<String>, Body) {
+        fn get_content_type_and_body(input: &ValueAndType) -> (Option<String>, Body) {
             let response_body = internal::get_response_body(input).unwrap();
             let response = response_body.into_response();
             let (parts, body) = response.into_parts();
@@ -589,7 +552,7 @@ mod tests {
 
         #[test]
         async fn test_string_type() {
-            let type_annotated_value = TypeAnnotatedValue::Str("Hello".to_string());
+            let type_annotated_value = "Hello".into_value_and_type();
             let (content_type, body) = get_content_type_and_body(&type_annotated_value);
             let result = String::from_utf8_lossy(&body.into_bytes().await.unwrap()).to_string();
             // Had it serialized as json, it would have been "\"Hello\""
@@ -601,7 +564,7 @@ mod tests {
 
         #[test]
         async fn test_singleton_u8_type() {
-            let type_annotated_value = TypeAnnotatedValue::U8(10);
+            let type_annotated_value = 10u8.into_value_and_type();
             let (content_type, body) = get_content_type_and_body(&type_annotated_value);
             let result = String::from_utf8_lossy(&body.into_bytes().await.unwrap()).to_string();
             assert_eq!(
@@ -612,7 +575,7 @@ mod tests {
 
         #[test]
         async fn test_list_u8_type() {
-            let type_annotated_value = create_list(vec![TypeAnnotatedValue::U8(10)], &u8());
+            let type_annotated_value = create_list(vec![10u8.into_value()], u8());
             let (content_type, body) = get_content_type_and_body(&type_annotated_value);
             let result = body.into_bytes().await.unwrap();
 
@@ -627,12 +590,13 @@ mod tests {
 
         #[test]
         async fn test_list_non_u8_type() {
-            let type_annotated_value = create_list(vec![TypeAnnotatedValue::U16(10)], &u16());
+            let type_annotated_value = create_list(vec![10u16.into_value()], u16());
 
             let (content_type, body) = get_content_type_and_body(&type_annotated_value);
             let data_as_str =
                 String::from_utf8_lossy(&body.into_bytes().await.unwrap()).to_string();
-            let result_json: Value = serde_json::from_str(data_as_str.as_str()).unwrap();
+            let result_json: serde_json::Value =
+                serde_json::from_str(data_as_str.as_str()).unwrap();
             let expected_json = serde_json::Value::Array(vec![serde_json::Value::Number(
                 serde_json::Number::from(10),
             )]);
@@ -644,15 +608,13 @@ mod tests {
 
         #[test]
         async fn test_record_type() {
-            let type_annotated_value = create_record(vec![(
-                "name".to_string(),
-                TypeAnnotatedValue::Str("Hello".to_string()),
-            )]);
+            let type_annotated_value = create_record(vec![("name", "Hello".into_value_and_type())]);
 
             let (content_type, body) = get_content_type_and_body(&type_annotated_value);
             let data_as_str =
                 String::from_utf8_lossy(&body.into_bytes().await.unwrap()).to_string();
-            let result_json: Value = serde_json::from_str(data_as_str.as_str()).unwrap();
+            let result_json: serde_json::Value =
+                serde_json::from_str(data_as_str.as_str()).unwrap();
             let expected_json = serde_json::json!({"name": "Hello"});
             assert_eq!(
                 (result_json, content_type),
@@ -667,9 +629,10 @@ mod tests {
 
         use super::*;
         use golem_wasm_ast::analysis::analysed_type::{u16, u8};
+        use golem_wasm_rpc::IntoValueAndType;
 
         fn get_content_type_and_body(
-            input: &TypeAnnotatedValue,
+            input: &ValueAndType,
             header: &ContentType,
         ) -> (Option<String>, Body) {
             let response_body =
@@ -685,7 +648,7 @@ mod tests {
 
         #[test]
         async fn test_string_type_as_text() {
-            let type_annotated_value = TypeAnnotatedValue::Str("Hello".to_string());
+            let type_annotated_value = "Hello".into_value_and_type();
             let (content_type, body) =
                 get_content_type_and_body(&type_annotated_value, &ContentType::text());
             let result = String::from_utf8_lossy(&body.into_bytes().await.unwrap()).to_string();
@@ -698,7 +661,7 @@ mod tests {
 
         #[test]
         async fn test_string_type_as_json() {
-            let type_annotated_value = TypeAnnotatedValue::Str("\"Hello\"".to_string());
+            let type_annotated_value = "\"Hello\"".into_value_and_type();
             let (content_type, body) =
                 get_content_type_and_body(&type_annotated_value, &ContentType::json());
             let result = String::from_utf8_lossy(&body.into_bytes().await.unwrap()).to_string();
@@ -715,7 +678,7 @@ mod tests {
 
         #[test]
         async fn test_singleton_u8_type() {
-            let type_annotated_value = TypeAnnotatedValue::U8(10);
+            let type_annotated_value = 10u8.into_value_and_type();
             let (content_type, body) =
                 get_content_type_and_body(&type_annotated_value, &ContentType::json());
             let result = String::from_utf8_lossy(&body.into_bytes().await.unwrap()).to_string();
@@ -727,13 +690,14 @@ mod tests {
 
         #[test]
         async fn test_list_u8_type() {
-            let type_annotated_value = create_list(vec![TypeAnnotatedValue::U8(10)], &u8());
+            let type_annotated_value = create_list(vec![10u8.into_value()], u8());
 
             let (content_type, body) =
                 get_content_type_and_body(&type_annotated_value, &ContentType::json());
             let result = &body.into_bytes().await.unwrap();
             let data_as_str = String::from_utf8_lossy(result).to_string();
-            let result_json: Result<Value, _> = serde_json::from_str(data_as_str.as_str());
+            let result_json: Result<serde_json::Value, _> =
+                serde_json::from_str(data_as_str.as_str());
 
             assert_eq!(
                 (result, content_type),
@@ -747,14 +711,15 @@ mod tests {
 
         #[test]
         async fn test_list_non_u8_type() {
-            let type_annotated_value = create_list(vec![TypeAnnotatedValue::U16(10)], &u16());
+            let type_annotated_value = create_list(vec![10u16.into_value()], u16());
 
             let (content_type, body) =
                 get_content_type_and_body(&type_annotated_value, &ContentType::json());
             let data_as_str =
                 String::from_utf8_lossy(&body.into_bytes().await.unwrap()).to_string();
-            let result_json: Value = serde_json::from_str(data_as_str.as_str()).unwrap();
-            let expected_json = Value::Array(vec![serde_json::Value::Number(
+            let result_json: serde_json::Value =
+                serde_json::from_str(data_as_str.as_str()).unwrap();
+            let expected_json = serde_json::Value::Array(vec![serde_json::Value::Number(
                 serde_json::Number::from(10),
             )]);
             // That we jsonify any list other than u8, and can be retrieveed as a valid JSON
@@ -773,7 +738,8 @@ mod tests {
                 get_content_type_and_body(&type_annotated_value, &ContentType::json());
             let data_as_str =
                 String::from_utf8_lossy(&body.into_bytes().await.unwrap()).to_string();
-            let result_json: Value = serde_json::from_str(data_as_str.as_str()).unwrap();
+            let result_json: serde_json::Value =
+                serde_json::from_str(data_as_str.as_str()).unwrap();
             let expected_json = serde_json::json!({"name": "Hello"});
             assert_eq!(
                 (result_json, content_type),
@@ -788,9 +754,10 @@ mod tests {
 
         use super::*;
         use golem_wasm_ast::analysis::analysed_type::{u16, u8};
+        use golem_wasm_rpc::IntoValueAndType;
 
         fn get_content_type_and_body(
-            input: &TypeAnnotatedValue,
+            input: &ValueAndType,
             headers: &AcceptHeaders,
         ) -> (Option<String>, Body) {
             let response_body =
@@ -806,7 +773,7 @@ mod tests {
 
         #[test]
         async fn test_string_type_with_json() {
-            let type_annotated_value = TypeAnnotatedValue::Str("Hello".to_string());
+            let type_annotated_value = "Hello".into_value_and_type();
             let (content_type, body) = get_content_type_and_body(
                 &type_annotated_value,
                 &AcceptHeaders::from_str("text/html;q=0.8, application/json;q=0.5"),
@@ -823,7 +790,7 @@ mod tests {
 
         #[test]
         async fn test_string_type_without_json() {
-            let type_annotated_value = TypeAnnotatedValue::Str("Hello".to_string());
+            let type_annotated_value = "Hello".into_value_and_type();
             let (content_type, body) = get_content_type_and_body(
                 &type_annotated_value,
                 &AcceptHeaders::from_str("text/html;q=0.8, application/json;q=0.5"),
@@ -840,7 +807,7 @@ mod tests {
 
         #[test]
         async fn test_string_type_with_html() {
-            let type_annotated_value = TypeAnnotatedValue::Str("Hello".to_string());
+            let type_annotated_value = "Hello".into_value_and_type();
             let (content_type, body) = get_content_type_and_body(
                 &type_annotated_value,
                 &AcceptHeaders::from_str("text/html"),
@@ -854,7 +821,7 @@ mod tests {
 
         #[test]
         async fn test_singleton_u8_type_text() {
-            let type_annotated_value = TypeAnnotatedValue::U8(10);
+            let type_annotated_value = 10u8.into_value_and_type();
             let (content_type, body) = get_content_type_and_body(
                 &type_annotated_value,
                 &AcceptHeaders::from_str("application/json"),
@@ -868,7 +835,7 @@ mod tests {
 
         #[test]
         async fn test_singleton_u8_type_json() {
-            let type_annotated_value = TypeAnnotatedValue::U8(10);
+            let type_annotated_value = 10u8.into_value_and_type();
             let (content_type, body) = get_content_type_and_body(
                 &type_annotated_value,
                 &AcceptHeaders::from_str("application/json"),
@@ -882,7 +849,7 @@ mod tests {
 
         #[test]
         async fn test_singleton_u8_failed_content_mapping() {
-            let type_annotated_value = TypeAnnotatedValue::U8(10);
+            let type_annotated_value = 10u8.into_value_and_type();
             let result = internal::get_response_body_based_on_content_type(
                 &type_annotated_value,
                 &AcceptHeaders::from_str("text/html"),
@@ -896,7 +863,7 @@ mod tests {
 
         #[test]
         async fn test_list_u8_type_with_json() {
-            let type_annotated_value = create_list(vec![TypeAnnotatedValue::U8(10)], &u8());
+            let type_annotated_value = create_list(vec![10u8.into_value()], u8());
 
             let (content_type, body) = get_content_type_and_body(
                 &type_annotated_value,
@@ -904,7 +871,8 @@ mod tests {
             );
             let result = &body.into_bytes().await.unwrap();
             let data_as_str = String::from_utf8_lossy(result).to_string();
-            let result_json: Result<Value, _> = serde_json::from_str(data_as_str.as_str());
+            let result_json: Result<serde_json::Value, _> =
+                serde_json::from_str(data_as_str.as_str());
 
             assert_eq!(
                 (result, content_type),
@@ -918,7 +886,7 @@ mod tests {
 
         #[test]
         async fn test_list_non_u8_type_with_json() {
-            let type_annotated_value = create_list(vec![TypeAnnotatedValue::U16(10)], &u16());
+            let type_annotated_value = create_list(vec![10u16.into_value()], u16());
 
             let (content_type, body) = get_content_type_and_body(
                 &type_annotated_value,
@@ -926,8 +894,9 @@ mod tests {
             );
             let data_as_str =
                 String::from_utf8_lossy(&body.into_bytes().await.unwrap()).to_string();
-            let result_json: Value = serde_json::from_str(data_as_str.as_str()).unwrap();
-            let expected_json = Value::Array(vec![serde_json::Value::Number(
+            let result_json: serde_json::Value =
+                serde_json::from_str(data_as_str.as_str()).unwrap();
+            let expected_json = serde_json::Value::Array(vec![serde_json::Value::Number(
                 serde_json::Number::from(10),
             )]);
             assert_eq!(
@@ -938,7 +907,7 @@ mod tests {
 
         #[test]
         async fn test_list_non_u8_type_with_html_fail() {
-            let type_annotated_value = create_list(vec![TypeAnnotatedValue::U16(10)], &u16());
+            let type_annotated_value = create_list(vec![10u16.into_value()], u16());
 
             let result = internal::get_response_body_based_on_content_type(
                 &type_annotated_value,
@@ -960,7 +929,8 @@ mod tests {
             );
             let data_as_str =
                 String::from_utf8_lossy(&body.into_bytes().await.unwrap()).to_string();
-            let result_json: Value = serde_json::from_str(data_as_str.as_str()).unwrap();
+            let result_json: serde_json::Value =
+                serde_json::from_str(data_as_str.as_str()).unwrap();
             let expected_json = serde_json::json!({"name": "Hello"});
             assert_eq!(
                 (result_json, content_type),
diff --git a/golem-worker-service/src/gateway_execution/http_handler_binding_handler.rs b/golem-worker-service/src/gateway_execution/http_handler_binding_handler.rs
index e2d7712b..46506ac6 100644
--- a/golem-worker-service/src/gateway_execution/http_handler_binding_handler.rs
+++ b/golem-worker-service/src/gateway_execution/http_handler_binding_handler.rs
@@ -19,8 +19,7 @@ use bytes::Bytes;
 use golem_common::model::auth::Namespace;
 use golem_common::virtual_exports::http_incoming_handler::IncomingHttpRequest;
 use golem_common::{virtual_exports, widen_infallible};
-use golem_wasm_rpc::protobuf::type_annotated_value::TypeAnnotatedValue;
-use golem_wasm_rpc::TypeAnnotatedValueConstructors;
+use golem_wasm_rpc::ValueAndType;
 use http::StatusCode;
 use http_body_util::combinators::BoxBody;
 use http_body_util::BodyExt;
@@ -71,19 +70,20 @@ impl HttpHandlerBindingHandler for DefaultHttpHandlerBindingHandler {
     ) -> HttpHandlerBindingResult {
         let component_id = worker_detail.component_id.clone();
 
-        let typ: golem_wasm_ast::analysis::protobuf::Type =
-            (&IncomingHttpRequest::analysed_type()).into();
-
-        let type_annotated_param =
-            TypeAnnotatedValue::create(&incoming_http_request.to_value(), typ).map_err(|e| {
-                HttpHandlerBindingError::InternalError(format!(
-                    "Failed converting request into wasm rpc: {e:?}"
-                ))
-            })?;
+        let type_annotated_param = ValueAndType::new(
+            incoming_http_request.to_value(),
+            IncomingHttpRequest::analysed_type(),
+        );
 
         let resolved_request = GatewayResolvedWorkerRequest {
             component_id,
-            worker_name: worker_detail.worker_name.clone(),
+            worker_name: worker_detail
+                .worker_name
+                .as_ref()
+                .ok_or_else(|| {
+                    HttpHandlerBindingError::InternalError("Missing worker name".to_string())
+                })?
+                .clone(),
             function_name: virtual_exports::http_incoming_handler::FUNCTION_NAME.to_string(),
             function_params: vec![type_annotated_param],
             idempotency_key: worker_detail.idempotency_key.clone(),
diff --git a/golem-worker-service/src/gateway_execution/to_response.rs b/golem-worker-service/src/gateway_execution/to_response.rs
index e9181636..46b2e886 100644
--- a/golem-worker-service/src/gateway_execution/to_response.rs
+++ b/golem-worker-service/src/gateway_execution/to_response.rs
@@ -15,6 +15,7 @@
 use super::auth_call_back_binding_handler::{AuthorisationError, AuthorisationSuccess};
 use super::file_server_binding_handler::FileServerBindingSuccess;
 use super::http_handler_binding_handler::{HttpHandlerBindingError, HttpHandlerBindingSuccess};
+use super::swagger_binding_handler::{SwaggerBindingError, SwaggerBindingSuccess};
 use super::RibInputTypeMismatch;
 use crate::api::common::ApiEndpointError;
 use crate::gateway_execution::file_server_binding_handler::FileServerBindingError;
@@ -283,6 +284,30 @@ impl ToHttpResponse for AuthorisationError {
     }
 }
 
+#[async_trait]
+impl ToHttpResponse for SwaggerBindingSuccess {
+    async fn to_response(
+        self,
+        _request_details: &RichRequest,
+        _session_store: &GatewaySessionStore,
+    ) -> poem::Response {
+        poem::Response::builder()
+            .content_type("text/html")
+            .body(Body::from_string(self.html_content))
+    }
+}
+
+#[async_trait]
+impl ToHttpResponse for SwaggerBindingError {
+    async fn to_response(
+        self,
+        _request_details: &RichRequest,
+        _session_store: &GatewaySessionStore,
+    ) -> poem::Response {
+        self.into()
+    }
+}
+
 mod internal {
     use crate::gateway_execution::http_content_type_mapper::{
         ContentTypeHeaders, HttpContentTypeResponseMapper,
@@ -295,13 +320,13 @@ mod internal {
     use crate::path::Path;
 
     use crate::headers::ResolvedResponseHeaders;
-    use golem_wasm_rpc::protobuf::type_annotated_value::TypeAnnotatedValue;
+    use golem_wasm_rpc::ValueAndType;
     use poem::{Body, IntoResponse, ResponseParts};
     use rib::RibResult;
 
     #[derive(Debug)]
     pub(crate) struct IntermediateHttpResponse {
-        body: Option<TypeAnnotatedValue>,
+        body: Option<ValueAndType>,
         status: StatusCode,
         headers: ResolvedResponseHeaders,
     }
@@ -317,14 +342,9 @@ mod internal {
                     let headers =
                         get_response_headers_or_default(rib_result).map_err(RibRuntimeError)?;
 
-                    let tav: TypeAnnotatedValue = rib_result
-                        .clone()
-                        .try_into()
-                        .map_err(|errs: Vec<String>| RibRuntimeError(errs.join(", ")))?;
-
-                    let body = tav
+                    let body = rib_result
                         .get_optional(&Path::from_key("body"))
-                        .unwrap_or(tav.clone());
+                        .unwrap_or(rib_result.clone());
 
                     Ok(IntermediateHttpResponse {
                         body: Some(body),
diff --git a/golem-worker-service/src/getter.rs b/golem-worker-service/src/getter.rs
index a5ec51ed..97cca56f 100644
--- a/golem-worker-service/src/getter.rs
+++ b/golem-worker-service/src/getter.rs
@@ -14,10 +14,8 @@
 
 use crate::headers::ResolvedResponseHeaders;
 use crate::path::{Path, PathComponent};
-use golem_wasm_ast::analysis::{AnalysedType, TypeRecord};
-use golem_wasm_rpc::json::TypeAnnotatedValueJsonExtensions;
-use golem_wasm_rpc::protobuf::type_annotated_value::TypeAnnotatedValue;
-use golem_wasm_rpc::protobuf::{TypedList, TypedRecord, TypedTuple};
+use golem_wasm_ast::analysis::{AnalysedType, TypeList, TypeRecord, TypeTuple};
+use golem_wasm_rpc::json::ValueAndTypeJsonExtensions;
 use golem_wasm_rpc::{Value, ValueAndType};
 use http::StatusCode;
 use rib::GetLiteralValue;
@@ -42,36 +40,45 @@ pub enum GetError {
 }
 
 // To deal with fields in a TypeAnnotatedValue (that's returned from golem-rib)
-impl Getter<TypeAnnotatedValue> for TypeAnnotatedValue {
-    fn get(&self, key: &Path) -> Result<TypeAnnotatedValue, GetError> {
+impl Getter<ValueAndType> for ValueAndType {
+    fn get(&self, key: &Path) -> Result<ValueAndType, GetError> {
         let size = key.0.len();
         fn go(
-            type_annotated_value: &TypeAnnotatedValue,
+            value_and_type: &ValueAndType,
             paths: Vec<PathComponent>,
             index: usize,
             size: usize,
-        ) -> Result<TypeAnnotatedValue, GetError> {
+        ) -> Result<ValueAndType, GetError> {
             if index < size {
                 match &paths[index] {
-                    PathComponent::KeyName(key) => match type_annotated_value {
-                        TypeAnnotatedValue::Record(TypedRecord { value, .. }) => {
-                            let new_value = value
-                                .iter()
-                                .find(|name_value| name_value.name == key.0)
-                                .and_then(|v| v.value.clone().map(|vv| vv.type_annotated_value))
-                                .flatten();
-
-                            match new_value {
-                                Some(new_value) => go(&new_value, paths, index + 1, size),
-                                _ => Err(GetError::KeyNotFound(key.0.clone())),
+                    PathComponent::KeyName(key) => {
+                        match (&value_and_type.typ, &value_and_type.value) {
+                            (
+                                AnalysedType::Record(TypeRecord { fields, .. }),
+                                Value::Record(field_values),
+                            ) => {
+                                let new_value = fields
+                                    .iter()
+                                    .zip(field_values)
+                                    .find(|(field, _value)| field.name == key.0)
+                                    .map(|(field, value)| {
+                                        ValueAndType::new(value.clone(), field.typ.clone())
+                                    });
+                                match new_value {
+                                    Some(new_value) => go(&new_value, paths, index + 1, size),
+                                    _ => Err(GetError::KeyNotFound(key.0.clone())),
+                                }
                             }
+                            _ => match value_and_type.to_json_value() {
+                                Ok(json) => Err(GetError::NotRecord {
+                                    key_name: key.0.clone(),
+                                    found: json.to_string(),
+                                }),
+                                Err(err) => Err(GetError::Internal(err)),
+                            },
                         }
-                        _ => Err(GetError::NotRecord {
-                            key_name: key.0.clone(),
-                            found: type_annotated_value.to_json_value().to_string(),
-                        }),
-                    },
-                    PathComponent::Index(value_index) => match get_array(type_annotated_value) {
+                    }
+                    PathComponent::Index(value_index) => match get_array(value_and_type) {
                         Some(type_values) => {
                             let new_value = type_values.get(value_index.0);
                             match new_value {
@@ -79,14 +86,17 @@ impl Getter<TypeAnnotatedValue> for TypeAnnotatedValue {
                                 None => Err(GetError::IndexNotFound(value_index.0)),
                             }
                         }
-                        None => Err(GetError::NotArray {
-                            index: value_index.0,
-                            found: type_annotated_value.to_json_value().to_string(),
-                        }),
+                        None => match value_and_type.to_json_value() {
+                            Ok(json) => Err(GetError::NotArray {
+                                index: value_index.0,
+                                found: json.to_string(),
+                            }),
+                            Err(err) => Err(GetError::Internal(err)),
+                        },
                     },
                 }
             } else {
-                Ok(type_annotated_value.clone())
+                Ok(value_and_type.clone())
             }
         }
 
@@ -94,30 +104,20 @@ impl Getter<TypeAnnotatedValue> for TypeAnnotatedValue {
     }
 }
 
-impl Getter<ValueAndType> for ValueAndType {
-    fn get(&self, key: &Path) -> Result<ValueAndType, GetError> {
-        let tav: TypeAnnotatedValue = self
-            .clone()
-            .try_into()
-            .map_err(|errs: Vec<String>| GetError::Internal(errs.join(", ")))?;
-        let result = tav.get(key)?;
-        result.try_into().map_err(GetError::Internal)
-    }
-}
-
-fn get_array(value: &TypeAnnotatedValue) -> Option<Vec<TypeAnnotatedValue>> {
-    match value {
-        TypeAnnotatedValue::List(TypedList { values, .. }) => {
+fn get_array(value: &ValueAndType) -> Option<Vec<ValueAndType>> {
+    match (&value.typ, &value.value) {
+        (AnalysedType::List(TypeList { inner, .. }), Value::List(values)) => {
             let vec = values
                 .iter()
-                .filter_map(|v| v.clone().type_annotated_value)
+                .map(|v| ValueAndType::new(v.clone(), (**inner).clone()))
                 .collect::<Vec<_>>();
             Some(vec)
         }
-        TypeAnnotatedValue::Tuple(TypedTuple { value, .. }) => {
-            let vec = value
+        (AnalysedType::Tuple(TypeTuple { items, .. }), Value::Tuple(values)) => {
+            let vec = items
                 .iter()
-                .filter_map(|v| v.clone().type_annotated_value)
+                .zip(values)
+                .map(|(typ, v)| ValueAndType::new(v.clone(), typ.clone()))
                 .collect::<Vec<_>>();
             Some(vec)
         }
diff --git a/golem-worker-service/src/grpcapi/mod.rs b/golem-worker-service/src/grpcapi/mod.rs
index 4e274b25..76b6b109 100644
--- a/golem-worker-service/src/grpcapi/mod.rs
+++ b/golem-worker-service/src/grpcapi/mod.rs
@@ -17,15 +17,15 @@ mod worker;
 
 use crate::grpcapi::worker::WorkerGrpcApi;
 use crate::service::Services;
-use futures_util::TryFutureExt;
+use futures::TryFutureExt;
 use golem_api_grpc::proto;
 use golem_api_grpc::proto::golem::common::{ErrorBody, ErrorsBody};
 use golem_api_grpc::proto::golem::worker::v1::worker_service_server::WorkerServiceServer;
 use golem_api_grpc::proto::golem::worker::v1::{
     worker_error, worker_execution_error, WorkerError, WorkerExecutionError,
 };
-use golem_common::model::{ComponentFilePath, TargetWorkerId, WorkerId};
-use golem_wasm_rpc::json::OptionallyTypeAnnotatedValueJson;
+use golem_common::model::{ComponentFilePath, WorkerId};
+use golem_wasm_rpc::json::OptionallyValueAndTypeJson;
 use std::net::SocketAddr;
 use tokio::net::TcpListener;
 use tokio::task::JoinSet;
@@ -40,7 +40,7 @@ pub async fn start_grpc_server(
     services: Services,
     join_set: &mut JoinSet<Result<(), anyhow::Error>>,
 ) -> anyhow::Result<u16> {
-    let (mut health_reporter, health_service) = tonic_health::server::health_reporter();
+    let (health_reporter, health_service) = tonic_health::server::health_reporter();
 
     let listener = TcpListener::bind(addr).await?;
     let port = listener.local_addr()?.port();
@@ -90,20 +90,6 @@ pub fn validated_worker_id(
     })
 }
 
-pub fn validated_target_worker_id(
-    component_id: golem_common::model::ComponentId,
-    worker_name: Option<String>,
-) -> Result<TargetWorkerId, WorkerError> {
-    if let Some(worker_name) = &worker_name {
-        WorkerId::validate_worker_name(worker_name)
-            .map_err(|error| bad_request_error(format!("Invalid worker name: {error}")))?;
-    }
-    Ok(TargetWorkerId {
-        component_id,
-        worker_name,
-    })
-}
-
 pub fn validate_protobuf_worker_id(
     worker_id: Option<golem_api_grpc::proto::golem::worker::WorkerId>,
 ) -> Result<WorkerId, WorkerError> {
@@ -114,16 +100,6 @@ pub fn validate_protobuf_worker_id(
     validated_worker_id(worker_id.component_id, worker_id.worker_name)
 }
 
-pub fn validate_protobuf_target_worker_id(
-    worker_id: Option<golem_api_grpc::proto::golem::worker::TargetWorkerId>,
-) -> Result<TargetWorkerId, WorkerError> {
-    let worker_id = worker_id.ok_or_else(|| bad_request_error("Missing worker id"))?;
-    let worker_id: TargetWorkerId = worker_id
-        .try_into()
-        .map_err(|e| bad_request_error(format!("Invalid target worker id: {e}")))?;
-    validated_target_worker_id(worker_id.component_id, worker_id.worker_name)
-}
-
 pub fn validate_protobuf_plugin_installation_id(
     plugin_installation_id: Option<golem_api_grpc::proto::golem::common::PluginInstallationId>,
 ) -> Result<golem_common::model::PluginInstallationId, WorkerError> {
@@ -270,8 +246,8 @@ pub fn error_to_status(error: WorkerError) -> Status {
 
 pub fn parse_json_invoke_parameters(
     parameters: &[String],
-) -> Result<Vec<OptionallyTypeAnnotatedValueJson>, WorkerError> {
-    let optionally_typed_parameters: Vec<OptionallyTypeAnnotatedValueJson> = parameters
+) -> Result<Vec<OptionallyValueAndTypeJson>, WorkerError> {
+    let optionally_typed_parameters: Vec<OptionallyValueAndTypeJson> = parameters
         .iter()
         .map(|param| serde_json::from_str(param))
         .collect::<Result<Vec<_>, _>>()
diff --git a/golem-worker-service/src/grpcapi/worker.rs b/golem-worker-service/src/grpcapi/worker.rs
index 76800377..8c5ce871 100644
--- a/golem-worker-service/src/grpcapi/worker.rs
+++ b/golem-worker-service/src/grpcapi/worker.rs
@@ -16,7 +16,7 @@ use super::error::WorkerTraceErrorKind;
 use super::{
     bad_request_error, bad_request_errors, error_to_status, parse_json_invoke_parameters,
     validate_component_file_path, validate_protobuf_plugin_installation_id,
-    validate_protobuf_target_worker_id, validate_protobuf_worker_id, validated_worker_id,
+    validate_protobuf_worker_id, validated_worker_id,
 };
 use crate::service::auth::AuthService;
 use crate::service::component::ComponentService;
@@ -28,22 +28,23 @@ use golem_api_grpc::proto::golem::common::{Empty, ErrorBody};
 use golem_api_grpc::proto::golem::worker::v1::worker_service_server::WorkerService as GrpcWorkerService;
 use golem_api_grpc::proto::golem::worker::v1::{
     activate_plugin_response, cancel_invocation_response, complete_promise_response,
-    deactivate_plugin_response, delete_worker_response, fork_worker_response, get_oplog_response,
-    get_worker_metadata_response, get_workers_metadata_response, interrupt_worker_response,
-    invoke_and_await_json_response, invoke_and_await_response, invoke_and_await_typed_response,
-    invoke_response, launch_new_worker_response, list_directory_response, resume_worker_response,
-    revert_worker_response, search_oplog_response, update_worker_response, worker_error,
-    worker_execution_error, ActivatePluginRequest, ActivatePluginResponse, CancelInvocationRequest,
+    deactivate_plugin_response, delete_worker_response, fork_worker_response,
+    get_file_system_node_response, get_oplog_response, get_worker_metadata_response,
+    get_workers_metadata_response, interrupt_worker_response, invoke_and_await_json_response,
+    invoke_and_await_response, invoke_and_await_typed_response, invoke_response,
+    launch_new_worker_response, resume_worker_response, revert_worker_response,
+    search_oplog_response, update_worker_response, worker_error, worker_execution_error,
+    ActivatePluginRequest, ActivatePluginResponse, CancelInvocationRequest,
     CancelInvocationResponse, CompletePromiseRequest, CompletePromiseResponse,
     ConnectWorkerRequest, DeactivatePluginRequest, DeactivatePluginResponse, DeleteWorkerRequest,
     DeleteWorkerResponse, ForkWorkerRequest, ForkWorkerResponse, GetFileContentsRequest,
-    GetFileContentsResponse, GetOplogRequest, GetOplogResponse, GetOplogSuccessResponse,
-    GetWorkerMetadataRequest, GetWorkerMetadataResponse, GetWorkersMetadataRequest,
-    GetWorkersMetadataResponse, GetWorkersMetadataSuccessResponse, InterruptWorkerRequest,
-    InterruptWorkerResponse, InvokeAndAwaitJsonRequest, InvokeAndAwaitJsonResponse,
-    InvokeAndAwaitRequest, InvokeAndAwaitResponse, InvokeAndAwaitTypedResponse, InvokeJsonRequest,
-    InvokeRequest, InvokeResponse, LaunchNewWorkerRequest, LaunchNewWorkerResponse,
-    LaunchNewWorkerSuccessResponse, ListDirectoryRequest, ListDirectoryResponse,
+    GetFileContentsResponse, GetFileSystemNodeRequest, GetFileSystemNodeResponse, GetOplogRequest,
+    GetOplogResponse, GetOplogSuccessResponse, GetWorkerMetadataRequest, GetWorkerMetadataResponse,
+    GetWorkersMetadataRequest, GetWorkersMetadataResponse, GetWorkersMetadataSuccessResponse,
+    InterruptWorkerRequest, InterruptWorkerResponse, InvokeAndAwaitJsonRequest,
+    InvokeAndAwaitJsonResponse, InvokeAndAwaitRequest, InvokeAndAwaitResponse,
+    InvokeAndAwaitTypedResponse, InvokeJsonRequest, InvokeRequest, InvokeResponse,
+    LaunchNewWorkerRequest, LaunchNewWorkerResponse, LaunchNewWorkerSuccessResponse,
     ResumeWorkerRequest, ResumeWorkerResponse, RevertWorkerRequest, RevertWorkerResponse,
     SearchOplogRequest, SearchOplogResponse, SearchOplogSuccessResponse, UnknownError,
     UpdateWorkerRequest, UpdateWorkerResponse, WorkerError as GrpcWorkerError,
@@ -53,7 +54,7 @@ use golem_api_grpc::proto::golem::worker::{InvokeResult, InvokeResultTyped, Work
 use golem_common::grpc::{
     proto_component_id_string, proto_idempotency_key_string,
     proto_invocation_context_parent_worker_id_string, proto_plugin_installation_id_string,
-    proto_target_worker_id_string, proto_worker_id_string,
+    proto_worker_id_string,
 };
 use golem_common::model::auth::AuthCtx;
 use golem_common::model::auth::ProjectAction;
@@ -61,6 +62,7 @@ use golem_common::model::oplog::OplogIndex;
 use golem_common::model::{ComponentVersion, ScanCursor, WorkerFilter, WorkerId};
 use golem_common::recorded_grpc_api_request;
 use golem_service_base::clients::get_authorisation_token;
+use std::collections::BTreeMap;
 use std::pin::Pin;
 use std::sync::Arc;
 use tap::TapFallible;
@@ -225,7 +227,7 @@ impl GrpcWorkerService for WorkerGrpcApi {
         let (m, _, r) = request.into_parts();
         let record = recorded_grpc_api_request!(
             "invoke_and_await",
-            worker_id = proto_target_worker_id_string(&r.worker_id),
+            worker_id = proto_worker_id_string(&r.worker_id),
             idempotency_key = proto_idempotency_key_string(&r.idempotency_key),
             function = r.function,
             context_parent_worker_id = proto_invocation_context_parent_worker_id_string(&r.context)
@@ -255,7 +257,7 @@ impl GrpcWorkerService for WorkerGrpcApi {
         let (m, _, r) = request.into_parts();
         let record = recorded_grpc_api_request!(
             "invoke_and_await_json",
-            worker_id = proto_target_worker_id_string(&r.worker_id),
+            worker_id = proto_worker_id_string(&r.worker_id),
             idempotency_key = proto_idempotency_key_string(&r.idempotency_key),
             function = r.function,
             context_parent_worker_id = proto_invocation_context_parent_worker_id_string(&r.context)
@@ -285,7 +287,7 @@ impl GrpcWorkerService for WorkerGrpcApi {
         let (m, _, r) = request.into_parts();
         let record = recorded_grpc_api_request!(
             "invoke_and_await_typed",
-            worker_id = proto_target_worker_id_string(&r.worker_id),
+            worker_id = proto_worker_id_string(&r.worker_id),
             idempotency_key = proto_idempotency_key_string(&r.idempotency_key),
             function = r.function,
             context_parent_worker_id = proto_invocation_context_parent_worker_id_string(&r.context)
@@ -315,7 +317,7 @@ impl GrpcWorkerService for WorkerGrpcApi {
         let (m, _, r) = request.into_parts();
         let record = recorded_grpc_api_request!(
             "invoke",
-            worker_id = proto_target_worker_id_string(&r.worker_id),
+            worker_id = proto_worker_id_string(&r.worker_id),
             idempotency_key = proto_idempotency_key_string(&r.idempotency_key),
             function = r.function,
             context_parent_worker_id = proto_invocation_context_parent_worker_id_string(&r.context)
@@ -341,7 +343,7 @@ impl GrpcWorkerService for WorkerGrpcApi {
         let (m, _, r) = request.into_parts();
         let record = recorded_grpc_api_request!(
             "invoke_json",
-            worker_id = proto_target_worker_id_string(&r.worker_id),
+            worker_id = proto_worker_id_string(&r.worker_id),
             idempotency_key = proto_idempotency_key_string(&r.idempotency_key),
             function = r.function,
             context_parent_worker_id = proto_invocation_context_parent_worker_id_string(&r.context)
@@ -523,30 +525,31 @@ impl GrpcWorkerService for WorkerGrpcApi {
         }))
     }
 
-    async fn list_directory(
+    async fn get_file_system_node(
         &self,
-        request: Request<ListDirectoryRequest>,
-    ) -> Result<Response<ListDirectoryResponse>, Status> {
-        let (metadata, _, request) = request.into_parts();
+        request: Request<GetFileSystemNodeRequest>,
+    ) -> Result<Response<GetFileSystemNodeResponse>, Status> {
+        let (metadata, _, req) = request.into_parts();
         let record = recorded_grpc_api_request!(
-            "get_file_contents",
-            worker_id = proto_target_worker_id_string(&request.worker_id),
+            "get_file_system_node",
+            worker_id = proto_worker_id_string(&req.worker_id),
+            path = req.path
         );
 
         let response = match self
-            .list_directory(request, metadata)
+            .get_file_system_node(req, metadata)
             .instrument(record.span.clone())
             .await
         {
-            Ok(response) => record.succeed(list_directory_response::Result::Success(response)),
+            Ok(response) => record.succeed(response.result.unwrap()),
             Err(error) => record.fail(
-                list_directory_response::Result::Error(error.clone()),
+                get_file_system_node_response::Result::Error(error.clone()),
                 &WorkerTraceErrorKind(&error),
             ),
         };
 
         Ok(Response::new(
-            golem_api_grpc::proto::golem::worker::v1::ListDirectoryResponse {
+            golem_api_grpc::proto::golem::worker::v1::GetFileSystemNodeResponse {
                 result: Some(response),
             },
         ))
@@ -562,7 +565,7 @@ impl GrpcWorkerService for WorkerGrpcApi {
         let (metadata, _, request) = request.into_parts();
         let record = recorded_grpc_api_request!(
             "get_file_contents",
-            worker_id = proto_target_worker_id_string(&request.worker_id),
+            worker_id = proto_worker_id_string(&request.worker_id),
         );
 
         let stream = self
@@ -573,7 +576,7 @@ impl GrpcWorkerService for WorkerGrpcApi {
         let stream = match stream {
             Ok(stream) => record.succeed(stream),
             Err(error) => {
-                let res = golem_api_grpc::proto::golem::worker::v1::GetFileContentsResponse {
+                let res = GetFileContentsResponse {
                     result: Some(
                         golem_api_grpc::proto::golem::worker::v1::get_file_contents_response::Result::Error(error.clone())
                     )
@@ -760,6 +763,11 @@ impl WorkerGrpcApi {
             .and_then(|id| id.try_into().ok())
             .ok_or_else(|| bad_request_error("Missing component id"))?;
 
+        let wasi_config_vars: BTreeMap<String, String> = request
+            .wasi_config_vars
+            .ok_or_else(|| bad_request_error("no wasi_config_vars field"))?
+            .into();
+
         let latest_component = self
             .component_service
             .get_latest(&component_id, &auth)
@@ -784,6 +792,8 @@ impl WorkerGrpcApi {
                 latest_component.versioned_component_id.version,
                 request.args,
                 request.env,
+                wasi_config_vars,
+                request.ignore_already_existing,
                 namespace,
             )
             .await?;
@@ -919,7 +929,7 @@ impl WorkerGrpcApi {
         metadata: MetadataMap,
     ) -> Result<(), GrpcWorkerError> {
         let auth = self.auth(metadata)?;
-        let worker_id = validate_protobuf_target_worker_id(request.worker_id)?;
+        let worker_id = validate_protobuf_worker_id(request.worker_id)?;
 
         let params = request
             .invoke_parameters
@@ -949,7 +959,7 @@ impl WorkerGrpcApi {
         metadata: MetadataMap,
     ) -> Result<(), GrpcWorkerError> {
         let auth = self.auth(metadata)?;
-        let worker_id = validate_protobuf_target_worker_id(request.worker_id)?;
+        let worker_id = validate_protobuf_worker_id(request.worker_id)?;
 
         let params = parse_json_invoke_parameters(&request.invoke_parameters)?;
         let params = InvocationParameters::from_optionally_type_annotated_value_jsons(params)
@@ -1001,7 +1011,7 @@ impl WorkerGrpcApi {
         metadata: MetadataMap,
     ) -> Result<InvokeResult, GrpcWorkerError> {
         let auth = self.auth(metadata)?;
-        let worker_id = validate_protobuf_target_worker_id(request.worker_id)?;
+        let worker_id = validate_protobuf_worker_id(request.worker_id)?;
 
         let params = request
             .invoke_parameters
@@ -1032,7 +1042,7 @@ impl WorkerGrpcApi {
         metadata: MetadataMap,
     ) -> Result<String, GrpcWorkerError> {
         let auth = self.auth(metadata)?;
-        let worker_id = validate_protobuf_target_worker_id(request.worker_id)?;
+        let worker_id = validate_protobuf_worker_id(request.worker_id)?;
         let params = parse_json_invoke_parameters(&request.invoke_parameters)?;
         let params = InvocationParameters::from_optionally_type_annotated_value_jsons(params)
             .map_err(bad_request_errors)?;
@@ -1091,7 +1101,7 @@ impl WorkerGrpcApi {
         metadata: MetadataMap,
     ) -> Result<InvokeResultTyped, GrpcWorkerError> {
         let auth = self.auth(metadata)?;
-        let worker_id = validate_protobuf_target_worker_id(request.worker_id)?;
+        let worker_id = validate_protobuf_worker_id(request.worker_id)?;
         let params = request
             .invoke_parameters
             .ok_or(bad_request_error("Missing invoke parameters"))?;
@@ -1118,9 +1128,7 @@ impl WorkerGrpcApi {
             .await?;
 
         Ok(InvokeResultTyped {
-            result: result.map(|tav| golem_wasm_rpc::protobuf::TypeAnnotatedValue {
-                type_annotated_value: Some(tav),
-            }),
+            result: result.map(|tav| tav.into()),
         })
     }
 
@@ -1279,16 +1287,14 @@ impl WorkerGrpcApi {
         })
     }
 
-    async fn list_directory(
+    async fn get_file_system_node(
         &self,
-        request: ListDirectoryRequest,
+        request: GetFileSystemNodeRequest,
         metadata: MetadataMap,
-    ) -> Result<
-        golem_api_grpc::proto::golem::worker::v1::ListDirectorySuccessResponse,
-        GrpcWorkerError,
-    > {
+    ) -> Result<golem_api_grpc::proto::golem::worker::v1::GetFileSystemNodeResponse, GrpcWorkerError>
+    {
         let auth = self.auth(metadata)?;
-        let worker_id = validate_protobuf_target_worker_id(request.worker_id)?;
+        let worker_id = validate_protobuf_worker_id(request.worker_id)?;
         let file_path = validate_component_file_path(request.path)?;
 
         let namespace = self
@@ -1297,12 +1303,18 @@ impl WorkerGrpcApi {
             .await?;
         let result = self
             .worker_service
-            .list_directory(&worker_id, file_path, namespace)
+            .get_file_system_node(&worker_id, file_path, namespace)
             .await?;
 
         Ok(
-            golem_api_grpc::proto::golem::worker::v1::ListDirectorySuccessResponse {
-                nodes: result.into_iter().map(|e| e.into()).collect(),
+            golem_api_grpc::proto::golem::worker::v1::GetFileSystemNodeResponse {
+                result: Some(
+                    golem_api_grpc::proto::golem::worker::v1::get_file_system_node_response::Result::Success(
+                        golem_api_grpc::proto::golem::worker::v1::ListFileSystemNodeResponse {
+                            nodes: result.into_iter().map(|e| e.into()).collect(),
+                        },
+                    ),
+                ),
             },
         )
     }
@@ -1313,7 +1325,7 @@ impl WorkerGrpcApi {
         metadata: MetadataMap,
     ) -> Result<<Self as GrpcWorkerService>::GetFileContentsStream, GrpcWorkerError> {
         let auth = self.auth(metadata)?;
-        let worker_id = validate_protobuf_target_worker_id(request.worker_id)?;
+        let worker_id = validate_protobuf_worker_id(request.worker_id)?;
         let file_path = validate_component_file_path(request.file_path)?;
 
         let namespace = self
@@ -1331,11 +1343,11 @@ impl WorkerGrpcApi {
             .map(|item|
                 match item {
                     Ok(data) =>
-                        Ok(golem_api_grpc::proto::golem::worker::v1::GetFileContentsResponse {
+                        Ok(GetFileContentsResponse {
                             result: Some(golem_api_grpc::proto::golem::worker::v1::get_file_contents_response::Result::Success(data.into())),
                         }),
                     Err(error) =>
-                        Ok(golem_api_grpc::proto::golem::worker::v1::GetFileContentsResponse {
+                        Ok(GetFileContentsResponse {
                             result: Some(golem_api_grpc::proto::golem::worker::v1::get_file_contents_response::Result::Error(error.into())),
                         })
                 }
diff --git a/golem-worker-service/src/model.rs b/golem-worker-service/src/model.rs
index 058490be..75dc098b 100644
--- a/golem-worker-service/src/model.rs
+++ b/golem-worker-service/src/model.rs
@@ -15,24 +15,38 @@
 use crate::gateway_api_definition::{ApiDefinitionId, ApiVersion};
 use crate::gateway_api_deployment::ApiSite;
 use derive_more::FromStr;
+use golem_common::model::oplog::WorkerResourceId;
 use golem_common::model::regions::OplogRegion;
-use golem_common::model::{AccountId, PluginInstallationId, ScanCursor, WorkerId};
+use golem_common::model::worker::WasiConfigVars;
+use golem_common::model::{
+    AccountId, PluginInstallationId, ScanCursor, WorkerId, WorkerResourceDescription,
+};
 use golem_common::model::{ComponentVersion, ProjectId, Timestamp, WorkerStatus};
-use golem_service_base::model::{ResourceMetadata, UpdateRecord};
+use golem_service_base::model::UpdateRecord;
 use poem_openapi::{NewType, Object};
 use serde::{Deserialize, Serialize};
 use std::collections::{HashMap, HashSet};
 use std::fmt::{Debug, Display};
 use uuid::Uuid;
 
-#[derive(Debug, Clone, PartialEq, Eq, serde::Serialize, serde::Deserialize, Object)]
+#[derive(Debug, Clone, PartialEq, serde::Serialize, serde::Deserialize, Object)]
+#[serde(rename_all = "camelCase")]
+#[oai(rename_all = "camelCase")]
+pub struct ExportedResourceMetadata {
+    pub key: WorkerResourceId,
+    pub description: WorkerResourceDescription,
+}
+
+#[derive(Debug, Clone, PartialEq, serde::Serialize, serde::Deserialize, Object)]
 #[serde(rename_all = "camelCase")]
 #[oai(rename_all = "camelCase")]
 pub struct WorkerMetadata {
     pub worker_id: WorkerId,
-    pub account_id: AccountId,
+    pub project_id: ProjectId,
+    pub created_by: AccountId,
     pub args: Vec<String>,
     pub env: HashMap<String, String>,
+    pub wasi_config_vars: WasiConfigVars,
     pub status: WorkerStatus,
     pub component_version: ComponentVersion,
     pub retry_count: u64,
@@ -42,7 +56,7 @@ pub struct WorkerMetadata {
     pub last_error: Option<String>,
     pub component_size: u64,
     pub total_linear_memory_size: u64,
-    pub owned_resources: HashMap<u64, ResourceMetadata>,
+    pub exported_resource_instances: Vec<ExportedResourceMetadata>,
     pub active_plugins: HashSet<PluginInstallationId>,
     /// Oplog regions that are skipped during the worker's state recovery, but describe
     /// the history of the worker. For example if an atomic region gets restarted, its partially
@@ -58,11 +72,28 @@ impl TryFrom<golem_api_grpc::proto::golem::worker::WorkerMetadata> for WorkerMet
     fn try_from(
         value: golem_api_grpc::proto::golem::worker::WorkerMetadata,
     ) -> Result<Self, Self::Error> {
+        let mut exported_resource_instances = Vec::new();
+
+        for desc in value.owned_resources {
+            exported_resource_instances.push(ExportedResourceMetadata {
+                key: WorkerResourceId(desc.resource_id),
+                description: WorkerResourceDescription {
+                    created_at: desc.created_at.ok_or("Missing created_at")?.into(),
+                    resource_owner: desc.resource_owner,
+                    resource_name: desc.resource_name,
+                },
+            });
+        }
         Ok(Self {
             worker_id: value.worker_id.ok_or("Missing worker_id")?.try_into()?,
-            account_id: value.account_id.ok_or("Missing account_id")?.into(),
+            project_id: value.project_id.ok_or("Missing project_id")?.try_into()?,
+            created_by: value.created_by.ok_or("Missing account_id")?.into(),
             args: value.args,
             env: value.env,
+            wasi_config_vars: value
+                .wasi_config_vars
+                .ok_or("Missing wasi_config_vars field")?
+                .into(),
             status: value.status.try_into()?,
             component_version: value.component_version,
             retry_count: value.retry_count,
@@ -76,11 +107,7 @@ impl TryFrom<golem_api_grpc::proto::golem::worker::WorkerMetadata> for WorkerMet
             last_error: value.last_error,
             component_size: value.component_size,
             total_linear_memory_size: value.total_linear_memory_size,
-            owned_resources: value
-                .owned_resources
-                .into_iter()
-                .map(|(k, v)| v.try_into().map(|v| (k, v)))
-                .collect::<Result<HashMap<_, _>, _>>()?,
+            exported_resource_instances,
             active_plugins: value
                 .active_plugins
                 .into_iter()
@@ -102,11 +129,23 @@ impl TryFrom<golem_api_grpc::proto::golem::worker::WorkerMetadata> for WorkerMet
 
 impl From<WorkerMetadata> for golem_api_grpc::proto::golem::worker::WorkerMetadata {
     fn from(value: WorkerMetadata) -> Self {
+        let mut owned_resources = Vec::new();
+        for instance in value.exported_resource_instances {
+            owned_resources.push(golem_api_grpc::proto::golem::worker::ResourceDescription {
+                resource_id: instance.key.0,
+                resource_name: instance.description.resource_name,
+                resource_owner: instance.description.resource_owner,
+                created_at: Some(instance.description.created_at.into()),
+            });
+        }
+
         Self {
             worker_id: Some(value.worker_id.into()),
-            account_id: Some(value.account_id.into()),
+            project_id: Some(value.project_id.into()),
+            created_by: Some(value.created_by.into()),
             args: value.args,
             env: value.env,
+            wasi_config_vars: Some(value.wasi_config_vars.into()),
             status: value.status.into(),
             component_version: value.component_version,
             retry_count: value.retry_count,
@@ -116,11 +155,7 @@ impl From<WorkerMetadata> for golem_api_grpc::proto::golem::worker::WorkerMetada
             last_error: value.last_error,
             component_size: value.component_size,
             total_linear_memory_size: value.total_linear_memory_size,
-            owned_resources: value
-                .owned_resources
-                .into_iter()
-                .map(|(k, v)| (k, v.into()))
-                .collect(),
+            owned_resources,
             active_plugins: value
                 .active_plugins
                 .into_iter()
@@ -140,7 +175,7 @@ impl From<WorkerMetadata> for golem_api_grpc::proto::golem::worker::WorkerMetada
     }
 }
 
-#[derive(Debug, Clone, PartialEq, Eq, serde::Serialize, serde::Deserialize, Object)]
+#[derive(Debug, Clone, PartialEq, serde::Serialize, serde::Deserialize, Object)]
 pub struct WorkersMetadataResponse {
     pub workers: Vec<WorkerMetadata>,
     pub cursor: Option<ScanCursor>,
diff --git a/golem-worker-service/src/service/gateway/api_definition.rs b/golem-worker-service/src/service/gateway/api_definition.rs
index 438100fd..4c728c53 100644
--- a/golem-worker-service/src/service/gateway/api_definition.rs
+++ b/golem-worker-service/src/service/gateway/api_definition.rs
@@ -40,6 +40,7 @@ use rib::RibCompilationError;
 use serde::{Deserialize, Serialize};
 use std::collections::{HashMap, HashSet};
 use std::fmt::Debug;
+use std::fmt::Write;
 use std::hash::Hash;
 use std::sync::Arc;
 use tracing::{error, info};
@@ -58,7 +59,8 @@ pub struct ApiDefinitionIdWithVersion {
 pub enum ApiDefinitionError {
     #[error(transparent)]
     ValidationError(#[from] ValidationErrors),
-    #[error("Unable to fetch component: {}", .0.iter().map(|c| c.to_string()).collect::<Vec<_>>().join(", "))]
+    #[error("Unable to fetch component: {}", .0.iter().map(|c| c.to_string()).collect::<Vec<_>>().join(", ")
+    )]
     ComponentNotFoundError(Vec<VersionedComponentId>),
     #[error("Rib compilation error: {0}")]
     RibCompilationErrors(String),
@@ -235,6 +237,23 @@ pub struct ApiDefinitionServiceConfig {
     component_by_id_cache_size: usize,
 }
 
+impl SafeDisplay for ApiDefinitionServiceConfig {
+    fn to_safe_string(&self) -> String {
+        let mut result = String::new();
+        let _ = writeln!(
+            &mut result,
+            "component by name cache size: {}",
+            self.component_by_name_cache_size
+        );
+        let _ = writeln!(
+            &mut result,
+            "component by id cache size: {}",
+            self.component_by_id_cache_size
+        );
+        result
+    }
+}
+
 impl Default for ApiDefinitionServiceConfig {
     fn default() -> Self {
         Self {
@@ -464,10 +483,13 @@ impl ApiDefinitionService for ApiDefinitionServiceDefault {
         let component_metadata_dictionary =
             ComponentMetadataDictionary::from_components(&components);
 
+        let conversion_context = self.conversion_context(namespace, auth_ctx);
+
         let compiled_http_api_definition = CompiledHttpApiDefinition::from_http_api_definition(
             &definition,
             &component_metadata_dictionary,
             namespace,
+            &conversion_context,
         )?;
 
         let record = ApiDefinitionRecord::new(compiled_http_api_definition.clone(), created_at)
@@ -536,10 +558,13 @@ impl ApiDefinitionService for ApiDefinitionServiceDefault {
         let component_metadata_dictionary =
             ComponentMetadataDictionary::from_components(&components);
 
+        let conversion_context = self.conversion_context(namespace, auth_ctx);
+
         let compiled_http_api_definition = CompiledHttpApiDefinition::from_http_api_definition(
             &definition,
             &component_metadata_dictionary,
             namespace,
+            &conversion_context,
         )?;
 
         let record = ApiDefinitionRecord::new(compiled_http_api_definition.clone(), created_at)
diff --git a/golem-worker-service/src/service/mod.rs b/golem-worker-service/src/service/mod.rs
index e510553a..443e4aa5 100644
--- a/golem-worker-service/src/service/mod.rs
+++ b/golem-worker-service/src/service/mod.rs
@@ -81,7 +81,7 @@ use golem_service_base::storage::blob::BlobStorage;
 use std::sync::Arc;
 use std::time::Duration;
 use tonic::codec::CompressionEncoding;
-use tracing::{error, info};
+use tracing::error;
 
 #[derive(Clone)]
 pub struct Services {
@@ -294,14 +294,6 @@ impl Services {
                 format!("Init error (aws domain): {e:?}")
             })?;
 
-            info!(
-                "AWS domain environment: {}, workspace: {}, region: {:?}, DNS name: {}",
-                config.environment,
-                config.workspace,
-                aws_config.region,
-                aws_domain_route.load_balancer.dns_name
-            );
-
             let domain_route: Arc<dyn RegisterDomainRoute> = Arc::new(aws_domain_route);
 
             let aws_cm = AwsCertificateManager::new(
@@ -320,16 +312,7 @@ impl Services {
                     format!("Init error (aws cert): {e:?}")
                 })?;
 
-            info!(
-                "AWS Certificate Manager environment: {}, workspace: {}, region: {:?}, DNS name: {}",
-                config.environment,
-                config.workspace,
-                aws_config.region,
-                aws_cm.load_balancer.dns_name
-            );
-
             let certificate_manager: Arc<dyn CertificateManager> = Arc::new(aws_cm);
-
             let domain_register_service: Arc<dyn RegisterDomain> =
                 Arc::new(AwsRegisterDomain::new(&aws_config, &config.domain_records));
 
@@ -381,6 +364,8 @@ impl Services {
             config.worker_executor_retries.clone(),
             routing_table_service.clone(),
             limit_service.clone(),
+            project_service.clone(),
+            config.cloud_service.clone(),
         ));
 
         let worker_request_to_http_service: Arc<dyn GatewayWorkerRequestExecutor> = Arc::new(
diff --git a/golem-worker-service/src/service/worker/default.rs b/golem-worker-service/src/service/worker/default.rs
index 7ec63634..9ad688cd 100644
--- a/golem-worker-service/src/service/worker/default.rs
+++ b/golem-worker-service/src/service/worker/default.rs
@@ -32,23 +32,26 @@ use golem_api_grpc::proto::golem::workerexecutor::v1::{
     RevertWorkerRequest, SearchOplogResponse, UpdateWorkerRequest,
 };
 use golem_common::client::MultiTargetGrpcClient;
-use golem_common::model::auth::Namespace;
+use golem_common::model::auth::{Namespace, TokenSecret};
 use golem_common::model::oplog::OplogIndex;
 use golem_common::model::public_oplog::{OplogCursor, PublicOplogEntry};
 use golem_common::model::RetryConfig;
 use golem_common::model::{
     ComponentFilePath, ComponentFileSystemNode, ComponentId, ComponentVersion, FilterComparator,
-    IdempotencyKey, PluginInstallationId, PromiseId, ScanCursor, TargetWorkerId, WorkerFilter,
-    WorkerId, WorkerStatus,
+    IdempotencyKey, PluginInstallationId, PromiseId, ScanCursor, WorkerFilter, WorkerId,
+    WorkerStatus,
 };
 use golem_service_base::clients::limit::LimitService;
+use golem_service_base::clients::project::ProjectService;
+use golem_service_base::clients::RemoteServiceConfig;
 use golem_service_base::error::worker_executor::WorkerExecutorError;
 use golem_service_base::model::RevertWorkerTarget;
 use golem_service_base::model::{GetOplogResponse, PublicOplogEntryWithIndex, ResourceLimits};
 use golem_service_base::service::routing_table::{HasRoutingTableService, RoutingTableService};
 use golem_wasm_ast::analysis::AnalysedFunctionResult;
-use golem_wasm_rpc::protobuf::type_annotated_value::TypeAnnotatedValue;
 use golem_wasm_rpc::protobuf::Val as ProtoVal;
+use golem_wasm_rpc::ValueAndType;
+use std::collections::BTreeMap;
 use std::pin::Pin;
 use std::{collections::HashMap, sync::Arc};
 use tonic::transport::Channel;
@@ -64,6 +67,8 @@ pub trait WorkerService: Send + Sync {
         component_version: u64,
         arguments: Vec<String>,
         environment_variables: HashMap<String, String>,
+        wasi_config_vars: BTreeMap<String, String>,
+        ignore_already_existing: bool,
         namespace: Namespace,
     ) -> WorkerResult<WorkerId>;
 
@@ -75,22 +80,19 @@ pub trait WorkerService: Send + Sync {
 
     async fn delete(&self, worker_id: &WorkerId, namespace: Namespace) -> WorkerResult<()>;
 
-    fn validate_typed_parameters(
-        &self,
-        params: Vec<TypeAnnotatedValue>,
-    ) -> WorkerResult<Vec<ProtoVal>>;
+    fn validate_typed_parameters(&self, params: Vec<ValueAndType>) -> WorkerResult<Vec<ProtoVal>>;
 
     /// Validates the provided list of `TypeAnnotatedValue` parameters, and then
     /// invokes the worker and waits its results, returning it as a `TypeAnnotatedValue`.
     async fn validate_and_invoke_and_await_typed(
         &self,
-        worker_id: &TargetWorkerId,
+        worker_id: &WorkerId,
         idempotency_key: Option<IdempotencyKey>,
         function_name: String,
-        params: Vec<TypeAnnotatedValue>,
+        params: Vec<ValueAndType>,
         invocation_context: Option<InvocationContext>,
         namespace: Namespace,
-    ) -> WorkerResult<Option<TypeAnnotatedValue>> {
+    ) -> WorkerResult<Option<ValueAndType>> {
         let params = self.validate_typed_parameters(params)?;
         self.invoke_and_await_typed(
             worker_id,
@@ -107,19 +109,19 @@ pub trait WorkerService: Send + Sync {
     /// it as a `TypeAnnotatedValue`.
     async fn invoke_and_await_typed(
         &self,
-        worker_id: &TargetWorkerId,
+        worker_id: &WorkerId,
         idempotency_key: Option<IdempotencyKey>,
         function_name: String,
         params: Vec<ProtoVal>,
         invocation_context: Option<InvocationContext>,
         namespace: Namespace,
-    ) -> WorkerResult<Option<TypeAnnotatedValue>>;
+    ) -> WorkerResult<Option<ValueAndType>>;
 
     /// Invokes a worker using raw `Val` parameter values and awaits its results returning
     /// a `Val` values (without type information)
     async fn invoke_and_await(
         &self,
-        worker_id: &TargetWorkerId,
+        worker_id: &WorkerId,
         idempotency_key: Option<IdempotencyKey>,
         function_name: String,
         params: Vec<ProtoVal>,
@@ -132,22 +134,22 @@ pub trait WorkerService: Send + Sync {
     /// without type information so they get forwarded to the executor.
     async fn invoke_and_await_json(
         &self,
-        worker_id: &TargetWorkerId,
+        worker_id: &WorkerId,
         idempotency_key: Option<IdempotencyKey>,
         function_name: String,
         params: Vec<String>,
         invocation_context: Option<InvocationContext>,
         namespace: Namespace,
-    ) -> WorkerResult<Option<TypeAnnotatedValue>>;
+    ) -> WorkerResult<Option<ValueAndType>>;
 
     /// Validates the provided list of `TypeAnnotatedValue` parameters, and then enqueues
     /// an invocation for the worker without awaiting its results.
     async fn validate_and_invoke(
         &self,
-        worker_id: &TargetWorkerId,
+        worker_id: &WorkerId,
         idempotency_key: Option<IdempotencyKey>,
         function_name: String,
-        params: Vec<TypeAnnotatedValue>,
+        params: Vec<ValueAndType>,
         invocation_context: Option<InvocationContext>,
         namespace: Namespace,
     ) -> WorkerResult<()> {
@@ -167,7 +169,7 @@ pub trait WorkerService: Send + Sync {
     /// parameters.
     async fn invoke(
         &self,
-        worker_id: &TargetWorkerId,
+        worker_id: &WorkerId,
         idempotency_key: Option<IdempotencyKey>,
         function_name: String,
         params: Vec<ProtoVal>,
@@ -180,7 +182,7 @@ pub trait WorkerService: Send + Sync {
     /// be converted to `Val` so they get forwarded as-is to the executor.
     async fn invoke_json(
         &self,
-        worker_id: &TargetWorkerId,
+        worker_id: &WorkerId,
         idempotency_key: Option<IdempotencyKey>,
         function_name: String,
         params: Vec<String>,
@@ -252,16 +254,16 @@ pub trait WorkerService: Send + Sync {
         namespace: Namespace,
     ) -> Result<GetOplogResponse, WorkerServiceError>;
 
-    async fn list_directory(
+    async fn get_file_system_node(
         &self,
-        worker_id: &TargetWorkerId,
+        worker_id: &WorkerId,
         path: ComponentFilePath,
         namespace: Namespace,
     ) -> WorkerResult<Vec<ComponentFileSystemNode>>;
 
     async fn get_file_contents(
         &self,
-        worker_id: &TargetWorkerId,
+        worker_id: &WorkerId,
         path: ComponentFilePath,
         namespace: Namespace,
     ) -> WorkerResult<Pin<Box<dyn Stream<Item = WorkerResult<Bytes>> + Send + 'static>>>;
@@ -304,7 +306,7 @@ pub trait WorkerService: Send + Sync {
 }
 
 pub struct TypedResult {
-    pub result: TypeAnnotatedValue,
+    pub result: ValueAndType,
     pub function_result_types: Vec<AnalysedFunctionResult>,
 }
 
@@ -317,6 +319,8 @@ pub struct WorkerServiceDefault {
     worker_executor_retries: RetryConfig,
     routing_table_service: Arc<dyn RoutingTableService + Send + Sync>,
     limit_service: Arc<dyn LimitService>,
+    project_service: Arc<dyn ProjectService + Send + Sync>,
+    cloud_service_config: RemoteServiceConfig,
 }
 
 impl WorkerServiceDefault {
@@ -325,19 +329,32 @@ impl WorkerServiceDefault {
         worker_executor_retries: RetryConfig,
         routing_table_service: Arc<dyn RoutingTableService>,
         limit_service: Arc<dyn LimitService>,
+        project_service: Arc<dyn ProjectService + Send + Sync>,
+        cloud_service_config: RemoteServiceConfig,
     ) -> Self {
         Self {
             worker_executor_clients,
             worker_executor_retries,
             routing_table_service,
             limit_service,
+            project_service,
+            cloud_service_config,
         }
     }
 
     async fn get_resource_limits(&self, namespace: &Namespace) -> WorkerResult<ResourceLimits> {
+        // TODO: cache this?
+        let project_owner = self
+            .project_service
+            .get(
+                &namespace.project_id,
+                &TokenSecret::new(self.cloud_service_config.access_token),
+            )
+            .await?
+            .owner_account_id;
         let resource_limits = self
             .limit_service
-            .get_resource_limits(&namespace.account_id)
+            .get_resource_limits(&project_owner)
             .await?;
 
         Ok(resource_limits)
@@ -416,6 +433,7 @@ impl WorkerServiceDefault {
                             count,
                             precise,
                             account_id: Some(namespace.account_id.clone().into()),
+                            project_id: Some(namespace.project_id.clone().into()),
                         },
                     ))
                 },
@@ -482,6 +500,8 @@ impl WorkerService for WorkerServiceDefault {
         component_version: u64,
         arguments: Vec<String>,
         environment_variables: HashMap<String, String>,
+        wasi_config_vars: BTreeMap<String, String>,
+        ignore_already_existing: bool,
         namespace: Namespace,
     ) -> WorkerResult<WorkerId> {
         let resource_limits = self.get_resource_limits(&namespace).await?;
@@ -499,7 +519,10 @@ impl WorkerService for WorkerServiceDefault {
                     args: arguments.clone(),
                     env: environment_variables.clone(),
                     account_id: Some(account_id.clone().into()),
+                    project_id: Some(namespace.project_id.clone().into()),
                     account_limits: Some(resource_limits.clone().into()),
+                    wasi_config_vars: Some(wasi_config_vars.clone().into()),
+                    ignore_already_existing,
                 }))
             },
             |response| match response.into_inner() {
@@ -530,6 +553,7 @@ impl WorkerService for WorkerServiceDefault {
         let resource_limits = self.get_resource_limits(&namespace).await?;
 
         let account_id = namespace.account_id.clone();
+        let project_id = namespace.project_id.clone();
         let worker_id_clone = worker_id.clone();
         let worker_id_err = worker_id.clone();
         let stream = self
@@ -541,6 +565,7 @@ impl WorkerService for WorkerServiceDefault {
                         worker_id: Some(worker_id_clone.clone().into()),
                         account_id: Some(account_id.clone().into()),
                         account_limits: Some(resource_limits.clone().into()),
+                        project_id: Some(project_id.clone().into()),
                     }))
                 },
                 |response| Ok(WorkerStream::new(response.into_inner())),
@@ -581,6 +606,7 @@ impl WorkerService for WorkerServiceDefault {
                             worker_id_clone.clone(),
                         )),
                         account_id: Some(account_id_clone.clone().into()),
+                        project_id: Some(namespace.project_id.clone().into()),
                     },
                 ))
             },
@@ -604,14 +630,10 @@ impl WorkerService for WorkerServiceDefault {
         Ok(())
     }
 
-    fn validate_typed_parameters(
-        &self,
-        params: Vec<TypeAnnotatedValue>,
-    ) -> WorkerResult<Vec<ProtoVal>> {
+    fn validate_typed_parameters(&self, params: Vec<ValueAndType>) -> WorkerResult<Vec<ProtoVal>> {
         let mut result = Vec::new();
         for param in params {
-            let val =
-                golem_wasm_rpc::Value::try_from(param).map_err(WorkerServiceError::TypeChecker)?;
+            let val = param.value;
             result.push(golem_wasm_rpc::protobuf::Val::from(val));
         }
         Ok(result)
@@ -619,13 +641,13 @@ impl WorkerService for WorkerServiceDefault {
 
     async fn invoke_and_await_typed(
         &self,
-        worker_id: &TargetWorkerId,
+        worker_id: &WorkerId,
         idempotency_key: Option<IdempotencyKey>,
         function_name: String,
         params: Vec<ProtoVal>,
         invocation_context: Option<InvocationContext>,
         namespace: Namespace,
-    ) -> WorkerResult<Option<TypeAnnotatedValue>> {
+    ) -> WorkerResult<Option<ValueAndType>> {
         let resource_limits = self.get_resource_limits(&namespace).await?;
         let worker_id = worker_id.clone();
         let worker_id_clone = worker_id.clone();
@@ -643,6 +665,7 @@ impl WorkerService for WorkerServiceDefault {
                         account_id: Some(namespace.account_id.clone().into()),
                         account_limits: Some(resource_limits.clone().into()),
                         context: invocation_context.clone(),
+                        project_id: Some(namespace.project_id.clone().into()),
                     }
                 )
                 )
@@ -657,7 +680,10 @@ impl WorkerService for WorkerServiceDefault {
                                  },
                              )),
                     } => {
-                        Ok(output.and_then(|tav| tav.type_annotated_value))
+                        match output {
+                            Some(vnt) => ValueAndType::try_from(vnt).map(Some).map_err(|err| WorkerExecutorError::unknown(err).into()),
+                            None => Ok(None),
+                        }
                     }
                     workerexecutor::v1::InvokeAndAwaitWorkerResponseTyped {
                         result:
@@ -678,7 +704,7 @@ impl WorkerService for WorkerServiceDefault {
 
     async fn invoke_and_await(
         &self,
-        worker_id: &TargetWorkerId,
+        worker_id: &WorkerId,
         idempotency_key: Option<IdempotencyKey>,
         function_name: String,
         params: Vec<ProtoVal>,
@@ -702,6 +728,7 @@ impl WorkerService for WorkerServiceDefault {
                         account_id: Some(namespace.account_id.clone().into()),
                         account_limits: Some(resource_limits.clone().into()),
                         context: invocation_context.clone(),
+                        project_id: Some(namespace.project_id.clone().into()),
                     }
                 )
                 )
@@ -737,13 +764,13 @@ impl WorkerService for WorkerServiceDefault {
 
     async fn invoke_and_await_json(
         &self,
-        worker_id: &TargetWorkerId,
+        worker_id: &WorkerId,
         idempotency_key: Option<IdempotencyKey>,
         function_name: String,
         params: Vec<String>,
         invocation_context: Option<InvocationContext>,
         namespace: Namespace,
-    ) -> WorkerResult<Option<TypeAnnotatedValue>> {
+    ) -> WorkerResult<Option<ValueAndType>> {
         let resource_limits = self.get_resource_limits(&namespace).await?;
         let worker_id = worker_id.clone();
         let worker_id_clone = worker_id.clone();
@@ -761,6 +788,7 @@ impl WorkerService for WorkerServiceDefault {
                         account_id: Some(namespace.account_id.clone().into()),
                         account_limits: Some(resource_limits.clone().into()),
                         context: invocation_context.clone(),
+                        project_id: Some(namespace.project_id.clone().into()),
                     }
                 )
                 )
@@ -775,7 +803,12 @@ impl WorkerService for WorkerServiceDefault {
                                  },
                              )),
                     } => {
-                        Ok(output.and_then(|tav| tav.type_annotated_value))
+                        match output {
+                            Some(vnt) => {
+                                ValueAndType::try_from(vnt).map(Some).map_err(|err| WorkerExecutorError::unknown(err).into())
+                            }
+                            None => Ok(None),
+                        }
                     }
                     workerexecutor::v1::InvokeAndAwaitWorkerResponseTyped {
                         result:
@@ -796,7 +829,7 @@ impl WorkerService for WorkerServiceDefault {
 
     async fn invoke(
         &self,
-        worker_id: &TargetWorkerId,
+        worker_id: &WorkerId,
         idempotency_key: Option<IdempotencyKey>,
         function_name: String,
         params: Vec<ProtoVal>,
@@ -819,6 +852,7 @@ impl WorkerService for WorkerServiceDefault {
                         account_id: Some(namespace.account_id.clone().into()),
                         account_limits: Some(resource_limits.clone().into()),
                         context: invocation_context.clone(),
+                        project_id: Some(namespace.project_id.clone().into()),
                     },
                 ))
             },
@@ -839,7 +873,7 @@ impl WorkerService for WorkerServiceDefault {
 
     async fn invoke_json(
         &self,
-        worker_id: &TargetWorkerId,
+        worker_id: &WorkerId,
         idempotency_key: Option<IdempotencyKey>,
         function_name: String,
         params: Vec<String>,
@@ -862,6 +896,7 @@ impl WorkerService for WorkerServiceDefault {
                         account_id: Some(namespace.account_id.clone().into()),
                         account_limits: Some(resource_limits.clone().into()),
                         context: invocation_context.clone(),
+                        project_id: Some(namespace.project_id.clone().into()),
                     },
                 ))
             },
@@ -904,8 +939,9 @@ impl WorkerService for WorkerServiceDefault {
                             .complete_promise(CompletePromiseRequest {
                                 promise_id: Some(promise_id.into()),
                                 data,
-                                account_id: Some(namespace.account_id.clone().into())
-                        })
+                                account_id: Some(namespace.account_id.clone().into()),
+                                project_id: Some(namespace.project_id.clone().into()),
+                            })
                     )
                 },
                 |response| {
@@ -950,6 +986,7 @@ impl WorkerService for WorkerServiceDefault {
                         worker_id: Some(worker_id.into()),
                         recover_immediately,
                         account_id: Some(namespace.account_id.clone().into()),
+                        project_id: Some(namespace.project_id.clone().into()),
                     }),
                 )
             },
@@ -984,7 +1021,7 @@ impl WorkerService for WorkerServiceDefault {
                 Box::pin(worker_executor_client.get_worker_metadata(
                     workerexecutor::v1::GetWorkerMetadataRequest {
                         worker_id: Some(golem_api_grpc::proto::golem::worker::WorkerId::from(worker_id)),
-                        account_id: Some(namespace.account_id.clone().into())
+                        project_id: Some(namespace.project_id.clone().into()),
                     }
                 ))
             },
@@ -1050,6 +1087,7 @@ impl WorkerService for WorkerServiceDefault {
                     worker_id: Some(worker_id.into()),
                     account_id: Some(namespace.account_id.clone().into()),
                     force: Some(force),
+                    project_id: Some(namespace.project_id.clone().into()),
                 }))
             },
             |response| match response.into_inner() {
@@ -1085,6 +1123,7 @@ impl WorkerService for WorkerServiceDefault {
                     mode: update_mode.into(),
                     target_version,
                     account_id: Some(namespace.account_id.clone().into()),
+                    project_id: Some(namespace.project_id.clone().into()),
                 }))
             },
             |response| match response.into_inner() {
@@ -1122,7 +1161,7 @@ impl WorkerService for WorkerServiceDefault {
                         from_oplog_index: from_oplog_index.into(),
                         cursor: cursor.clone().map(|c| c.into()),
                         count,
-                        account_id: Some(namespace.account_id.clone().into()),
+                        project_id: Some(namespace.project_id.clone().into()),
                     }),
                 )
             },
@@ -1194,7 +1233,7 @@ impl WorkerService for WorkerServiceDefault {
                         query: query_clone,
                         cursor: cursor.clone().map(|c| c.into()),
                         count,
-                        account_id: Some(namespace.account_id.clone().into())
+                        project_id: Some(namespace.project_id.clone().into()),
                     }),
                 )
             },
@@ -1214,7 +1253,7 @@ impl WorkerService for WorkerServiceDefault {
                         .map(|e| e.try_into())
                         .collect::<Result<Vec<_>, _>>()
                         .map_err(|err| WorkerExecutorError::unknown(format!("Unexpected oplog entries in error: {err}")))?;
-                    let first_index_in_chunk =  entries.first().map(|entry| entry.oplog_index).unwrap_or(OplogIndex::INITIAL).into();
+                    let first_index_in_chunk = entries.first().map(|entry| entry.oplog_index).unwrap_or(OplogIndex::INITIAL).into();
                     Ok(GetOplogResponse {
                         entries,
                         next: next.map(|c| c.into()),
@@ -1232,9 +1271,9 @@ impl WorkerService for WorkerServiceDefault {
             .await
     }
 
-    async fn list_directory(
+    async fn get_file_system_node(
         &self,
-        worker_id: &TargetWorkerId,
+        worker_id: &WorkerId,
         path: ComponentFilePath,
         namespace: Namespace,
     ) -> WorkerResult<Vec<ComponentFileSystemNode>> {
@@ -1243,41 +1282,48 @@ impl WorkerService for WorkerServiceDefault {
         let path_clone = path.clone();
         self.call_worker_executor(
             worker_id.clone(),
-            "list_directory",
+            "get_file_system_node",
             move |worker_executor_client| {
                 let worker_id = worker_id.clone();
                 Box::pin(
-                    worker_executor_client.list_directory(workerexecutor::v1::ListDirectoryRequest {
+                    worker_executor_client.get_file_system_node(workerexecutor::v1::GetFileSystemNodeRequest {
                         worker_id: Some(worker_id.into()),
                         account_id: Some(namespace.account_id.clone().into()),
                         account_limits: Some(resource_limits.clone().into()),
-                        path: path_clone.to_string()
+                        path: path_clone.to_string(),
+                        project_id: Some(namespace.project_id.clone().into()),
                     }),
                 )
             },
             |response| match response.into_inner() {
-                workerexecutor::v1::ListDirectoryResponse {
-                    result: Some(golem_api_grpc::proto::golem::workerexecutor::v1::list_directory_response::Result::Success(success)),
+                workerexecutor::v1::GetFileSystemNodeResponse {
+                    result: Some(golem_api_grpc::proto::golem::workerexecutor::v1::get_file_system_node_response::Result::DirSuccess(success)),
                 } => {
                     success.nodes
                         .into_iter()
                         .map(|v|
                             v
-                            .try_into()
-                            .map_err(|_| "Failed to convert node".into())
+                                .try_into()
+                                .map_err(|_| "Failed to convert node".into())
                         )
                         .collect::<Result<Vec<_>, _>>()
                 }
-                workerexecutor::v1::ListDirectoryResponse {
-                    result: Some(workerexecutor::v1::list_directory_response::Result::Failure(err)),
+                workerexecutor::v1::GetFileSystemNodeResponse {
+                    result: Some(workerexecutor::v1::get_file_system_node_response::Result::Failure(err)),
                 } => Err(err.into()),
-                workerexecutor::v1::ListDirectoryResponse {
-                    result: Some(workerexecutor::v1::list_directory_response::Result::NotFound(_)),
+                workerexecutor::v1::GetFileSystemNodeResponse {
+                    result: Some(workerexecutor::v1::get_file_system_node_response::Result::NotFound(_)),
                 } => Err(WorkerServiceError::FileNotFound(path.clone()).into()),
-                workerexecutor::v1::ListDirectoryResponse {
-                    result: Some(workerexecutor::v1::list_directory_response::Result::NotADirectory(_)),
-                } => Err(WorkerServiceError::BadFileType(path.clone()).into()),
-                workerexecutor::v1::ListDirectoryResponse {
+                workerexecutor::v1::GetFileSystemNodeResponse {
+                    result: Some(workerexecutor::v1::get_file_system_node_response::Result::FileSuccess(file_response)),
+                } => {
+                    let file_node = file_response.file
+                        .ok_or(WorkerServiceError::Internal("Missing file data in response".to_string()))?
+                        .try_into()
+                        .map_err(|_| WorkerServiceError::Internal("Failed to convert file node".to_string()))?;
+                    Ok(vec![file_node])
+                },
+                workerexecutor::v1::GetFileSystemNodeResponse {
                     result: None
                 } => Err("Empty response".into()),
             },
@@ -1288,7 +1334,7 @@ impl WorkerService for WorkerServiceDefault {
 
     async fn get_file_contents(
         &self,
-        worker_id: &TargetWorkerId,
+        worker_id: &WorkerId,
         path: ComponentFilePath,
         namespace: Namespace,
     ) -> WorkerResult<Pin<Box<dyn Stream<Item = WorkerResult<Bytes>> + Send + 'static>>> {
@@ -1306,6 +1352,7 @@ impl WorkerService for WorkerServiceDefault {
                             account_id: Some(namespace.account_id.clone().into()),
                             account_limits: Some(resource_limits.clone().into()),
                             file_path: path_clone.to_string(),
+                            project_id: Some(namespace.project_id.clone().into()),
                         },
                     ))
                 },
@@ -1395,7 +1442,8 @@ impl WorkerService for WorkerServiceDefault {
                     worker_executor_client.activate_plugin(ActivatePluginRequest {
                         worker_id: Some(worker_id.into()),
                         installation_id: Some(plugin_installation_id.clone().into()),
-                        account_id: Some(namespace.account_id.clone().into())
+                        account_id: Some(namespace.account_id.clone().into()),
+                        project_id: Some(namespace.project_id.clone().into()),
                     }),
                 )
             },
@@ -1433,7 +1481,8 @@ impl WorkerService for WorkerServiceDefault {
                     worker_executor_client.deactivate_plugin(DeactivatePluginRequest {
                         worker_id: Some(worker_id.into()),
                         installation_id: Some(plugin_installation_id.clone().into()),
-                        account_id: Some(namespace.account_id.clone().into())
+                        account_id: Some(namespace.account_id.clone().into()),
+                        project_id: Some(namespace.project_id.clone().into()),
                     }),
                 )
             },
@@ -1474,6 +1523,7 @@ impl WorkerService for WorkerServiceDefault {
                     target_worker_id: Some(target_worker_id.into()),
                     account_id: Some(namespace.account_id.clone().into()),
                     oplog_index_cutoff: oplog_index_cut_off.into(),
+                    project_id: Some(namespace.project_id.clone().into()),
                 }))
             },
             |response| match response.into_inner() {
@@ -1508,6 +1558,7 @@ impl WorkerService for WorkerServiceDefault {
                     worker_id: Some(worker_id.into()),
                     target: Some(target.into()),
                     account_id: Some(namespace.account_id.clone().into()),
+                    project_id: Some(namespace.project_id.clone().into()),
                 }))
             },
             |response| match response.into_inner() {
@@ -1543,6 +1594,7 @@ impl WorkerService for WorkerServiceDefault {
                     worker_id: Some(worker_id.into()),
                     idempotency_key: Some(idempotency_key.into()),
                     account_id: Some(namespace.account_id.clone().into()),
+                    project_id: Some(namespace.project_id.clone().into()),
                 }))
             },
             |response| match response.into_inner() {
@@ -1556,7 +1608,7 @@ impl WorkerService for WorkerServiceDefault {
             },
             WorkerServiceError::InternalCallError,
         )
-        .await?;
+            .await?;
         Ok(canceled)
     }
 }
diff --git a/golem-worker-service/src/service/worker/error.rs b/golem-worker-service/src/service/worker/error.rs
index 45bf98e2..e78fc130 100644
--- a/golem-worker-service/src/service/worker/error.rs
+++ b/golem-worker-service/src/service/worker/error.rs
@@ -18,6 +18,7 @@ use golem_common::model::component::VersionedComponentId;
 use golem_common::model::{AccountId, ComponentFilePath, ComponentId, WorkerId};
 use golem_common::SafeDisplay;
 use golem_service_base::clients::limit::LimitError;
+use golem_service_base::clients::project::ProjectError;
 use golem_service_base::error::worker_executor::WorkerExecutorError;
 
 #[derive(Debug, thiserror::Error)]
@@ -30,6 +31,8 @@ pub enum WorkerServiceError {
     InternalCallError(CallWorkerExecutorError),
     #[error(transparent)]
     GolemError(#[from] WorkerExecutorError),
+    #[error(transparent)]
+    Project(#[from] ProjectError),
 
     #[error("Type checker error: {0}")]
     TypeChecker(String),
@@ -64,6 +67,7 @@ impl SafeDisplay for WorkerServiceError {
             Self::FileNotFound(_) => self.to_string(),
             Self::BadFileType(_) => self.to_string(),
             Self::LimitError(inner) => inner.to_safe_string(),
+            Self::Project(inner) => inner.to_safe_string(),
         }
     }
 }
@@ -116,6 +120,7 @@ impl From<WorkerServiceError> for golem_api_grpc::proto::golem::worker::v1::work
             }
 
             WorkerServiceError::Component(component) => component.into(),
+            WorkerServiceError::Project(project_error) => project_error.into(),
 
             WorkerServiceError::LimitError(LimitError::LimitExceeded(_)) => {
                 Self::LimitExceeded(ErrorBody {
diff --git a/golem-worker-service/src/service/worker/routing_logic.rs b/golem-worker-service/src/service/worker/routing_logic.rs
index c31a21ed..39464709 100644
--- a/golem-worker-service/src/service/worker/routing_logic.rs
+++ b/golem-worker-service/src/service/worker/routing_logic.rs
@@ -28,7 +28,7 @@ use golem_api_grpc::proto::golem::worker::v1::WorkerExecutionError;
 use golem_api_grpc::proto::golem::workerexecutor::v1::worker_executor_client::WorkerExecutorClient;
 use golem_common::client::MultiTargetGrpcClient;
 use golem_common::model::RetryConfig;
-use golem_common::model::{Pod, ShardId, TargetWorkerId, WorkerId};
+use golem_common::model::{Pod, ShardId, WorkerId};
 use golem_common::retriable_error::IsRetriableError;
 use golem_common::retries::get_delay;
 use golem_common::SafeDisplay;
@@ -137,49 +137,6 @@ impl<Out: Send + 'static> CallOnExecutor<Out> for WorkerId {
     }
 }
 
-#[async_trait]
-impl<Out: Send + 'static> CallOnExecutor<Out> for TargetWorkerId {
-    type ResultOut = Out;
-
-    async fn call_on_worker_executor<F>(
-        &self,
-        description: impl AsRef<str> + Send,
-        context: &(impl HasRoutingTableService + HasWorkerExecutorClients + Send + Sync),
-        f: F,
-    ) -> Result<(Option<Self::ResultOut>, Option<Pod>), CallWorkerExecutorErrorWithContext>
-    where
-        F: for<'a> Fn(
-                &'a mut WorkerExecutorClient<Channel>,
-            )
-                -> Pin<Box<dyn Future<Output = Result<Out, Status>> + 'a + Send>>
-            + Send
-            + Sync
-            + Clone
-            + 'static,
-    {
-        if let Some(worker_id) = self.clone().try_into_worker_id() {
-            // The TargetWorkerId had a worker name so we know which shard we need to call it on
-            worker_id
-                .call_on_worker_executor(description, context, f)
-                .await
-        } else {
-            // The TargetWorkerId did not have a worker name specified so we can forward the call to a random
-            // executor
-            RandomExecutor
-                .call_on_worker_executor(description, context, f)
-                .await
-        }
-    }
-
-    fn tracing_kind(&self) -> &'static str {
-        if self.worker_name.is_none() {
-            "RandomExecutor"
-        } else {
-            "WorkerId"
-        }
-    }
-}
-
 pub struct RandomExecutor;
 
 #[async_trait]
diff --git a/golem-worker-service/tests/api_gateway_end_to_end_tests.rs b/golem-worker-service/tests/api_gateway_end_to_end_tests.rs
index 43be8493..20d2927c 100644
--- a/golem-worker-service/tests/api_gateway_end_to_end_tests.rs
+++ b/golem-worker-service/tests/api_gateway_end_to_end_tests.rs
@@ -34,11 +34,11 @@ use golem_worker_service::gateway_security::{Provider, SecurityScheme, SecurityS
 use golem_worker_service::service::gateway::api_definition_validator::ValidationErrors;
 use golem_worker_service::service::gateway::{ComponentView, ConversionContext};
 use golem_worker_service::{api, gateway_api_definition};
-use http::header::{LOCATION, ORIGIN};
+use http::header::{HOST, LOCATION, ORIGIN};
 use http::{HeaderMap, HeaderValue, Method, StatusCode, Uri};
 use openidconnect::{ClientId, ClientSecret, RedirectUrl, Scope};
 use poem::{Request, Response};
-use serde_json::{Number, Value};
+use serde_json::{Number, Value as JsonValue};
 use std::sync::Arc;
 use test_r::test;
 use url::Url;
@@ -65,6 +65,7 @@ async fn execute(
         api_specification,
         &internal::get_component_metadata(),
         &test_namespace(),
+        &(Box::new(TestConversionContext) as Box<dyn ConversionContext>),
     )
     .expect("Failed to compile API definition");
 
@@ -73,6 +74,7 @@ async fn execute(
         internal::get_test_file_server_binding_handler(),
         Arc::new(DefaultAuthCallBack),
         internal::get_test_http_handler_binding_handler(),
+        internal::get_test_swagger_binding_handler(),
         Arc::new(internal::TestApiDefinitionLookup::new(compiled)),
         Arc::clone(session_store),
         Arc::new(test_identity_provider.clone()),
@@ -96,8 +98,15 @@ impl ConversionContext for TestConversionContext {
             Err("component not found".to_string())
         }
     }
-    async fn component_by_id(&self, _component_id: &ComponentId) -> Result<ComponentView, String> {
-        unimplemented!()
+    async fn component_by_id(&self, component_id: &ComponentId) -> Result<ComponentView, String> {
+        match component_id.to_string().as_str() {
+            "0b6d9cd8-f373-4e29-8a5a-548e61b868a5" => Ok(ComponentView {
+                id: component_id.clone(),
+                name: ComponentName("test-component".to_string()),
+                latest_version: 0,
+            }),
+            _ => Err("component not found".to_string()),
+        }
     }
 }
 
@@ -124,7 +133,7 @@ fn test_namespace() -> Namespace {
 
 #[test]
 async fn test_api_def_with_resource_1() {
-    let api_request = get_gateway_request("/foo/mystore", None, &HeaderMap::new(), Value::Null);
+    let api_request = get_gateway_request("/foo/mystore", None, &HeaderMap::new(), JsonValue::Null);
 
     // These functions get-user-name and get-currency produce the same result
     let response_mapping = r#"
@@ -169,7 +178,8 @@ async fn test_api_def_with_resource_1() {
 
 #[test]
 async fn test_api_def_with_single_query_param() {
-    let api_request = get_gateway_request("/foo?userid=jon", None, &HeaderMap::new(), Value::Null);
+    let api_request =
+        get_gateway_request("/foo?userid=jon", None, &HeaderMap::new(), JsonValue::Null);
 
     let response_mapping = r#"
        let user_id = request.query.userid;
@@ -198,9 +208,9 @@ async fn test_api_def_with_single_query_param() {
 
     let expected = (
         "golem:it/api.{get-cart-contents}".to_string(),
-        Value::Array(vec![
-            Value::String("jon".to_string()),
-            Value::String("bar".to_string()),
+        JsonValue::Array(vec![
+            JsonValue::String("jon".to_string()),
+            JsonValue::String("bar".to_string()),
         ]),
     );
 
@@ -213,7 +223,7 @@ async fn test_api_def_with_multiple_query_params() {
         "/foo?userid=jon&country=usa",
         None,
         &HeaderMap::new(),
-        Value::Null,
+        JsonValue::Null,
     );
 
     let response_mapping = r#"
@@ -244,9 +254,9 @@ async fn test_api_def_with_multiple_query_params() {
 
     let expected = (
         "golem:it/api.{get-cart-contents}".to_string(),
-        Value::Array(vec![
-            Value::String("jon".to_string()),
-            Value::String("usa".to_string()),
+        JsonValue::Array(vec![
+            JsonValue::String("jon".to_string()),
+            JsonValue::String("usa".to_string()),
         ]),
     );
 
@@ -255,8 +265,12 @@ async fn test_api_def_with_multiple_query_params() {
 
 #[test]
 async fn test_api_def_with_query_and_path_params() {
-    let api_request =
-        get_gateway_request("/foo/jon?country=usa", None, &HeaderMap::new(), Value::Null);
+    let api_request = get_gateway_request(
+        "/foo/jon?country=usa",
+        None,
+        &HeaderMap::new(),
+        JsonValue::Null,
+    );
 
     let response_mapping = r#"
        let user_id = request.path.user-id;
@@ -286,9 +300,9 @@ async fn test_api_def_with_query_and_path_params() {
 
     let expected = (
         "golem:it/api.{get-cart-contents}".to_string(),
-        Value::Array(vec![
-            Value::String("jon".to_string()),
-            Value::String("usa".to_string()),
+        JsonValue::Array(vec![
+            JsonValue::String("jon".to_string()),
+            JsonValue::String("usa".to_string()),
         ]),
     );
 
@@ -312,6 +326,7 @@ async fn test_api_def_with_invalid_path_lookup() {
         &api_specification,
         &internal::get_component_metadata(),
         &test_namespace(),
+        &(Box::new(TestConversionContext) as Box<dyn ConversionContext>),
     )
     .unwrap_err();
 
@@ -342,6 +357,7 @@ async fn test_api_def_with_invalid_query_and_path_lookup() {
         &api_specification1,
         &internal::get_component_metadata(),
         &test_namespace(),
+        &(Box::new(TestConversionContext) as Box<dyn ConversionContext>),
     )
     .unwrap_err();
 
@@ -363,6 +379,7 @@ async fn test_api_def_with_invalid_query_and_path_lookup() {
         &api_specification2,
         &internal::get_component_metadata(),
         &test_namespace(),
+        &(Box::new(TestConversionContext) as Box<dyn ConversionContext>),
     )
     .unwrap_err();
 
@@ -385,8 +402,12 @@ async fn test_api_def_with_path_parameters_in_space() {
         get_api_def_with_worker_binding("/foo/{ user-id   }?{    country }", response_mapping)
             .await;
 
-    let api_request =
-        get_gateway_request("/foo/jon?country=usa", None, &HeaderMap::new(), Value::Null);
+    let api_request = get_gateway_request(
+        "/foo/jon?country=usa",
+        None,
+        &HeaderMap::new(),
+        JsonValue::Null,
+    );
 
     let session_store: Arc<dyn GatewaySession + Sync + Send> = internal::get_session_store();
 
@@ -404,9 +425,9 @@ async fn test_api_def_with_path_parameters_in_space() {
 
     let expected = (
         "golem:it/api.{get-cart-contents}".to_string(),
-        Value::Array(vec![
-            Value::String("jon".to_string()),
-            Value::String("usa".to_string()),
+        JsonValue::Array(vec![
+            JsonValue::String("jon".to_string()),
+            JsonValue::String("usa".to_string()),
         ]),
     );
 
@@ -430,6 +451,7 @@ async fn test_api_def_with_invalid_query_lookup() {
         &api_specification,
         &internal::get_component_metadata(),
         &test_namespace(),
+        &(Box::new(TestConversionContext) as Box<dyn ConversionContext>),
     )
     .unwrap_err();
 
@@ -446,7 +468,8 @@ async fn test_api_def_with_invalid_query_lookup() {
 async fn test_api_def_with_request_path_0() {
     let empty_headers = HeaderMap::new();
 
-    let api_request = get_gateway_request("/foo/foo_value/1", None, &empty_headers, Value::Null);
+    let api_request =
+        get_gateway_request("/foo/foo_value/1", None, &empty_headers, JsonValue::Null);
 
     let response_mapping = r#"
          let bar-value: u32 = request.path.bar;
@@ -479,9 +502,9 @@ async fn test_api_def_with_request_path_0() {
     let expected = (
         "foo_value".to_string(),
         "golem:it/api.{add-item}".to_string(),
-        Value::Array(vec![
-            Value::Number(1.into()),
-            Value::String("bar".to_string()),
+        JsonValue::Array(vec![
+            JsonValue::Number(1.into()),
+            JsonValue::String("bar".to_string()),
         ]),
     );
 
@@ -491,7 +514,7 @@ async fn test_api_def_with_request_path_0() {
 // A test where the input path is a number, and the rib script refers to request.path.* as a u64
 #[test]
 async fn test_api_def_with_request_path_only_1() {
-    let api_request = get_gateway_request("/foo/1", None, &HeaderMap::new(), Value::Null);
+    let api_request = get_gateway_request("/foo/1", None, &HeaderMap::new(), JsonValue::Null);
 
     let response_mapping = r#"
        let id: u64 = request.path.user-id;
@@ -520,9 +543,9 @@ async fn test_api_def_with_request_path_only_1() {
 
     let expected = (
         "golem:it/api.{get-cart-contents}".to_string(),
-        Value::Array(vec![
-            Value::String("a".to_string()),
-            Value::String("b".to_string()),
+        JsonValue::Array(vec![
+            JsonValue::String("a".to_string()),
+            JsonValue::String("b".to_string()),
         ]),
     );
 
@@ -536,7 +559,8 @@ async fn test_api_def_with_request_path_only_2() {
     let mut header_map = HeaderMap::new();
     header_map.insert("project-id", HeaderValue::from_static("4"));
 
-    let api_request = get_gateway_request("/foo/1/2?account-id=3", None, &header_map, Value::Null);
+    let api_request =
+        get_gateway_request("/foo/1/2?account-id=3", None, &header_map, JsonValue::Null);
 
     let response_mapping = r#"
        let user-id = request.path.user-id;
@@ -570,9 +594,9 @@ async fn test_api_def_with_request_path_only_2() {
 
     let expected = (
         "golem:it/api.{get-cart-contents}".to_string(),
-        Value::Array(vec![
-            Value::String("1-2-3-4".to_string()),
-            Value::String("b".to_string()),
+        JsonValue::Array(vec![
+            JsonValue::String("1-2-3-4".to_string()),
+            JsonValue::String("b".to_string()),
         ]),
     );
 
@@ -647,20 +671,20 @@ async fn test_api_def_with_invalid_input_1() {
 async fn test_api_def_with_request_body_0() {
     let empty_headers = HeaderMap::new();
 
-    let mut request_body: serde_json::Map<String, Value> = serde_json::Map::new();
+    let mut request_body: serde_json::Map<String, JsonValue> = serde_json::Map::new();
 
-    request_body.insert("foo_key".to_string(), Value::Number(Number::from(1)));
+    request_body.insert("foo_key".to_string(), JsonValue::Number(Number::from(1)));
 
     request_body.insert(
         "bar_key".to_string(),
-        Value::String("bar_value".to_string()),
+        JsonValue::String("bar_value".to_string()),
     );
 
     let api_request = get_gateway_request(
         "/foo/john",
         None,
         &empty_headers,
-        Value::Object(request_body),
+        JsonValue::Object(request_body),
     );
 
     let response_mapping = r#"
@@ -693,9 +717,9 @@ async fn test_api_def_with_request_body_0() {
     let expected = (
         "bar_value".to_string(),
         "golem:it/api.{add-item}".to_string(),
-        Value::Array(vec![
-            Value::Number(1.into()),
-            Value::String("bar".to_string()),
+        JsonValue::Array(vec![
+            JsonValue::Number(1.into()),
+            JsonValue::String("bar".to_string()),
         ]),
     );
 
@@ -706,20 +730,20 @@ async fn test_api_def_with_request_body_0() {
 async fn test_api_def_with_request_body_1() {
     let empty_headers = HeaderMap::new();
 
-    let mut request_body: serde_json::Map<String, Value> = serde_json::Map::new();
+    let mut request_body: serde_json::Map<String, JsonValue> = serde_json::Map::new();
 
-    request_body.insert("foo_key".to_string(), Value::Number(Number::from(1)));
+    request_body.insert("foo_key".to_string(), JsonValue::Number(Number::from(1)));
 
     request_body.insert(
         "bar_key".to_string(),
-        Value::String("bar_value".to_string()),
+        JsonValue::String("bar_value".to_string()),
     );
 
     let api_request = get_gateway_request(
         "/foo/john",
         None,
         &empty_headers,
-        Value::Object(request_body),
+        JsonValue::Object(request_body),
     );
 
     let response_mapping = r#"
@@ -757,9 +781,9 @@ async fn test_api_def_with_request_body_1() {
     let expected = (
         "shopping-cart-1".to_string(),
         "golem:it/api.{add-item}".to_string(),
-        Value::Array(vec![
-            Value::Number(1.into()),
-            Value::String("bar_value".to_string()),
+        JsonValue::Array(vec![
+            JsonValue::Number(1.into()),
+            JsonValue::String("bar_value".to_string()),
         ]),
     );
 
@@ -774,7 +798,7 @@ async fn test_api_def_with_request_body_2() {
         "/foo/2",
         None,
         &empty_headers,
-        Value::String("address".to_string()),
+        JsonValue::String("address".to_string()),
     );
 
     let response_mapping = r#"
@@ -813,9 +837,9 @@ async fn test_api_def_with_request_body_2() {
     let expected = (
         "shopping-cart-1".to_string(),
         "golem:it/api.{get-cart-contents}".to_string(),
-        Value::Array(vec![
-            Value::String("address".to_string()),
-            Value::String("address".to_string()),
+        JsonValue::Array(vec![
+            JsonValue::String("address".to_string()),
+            JsonValue::String("address".to_string()),
         ]),
     );
 
@@ -828,20 +852,20 @@ async fn test_api_def_with_request_body_2() {
 async fn test_api_def_with_invalid_request_body() {
     let empty_headers = HeaderMap::new();
 
-    let mut request_body: serde_json::Map<String, Value> = serde_json::Map::new();
+    let mut request_body: serde_json::Map<String, JsonValue> = serde_json::Map::new();
 
-    request_body.insert("foo_key".to_string(), Value::String("1".to_string()));
+    request_body.insert("foo_key".to_string(), JsonValue::String("1".to_string()));
 
     request_body.insert(
         "bar_key".to_string(),
-        Value::String("bar_value".to_string()),
+        JsonValue::String("bar_value".to_string()),
     );
 
     let api_request = get_gateway_request(
         "/foo/john",
         None,
         &empty_headers,
-        Value::Object(request_body),
+        JsonValue::Object(request_body),
     );
 
     let response_mapping = r#"
@@ -987,9 +1011,9 @@ async fn test_api_def_with_security() {
 
     let expected = (
         "golem:it/api.{get-cart-contents}".to_string(),
-        Value::Array(vec![
-            Value::String("a".to_string()),
-            Value::String("b".to_string()),
+        JsonValue::Array(vec![
+            JsonValue::String("a".to_string()),
+            JsonValue::String("b".to_string()),
         ]),
         Some("bob@example.com".to_string()),
     );
@@ -1388,9 +1412,9 @@ async fn test_api_def_with_security_with_relative_callback() {
 
     let expected = (
         "golem:it/api.{get-cart-contents}".to_string(),
-        Value::Array(vec![
-            Value::String("a".to_string()),
-            Value::String("b".to_string()),
+        JsonValue::Array(vec![
+            JsonValue::String("a".to_string()),
+            JsonValue::String("b".to_string()),
         ]),
         Some("bob@example.com".to_string()),
     );
@@ -1659,8 +1683,12 @@ async fn test_api_def_with_custom_cors_preflight_3() {
 #[test]
 async fn test_api_def_with_path_and_query_1() {
     let empty_headers = HeaderMap::new();
-    let api_request =
-        get_gateway_request("/foo/1", Some("token-id=jon"), &empty_headers, Value::Null);
+    let api_request = get_gateway_request(
+        "/foo/1",
+        Some("token-id=jon"),
+        &empty_headers,
+        JsonValue::Null,
+    );
 
     let response_mapping = r#"
         let x: u64 = request.path.user-id;
@@ -1693,9 +1721,9 @@ async fn test_api_def_with_path_and_query_1() {
     let expected = (
         "shopping-cart-1".to_string(),
         "golem:it/api.{get-cart-contents}".to_string(),
-        Value::Array(vec![
-            Value::String("jon".to_string()),
-            Value::String("jon".to_string()),
+        JsonValue::Array(vec![
+            JsonValue::String("jon".to_string()),
+            JsonValue::String("jon".to_string()),
         ]),
     );
 
@@ -1706,8 +1734,12 @@ async fn test_api_def_with_path_and_query_1() {
 #[test]
 async fn test_api_def_with_path_and_query_2() {
     let empty_headers = HeaderMap::new();
-    let api_request =
-        get_gateway_request("/foo/1", Some("token-id=2"), &empty_headers, Value::Null);
+    let api_request = get_gateway_request(
+        "/foo/1",
+        Some("token-id=2"),
+        &empty_headers,
+        JsonValue::Null,
+    );
 
     // Default types for path and query parameters are string
     let response_mapping = r#"
@@ -1742,9 +1774,9 @@ async fn test_api_def_with_path_and_query_2() {
     let expected = (
         "shopping-cart-1".to_string(),
         "golem:it/api.{get-cart-contents}".to_string(),
-        Value::Array(vec![
-            Value::String("1".to_string()),
-            Value::String("2".to_string()),
+        JsonValue::Array(vec![
+            JsonValue::String("1".to_string()),
+            JsonValue::String("2".to_string()),
         ]),
     );
 
@@ -1758,9 +1790,9 @@ async fn test_api_def_with_path_and_query_3() {
         "/foo/1",
         None,
         &empty_headers,
-        Value::Object(serde_json::Map::from_iter(vec![(
+        JsonValue::Object(serde_json::Map::from_iter(vec![(
             "age".to_string(),
-            Value::Number(serde_json::Number::from(10)),
+            JsonValue::Number(serde_json::Number::from(10)),
         )])),
     );
 
@@ -1798,9 +1830,9 @@ async fn test_api_def_with_path_and_query_3() {
     let expected = (
         "shopping-cart-1".to_string(),
         "golem:it/api.{get-cart-contents}".to_string(),
-        Value::Array(vec![
-            Value::String("a".to_string()),
-            Value::String("b".to_string()),
+        JsonValue::Array(vec![
+            JsonValue::String("a".to_string()),
+            JsonValue::String("b".to_string()),
         ]),
     );
 
@@ -1811,23 +1843,23 @@ async fn test_api_def_with_path_and_query_3() {
 async fn test_api_def_with_path_and_request_body_1() {
     let empty_headers = HeaderMap::new();
 
-    let mut request_body: serde_json::Map<String, Value> = serde_json::Map::new();
+    let mut request_body: serde_json::Map<String, JsonValue> = serde_json::Map::new();
 
     request_body.insert(
         "foo_key".to_string(),
-        Value::String("foo_value".to_string()),
+        JsonValue::String("foo_value".to_string()),
     );
 
     request_body.insert(
         "bar_key".to_string(),
-        Value::Array(vec![Value::String("bar_value".to_string())]),
+        JsonValue::Array(vec![JsonValue::String("bar_value".to_string())]),
     );
 
     let api_request = get_gateway_request(
         "/foo/bar",
         None,
         &empty_headers,
-        Value::Object(request_body),
+        JsonValue::Object(request_body),
     );
 
     let response_mapping = r#"
@@ -1865,9 +1897,9 @@ async fn test_api_def_with_path_and_request_body_1() {
     let expected = (
         "shopping-cart-1".to_string(),
         "golem:it/api.{get-cart-contents}".to_string(),
-        Value::Array(vec![
-            Value::String("foo_value".to_string()),
-            Value::String("bar_value".to_string()),
+        JsonValue::Array(vec![
+            JsonValue::String("foo_value".to_string()),
+            JsonValue::String("bar_value".to_string()),
         ]),
     );
 
@@ -1878,23 +1910,23 @@ async fn test_api_def_with_path_and_request_body_1() {
 async fn test_api_def_with_path_and_request_body_2() {
     let empty_headers = HeaderMap::new();
 
-    let mut request_body: serde_json::Map<String, Value> = serde_json::Map::new();
+    let mut request_body: serde_json::Map<String, JsonValue> = serde_json::Map::new();
 
     request_body.insert(
         "foo_key".to_string(),
-        Value::String("foo_value".to_string()),
+        JsonValue::String("foo_value".to_string()),
     );
 
     request_body.insert(
         "bar_key".to_string(),
-        Value::Array(vec![Value::String("bar_value".to_string())]),
+        JsonValue::Array(vec![JsonValue::String("bar_value".to_string())]),
     );
 
     let api_request = get_gateway_request(
         "/foo/2",
         None,
         &empty_headers,
-        Value::Object(request_body.clone()),
+        JsonValue::Object(request_body.clone()),
     );
 
     let response_mapping = r#"
@@ -1930,9 +1962,9 @@ async fn test_api_def_with_path_and_request_body_2() {
     let expected = (
         "shopping-cart-1".to_string(),
         "golem:it/api.{get-cart-contents}".to_string(),
-        Value::Array(vec![
-            Value::String("foo_value".to_string()),
-            Value::String("bar_value".to_string()),
+        JsonValue::Array(vec![
+            JsonValue::String("foo_value".to_string()),
+            JsonValue::String("bar_value".to_string()),
         ]),
     );
 
@@ -1992,9 +2024,9 @@ async fn test_api_def_with_path_and_query_and_header_and_body() {
     let expected = (
         "shopping-cart-1".to_string(),
         "golem:it/api.{get-cart-contents}".to_string(),
-        Value::Array(vec![
-            Value::String("1-2".to_string()),
-            Value::String("42-qux_value-quux_value".to_string()),
+        JsonValue::Array(vec![
+            JsonValue::String("1-2".to_string()),
+            JsonValue::String("42-qux_value-quux_value".to_string()),
         ]),
     );
 
@@ -2004,7 +2036,8 @@ async fn test_api_def_with_path_and_query_and_header_and_body() {
 #[test]
 async fn test_api_def_with_idempotency_key() {
     async fn test_key(header_map: &HeaderMap, idempotency_key: Option<IdempotencyKey>) {
-        let api_request = get_gateway_request("/getcartcontent/1", None, header_map, Value::Null);
+        let api_request =
+            get_gateway_request("/getcartcontent/1", None, header_map, JsonValue::Null);
 
         let expression = r#"
             let x: u64 = request.path.cart-id;
@@ -2081,7 +2114,7 @@ fn get_preflight_gateway_request(
     base_path: &str,
     query_path: Option<&str>,
     headers: &HeaderMap,
-    req_body: Value,
+    req_body: JsonValue,
 ) -> Request {
     let full_uri = match query_path {
         Some(query) => format!("{}?{}", base_path.trim_end_matches('/'), query),
@@ -2441,13 +2474,12 @@ mod internal {
         AnalysedExport, AnalysedFunction, AnalysedFunctionParameter, AnalysedFunctionResult,
         AnalysedInstance, AnalysedResourceId, AnalysedResourceMode, AnalysedType, TypeHandle,
     };
-    use golem_wasm_rpc::protobuf::type_annotated_value::TypeAnnotatedValue;
-    use golem_wasm_rpc::protobuf::{NameTypePair, NameValuePair, Type, TypedRecord, TypedTuple};
-    use golem_wasm_rpc::ValueAndType;
+    use golem_wasm_rpc::{IntoValueAndType, Value, ValueAndType};
     use golem_worker_service::gateway_api_definition::http::{
         CompiledHttpApiDefinition, ComponentDetails, ComponentMetadataDictionary,
     };
     use golem_worker_service::gateway_api_deployment::ApiSiteString;
+    use golem_worker_service::gateway_binding::SwaggerUiBinding;
     use golem_worker_service::gateway_execution::api_definition_lookup::{
         ApiDefinitionLookupError, HttpApiDefinitionsLookup,
     };
@@ -2460,6 +2492,9 @@ mod internal {
     use golem_worker_service::gateway_execution::http_handler_binding_handler::{
         HttpHandlerBindingHandler, HttpHandlerBindingResult,
     };
+    use golem_worker_service::gateway_execution::swagger_binding_handler::{
+        SwaggerBindingHandler, SwaggerBindingResult, SwaggerBindingSuccess,
+    };
     use golem_worker_service::gateway_execution::WorkerDetails;
     use golem_worker_service::gateway_execution::{
         GatewayResolvedWorkerRequest, GatewayWorkerRequestExecutor, WorkerRequestExecutorError,
@@ -2467,7 +2502,7 @@ mod internal {
     };
     use golem_worker_service::gateway_middleware::HttpCors;
     use golem_worker_service::gateway_rib_interpreter::{
-        DefaultRibInterpreter, RibRuntimeError, WorkerServiceRibInterpreter,
+        DefaultRibInterpreter, WorkerServiceRibInterpreter,
     };
     use http::header::{
         ACCESS_CONTROL_ALLOW_CREDENTIALS, ACCESS_CONTROL_ALLOW_HEADERS,
@@ -2476,7 +2511,7 @@ mod internal {
     };
     use poem::Response;
     use rib::{ComponentDependencyKey, RibResult};
-    use serde_json::Value;
+    use serde_json::Value as JsonValue;
     use std::collections::HashMap;
     use std::sync::{Arc, Mutex};
     use uuid::Uuid;
@@ -2520,7 +2555,7 @@ mod internal {
             if function_name == "bigw:shopping/api.{store.new}" {
                 let uri = format!(
                     "urn:worker:71a31a33-28a5-4978-8a58-83424a149c8b/{}",
-                    resolved_worker_request.worker_name.unwrap_or_default()
+                    resolved_worker_request.worker_name
                 );
                 let handle = golem_wasm_rpc::Value::Handle {
                     uri,
@@ -2530,46 +2565,42 @@ mod internal {
                 let handle_type = AnalysedType::Handle(TypeHandle {
                     resource_id: AnalysedResourceId(0),
                     mode: AnalysedResourceMode::Owned,
+                    name: None,
+                    owner: None,
                 });
 
                 let value_and_type = ValueAndType::new(handle, handle_type);
 
-                let type_annotated_value = TypeAnnotatedValue::try_from(value_and_type).unwrap();
-                return Ok(WorkerResponse::new(Some(type_annotated_value)));
+                return Ok(WorkerResponse::new(Some(value_and_type)));
             }
 
             if function_name.clone() == "bigw:shopping/api.{get-user-name}" {
-                let x = ValueAndType::new(
+                let value_and_type = ValueAndType::new(
                     golem_wasm_rpc::Value::String("test-user".to_string()),
                     str(),
                 );
 
-                let type_annotated_value = TypeAnnotatedValue::try_from(x).unwrap();
-                return Ok(WorkerResponse::new(Some(type_annotated_value)));
+                return Ok(WorkerResponse::new(Some(value_and_type)));
             }
 
             if function_name == "bigw:shopping/api.{store.get-currency}" {
-                let x = ValueAndType::new(
+                let value_and_type = ValueAndType::new(
                     golem_wasm_rpc::Value::Result(Ok(Some(Box::new(
                         golem_wasm_rpc::Value::String("USD".to_string()),
                     )))),
                     result(str(), str()),
                 );
 
-                let type_annotated_value = TypeAnnotatedValue::try_from(x).unwrap();
-
-                return Ok(WorkerResponse::new(Some(type_annotated_value)));
+                return Ok(WorkerResponse::new(Some(value_and_type)));
             }
 
             if function_name == "bigw:shopping/api.{store.add-user}" {
-                let x = ValueAndType::new(
+                let value_and_type = ValueAndType::new(
                     golem_wasm_rpc::Value::String("test-user-generated".to_string()),
                     str(),
                 );
 
-                let type_annotated_value = TypeAnnotatedValue::try_from(x).unwrap();
-
-                return Ok(WorkerResponse::new(Some(type_annotated_value)));
+                return Ok(WorkerResponse::new(Some(value_and_type)));
             }
 
             let type_annotated_value = convert_to_worker_response(&resolved_worker_request);
@@ -2584,7 +2615,7 @@ mod internal {
         async fn handle_file_server_binding_result(
             &self,
             _namespace: Namespace,
-            _worker_name: Option<&str>,
+            _worker_name: &str,
             _component_id: &ComponentId,
             _original_result: RibResult,
         ) -> FileServerBindingResult {
@@ -2610,7 +2641,7 @@ mod internal {
     pub struct DefaultResult {
         pub worker_name: String,
         pub function_name: String,
-        pub function_params: Value,
+        pub function_params: JsonValue,
         pub user_email: Option<String>,
         pub cors_middleware_headers: Option<CorsMiddlewareHeadersInResponse>, // if binding has cors middleware configured,
         pub idempotency_key: Option<IdempotencyKey>,
@@ -2623,86 +2654,68 @@ mod internal {
         pub cors_header_expose_headers: Option<String>,  // If cors middleware is applied
     }
 
-    pub fn create_tuple(type_annotated_value: Vec<TypeAnnotatedValue>) -> TypeAnnotatedValue {
-        let root = type_annotated_value
-            .iter()
-            .map(|x| golem_wasm_rpc::protobuf::TypeAnnotatedValue {
-                type_annotated_value: Some(x.clone()),
-            })
-            .collect::<Vec<_>>();
-
-        let types = type_annotated_value
-            .iter()
-            .map(|x| golem_wasm_rpc::protobuf::Type::try_from(x).unwrap())
-            .collect::<Vec<_>>();
-
-        TypeAnnotatedValue::Tuple(TypedTuple {
-            value: root,
-            typ: types,
-        })
+    pub fn create_tuple(items: Vec<ValueAndType>) -> ValueAndType {
+        ValueAndType::new(
+            Value::Tuple(items.iter().map(|item| item.value.clone()).collect()),
+            tuple(
+                items
+                    .iter()
+                    .map(|item| item.typ.clone())
+                    .collect::<Vec<AnalysedType>>(),
+            ),
+        )
     }
 
-    pub fn create_record(
-        values: Vec<(String, TypeAnnotatedValue)>,
-    ) -> Result<TypeAnnotatedValue, RibRuntimeError> {
-        let mut name_type_pairs = vec![];
-        let mut name_value_pairs = vec![];
-
-        for (key, value) in values.iter() {
-            let typ = Type::try_from(value)
-                .map_err(|_| RibRuntimeError("Failed to get type".to_string()))?;
-            name_type_pairs.push(NameTypePair {
-                name: key.to_string(),
-                typ: Some(typ),
-            });
-
-            name_value_pairs.push(NameValuePair {
-                name: key.to_string(),
-                value: Some(golem_wasm_rpc::protobuf::TypeAnnotatedValue {
-                    type_annotated_value: Some(value.clone()),
-                }),
-            });
-        }
-
-        Ok(TypeAnnotatedValue::Record(TypedRecord {
-            typ: name_type_pairs,
-            value: name_value_pairs,
-        }))
+    pub fn create_record(values: Vec<(&str, ValueAndType)>) -> ValueAndType {
+        ValueAndType::new(
+            Value::Record(values.iter().map(|(_, vnt)| vnt.value.clone()).collect()),
+            record(
+                values
+                    .iter()
+                    .map(|(name, vnt)| field(name, vnt.typ.clone()))
+                    .collect::<Vec<_>>(),
+            ),
+        )
     }
 
     pub fn convert_to_worker_response(
         worker_request: &GatewayResolvedWorkerRequest,
-    ) -> TypeAnnotatedValue {
+    ) -> ValueAndType {
         let mut record_elems = vec![
             (
-                "component_id".to_string(),
-                TypeAnnotatedValue::Str(worker_request.component_id.0.to_string()),
+                "component_id",
+                worker_request
+                    .component_id
+                    .0
+                    .to_string()
+                    .into_value_and_type(),
             ),
             (
-                "function_name".to_string(),
-                TypeAnnotatedValue::Str(worker_request.function_name.to_string()),
+                "function_name",
+                worker_request
+                    .function_name
+                    .to_string()
+                    .into_value_and_type(),
             ),
             (
-                "function_params".to_string(),
+                "function_params",
                 create_tuple(worker_request.function_params.clone()),
             ),
         ];
 
-        if let Some(worker_name) = worker_request.clone().worker_name {
-            record_elems.push((
-                "worker_name".to_string(),
-                TypeAnnotatedValue::Str(worker_name),
-            ))
-        };
+        record_elems.push((
+            "worker_name",
+            worker_request.worker_name.clone().into_value_and_type(),
+        ));
 
         if let Some(idempotency_key) = worker_request.clone().idempotency_key {
             record_elems.push((
-                "idempotency_key".to_string(),
-                TypeAnnotatedValue::Str(idempotency_key.to_string()),
+                "idempotency_key",
+                idempotency_key.to_string().into_value_and_type(),
             ))
         };
 
-        create_record(record_elems).unwrap()
+        create_record(record_elems)
     }
 
     pub(crate) fn get_bigw_shopping_metadata() -> Vec<AnalysedExport> {
@@ -2917,7 +2930,7 @@ mod internal {
             .await
             .expect("TestResponse for worker-binding expects a response body");
 
-        let body_json: Value =
+        let body_json: JsonValue =
             serde_json::from_slice(&bytes).expect("Failed to read the response body");
 
         let worker_name = body_json
@@ -2959,7 +2972,7 @@ mod internal {
             .await
             .expect("TestResponse for worker-binding expects a response body");
 
-        let body_json: Value =
+        let body_json: JsonValue =
             serde_json::from_slice(&bytes).expect("Failed to read the response body");
 
         let worker_name = body_json
@@ -3110,6 +3123,25 @@ mod internal {
     pub fn get_session_store_with_zero_ttl() -> GatewaySessionStore {
         Arc::new(NoopTestSessionBackend)
     }
+
+    struct TestSwaggerBindingHandler {}
+    // Create a test swagger binding handler which outputs a static html page
+    #[async_trait]
+    impl SwaggerBindingHandler for TestSwaggerBindingHandler {
+        async fn handle_swagger_binding_request(
+            &self,
+            _authority: &str,
+            _swagger_binding: &SwaggerUiBinding,
+        ) -> SwaggerBindingResult {
+            Ok(SwaggerBindingSuccess {
+                html_content: "<html><body>Test Swagger UI</body></html>".to_string(),
+            })
+        }
+    }
+
+    pub fn get_test_swagger_binding_handler() -> Arc<dyn SwaggerBindingHandler + Sync + Send> {
+        Arc::new(TestSwaggerBindingHandler {})
+    }
 }
 
 pub mod security {
@@ -3757,3 +3789,79 @@ nUhg4edJVHjqxYyoQT+YSPLlHl6AkLZt9/n1NJ+bft0=
         cookies
     }
 }
+
+#[test]
+async fn test_swagger_ui_binding() {
+    // Create a Swagger UI API definition
+    let api_specification = get_api_def_with_swagger_ui("/swagger-ui").await;
+
+    // Create a request to the Swagger UI endpoint
+    let mut headers = HeaderMap::new();
+    headers.insert(HOST, HeaderValue::from_static("localhost:8080"));
+    let api_request = get_gateway_request("/swagger-ui", None, &headers, JsonValue::Null);
+
+    // Create a session store
+    let session_store = internal::get_session_store();
+
+    // Execute the request
+    let response = execute(
+        api_request,
+        &api_specification,
+        &session_store,
+        &TestIdentityProvider::default(),
+    )
+    .await;
+
+    // Verify response status code
+    assert_eq!(response.status(), StatusCode::OK);
+
+    // Get response body
+    let body = match response.into_body().into_bytes().await {
+        Ok(b) => b,
+        Err(_) => panic!("Failed to read body"),
+    };
+    let html_content = String::from_utf8(body.to_vec()).unwrap();
+
+    // Verify the HTML contains the expected Swagger UI content
+    // The test checks whether the static html page
+    // is properly returned by the swagger binding handler
+    assert!(html_content.contains("<html><body>Test Swagger UI</body></html>"));
+}
+
+// Helper function to create an API definition with a Swagger UI binding
+async fn get_api_def_with_swagger_ui(path_pattern: &str) -> HttpApiDefinition {
+    let yaml_string = format!(
+        r#"
+          id: api-docs
+          version: 0.0.1
+          createdAt: 2024-08-21T07:42:15.696Z
+          routes:
+          - method: Get
+            path: {path_pattern}
+            binding:
+              bindingType: swagger-ui
+        "#,
+    );
+
+    // Parse the YAML into an API definition request
+    let http_api_definition_request: api::dto::HttpApiDefinitionRequest =
+        serde_yaml::from_str(yaml_string.as_str()).unwrap();
+
+    // Convert to core request
+    let core_request: gateway_api_definition::http::HttpApiDefinitionRequest =
+        http_api_definition_request
+            .into_core(&TestConversionContext.boxed())
+            .await
+            .unwrap();
+
+    // Create the API definition
+    let create_at: DateTime<Utc> = "2024-08-21T07:42:15.696Z".parse().unwrap();
+    HttpApiDefinition::from_http_api_definition_request(
+        &test_namespace(),
+        core_request,
+        create_at,
+        &security::get_test_security_scheme_service(TestIdentityProvider::default()),
+    )
+    .await
+    .unwrap()
+}
diff --git a/golem-worker-service/tests/services_tests.rs b/golem-worker-service/tests/services_tests.rs
index 2c08b704..3c4d0f65 100644
--- a/golem-worker-service/tests/services_tests.rs
+++ b/golem-worker-service/tests/services_tests.rs
@@ -16,7 +16,6 @@ use async_trait::async_trait;
 use chrono::Utc;
 use golem_common::config::{DbPostgresConfig, DbSqliteConfig, RedisConfig};
 use golem_common::model::auth::{AuthCtx, Namespace, ProjectAction, TokenSecret};
-use golem_common::model::base64::Base64;
 use golem_common::model::component::{ComponentOwner, VersionedComponentId};
 use golem_common::model::component_constraint::{FunctionConstraints, FunctionSignature};
 use golem_common::model::{AccountId, ComponentId, ComponentType, ProjectId, RetryConfig};
@@ -84,7 +83,6 @@ use openidconnect::{
     TokenUrl, UserInfoUrl,
 };
 use std::collections::HashMap;
-use std::env;
 use std::sync::Arc;
 use std::time::Duration;
 use test_r::test;
@@ -410,15 +408,14 @@ impl TestComponentService {
             versioned_component_id: id.clone(),
             component_name: ComponentName("test".to_string()),
             component_size: 0,
-            metadata: ComponentMetadata {
-                exports: Self::get_metadata(),
-                producers: vec![],
-                memories: vec![],
-                binary_wit: Base64(vec![]),
-                root_package_name: Some("golem:it".to_string()),
-                root_package_version: None,
-                dynamic_linking: HashMap::new(),
-            },
+            metadata: ComponentMetadata::from_parts(
+                Self::get_metadata(),
+                vec![],
+                HashMap::new(),
+                Some("golem:it".to_string()),
+                None,
+                vec![],
+            ),
             created_at: Utc::now(),
             component_type: ComponentType::Durable,
             files: vec![],
@@ -504,45 +501,19 @@ impl ComponentService for TestComponentService {
 
 struct SqliteDb {
     db_path: String,
-    db_pool: SqlitePool,
 }
 
-impl SqliteDb {
-    async fn new() -> Self {
-        let db_path = format!(
-            "{}/golem-worker-{}.db",
-            env::temp_dir().display(),
-            Uuid::new_v4()
-        );
-        let db_config = DbSqliteConfig {
-            database: db_path.clone(),
-            max_connections: 10,
-        };
-
-        db::sqlite::migrate(
-            &db_config,
-            MigrationsDir::new("../golem-worker-service/db/migration".into()).sqlite_migrations(),
-        )
-        .await
-        .expect("Failed migration");
-
-        let db_pool = SqlitePool::configured(&db_config)
-            .await
-            .expect("Failed db configuration");
-
-        Self { db_path, db_pool }
+impl Default for SqliteDb {
+    fn default() -> Self {
+        Self {
+            db_path: format!("/tmp/golem-worker-{}.db", Uuid::new_v4()),
+        }
     }
 }
 
 impl Drop for SqliteDb {
     fn drop(&mut self) {
-        futures::executor::block_on(self.db_pool.close());
-        if let Err(e) = std::fs::remove_file(&self.db_path) {
-            eprintln!(
-                "Warning: Failed to remove test database file '{}': {}",
-                self.db_path, e
-            );
-        }
+        std::fs::remove_file(&self.db_path).unwrap();
     }
 }
 
@@ -658,7 +629,13 @@ pub async fn test_with_postgres_db() {
 
 #[test]
 pub async fn test_gateway_session_with_sqlite() {
-    let db = SqliteDb::new().await;
+    let db = SqliteDb::default();
+    let db_config = DbSqliteConfig {
+        database: db.db_path.clone(),
+        max_connections: 10,
+    };
+
+    let db_pool = SqlitePool::configured(&db_config).await.unwrap();
 
     let data_value = DataValue(serde_json::Value::String(
         Nonce::new_random().secret().to_string(),
@@ -668,7 +645,7 @@ pub async fn test_gateway_session_with_sqlite() {
         SessionId("test1".to_string()),
         DataKey::nonce(),
         data_value.clone(),
-        db.db_pool.clone(),
+        db_pool.clone(),
     )
     .await
     .expect("Expecting a value for longer expiry");
@@ -678,7 +655,13 @@ pub async fn test_gateway_session_with_sqlite() {
 
 #[test]
 pub async fn test_gateway_session_with_sqlite_expired() {
-    let db = SqliteDb::new().await;
+    let db = SqliteDb::default();
+    let db_config = DbSqliteConfig {
+        database: db.db_path.clone(),
+        max_connections: 10,
+    };
+
+    let pool = SqlitePool::configured(&db_config).await.unwrap();
 
     let data_value = DataValue(serde_json::Value::String(
         Nonce::new_random().secret().to_string(),
@@ -687,7 +670,7 @@ pub async fn test_gateway_session_with_sqlite_expired() {
     let expiration =
         SqliteGatewaySessionExpiration::new(Duration::from_secs(1), Duration::from_secs(1));
 
-    let sqlite_session = SqliteGatewaySession::new(db.db_pool.clone(), expiration.clone())
+    let sqlite_session = SqliteGatewaySession::new(pool.clone(), expiration.clone())
         .await
         .expect("Failed to create sqlite session");
 
@@ -701,12 +684,9 @@ pub async fn test_gateway_session_with_sqlite_expired() {
         .await
         .expect("Insert to session failed");
 
-    SqliteGatewaySession::cleanup_expired(
-        db.db_pool.clone(),
-        SqliteGatewaySession::current_time() + 10,
-    )
-    .await
-    .expect("Failed to cleanup expired sessions");
+    SqliteGatewaySession::cleanup_expired(pool, SqliteGatewaySession::current_time() + 10)
+        .await
+        .expect("Failed to cleanup expired sessions");
 
     let result = session_store.get(&session_id, &data_key).await;
 
@@ -796,21 +776,34 @@ async fn insert_and_get_session_with_sqlite(
 
 #[test]
 pub async fn test_with_sqlite_db() {
-    let db = SqliteDb::new().await;
+    let db = SqliteDb::default();
+    let db_config = DbSqliteConfig {
+        database: db.db_path.clone(),
+        max_connections: 10,
+    };
 
-    let api_definition_repo: Arc<dyn api_definition::ApiDefinitionRepo + Sync + Send> =
-        Arc::new(api_definition::DbApiDefinitionRepo::new(db.db_pool.clone()));
-    let api_deployment_repo: Arc<dyn api_deployment::ApiDeploymentRepo + Sync + Send> =
-        Arc::new(api_deployment::DbApiDeploymentRepo::new(db.db_pool.clone()));
+    db::sqlite::migrate(
+        &db_config,
+        MigrationsDir::new("../golem-worker-service/db/migration".into()).sqlite_migrations(),
+    )
+    .await
+    .unwrap();
 
-    let security_scheme_repo: Arc<dyn SecuritySchemeRepo + Sync + Send> =
-        Arc::new(DbSecuritySchemeRepo::new(db.db_pool.clone()));
+    let db_pool = SqlitePool::configured(&db_config).await.unwrap();
+
+    let api_definition_repo: Arc<dyn api_definition::ApiDefinitionRepo> =
+        Arc::new(api_definition::DbApiDefinitionRepo::new(db_pool.clone()));
+
+    let api_deployment_repo: Arc<dyn api_deployment::ApiDeploymentRepo> =
+        Arc::new(api_deployment::DbApiDeploymentRepo::new(db_pool.clone()));
+
+    let security_scheme_repo: Arc<dyn SecuritySchemeRepo> =
+        Arc::new(DbSecuritySchemeRepo::new(db_pool.clone()));
 
     let api_certificate_repo: Arc<dyn ApiCertificateRepo> =
-        Arc::new(DbApiCertificateRepo::new(db.db_pool.clone()));
+        Arc::new(DbApiCertificateRepo::new(db_pool.clone()));
 
-    let api_domain_repo: Arc<dyn ApiDomainRepo> =
-        Arc::new(DbApiDomainRepo::new(db.db_pool.clone()));
+    let api_domain_repo: Arc<dyn ApiDomainRepo> = Arc::new(DbApiDomainRepo::new(db_pool.clone()));
 
     test_services(
         api_definition_repo,
diff --git a/integration-tests/Cargo.toml b/integration-tests/Cargo.toml
index da6d052e..b822286b 100644
--- a/integration-tests/Cargo.toml
+++ b/integration-tests/Cargo.toml
@@ -12,15 +12,15 @@ license-file = "../LICENSE"
 autotests = false
 
 [dependencies]
-golem-api-grpc = { path = "../golem-api-grpc", version = "=0.0.0" }
-golem-client = { path = "../golem-client", version = "=0.0.0" }
-golem-common = { path = "../golem-common", version = "=0.0.0" }
-golem-rib = { path = "../golem-rib", version = "=0.0.0" }
-golem-rib-repl = { path = "../golem-rib-repl", version = "=0.0.0" }
-golem-test-framework = { path = "../golem-test-framework", version = "=0.0.0" }
-golem-wasm-ast = { path = "../wasm-ast", version = "=0.0.0" }
-golem-wasm-rpc = { path = "../wasm-rpc", version = "=0.0.0", default-features = false, features = ["host"] }
-golem-wasm-rpc-derive= { path = "../wasm-rpc-derive", version = "=0.0.0" }
+golem-api-grpc = { workspace = true }
+golem-client = { workspace = true }
+golem-common = { workspace = true, default-features = true }
+golem-rib = { workspace = true, default-features = true }
+golem-rib-repl = { workspace = true }
+golem-test-framework = { workspace = true }
+golem-wasm-ast = { workspace = true, default-features = true }
+golem-wasm-rpc = { workspace = true, features = ["host"] }
+golem-wasm-rpc-derive= { workspace = true }
 
 anyhow = { workspace = true }
 assert2 = { workspace = true }
@@ -38,6 +38,7 @@ tokio = { workspace = true }
 tokio-stream = { workspace = true }
 tracing = { workspace = true }
 uuid = { workspace = true, features = ["v4"] }
+serde_yaml = { workspace = true }
 
 [dev-dependencies]
 test-r = { workspace = true }
@@ -67,8 +68,8 @@ path = "src/rib_repl/main.rs"
 harness = false
 test = false
 
-# [[bin]]
-# name = "benchmarks"
-# path = "src/benchmarks/all.rs"
-# harness = false
-# test = false
+[[bin]]
+name = "benchmarks"
+path = "src/benchmarks/all.rs"
+harness = false
+test = false
diff --git a/integration-tests/src/benchmarks/durability_overhead.rs b/integration-tests/src/benchmarks/durability_overhead.rs
index dd70e06f..24135e45 100644
--- a/integration-tests/src/benchmarks/durability_overhead.rs
+++ b/integration-tests/src/benchmarks/durability_overhead.rs
@@ -67,6 +67,7 @@ impl Benchmark for DurabilityOverhead {
         let component_id = benchmark_context
             .deps
             .admin()
+            .await
             .component("durability-overhead")
             .unique()
             .store()
diff --git a/integration-tests/src/benchmarks/large_dynamic_memory.rs b/integration-tests/src/benchmarks/large_dynamic_memory.rs
index d6d324ee..3a5a9d04 100644
--- a/integration-tests/src/benchmarks/large_dynamic_memory.rs
+++ b/integration-tests/src/benchmarks/large_dynamic_memory.rs
@@ -67,8 +67,13 @@ impl Benchmark for LargeDynamicMemory {
         context: &Self::IterationContext,
     ) {
         if let Some(worker_id) = context.worker_ids.first() {
-            let result =
-                invoke_and_await(&benchmark_context.deps.admin(), worker_id, "run", vec![]).await;
+            let result = invoke_and_await(
+                &benchmark_context.deps.admin().await,
+                worker_id,
+                "run",
+                vec![],
+            )
+            .await;
             println!("Warmup invocation took {:?}", result.accumulated_time);
         }
     }
diff --git a/integration-tests/src/benchmarks/large_initial_memory.rs b/integration-tests/src/benchmarks/large_initial_memory.rs
index c3591833..82c1510a 100644
--- a/integration-tests/src/benchmarks/large_initial_memory.rs
+++ b/integration-tests/src/benchmarks/large_initial_memory.rs
@@ -68,8 +68,13 @@ impl Benchmark for LargeInitialMemory {
         context: &Self::IterationContext,
     ) {
         if let Some(worker_id) = context.worker_ids.first() {
-            let result =
-                invoke_and_await(&benchmark_context.deps.admin(), worker_id, "run", vec![]).await;
+            let result = invoke_and_await(
+                &benchmark_context.deps.admin().await,
+                worker_id,
+                "run",
+                vec![],
+            )
+            .await;
             println!("Warmup invocation took {:?}", result.accumulated_time);
         }
     }
diff --git a/integration-tests/src/benchmarks/mod.rs b/integration-tests/src/benchmarks/mod.rs
index 0ff564e0..851a18df 100644
--- a/integration-tests/src/benchmarks/mod.rs
+++ b/integration-tests/src/benchmarks/mod.rs
@@ -87,6 +87,7 @@ pub async fn setup_iteration(
     // Upload test component
     let component_id = deps
         .admin()
+        .await
         .component(component_name)
         .unique()
         .store()
@@ -105,6 +106,7 @@ pub async fn start_workers(worker_ids: &[WorkerId], deps: &CliTestDependencies)
     for worker_id in worker_ids {
         let _ = deps
             .admin()
+            .await
             .start_worker(&worker_id.component_id, &worker_id.worker_name)
             .await;
     }
@@ -137,7 +139,7 @@ pub async fn setup_simple_iteration(
 
 pub async fn delete_workers(deps: &CliTestDependencies, worker_ids: &[WorkerId]) {
     for worker_id in worker_ids {
-        if let Err(err) = deps.admin().delete_worker(worker_id).await {
+        if let Err(err) = deps.admin().await.delete_worker(worker_id).await {
             warn!("Failed to delete worker: {:?}", err);
         }
     }
@@ -151,7 +153,7 @@ pub async fn warmup_workers(
 ) {
     let mut fibers = JoinSet::new();
     for worker_id in worker_ids {
-        let deps_clone = deps.clone().into_admin();
+        let deps_clone = deps.clone().into_admin().await;
         let worker_id_clone = worker_id.clone();
         let params_clone = params.clone();
         let function_clone = function.to_string();
@@ -177,7 +179,7 @@ pub async fn benchmark_invocations(
     // Invoke each worker a 'length' times in parallel and record the duration
     let mut fibers = JoinSet::new();
     for (n, worker_id) in worker_ids.iter().enumerate() {
-        let deps_clone = deps.clone().into_admin();
+        let deps_clone = deps.clone().into_admin().await;
         let function_clone = function.to_string();
         let params_clone = params.clone();
         let worker_id_clone = worker_id.clone();
diff --git a/integration-tests/src/benchmarks/rpc.rs b/integration-tests/src/benchmarks/rpc.rs
index a07649f1..bfab0f22 100644
--- a/integration-tests/src/benchmarks/rpc.rs
+++ b/integration-tests/src/benchmarks/rpc.rs
@@ -89,6 +89,7 @@ impl Benchmark for Rpc {
         let child_component_id = benchmark_context
             .deps
             .admin()
+            .await
             .component("child_component")
             .unique()
             .store()
@@ -96,6 +97,7 @@ impl Benchmark for Rpc {
         let component_id = benchmark_context
             .deps
             .admin()
+            .await
             .component("parent_component_composed")
             .unique()
             .store()
@@ -130,11 +132,13 @@ impl Benchmark for Rpc {
             benchmark_context
                 .deps
                 .admin()
+                .await
                 .start_worker_with(
                     &parent_worker_id.component_id,
                     &parent_worker_id.worker_name,
                     vec![],
                     env,
+                    vec![],
                 )
                 .await
                 .expect("Failed to start parent worker");
@@ -210,12 +214,14 @@ impl Benchmark for Rpc {
             benchmark_context
                 .deps
                 .admin()
+                .await
                 .delete_worker(&worker_id.parent)
                 .await
                 .expect("Failed to delete parent worker");
             benchmark_context
                 .deps
                 .admin()
+                .await
                 .delete_worker(&worker_id.child)
                 .await
                 .expect("Failed to delete child worker");
@@ -250,7 +256,7 @@ impl Rpc {
             let _ = fibers.spawn(async move {
                 for _ in 0..length {
                     let result = invoke_and_await(
-                        &context_clone.deps.admin(),
+                        &context_clone.deps.admin().await,
                         &worker_id_clone,
                         &function_clone,
                         params_clone.clone(),
diff --git a/integration-tests/src/benchmarks/rpc_cpu_intensive.rs b/integration-tests/src/benchmarks/rpc_cpu_intensive.rs
index 8a294b6c..f52dd075 100644
--- a/integration-tests/src/benchmarks/rpc_cpu_intensive.rs
+++ b/integration-tests/src/benchmarks/rpc_cpu_intensive.rs
@@ -89,6 +89,7 @@ impl Benchmark for RpcCpuIntensive {
         let child_component_id = benchmark_context
             .deps
             .admin()
+            .await
             .component("child_component")
             .unique()
             .store()
@@ -97,6 +98,7 @@ impl Benchmark for RpcCpuIntensive {
         let component_id = benchmark_context
             .deps
             .admin()
+            .await
             .component("parent_component_composed")
             .unique()
             .store()
@@ -131,11 +133,13 @@ impl Benchmark for RpcCpuIntensive {
             benchmark_context
                 .deps
                 .admin()
+                .await
                 .start_worker_with(
                     &parent_worker_id.component_id,
                     &parent_worker_id.worker_name,
                     vec![],
                     env,
+                    vec![],
                 )
                 .await
                 .expect("Failed to start parent worker");
@@ -213,12 +217,14 @@ impl Benchmark for RpcCpuIntensive {
             benchmark_context
                 .deps
                 .admin()
+                .await
                 .delete_worker(&worker_id.parent)
                 .await
                 .expect("Failed to delete parent worker");
             benchmark_context
                 .deps
                 .admin()
+                .await
                 .delete_worker(&worker_id.child)
                 .await
                 .expect("Failed to delete child worker");
@@ -253,7 +259,7 @@ impl RpcCpuIntensive {
             let _ = fibers.spawn(async move {
                 for _ in 0..length {
                     let result = invoke_and_await(
-                        &context_clone.deps.admin(),
+                        &context_clone.deps.admin().await,
                         &worker_id_clone,
                         &function_clone,
                         params_clone.clone(),
diff --git a/integration-tests/src/benchmarks/rpc_large_input.rs b/integration-tests/src/benchmarks/rpc_large_input.rs
index e28e98ed..3d2d87b9 100644
--- a/integration-tests/src/benchmarks/rpc_large_input.rs
+++ b/integration-tests/src/benchmarks/rpc_large_input.rs
@@ -89,6 +89,7 @@ impl Benchmark for RpcLargeInput {
         let child_component_id = benchmark_context
             .deps
             .admin()
+            .await
             .component("child_component")
             .unique()
             .store()
@@ -96,6 +97,7 @@ impl Benchmark for RpcLargeInput {
         let component_id = benchmark_context
             .deps
             .admin()
+            .await
             .component("parent_component_composed")
             .unique()
             .store()
@@ -130,11 +132,13 @@ impl Benchmark for RpcLargeInput {
             benchmark_context
                 .deps
                 .admin()
+                .await
                 .start_worker_with(
                     &parent_worker_id.component_id,
                     &parent_worker_id.worker_name,
                     vec![],
                     env,
+                    vec![],
                 )
                 .await
                 .expect("Failed to start parent worker");
@@ -210,12 +214,14 @@ impl Benchmark for RpcLargeInput {
             benchmark_context
                 .deps
                 .admin()
+                .await
                 .delete_worker(&worker_id.parent)
                 .await
                 .expect("Failed to delete parent worker");
             benchmark_context
                 .deps
                 .admin()
+                .await
                 .delete_worker(&worker_id.child)
                 .await
                 .expect("Failed to delete child worker");
@@ -250,7 +256,7 @@ impl RpcLargeInput {
             let _ = fibers.spawn(async move {
                 for _ in 0..length {
                     let result = invoke_and_await(
-                        &context_clone.deps.admin(),
+                        &context_clone.deps.admin().await,
                         &worker_id_clone,
                         &function_clone,
                         params_clone.clone(),
diff --git a/integration-tests/src/rib_repl/bootstrap.rs b/integration-tests/src/rib_repl/bootstrap.rs
index 1a64cf44..ad321559 100644
--- a/integration-tests/src/rib_repl/bootstrap.rs
+++ b/integration-tests/src/rib_repl/bootstrap.rs
@@ -1,6 +1,7 @@
 use anyhow::anyhow;
 use async_trait::async_trait;
-use golem_common::base_model::{ComponentId, TargetWorkerId};
+use golem_common::base_model::ComponentId;
+use golem_common::model::WorkerId;
 use golem_rib_repl::WorkerFunctionInvoke;
 use golem_rib_repl::{ReplComponentDependencies, RibDependencyManager};
 use golem_test_framework::config::{EnvBasedTestDependencies, TestDependencies};
@@ -35,6 +36,7 @@ impl RibDependencyManager for TestRibReplDependencyManager {
         let component_id = self
             .dependencies
             .admin()
+            .await
             .component(component_name.as_str())
             .store()
             .await;
@@ -42,19 +44,20 @@ impl RibDependencyManager for TestRibReplDependencyManager {
         let metadata = self
             .dependencies
             .admin()
+            .await
             .get_latest_component_metadata(&component_id)
             .await;
 
         let component_dependency_key = ComponentDependencyKey {
             component_name,
             component_id: component_id.0,
-            root_package_name: metadata.root_package_name,
-            root_package_version: metadata.root_package_version,
+            root_package_name: metadata.root_package_name().clone(),
+            root_package_version: metadata.root_package_version().clone(),
         };
 
         Ok(ComponentDependency::new(
             component_dependency_key,
-            metadata.exports,
+            metadata.exports().to_vec(),
         ))
     }
 }
@@ -78,24 +81,20 @@ impl WorkerFunctionInvoke for TestRibReplWorkerFunctionInvoke {
         &self,
         component_id: Uuid,
         _component_name: &str,
-        worker_name: Option<String>,
+        worker_name: &str,
         function_name: &str,
         args: Vec<ValueAndType>,
         _return_type: Option<AnalysedType>,
     ) -> anyhow::Result<Option<ValueAndType>> {
-        let target_worker_id = worker_name
-            .map(|w| TargetWorkerId {
-                component_id: ComponentId(component_id),
-                worker_name: Some(w),
-            })
-            .unwrap_or_else(|| TargetWorkerId {
-                component_id: ComponentId(component_id),
-                worker_name: None,
-            });
+        let worker_id = WorkerId {
+            component_id: ComponentId(component_id),
+            worker_name: worker_name.to_string(),
+        };
 
         self.embedded_worker_executor
             .admin()
-            .invoke_and_await_typed(target_worker_id, function_name, args)
+            .await
+            .invoke_and_await_typed(&worker_id, function_name, args)
             .await
             .map_err(|e| anyhow!("Failed to invoke function: {:?}", e))
     }
diff --git a/integration-tests/src/rib_repl/main.rs b/integration-tests/src/rib_repl/main.rs
index a1a62826..b6b222c4 100644
--- a/integration-tests/src/rib_repl/main.rs
+++ b/integration-tests/src/rib_repl/main.rs
@@ -4,11 +4,11 @@ use golem_test_framework::config::{
 };
 use integration_tests::rib_repl::bootstrap::*;
 use std::sync::Arc;
+
 #[tokio::main]
 async fn main() {
     let deps = EnvBasedTestDependencies::new(EnvBasedTestDependenciesConfig::new()).await;
 
-    // component name from args
     let component_name = std::env::args()
         .nth(1)
         .unwrap_or_else(|| "shopping-cart".to_string());
@@ -30,5 +30,5 @@ async fn main() {
     .await
     .expect("Failed to bootstrap REPL");
 
-    rib_repl.run().await
+    rib_repl.run().await;
 }
diff --git a/integration-tests/tests/api/account.rs b/integration-tests/tests/api/account.rs
index 96d49dff..69419205 100644
--- a/integration-tests/tests/api/account.rs
+++ b/integration-tests/tests/api/account.rs
@@ -12,16 +12,21 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use crate::{Deps, Tracing};
-use golem_test_framework::config::{TestDependencies, TestDependenciesDsl};
+use crate::Tracing;
+use golem_test_framework::config::{
+    EnvBasedTestDependencies, TestDependencies, TestDependenciesDsl,
+};
 use golem_test_framework::dsl::TestDslUnsafe;
 use test_r::{inherit_test_dep, test};
 
 inherit_test_dep!(Tracing);
-inherit_test_dep!(Deps);
+inherit_test_dep!(EnvBasedTestDependencies);
 
 #[test]
-async fn get_account_of_owner_of_shared_project(deps: &Deps, _tracing: &Tracing) {
+async fn get_account_of_owner_of_shared_project(
+    deps: &EnvBasedTestDependencies,
+    _tracing: &Tracing,
+) {
     let user_1 = deps.user().await;
     let user_2 = deps.user().await;
 
@@ -35,7 +40,7 @@ async fn get_account_of_owner_of_shared_project(deps: &Deps, _tracing: &Tracing)
 }
 
 #[test]
-async fn cannot_get_unrelated_user(deps: &Deps, _tracing: &Tracing) {
+async fn cannot_get_unrelated_user(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
     let user_1 = deps.user().await;
     let user_2 = deps.user().await;
 
diff --git a/integration-tests/tests/api/api_definition.rs b/integration-tests/tests/api/api_definition.rs
index 7d0bf835..7a8e79e1 100644
--- a/integration-tests/tests/api/api_definition.rs
+++ b/integration-tests/tests/api/api_definition.rs
@@ -12,93 +12,74 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use crate::{to_grpc_rib_expr, Deps, Tracing};
-use assert2::{assert, check};
-use golem_api_grpc::proto::golem::apidefinition::v1::{
-    api_definition_request, create_api_definition_request, update_api_definition_request,
-    ApiDefinitionRequest, CreateApiDefinitionRequest, DeleteApiDefinitionRequest,
-    GetApiDefinitionRequest, GetApiDefinitionVersionsRequest, UpdateApiDefinitionRequest,
+use crate::Tracing;
+use assert2::assert;
+use golem_client::model::{
+    GatewayBindingComponent, GatewayBindingData, GatewayBindingType, HttpApiDefinitionRequest,
+    HttpApiDefinitionResponseData, HttpCors, MethodPattern, RouteRequestData,
 };
-use golem_api_grpc::proto::golem::apidefinition::{
-    api_definition, static_binding, ApiDefinition, ApiDefinitionId, GatewayBinding,
-    GatewayBindingType, HttpApiDefinition, HttpMethod, HttpRoute,
-};
-use golem_api_grpc::proto::golem::component::VersionedComponentId;
-use golem_test_framework::config::TestDependencies;
+use golem_test_framework::config::{EnvBasedTestDependencies, TestDependencies};
 use golem_test_framework::dsl::TestDslUnsafe;
 use std::collections::HashMap;
 use test_r::{inherit_test_dep, test};
 use uuid::Uuid;
 
 inherit_test_dep!(Tracing);
-inherit_test_dep!(Deps);
+inherit_test_dep!(EnvBasedTestDependencies);
 
 #[test]
 #[tracing::instrument]
-async fn create_and_get_api_security_scheme(deps: &Deps) {
-    let admin = deps.admin();
+async fn create_and_get_api_definition(deps: &EnvBasedTestDependencies) {
+    let admin = deps.admin().await;
 
-    let component_id = admin
+    let (_, component_name) = admin
         .component("shopping-cart-resource")
         .unique()
-        .store()
+        .store_and_get_name()
         .await;
 
-    let request = ApiDefinitionRequest {
-        id: Some(ApiDefinitionId {
-            value: Uuid::new_v4().to_string(),
-        }),
+    let request = HttpApiDefinitionRequest {
+        id: Uuid::new_v4().to_string(),
         version: "1".to_string(),
         draft: true,
-        definition: Some(api_definition_request::Definition::Http(
-            HttpApiDefinition {
-                routes: vec![HttpRoute {
-                    method: HttpMethod::Post as i32,
-                    path: "/{user-id}/test-path-1".to_string(),
-                    binding: Some(GatewayBinding {
-                        component: Some(VersionedComponentId {
-                            component_id: Some(component_id.clone().into()),
-                            version: 0,
-                        }),
-                        worker_name: None,
-                        response: Some(to_grpc_rib_expr(
-                            r#"
-                                let user-id = request.path.user-id;
-                                let worker = "shopping-cart-${user-id}";
-                                let inst = instance(worker);
-                                let res = inst.cart(user-id);
-                                let contents = res.get-cart-contents();
-                                {
-                                   headers: {ContentType: "json", userid: "foo"},
-                                   body: contents,
-                                   status: 201
-                                }
-                            "#,
-                        )),
-                        idempotency_key: None,
-                        binding_type: Some(GatewayBindingType::Default as i32),
-                        static_binding: None,
-                        invocation_context: None,
-                    }),
-                    middleware: None,
-                }],
+        security: None,
+        routes: vec![RouteRequestData {
+            method: MethodPattern::Post,
+            path: "/{user-id}/test-path-1".to_string(),
+            binding: GatewayBindingData {
+                component: Some(GatewayBindingComponent {
+                    name: component_name.0,
+                    version: Some(0),
+                }),
+                worker_name: None,
+                response: Some(
+                    r#"
+                        let user-id = request.path.user-id;
+                        let worker = "shopping-cart-${user-id}";
+                        let inst = instance(worker);
+                        let res = inst.cart(user-id);
+                        let contents = res.get-cart-contents();
+                        {
+                            headers: {ContentType: "json", userid: "foo"},
+                            body: contents,
+                            status: 201
+                        }
+                    "#
+                    .to_string(),
+                ),
+                idempotency_key: None,
+                binding_type: Some(GatewayBindingType::Default),
+                invocation_context: None,
             },
-        )),
+            security: None,
+        }],
     };
 
     let project = admin.default_project().await;
 
     let response = deps
         .worker_service()
-        .create_api_definition(
-            &admin.token,
-            &project,
-            CreateApiDefinitionRequest {
-                api_definition: Some(create_api_definition_request::ApiDefinition::Definition(
-                    request.clone(),
-                )),
-            },
-        )
+        .create_api_definition(&admin.token, &project, &request)
         .await
         .unwrap();
 
@@ -106,14 +87,7 @@ async fn create_and_get_api_security_scheme(deps: &Deps) {
 
     let response = deps
         .worker_service()
-        .get_api_definition(
-            &admin.token,
-            &project,
-            GetApiDefinitionRequest {
-                api_definition_id: request.id.clone(),
-                version: response.version.clone(),
-            },
-        )
+        .get_api_definition(&admin.token, &project, &request.id, &response.version)
         .await
         .unwrap();
 
@@ -121,14 +95,7 @@ async fn create_and_get_api_security_scheme(deps: &Deps) {
 
     let response = deps
         .worker_service()
-        .get_api_definition(
-            &admin.token,
-            &project,
-            GetApiDefinitionRequest {
-                api_definition_id: request.id.clone(),
-                version: "not-exists".to_string(),
-            },
-        )
+        .get_api_definition(&admin.token, &project, &request.id, "not-exists")
         .await;
 
     assert!(response.is_err());
@@ -137,176 +104,146 @@ async fn create_and_get_api_security_scheme(deps: &Deps) {
 
 #[test]
 #[tracing::instrument]
-async fn get_api_definition_versions(deps: &Deps) {
-    let admin = deps.admin();
+async fn get_api_definition_versions(deps: &EnvBasedTestDependencies) {
+    let admin = deps.admin().await;
 
-    let component_id = admin
+    let (_, component_name) = admin
         .component("shopping-cart-resource")
         .unique()
-        .store()
+        .store_and_get_name()
         .await;
 
-    let request_1 = ApiDefinitionRequest {
-        id: Some(ApiDefinitionId {
-            value: Uuid::new_v4().to_string(),
-        }),
+    let request_1 = HttpApiDefinitionRequest {
+        id: Uuid::new_v4().to_string(),
         version: "1".to_string(),
         draft: true,
-        definition: Some(api_definition_request::Definition::Http(
-            HttpApiDefinition {
-                routes: vec![HttpRoute {
-                    method: HttpMethod::Post as i32,
-                    path: "/{user-id}/test-path-1".to_string(),
-                    binding: Some(GatewayBinding {
-                        component: Some(VersionedComponentId {
-                            component_id: Some(component_id.clone().into()),
-                            version: 0,
-                        }),
-                        worker_name: None,
-                        response: Some(to_grpc_rib_expr(
-                            r#"
-                                let user-id = request.path.user-id;
-                                let worker = "shopping-cart-${user-id}";
-                                let inst = instance(worker);
-                                let res = inst.cart(user-id);
-                                let contents = res.get-cart-contents();
-                                {
-                                   headers: {ContentType: "json", userid: "foo"},
-                                   body: contents,
-                                   status: 201
-                                }
-                            "#,
-                        )),
-                        idempotency_key: None,
-                        binding_type: Some(GatewayBindingType::Default as i32),
-                        static_binding: None,
-                        invocation_context: None,
-                    }),
-                    middleware: None,
-                }],
+        security: None,
+        routes: vec![RouteRequestData {
+            method: MethodPattern::Post,
+            path: "/{user-id}/test-path-1".to_string(),
+            binding: GatewayBindingData {
+                component: Some(GatewayBindingComponent {
+                    name: component_name.0.to_string(),
+                    version: Some(0),
+                }),
+                worker_name: None,
+                response: Some(
+                    r#"
+                        let user-id = request.path.user-id;
+                        let worker = "shopping-cart-${user-id}";
+                        let inst = instance(worker);
+                        let res = inst.cart(user-id);
+                        let contents = res.get-cart-contents();
+                        {
+                            headers: {ContentType: "json", userid: "foo"},
+                            body: contents,
+                            status: 201
+                        }
+                    "#
+                    .to_string(),
+                ),
+                idempotency_key: None,
+                binding_type: Some(GatewayBindingType::Default),
+                invocation_context: None,
             },
-        )),
+            security: None,
+        }],
     };
 
-    let request_2 = ApiDefinitionRequest {
+    let request_2 = HttpApiDefinitionRequest {
         id: request_1.id.clone(),
         version: "2".to_string(),
         draft: true,
-        definition: Some(api_definition_request::Definition::Http(
-            HttpApiDefinition {
-                routes: vec![
-                    HttpRoute {
-                        method: HttpMethod::Get as i32,
-                        path: "/{user-id}/test-path-1".to_string(),
-                        binding: Some(GatewayBinding {
-                            component: Some(VersionedComponentId {
-                                component_id: Some(component_id.clone().into()),
-                                version: 0,
-                            }),
-                            worker_name: None,
-                            response: Some(to_grpc_rib_expr(
-                                r#"
-                                let user-id = request.path.user-id;
-                                let worker = "shopping-cart-${user-id}";
-                                let inst = instance(worker);
-                                let res = inst.cart(user-id);
-                                let contents = res.get-cart-contents();
-                                {
-                                   headers: {ContentType: "json", userid: "foo"},
-                                   body: contents,
-                                   status: 201
-                                }
-                            "#,
-                            )),
-                            idempotency_key: None,
-                            binding_type: Some(GatewayBindingType::Default as i32),
-                            static_binding: None,
-                            invocation_context: None,
-                        }),
-                        middleware: None,
-                    },
-                    HttpRoute {
-                        method: HttpMethod::Patch as i32,
-                        path: "/{user-id}/test-path-2".to_string(),
-                        binding: Some(GatewayBinding {
-                            component: Some(VersionedComponentId {
-                                component_id: Some(component_id.clone().into()),
-                                version: 0,
-                            }),
-                            worker_name: None,
-                            response: Some(to_grpc_rib_expr(
-                                r#"
-                                let user-id = request.path.user-id;
-                                let worker = "shopping-cart-${user-id}";
-                                let inst = instance(worker);
-                                let res = inst.cart(user-id);
-                                let contents = res.get-cart-contents();
-                                {
-                                   headers: {ContentType: "json", userid: "foo"},
-                                   body: contents,
-                                   status: 201
-                                }
-                            "#,
-                            )),
-                            idempotency_key: None,
-                            binding_type: Some(GatewayBindingType::Default as i32),
-                            static_binding: None,
-                            invocation_context: None,
-                        }),
-                        middleware: None,
-                    },
-                ],
+        security: None,
+        routes: vec![
+            RouteRequestData {
+                method: MethodPattern::Get,
+                path: "/{user-id}/test-path-1".to_string(),
+                binding: GatewayBindingData {
+                    component: Some(GatewayBindingComponent {
+                        name: component_name.0.to_string(),
+                        version: Some(0),
+                    }),
+                    worker_name: None,
+                    response: Some(
+                        r#"
+                            let user-id = request.path.user-id;
+                            let worker = "shopping-cart-${user-id}";
+                            let inst = instance(worker);
+                            let res = inst.cart(user-id);
+                            let contents = res.get-cart-contents();
+                            {
+                                headers: {ContentType: "json", userid: "foo"},
+                                body: contents,
+                                status: 201
+                            }
+                        "#
+                        .to_string(),
+                    ),
+                    idempotency_key: None,
+                    binding_type: Some(GatewayBindingType::Default),
+                    invocation_context: None,
+                },
+                security: None,
             },
-        )),
+            RouteRequestData {
+                method: MethodPattern::Patch,
+                path: "/{user-id}/test-path-2".to_string(),
+                binding: GatewayBindingData {
+                    component: Some(GatewayBindingComponent {
+                        name: component_name.0.to_string(),
+                        version: Some(0),
+                    }),
+                    worker_name: None,
+                    response: Some(
+                        r#"
+                            let user-id = request.path.user-id;
+                            let worker = "shopping-cart-${user-id}";
+                            let inst = instance(worker);
+                            let res = inst.cart(user-id);
+                            let contents = res.get-cart-contents();
+                            {
+                                headers: {ContentType: "json", userid: "foo"},
+                                body: contents,
+                                status: 201
+                            }
+                        "#
+                        .to_string(),
+                    ),
+                    idempotency_key: None,
+                    binding_type: Some(GatewayBindingType::Default),
+                    invocation_context: None,
+                },
+                security: None,
+            },
+        ],
     };
 
     let project = admin.default_project().await;
 
     let response_1 = deps
         .worker_service()
-        .create_api_definition(
-            &admin.token,
-            &project,
-            CreateApiDefinitionRequest {
-                api_definition: Some(create_api_definition_request::ApiDefinition::Definition(
-                    request_1.clone(),
-                )),
-            },
-        )
+        .create_api_definition(&admin.token, &project, &request_1)
         .await
         .unwrap();
     check_equal_api_definition_request_and_response(&request_1, &response_1);
 
     let versions = deps
         .worker_service()
-        .get_api_definition_versions(
-            &admin.token,
-            &project,
-            GetApiDefinitionVersionsRequest {
-                api_definition_id: request_1.id.clone(),
-            },
-        )
+        .get_api_definition_versions(&admin.token, &project, &request_1.id)
         .await
         .unwrap();
     assert!(versions.len() == 1);
     check_equal_api_definition_request_and_response(&request_1, &versions[0]);
 
-    let request_1 = ApiDefinitionRequest {
+    let request_1 = HttpApiDefinitionRequest {
         draft: false,
         ..request_1
     };
 
     let updated_1 = deps
         .worker_service()
-        .update_api_definition(
-            &admin.token,
-            &project,
-            UpdateApiDefinitionRequest {
-                api_definition: Some(update_api_definition_request::ApiDefinition::Definition(
-                    request_1.clone(),
-                )),
-            },
-        )
+        .update_api_definition(&admin.token, &project, &request_1)
         .await
         .unwrap();
 
@@ -314,13 +251,7 @@ async fn get_api_definition_versions(deps: &Deps) {
 
     let versions = deps
         .worker_service()
-        .get_api_definition_versions(
-            &admin.token,
-            &project,
-            GetApiDefinitionVersionsRequest {
-                api_definition_id: request_1.id.clone(),
-            },
-        )
+        .get_api_definition_versions(&admin.token, &project, &request_1.id)
         .await
         .unwrap();
     assert!(versions.len() == 1);
@@ -328,28 +259,15 @@ async fn get_api_definition_versions(deps: &Deps) {
 
     let response_2 = deps
         .worker_service()
-        .create_api_definition(
-            &admin.token,
-            &project,
-            CreateApiDefinitionRequest {
-                api_definition: Some(create_api_definition_request::ApiDefinition::Definition(
-                    request_2.clone(),
-                )),
-            },
-        )
+        .create_api_definition(&admin.token, &project, &request_2)
         .await
         .unwrap();
+
     check_equal_api_definition_request_and_response(&request_2, &response_2);
 
     let versions = deps
         .worker_service()
-        .get_api_definition_versions(
-            &admin.token,
-            &project,
-            GetApiDefinitionVersionsRequest {
-                api_definition_id: request_1.id.clone(),
-            },
-        )
+        .get_api_definition_versions(&admin.token, &project, &request_1.id)
         .await
         .unwrap();
     assert!(versions.len() == 2);
@@ -357,26 +275,13 @@ async fn get_api_definition_versions(deps: &Deps) {
     check_equal_api_definition_request_and_response(&request_2, &versions[1]);
 
     deps.worker_service()
-        .delete_api_definition(
-            &admin.token,
-            &project,
-            DeleteApiDefinitionRequest {
-                api_definition_id: request_1.id.clone(),
-                version: "1".to_string(),
-            },
-        )
+        .delete_api_definition(&admin.token, &project, &request_1.id, "1")
         .await
         .unwrap();
 
     let versions = deps
         .worker_service()
-        .get_api_definition_versions(
-            &admin.token,
-            &project,
-            GetApiDefinitionVersionsRequest {
-                api_definition_id: request_1.id.clone(),
-            },
-        )
+        .get_api_definition_versions(&admin.token, &project, &request_1.id)
         .await
         .unwrap();
     assert!(versions.len() == 1);
@@ -385,116 +290,106 @@ async fn get_api_definition_versions(deps: &Deps) {
 
 #[test]
 #[tracing::instrument]
-async fn get_api_definition_all_versions(deps: &Deps) {
-    let admin = deps.admin();
+async fn get_api_definition_all_versions(deps: &EnvBasedTestDependencies) {
+    let admin = deps.admin().await;
 
-    let component_id_1 = admin
+    let (_, component_name_1) = admin
         .component("shopping-cart-resource")
         .unique()
-        .store()
+        .store_and_get_name()
         .await;
 
-    let component_id_2 = admin
+    let (_, component_name_2) = admin
         .component("shopping-cart-resource")
         .unique()
-        .store()
+        .store_and_get_name()
         .await;
 
-    let request_1_1 = ApiDefinitionRequest {
-        id: Some(ApiDefinitionId {
-            value: Uuid::new_v4().to_string(),
-        }),
+    let request_1_1 = HttpApiDefinitionRequest {
+        id: Uuid::new_v4().to_string(),
         version: "1".to_string(),
         draft: true,
-        definition: Some(api_definition_request::Definition::Http(
-            HttpApiDefinition {
-                routes: vec![HttpRoute {
-                    method: HttpMethod::Post as i32,
-                    path: "/{user-id}/test-path-1".to_string(),
-                    binding: Some(GatewayBinding {
-                        component: Some(VersionedComponentId {
-                            component_id: Some(component_id_1.clone().into()),
-                            version: 0,
-                        }),
-                        worker_name: None,
-                        response: Some(to_grpc_rib_expr(
-                            r#"
-                                let user-id = request.path.user-id;
-                                let worker = "shopping-cart-${user-id}";
-                                let inst = instance(worker);
-                                let res = inst.cart(user-id);
-                                let contents = res.get-cart-contents();
-                                {
-                                   headers: {ContentType: "json", userid: "foo"},
-                                   body: contents,
-                                   status: 201
-                                }
-                            "#,
-                        )),
-                        idempotency_key: None,
-                        binding_type: Some(GatewayBindingType::Default as i32),
-                        static_binding: None,
-                        invocation_context: None,
-                    }),
-                    middleware: None,
-                }],
+        security: None,
+        routes: vec![RouteRequestData {
+            method: MethodPattern::Post,
+            path: "/{user-id}/test-path-1".to_string(),
+            binding: GatewayBindingData {
+                component: Some(GatewayBindingComponent {
+                    name: component_name_1.0,
+                    version: Some(0),
+                }),
+                worker_name: None,
+                response: Some(
+                    r#"
+                        let user-id = request.path.user-id;
+                        let worker = "shopping-cart-${user-id}";
+                        let inst = instance(worker);
+                        let res = inst.cart(user-id);
+                        let contents = res.get-cart-contents();
+                        {
+                            headers: {ContentType: "json", userid: "foo"},
+                            body: contents,
+                            status: 201
+                        }
+                    "#
+                    .to_string(),
+                ),
+                idempotency_key: None,
+                binding_type: Some(GatewayBindingType::Default),
+                invocation_context: None,
             },
-        )),
+            security: None,
+        }],
     };
 
-    let request_1_2 = ApiDefinitionRequest {
+    let request_1_2 = HttpApiDefinitionRequest {
         version: "2".to_string(),
         ..request_1_1.clone()
     };
 
-    let request_2_1 = ApiDefinitionRequest {
-        id: Some(ApiDefinitionId {
-            value: Uuid::new_v4().to_string(),
-        }),
+    let request_2_1 = HttpApiDefinitionRequest {
+        id: Uuid::new_v4().to_string(),
         version: "1".to_string(),
         draft: true,
-        definition: Some(api_definition_request::Definition::Http(
-            HttpApiDefinition {
-                routes: vec![HttpRoute {
-                    method: HttpMethod::Post as i32,
-                    path: "/{user-id}/test-path-2".to_string(),
-                    binding: Some(GatewayBinding {
-                        component: Some(VersionedComponentId {
-                            component_id: Some(component_id_2.clone().into()),
-                            version: 0,
-                        }),
-                        worker_name: None,
-                        response: Some(to_grpc_rib_expr(
-                            r#"
-                                 let user-id = request.path.user-id;
-                                let worker = "shopping-cart-${user-id}";
-                                let inst = instance(worker);
-                                let res = inst.cart(user-id);
-                                let contents = res.get-cart-contents();
-                                {
-                                   headers: {ContentType: "json", userid: "foo"},
-                                   body: contents,
-                                   status: 201
-                                }
-                            "#,
-                        )),
-                        idempotency_key: None,
-                        binding_type: Some(GatewayBindingType::Default as i32),
-                        static_binding: None,
-                        invocation_context: None,
-                    }),
-                    middleware: None,
-                }],
+        security: None,
+        routes: vec![RouteRequestData {
+            method: MethodPattern::Post,
+            path: "/{user-id}/test-path-2".to_string(),
+            binding: GatewayBindingData {
+                component: Some(GatewayBindingComponent {
+                    name: component_name_2.0,
+                    version: Some(0),
+                }),
+                worker_name: None,
+                response: Some(
+                    r#"
+                        let user-id = request.path.user-id;
+                        let worker = "shopping-cart-${user-id}";
+                        let inst = instance(worker);
+                        let res = inst.cart(user-id);
+                        let contents = res.get-cart-contents();
+                        {
+                            headers: {ContentType: "json", userid: "foo"},
+                            body: contents,
+                            status: 201
+                        }
+                    "#
+                    .to_string(),
+                ),
+                idempotency_key: None,
+                binding_type: Some(GatewayBindingType::Default),
+                invocation_context: None,
             },
-        )),
+            security: None,
+        }],
     };
 
-    let request_2_2 = ApiDefinitionRequest {
+    let request_2_2 = HttpApiDefinitionRequest {
         version: "2".to_string(),
         ..request_2_1.clone()
     };
 
-    let request_2_3 = ApiDefinitionRequest {
+    let request_2_3 = HttpApiDefinitionRequest {
         version: "3".to_string(),
         ..request_2_1.clone()
     };
@@ -509,15 +404,7 @@ async fn get_api_definition_all_versions(deps: &Deps) {
         &request_2_3,
     ] {
         deps.worker_service()
-            .create_api_definition(
-                &admin.token,
-                &project,
-                CreateApiDefinitionRequest {
-                    api_definition: Some(create_api_definition_request::ApiDefinition::Definition(
-                        request.clone(),
-                    )),
-                },
-            )
+            .create_api_definition(&admin.token, &project, request)
             .await
             .unwrap();
     }
@@ -533,27 +420,22 @@ async fn get_api_definition_all_versions(deps: &Deps) {
         .into_iter()
         .map(|api_definition| {
             (
-                format!(
-                    "{}@{}",
-                    &api_definition.id.as_ref().unwrap().value,
-                    api_definition.version
-                ),
+                format!("{}@{}", &api_definition.id, api_definition.version),
                 api_definition,
             )
         })
         .collect::<HashMap<_, _>>();
 
     fn check_contains(
-        result: &HashMap<String, ApiDefinition>,
-        api_definition_request: &ApiDefinitionRequest,
+        result: &HashMap<String, HttpApiDefinitionResponseData>,
+        api_definition_request: &HttpApiDefinitionRequest,
     ) {
         check_equal_api_definition_request_and_response(
             api_definition_request,
             result
                 .get(&format!(
                     "{}@{}",
-                    &api_definition_request.id.as_ref().unwrap().value,
-                    api_definition_request.version
+                    &api_definition_request.id, api_definition_request.version
                 ))
                 .unwrap(),
         );
@@ -567,24 +449,72 @@ async fn get_api_definition_all_versions(deps: &Deps) {
 }
 
 fn check_equal_api_definition_request_and_response(
-    request: &ApiDefinitionRequest,
-    response: &ApiDefinition,
+    request: &HttpApiDefinitionRequest,
+    response: &HttpApiDefinitionResponseData,
 ) {
-    check!(request.id == response.id);
-    check!(request.version == response.version);
-    check!(request.draft == response.draft);
-
-    let api_definition_request::Definition::Http(request_api_def) =
-        request.definition.as_ref().unwrap();
-    let api_definition::Definition::Http(response_api_def) = response.definition.as_ref().unwrap();
-    check!(request_api_def == response_api_def);
+    assert_eq!(request.id, response.id);
+    assert_eq!(request.version, response.version);
+    assert_eq!(request.draft, response.draft);
+
+    assert_eq!(request.routes.len(), response.routes.len());
+
+    for i in 0..request.routes.len() {
+        let request_route = &request.routes[i];
+        let response_route = &response.routes[i];
+
+        assert_eq!(request_route.method, response_route.method);
+        assert_eq!(request_route.path, response_route.path);
+        assert_eq!(request_route.security, response_route.security);
+
+        assert_eq!(
+            request_route.binding.binding_type,
+            response_route.binding.binding_type
+        );
+        check_optional_rib_code(
+            request_route.binding.idempotency_key.as_deref(),
+            response_route.binding.idempotency_key.as_deref(),
+        );
+        check_optional_rib_code(
+            request_route.binding.invocation_context.as_deref(),
+            response_route.binding.invocation_context.as_deref(),
+        );
+        check_optional_rib_code(
+            request_route.binding.response.as_deref(),
+            response_route.binding.response.as_deref(),
+        );
+        assert_eq!(
+            request_route.binding.component.clone().map(|c| c.name),
+            response_route.binding.component.clone().map(|c| c.name)
+        );
+
+        {
+            let component_version = request_route
+                .binding
+                .component
+                .clone()
+                .and_then(|c| c.version);
+            if let Some(component_version) = component_version {
+                assert_eq!(
+                    Some(component_version),
+                    response_route.binding.component.clone().map(|c| c.version)
+                );
+            }
+        }
+    }
+}
+
+fn check_optional_rib_code(actual: Option<&str>, expected: Option<&str>) {
+    assert_eq!(
+        actual.map(|v| rib::from_string(v).unwrap()),
+        expected.map(|v| rib::from_string(v).unwrap())
+    );
 }
 
 // Create API definition from OpenAPI YAML
 #[test]
 #[tracing::instrument]
-async fn create_openapi_yaml_definition(deps: &Deps) {
-    let admin = deps.admin();
+async fn create_openapi_yaml_definition(deps: &EnvBasedTestDependencies) {
+    let admin = deps.admin().await;
 
     let (_component_id, component_name) = admin
         .component("shopping-cart")
@@ -652,79 +582,61 @@ x-golem-api-definition-version: 0.0.1
 
     let result = deps
         .worker_service()
-        .create_api_definition(
-            &admin.token,
-            &project,
-            CreateApiDefinitionRequest {
-                api_definition: Some(create_api_definition_request::ApiDefinition::Openapi(
-                    openapi_yaml,
-                )),
-            },
-        )
+        .create_api_definition_from_yaml(&admin.token, &project, &openapi_yaml)
         .await;
 
     let response = result.unwrap();
 
     // Verify top-level fields
-    assert_eq!(response.id.as_ref().unwrap().value, "shopping-cart");
+    assert_eq!(response.id, "shopping-cart");
     assert_eq!(response.version, "0.0.1");
     assert!(response.draft);
 
-    let definition = response.definition.unwrap();
-
-    match definition {
-        api_definition::Definition::Http(http) => {
-            assert_eq!(http.routes.len(), 2);
-
-            let post_route = &http.routes[0];
-            assert_eq!(post_route.method, 2); // 2 = POST
-            assert_eq!(post_route.path, "/v0.0.1/{user}/add-item");
+    assert_eq!(response.routes.len(), 2);
 
-            let post_binding = post_route.binding.as_ref().unwrap();
-            assert_eq!(post_binding.binding_type, Some(0)); // 0 = Default
+    let post_route = &response.routes[0];
+    assert_eq!(post_route.method, MethodPattern::Post);
+    assert_eq!(post_route.path, "/v0.0.1/{user}/add-item");
 
-            let component = post_binding.component.as_ref().unwrap();
-            assert_eq!(component.version, 0);
-            assert!(component.component_id.is_some());
-
-            let response_binding = post_binding.response.as_ref().unwrap();
-            assert!(response_binding.expr.is_some());
-
-            let options_route = &http.routes[1];
-            assert_eq!(options_route.method, 6); // 6 = OPTIONS
-            assert_eq!(options_route.path, "/v0.0.1/{user}/add-item");
+    let post_binding = &post_route.binding;
+    assert_eq!(
+        post_route.binding.binding_type,
+        Some(GatewayBindingType::Default)
+    );
 
-            let options_binding = options_route.binding.as_ref().unwrap();
-            assert_eq!(options_binding.binding_type, Some(2)); // 2 = CorsPreflight
+    let component = post_binding.component.as_ref().unwrap();
+    assert_eq!(component.version, 0);
+    assert_eq!(component.name, unique_component_name);
 
-            let static_binding_wrapper = options_binding.static_binding.as_ref().unwrap();
-            let static_binding_value = static_binding_wrapper.static_binding.as_ref().unwrap();
+    assert!(post_binding.response.is_some());
 
-            assert!(matches!(
-                static_binding_value,
-                static_binding::StaticBinding::HttpCorsPreflight(_)
-            ));
+    let options_route = &response.routes[1];
+    assert_eq!(options_route.method, MethodPattern::Options);
+    assert_eq!(options_route.path, "/v0.0.1/{user}/add-item");
 
-            if let static_binding::StaticBinding::HttpCorsPreflight(cors) = static_binding_value {
-                assert_eq!(cors.allow_origin.as_deref(), Some("*"));
-                assert_eq!(
-                    cors.allow_methods.as_deref(),
-                    Some("GET, POST, PUT, DELETE, OPTIONS")
-                );
-                assert_eq!(
-                    cors.allow_headers.as_deref(),
-                    Some("Content-Type, Authorization")
-                );
-            }
-        }
-    }
+    let options_binding = &options_route.binding;
+    assert_eq!(
+        options_binding.binding_type,
+        Some(GatewayBindingType::CorsPreflight)
+    );
+    assert_eq!(
+        options_binding.cors_preflight,
+        Some(HttpCors {
+            allow_origin: "*".to_string(),
+            allow_methods: "GET, POST, PUT, DELETE, OPTIONS".to_string(),
+            allow_headers: "Content-Type, Authorization".to_string(),
+            expose_headers: None,
+            allow_credentials: None,
+            max_age: None
+        })
+    );
 }
 
 // Create API definition from OpenAPI JSON
 #[test]
 #[tracing::instrument]
-async fn create_openapi_json_definition(deps: &Deps) {
-    let admin = deps.admin();
+async fn create_openapi_json_definition(deps: &EnvBasedTestDependencies) {
+    let admin = deps.admin().await;
 
     let (_component_id, component_name) = admin
         .component("shopping-cart")
@@ -793,73 +705,253 @@ async fn create_openapi_json_definition(deps: &Deps) {
 
     let result = deps
         .worker_service()
-        .create_api_definition(
-            &admin.token,
-            &project,
-            CreateApiDefinitionRequest {
-                api_definition: Some(create_api_definition_request::ApiDefinition::Openapi(
-                    openapi_json,
-                )),
-            },
-        )
+        .create_api_definition_from_json(&admin.token, &project, &openapi_json)
         .await;
 
     let response = result.unwrap();
 
     // Verify top-level fields
-    assert_eq!(
-        response.id.as_ref().unwrap().value,
-        "shopping-cart-openapi-json"
-    );
+    assert_eq!(response.id, "shopping-cart-openapi-json");
     assert_eq!(response.version, "0.0.1");
     assert!(response.draft);
 
-    let definition = response.definition.unwrap();
+    assert_eq!(response.routes.len(), 2);
 
-    match definition {
-        api_definition::Definition::Http(http) => {
-            assert_eq!(http.routes.len(), 2);
+    let post_route = &response.routes[0];
+    assert_eq!(post_route.method, MethodPattern::Post);
+    assert_eq!(post_route.path, "/v0.0.1/{user}/add-item");
 
-            let post_route = &http.routes[0];
-            assert_eq!(post_route.method, 2); // 2 = POST
-            assert_eq!(post_route.path, "/v0.0.1/{user}/add-item");
+    let post_binding = &post_route.binding;
+    assert_eq!(
+        post_route.binding.binding_type,
+        Some(GatewayBindingType::Default)
+    );
 
-            let post_binding = post_route.binding.as_ref().unwrap();
-            assert_eq!(post_binding.binding_type, Some(0)); // 0 = Default
+    let component = post_binding.component.as_ref().unwrap();
+    assert_eq!(component.version, 0);
+    assert_eq!(component.name, unique_component_name);
 
-            let component = post_binding.component.as_ref().unwrap();
-            assert_eq!(component.version, 0);
-            assert!(component.component_id.is_some());
+    assert!(post_binding.response.is_some());
 
-            let response_binding = post_binding.response.as_ref().unwrap();
-            assert!(response_binding.expr.is_some());
+    let options_route = &response.routes[1];
+    assert_eq!(options_route.method, MethodPattern::Options);
+    assert_eq!(options_route.path, "/v0.0.1/{user}/add-item");
 
-            let options_route = &http.routes[1];
-            assert_eq!(options_route.method, 6); // 6 = OPTIONS
-            assert_eq!(options_route.path, "/v0.0.1/{user}/add-item");
+    let options_binding = &options_route.binding;
+    assert_eq!(
+        options_binding.binding_type,
+        Some(GatewayBindingType::CorsPreflight)
+    );
+    assert_eq!(
+        options_binding.cors_preflight,
+        Some(HttpCors {
+            allow_origin: "*".to_string(),
+            allow_methods: "GET, POST, PUT, DELETE, OPTIONS".to_string(),
+            allow_headers: "Content-Type, Authorization".to_string(),
+            expose_headers: None,
+            allow_credentials: None,
+            max_age: None
+        })
+    );
+}
 
-            let options_binding = options_route.binding.as_ref().unwrap();
-            assert_eq!(options_binding.binding_type, Some(2)); // 2 = CorsPreflight
+#[test]
+#[tracing::instrument]
+async fn test_export_openapi_spec_simple(deps: &EnvBasedTestDependencies) {
+    let admin = deps.admin().await;
+    let project = admin.default_project().await;
 
-            let static_binding_wrapper = options_binding.static_binding.as_ref().unwrap();
-            let static_binding_value = static_binding_wrapper.static_binding.as_ref().unwrap();
+    let (_component_id, component_name) = admin
+        .component("counters")
+        .unique()
+        .store_and_get_name()
+        .await;
 
-            assert!(matches!(
-                static_binding_value,
-                static_binding::StaticBinding::HttpCorsPreflight(_)
-            ));
+    // Create an API definition with a specific route
+    let api_id = Uuid::new_v4().to_string();
+    let request = HttpApiDefinitionRequest {
+        id: api_id.clone(),
+        version: "1.0".to_string(),
+        draft: true,
+        security: None,
+        routes: vec![RouteRequestData {
+            method: MethodPattern::Get,
+            path: "/test-simple-export".to_string(),
+            binding: GatewayBindingData {
+                component: Some(GatewayBindingComponent {
+                    name: component_name.0,
+                    version: Some(0),
+                }),
+                worker_name: None,
+                response: Some(
+                    r#"
+                        {
+                            headers: {ContentType: "application/json"},
+                            body: "Simple export test response",
+                            status: 200
+                        }
+                    "#
+                    .to_string(),
+                ),
+                idempotency_key: None,
+                binding_type: Some(GatewayBindingType::Default),
+                invocation_context: None,
+            },
+            security: None,
+        }],
+    };
 
-            if let static_binding::StaticBinding::HttpCorsPreflight(cors) = static_binding_value {
-                assert_eq!(cors.allow_origin.as_deref(), Some("*"));
-                assert_eq!(
-                    cors.allow_methods.as_deref(),
-                    Some("GET, POST, PUT, DELETE, OPTIONS")
-                );
-                assert_eq!(
-                    cors.allow_headers.as_deref(),
-                    Some("Content-Type, Authorization")
-                );
-            }
-        }
-    }
+    // Create the API definition
+    let response = deps
+        .worker_service()
+        .create_api_definition(&admin.token, &project, &request)
+        .await
+        .unwrap();
+
+    check_equal_api_definition_request_and_response(&request, &response);
+
+    // Export the API definition
+    let export_data = deps
+        .worker_service()
+        .export_openapi_spec(&admin.token, &project, &api_id, "1.0")
+        .await
+        .unwrap();
+
+    // Validate that there is YAML content
+    assert!(
+        !export_data.openapi_yaml.is_empty(),
+        "OpenAPI YAML should not be empty"
+    );
+
+    // Basic validation of the YAML structure
+    let yaml_value: serde_yaml::Value =
+        serde_yaml::from_str(&export_data.openapi_yaml).expect("Failed to parse OpenAPI YAML");
+
+    // Verify basic OpenAPI structure
+    assert_eq!(yaml_value["openapi"].as_str().unwrap(), "3.0.0");
+    assert_eq!(yaml_value["info"]["title"].as_str().unwrap(), api_id);
+    assert_eq!(yaml_value["info"]["version"].as_str().unwrap(), "1.0");
+    assert_eq!(
+        yaml_value["x-golem-api-definition-id"].as_str().unwrap(),
+        api_id
+    );
+    assert_eq!(
+        yaml_value["x-golem-api-definition-version"]
+            .as_str()
+            .unwrap(),
+        "1.0"
+    );
+
+    // Verify path exists
+    assert!(yaml_value["paths"]["/test-simple-export"].is_mapping());
+}
+
+#[test]
+#[tracing::instrument]
+// This is the full round trip test for API definition: API -> OpenAPI -> API
+async fn test_roundtrip_api_definition(deps: &EnvBasedTestDependencies) {
+    let admin = deps.admin().await;
+    let project = admin.default_project().await;
+
+    let (_component_id, component_name) = admin
+        .component("counters")
+        .unique()
+        .store_and_get_name()
+        .await;
+
+    // 1. Create an API definition request with a specific route
+    let api_id = Uuid::new_v4().to_string();
+    let request = HttpApiDefinitionRequest {
+        id: api_id.clone(),
+        version: "1.0".to_string(),
+        draft: true,
+        security: None,
+        routes: vec![RouteRequestData {
+            method: MethodPattern::Get,
+            path: "/test-fixed-export-path".to_string(),
+            binding: GatewayBindingData {
+                component: Some(GatewayBindingComponent {
+                    name: component_name.0,
+                    version: Some(0),
+                }),
+                worker_name: None,
+                response: Some(
+                    r#"
+                        {
+                            headers: {
+                                ContentType: "application/json"
+                            },
+                            body: "Fixed export test response",
+                            status: 200
+                        }
+                    "#
+                    .to_string(),
+                ),
+                idempotency_key: None,
+                binding_type: Some(GatewayBindingType::Default),
+                invocation_context: None,
+            },
+            security: None,
+        }],
+    };
+
+    // 2. Create the API definition
+    let original_api_definition = deps
+        .worker_service()
+        .create_api_definition(&admin.token, &project, &request)
+        .await
+        .unwrap();
+
+    check_equal_api_definition_request_and_response(&request, &original_api_definition);
+
+    // 3. Export the API definition to OpenAPI format
+    let export_data = deps
+        .worker_service()
+        .export_openapi_spec(&admin.token, &project, &api_id, "1.0")
+        .await
+        .unwrap();
+
+    // Validate that there is YAML content
+    assert!(
+        !export_data.openapi_yaml.is_empty(),
+        "OpenAPI YAML should not be empty"
+    );
+
+    // Basic validation of the YAML structure
+    let yaml_value: serde_yaml::Value =
+        serde_yaml::from_str(&export_data.openapi_yaml).expect("Failed to parse OpenAPI YAML");
+
+    // Verify basic OpenAPI structure
+    assert_eq!(yaml_value["openapi"].as_str().unwrap(), "3.0.0");
+    assert_eq!(yaml_value["info"]["title"].as_str().unwrap(), api_id);
+    assert_eq!(yaml_value["info"]["version"].as_str().unwrap(), "1.0");
+    assert_eq!(
+        yaml_value["x-golem-api-definition-id"].as_str().unwrap(),
+        api_id
+    );
+    assert_eq!(
+        yaml_value["x-golem-api-definition-version"]
+            .as_str()
+            .unwrap(),
+        "1.0"
+    );
+
+    // Verify path exists
+    assert!(yaml_value["paths"]["/test-fixed-export-path"].is_mapping());
+
+    // 4. Delete the original API definition
+    deps.worker_service()
+        .delete_api_definition(&admin.token, &project, &api_id, "1.0")
+        .await
+        .unwrap();
+
+    // 5. Create new API definition from the exported YAML
+    let imported_api_definition = deps
+        .worker_service()
+        .create_api_definition_from_yaml(&admin.token, &project, &export_data.openapi_yaml)
+        .await
+        .unwrap();
+
+    // 6. Compare both API definitions
+    check_equal_api_definition_request_and_response(&request, &imported_api_definition);
 }
diff --git a/integration-tests/tests/api/api_deployment.rs b/integration-tests/tests/api/api_deployment.rs
index ed40e0bb..d72ecae1 100644
--- a/integration-tests/tests/api/api_deployment.rs
+++ b/integration-tests/tests/api/api_deployment.rs
@@ -12,22 +12,15 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use crate::{to_grpc_rib_expr, Deps, Tracing};
+use crate::Tracing;
 use assert2::{assert, check};
-use golem_api_grpc::proto::golem::apidefinition::v1::{
-    api_definition_request, create_api_definition_request, ApiDefinitionRequest,
-    CreateApiDefinitionRequest,
-};
-use golem_api_grpc::proto::golem::apidefinition::{
-    ApiDefinition, ApiDefinitionId, GatewayBinding, GatewayBindingType, HttpApiDefinition,
-    HttpMethod, HttpRoute,
-};
-use golem_api_grpc::proto::golem::component::VersionedComponentId;
 use golem_client::model::{
     ApiDefinitionInfo, ApiDeployment, ApiDeploymentRequest, ApiSite, ComponentType,
+    GatewayBindingComponent, GatewayBindingData, GatewayBindingType, HttpApiDefinitionRequest,
+    HttpApiDefinitionResponseData, MethodPattern, RouteRequestData,
 };
-use golem_common::model::{ComponentId, ProjectId};
-use golem_test_framework::config::{GolemClientProtocol, TestDependencies};
+use golem_common::model::ProjectId;
+use golem_test_framework::config::{EnvBasedTestDependencies, TestDependencies};
 use golem_test_framework::dsl::TestDslUnsafe;
 use std::collections::HashMap;
 use std::panic;
@@ -35,19 +28,20 @@ use test_r::{inherit_test_dep, test};
 use uuid::Uuid;
 
 inherit_test_dep!(Tracing);
-inherit_test_dep!(Deps);
+inherit_test_dep!(EnvBasedTestDependencies);
 
 #[test]
 #[tracing::instrument]
-async fn create_and_get_api_deployment(deps: &Deps) {
-    if deps.worker_service().client_protocol() != GolemClientProtocol::Http {
-        return assert!(false, "Test requires to select HTTP golem client protocol");
-    }
-
-    let admin = deps.admin();
-    let component_id = admin.component("shopping-cart").unique().store().await;
+async fn create_and_get_api_deployment(deps: &EnvBasedTestDependencies) {
+    let admin = deps.admin().await;
     let project_id = admin.default_project().await;
 
+    let (_, component_name) = admin
+        .component("shopping-cart")
+        .unique()
+        .store_and_get_name()
+        .await;
+
     fn new_api_definition_id(prefix: &str) -> String {
         format!("{}-{}", prefix, Uuid::new_v4())
     }
@@ -56,7 +50,7 @@ async fn create_and_get_api_deployment(deps: &Deps) {
         deps,
         &admin.token,
         &project_id,
-        &component_id,
+        &component_name.0,
         new_api_definition_id("a"),
         "1".to_string(),
         "/path-1".to_string(),
@@ -67,7 +61,7 @@ async fn create_and_get_api_deployment(deps: &Deps) {
         deps,
         &admin.token,
         &project_id,
-        &component_id,
+        &component_name.0,
         new_api_definition_id("b"),
         "2".to_string(),
         "/path-2".to_string(),
@@ -78,11 +72,11 @@ async fn create_and_get_api_deployment(deps: &Deps) {
         project_id: project_id.0,
         api_definitions: vec![
             ApiDefinitionInfo {
-                id: api_definition_1.id.as_ref().unwrap().value.clone(),
+                id: api_definition_1.id.clone(),
                 version: api_definition_1.version.clone(),
             },
             ApiDefinitionInfo {
-                id: api_definition_2.id.as_ref().unwrap().value.clone(),
+                id: api_definition_2.id.clone(),
                 version: api_definition_2.version.clone(),
             },
         ],
@@ -112,7 +106,7 @@ async fn create_and_get_api_deployment(deps: &Deps) {
         deps,
         &admin.token,
         &project_id,
-        &component_id,
+        &component_name.0,
         new_api_definition_id("c"),
         "1".to_string(),
         "/path-3".to_string(),
@@ -123,11 +117,11 @@ async fn create_and_get_api_deployment(deps: &Deps) {
         project_id: project_id.0,
         api_definitions: vec![
             ApiDefinitionInfo {
-                id: api_definition_2.id.as_ref().unwrap().value.clone(),
+                id: api_definition_2.id.clone(),
                 version: api_definition_2.version.clone(),
             },
             ApiDefinitionInfo {
-                id: api_definition_3.id.as_ref().unwrap().value.clone(),
+                id: api_definition_3.id.clone(),
                 version: api_definition_3.version.clone(),
             },
         ],
@@ -142,15 +136,15 @@ async fn create_and_get_api_deployment(deps: &Deps) {
         project_id: project_id.0,
         api_definitions: vec![
             ApiDefinitionInfo {
-                id: api_definition_1.id.as_ref().unwrap().value.clone(),
+                id: api_definition_1.id.clone(),
                 version: api_definition_1.version.clone(),
             },
             ApiDefinitionInfo {
-                id: api_definition_2.id.as_ref().unwrap().value.clone(),
+                id: api_definition_2.id.clone(),
                 version: api_definition_2.version.clone(),
             },
             ApiDefinitionInfo {
-                id: api_definition_3.id.as_ref().unwrap().value.clone(),
+                id: api_definition_3.id.clone(),
                 version: api_definition_3.version.clone(),
             },
         ],
@@ -199,11 +193,15 @@ async fn create_and_get_api_deployment(deps: &Deps) {
 // Delete the API deployment, and the update should succeed.
 #[test]
 #[tracing::instrument]
-async fn create_api_deployment_and_update_component(deps: &Deps) {
-    let admin = deps.admin();
+async fn create_api_deployment_and_update_component(deps: &EnvBasedTestDependencies) {
+    let admin = deps.admin().await;
     let project_id = admin.default_project().await;
 
-    let component_id = admin.component("shopping-cart").unique().store().await;
+    let (component_id, component_name) = admin
+        .component("shopping-cart")
+        .unique()
+        .store_and_get_name()
+        .await;
 
     fn new_api_definition_id(prefix: &str) -> String {
         format!("{}-{}", prefix, Uuid::new_v4())
@@ -213,7 +211,7 @@ async fn create_api_deployment_and_update_component(deps: &Deps) {
         deps,
         &admin.token,
         &project_id,
-        &component_id,
+        &component_name.0,
         new_api_definition_id("a"),
         "1".to_string(),
         "/path-4".to_string(),
@@ -223,7 +221,7 @@ async fn create_api_deployment_and_update_component(deps: &Deps) {
     let request = ApiDeploymentRequest {
         project_id: project_id.0,
         api_definitions: vec![ApiDefinitionInfo {
-            id: api_definition_1.id.as_ref().unwrap().value.clone(),
+            id: api_definition_1.id.clone(),
             version: api_definition_1.version.clone(),
         }],
         site: ApiSite {
@@ -288,11 +286,15 @@ async fn create_api_deployment_and_update_component(deps: &Deps) {
 // Delete the second API deployment, and the update should succeed.
 #[test]
 #[tracing::instrument]
-async fn create_multiple_api_deployments_and_update_component_1(deps: &Deps) {
-    let admin = deps.admin();
+async fn create_multiple_api_deployments_and_update_component_1(deps: &EnvBasedTestDependencies) {
+    let admin = deps.admin().await;
     let project_id = admin.default_project().await;
 
-    let component_id = admin.component("shopping-cart").unique().store().await;
+    let (component_id, component_name) = admin
+        .component("shopping-cart")
+        .unique()
+        .store_and_get_name()
+        .await;
 
     fn new_api_definition_id(prefix: &str) -> String {
         format!("{}-{}", prefix, Uuid::new_v4())
@@ -302,7 +304,7 @@ async fn create_multiple_api_deployments_and_update_component_1(deps: &Deps) {
         deps,
         &admin.token,
         &project_id,
-        &component_id,
+        &component_name.0,
         new_api_definition_id("a"),
         "1".to_string(),
         "/path-5".to_string(),
@@ -313,7 +315,7 @@ async fn create_multiple_api_deployments_and_update_component_1(deps: &Deps) {
     let request1 = ApiDeploymentRequest {
         project_id: project_id.0,
         api_definitions: vec![ApiDefinitionInfo {
-            id: api_definition.id.as_ref().unwrap().value.clone(),
+            id: api_definition.id.clone(),
             version: api_definition.version.clone(),
         }],
         site: ApiSite {
@@ -325,7 +327,7 @@ async fn create_multiple_api_deployments_and_update_component_1(deps: &Deps) {
     let request2 = ApiDeploymentRequest {
         project_id: project_id.0,
         api_definitions: vec![ApiDefinitionInfo {
-            id: api_definition.id.as_ref().unwrap().value.clone(),
+            id: api_definition.id.clone(),
             version: api_definition.version.clone(),
         }],
         site: ApiSite {
@@ -420,9 +422,13 @@ async fn create_multiple_api_deployments_and_update_component_1(deps: &Deps) {
 // Delete the API deployment that uses worker function, and the update should succeed.
 #[test]
 #[tracing::instrument]
-async fn create_multiple_api_deployments_and_update_component_2(deps: &Deps) {
-    let admin = deps.admin();
-    let component_id = admin.component("shopping-cart").unique().store().await;
+async fn create_multiple_api_deployments_and_update_component_2(deps: &EnvBasedTestDependencies) {
+    let admin = deps.admin().await;
+    let (component_id, component_name) = admin
+        .component("shopping-cart")
+        .unique()
+        .store_and_get_name()
+        .await;
     let project_id = admin.default_project().await;
 
     fn new_api_definition_id(prefix: &str) -> String {
@@ -433,7 +439,7 @@ async fn create_multiple_api_deployments_and_update_component_2(deps: &Deps) {
         deps,
         &admin.token,
         &project_id,
-        &component_id,
+        &component_name.0,
         new_api_definition_id("a"),
         "1".to_string(),
         "/path-6".to_string(),
@@ -444,7 +450,7 @@ async fn create_multiple_api_deployments_and_update_component_2(deps: &Deps) {
         deps,
         &admin.token,
         &project_id,
-        &component_id,
+        &component_name.0,
         new_api_definition_id("a"),
         "1".to_string(),
         "/path-7".to_string(),
@@ -455,7 +461,7 @@ async fn create_multiple_api_deployments_and_update_component_2(deps: &Deps) {
     let request1 = ApiDeploymentRequest {
         project_id: project_id.0,
         api_definitions: vec![ApiDefinitionInfo {
-            id: api_definition1.id.as_ref().unwrap().value.clone(),
+            id: api_definition1.id.clone(),
             version: api_definition1.version.clone(),
         }],
         site: ApiSite {
@@ -467,7 +473,7 @@ async fn create_multiple_api_deployments_and_update_component_2(deps: &Deps) {
     let request2 = ApiDeploymentRequest {
         project_id: project_id.0,
         api_definitions: vec![ApiDefinitionInfo {
-            id: api_definition2.id.as_ref().unwrap().value.clone(),
+            id: api_definition2.id.clone(),
             version: api_definition2.version.clone(),
         }],
         site: ApiSite {
@@ -538,16 +544,20 @@ async fn create_multiple_api_deployments_and_update_component_2(deps: &Deps) {
 
 #[test]
 #[tracing::instrument]
-async fn get_all_api_deployments(deps: &Deps) {
-    let admin = deps.admin();
+async fn get_all_api_deployments(deps: &EnvBasedTestDependencies) {
+    let admin = deps.admin().await;
     let project_id = admin.default_project().await;
-    let component_id = admin.component("shopping-cart").unique().store().await;
+    let (_, component_name) = admin
+        .component("shopping-cart")
+        .unique()
+        .store_and_get_name()
+        .await;
 
     let api_definition_1 = create_api_definition(
         deps,
         &admin.token,
         &project_id,
-        &component_id,
+        &component_name.0,
         Uuid::new_v4().to_string(),
         "1".to_string(),
         "/path-1".to_string(),
@@ -557,7 +567,7 @@ async fn get_all_api_deployments(deps: &Deps) {
         deps,
         &admin.token,
         &project_id,
-        &component_id,
+        &component_name.0,
         Uuid::new_v4().to_string(),
         "2".to_string(),
         "/path-2".to_string(),
@@ -570,7 +580,7 @@ async fn get_all_api_deployments(deps: &Deps) {
             ApiDeploymentRequest {
                 project_id: project_id.0,
                 api_definitions: vec![ApiDefinitionInfo {
-                    id: api_definition_1.id.as_ref().unwrap().value.clone(),
+                    id: api_definition_1.id.clone(),
                     version: api_definition_1.version.clone(),
                 }],
                 site: ApiSite {
@@ -588,7 +598,7 @@ async fn get_all_api_deployments(deps: &Deps) {
             ApiDeploymentRequest {
                 project_id: project_id.0,
                 api_definitions: vec![ApiDefinitionInfo {
-                    id: api_definition_1.id.as_ref().unwrap().value.clone(),
+                    id: api_definition_1.id.clone(),
                     version: api_definition_1.version.clone(),
                 }],
                 site: ApiSite {
@@ -606,7 +616,7 @@ async fn get_all_api_deployments(deps: &Deps) {
             ApiDeploymentRequest {
                 project_id: project_id.0,
                 api_definitions: vec![ApiDefinitionInfo {
-                    id: api_definition_2.id.as_ref().unwrap().value.clone(),
+                    id: api_definition_2.id.clone(),
                     version: api_definition_2.version.clone(),
                 }],
                 site: ApiSite {
@@ -646,11 +656,7 @@ async fn get_all_api_deployments(deps: &Deps) {
 
     let result = by_domains(
         deps.worker_service()
-            .list_api_deployments(
-                &admin.token,
-                &project_id,
-                Some(&api_definition_1.id.as_ref().unwrap().value),
-            )
+            .list_api_deployments(&admin.token, &project_id, Some(&api_definition_1.id))
             .await
             .unwrap(),
     );
@@ -660,11 +666,7 @@ async fn get_all_api_deployments(deps: &Deps) {
 
     let result = by_domains(
         deps.worker_service()
-            .list_api_deployments(
-                &admin.token,
-                &project_id,
-                Some(&api_definition_2.id.as_ref().unwrap().value),
-            )
+            .list_api_deployments(&admin.token, &project_id, Some(&api_definition_2.id))
             .await
             .unwrap(),
     );
@@ -674,58 +676,49 @@ async fn get_all_api_deployments(deps: &Deps) {
 }
 
 async fn create_api_definition_without_worker_calls(
-    deps: &Deps,
+    deps: &EnvBasedTestDependencies,
     token: &Uuid,
     project: &ProjectId,
-    component_id: &ComponentId,
+    component_name: &str,
     api_definition_id: String,
     version: String,
     path: String,
-) -> ApiDefinition {
+) -> HttpApiDefinitionResponseData {
     deps.worker_service()
         .create_api_definition(
             token,
             project,
-            CreateApiDefinitionRequest {
-                api_definition: Some(create_api_definition_request::ApiDefinition::Definition(
-                    ApiDefinitionRequest {
-                        id: Some(ApiDefinitionId {
-                            value: api_definition_id,
+            &HttpApiDefinitionRequest {
+                id: api_definition_id,
+                version,
+                draft: false,
+                security: None,
+                routes: vec![RouteRequestData {
+                    method: MethodPattern::Post,
+                    path,
+                    binding: GatewayBindingData {
+                        component: Some(GatewayBindingComponent {
+                            name: component_name.to_string(),
+                            version: Some(0),
                         }),
-                        version,
-                        draft: false,
-                        definition: Some(api_definition_request::Definition::Http(
-                            HttpApiDefinition {
-                                routes: vec![HttpRoute {
-                                    method: HttpMethod::Post as i32,
-                                    path,
-                                    binding: Some(GatewayBinding {
-                                        component: Some(VersionedComponentId {
-                                            component_id: Some(component_id.clone().into()),
-                                            version: 0,
-                                        }),
-                                        worker_name: None,
-                                        response: Some(to_grpc_rib_expr(
-                                            r#"
-                                            let status: u64 = 200;
-                                            {
-                                              headers: {ContentType: "json", userid: "foo"},
-                                              body: "foo",
-                                              status: status
-                                            }
-                                        "#,
-                                        )),
-                                        idempotency_key: None,
-                                        binding_type: Some(GatewayBindingType::Default as i32),
-                                        static_binding: None,
-                                        invocation_context: None,
-                                    }),
-                                    middleware: None,
-                                }],
-                            },
-                        )),
+                        worker_name: None,
+                        response: Some(
+                            r#"
+                                let status: u64 = 200;
+                                {
+                                    headers: {ContentType: "json", userid: "foo"},
+                                    body: "foo",
+                                    status: status
+                                }
+                            "#
+                            .to_string(),
+                        ),
+                        idempotency_key: None,
+                        binding_type: Some(GatewayBindingType::Default),
+                        invocation_context: None,
                     },
-                )),
+                    security: None,
+                }],
             },
         )
         .await
@@ -733,60 +726,51 @@ async fn create_api_definition_without_worker_calls(
 }
 
 async fn create_api_definition(
-    deps: &Deps,
+    deps: &EnvBasedTestDependencies,
     token: &Uuid,
     project: &ProjectId,
-    component_id: &ComponentId,
+    component_name: &str,
     api_definition_id: String,
     version: String,
     path: String,
-) -> ApiDefinition {
+) -> HttpApiDefinitionResponseData {
     deps.worker_service()
         .create_api_definition(
             token,
             project,
-            CreateApiDefinitionRequest {
-                api_definition: Some(create_api_definition_request::ApiDefinition::Definition(
-                    ApiDefinitionRequest {
-                        id: Some(ApiDefinitionId {
-                            value: api_definition_id,
+            &HttpApiDefinitionRequest {
+                id: api_definition_id,
+                version,
+                draft: false,
+                security: None,
+                routes: vec![RouteRequestData {
+                    method: MethodPattern::Post,
+                    path,
+                    binding: GatewayBindingData {
+                        component: Some(GatewayBindingComponent {
+                            name: component_name.to_string(),
+                            version: Some(0),
                         }),
-                        version,
-                        draft: false,
-                        definition: Some(api_definition_request::Definition::Http(
-                            HttpApiDefinition {
-                                routes: vec![HttpRoute {
-                                    method: HttpMethod::Post as i32,
-                                    path,
-                                    binding: Some(GatewayBinding {
-                                        component: Some(VersionedComponentId {
-                                            component_id: Some(component_id.clone().into()),
-                                            version: 0,
-                                        }),
-                                        worker_name: None,
-                                        response: Some(to_grpc_rib_expr(
-                                            r#"
-                                            let worker = instance("shopping-cart");
-                                            let result = worker.get-cart-contents();
-                                            let status: u64 = 200;
-                                            {
-                                              headers: { ContentType: "json", userid: "foo" },
-                                              body: "foo",
-                                              status: status
-                                            }
-                                        "#,
-                                        )),
-                                        idempotency_key: None,
-                                        binding_type: Some(GatewayBindingType::Default as i32),
-                                        static_binding: None,
-                                        invocation_context: None,
-                                    }),
-                                    middleware: None,
-                                }],
-                            },
-                        )),
+                        worker_name: None,
+                        response: Some(
+                            r#"
+                                let worker = instance("shopping-cart");
+                                let result = worker.get-cart-contents();
+                                let status: u64 = 200;
+                                {
+                                    headers: { ContentType: "json", userid: "foo" },
+                                    body: "foo",
+                                    status: status
+                                }
+                            "#
+                            .to_string(),
+                        ),
+                        idempotency_key: None,
+                        binding_type: Some(GatewayBindingType::Default),
+                        invocation_context: None,
                     },
-                )),
+                    security: None,
+                }],
             },
         )
         .await
@@ -795,16 +779,20 @@ async fn create_api_definition(
 
 #[test]
 #[tracing::instrument]
-async fn undeploy_api_test(deps: &Deps) {
-    let admin = deps.admin();
-    let component_id = admin.component("shopping-cart").unique().store().await;
+async fn undeploy_api_test(deps: &EnvBasedTestDependencies) {
+    let admin = deps.admin().await;
+    let (_, component_name) = admin
+        .component("shopping-cart")
+        .unique()
+        .store_and_get_name()
+        .await;
     let project = admin.default_project().await;
 
     let api_definition_1 = create_api_definition(
         deps,
         &admin.token,
         &project,
-        &component_id,
+        &component_name.0,
         Uuid::new_v4().to_string(),
         "1".to_string(),
         "/api/v1/path-1".to_string(),
@@ -815,7 +803,7 @@ async fn undeploy_api_test(deps: &Deps) {
         deps,
         &admin.token,
         &project,
-        &component_id,
+        &component_name.0,
         Uuid::new_v4().to_string(),
         "2".to_string(),
         "/api/v2/path-2".to_string(),
@@ -830,11 +818,11 @@ async fn undeploy_api_test(deps: &Deps) {
                 project_id: project.0,
                 api_definitions: vec![
                     ApiDefinitionInfo {
-                        id: api_definition_1.id.as_ref().unwrap().value.clone(),
+                        id: api_definition_1.id.clone(),
                         version: api_definition_1.version.clone(),
                     },
                     ApiDefinitionInfo {
-                        id: api_definition_2.id.as_ref().unwrap().value.clone(),
+                        id: api_definition_2.id.clone(),
                         version: api_definition_2.version.clone(),
                     },
                 ],
@@ -856,13 +844,13 @@ async fn undeploy_api_test(deps: &Deps) {
     check!(deployments
         .iter()
         .any(|d| d.api_definitions.contains(&ApiDefinitionInfo {
-            id: api_definition_1.id.as_ref().unwrap().value.clone(),
+            id: api_definition_1.id.clone(),
             version: api_definition_1.version.clone(),
         })));
     check!(deployments
         .iter()
         .any(|d| d.api_definitions.contains(&ApiDefinitionInfo {
-            id: api_definition_2.id.as_ref().unwrap().value.clone(),
+            id: api_definition_2.id.clone(),
             version: api_definition_2.version.clone(),
         })));
 
@@ -872,7 +860,7 @@ async fn undeploy_api_test(deps: &Deps) {
             &admin.token,
             &project,
             "undeploy-test.localhost",
-            &api_definition_1.id.as_ref().unwrap().value,
+            &api_definition_1.id,
             &api_definition_1.version,
         )
         .await
@@ -887,7 +875,7 @@ async fn undeploy_api_test(deps: &Deps) {
     check!(!deployments
         .iter()
         .any(|d| d.api_definitions.contains(&ApiDefinitionInfo {
-            id: api_definition_1.id.as_ref().unwrap().value.clone(),
+            id: api_definition_1.id.clone(),
             version: api_definition_1.version.clone(),
         })));
 
@@ -895,7 +883,7 @@ async fn undeploy_api_test(deps: &Deps) {
     check!(deployments
         .iter()
         .any(|d| d.api_definitions.contains(&ApiDefinitionInfo {
-            id: api_definition_2.id.as_ref().unwrap().value.clone(),
+            id: api_definition_2.id.clone(),
             version: api_definition_2.version.clone(),
         })));
 
@@ -919,7 +907,7 @@ async fn undeploy_api_test(deps: &Deps) {
             &admin.token,
             &project,
             "non-existent.localhost",
-            &api_definition_2.id.as_ref().unwrap().value,
+            &api_definition_2.id,
             &api_definition_2.version,
         )
         .await;
@@ -928,11 +916,15 @@ async fn undeploy_api_test(deps: &Deps) {
 
 #[test]
 #[tracing::instrument]
-async fn undeploy_component_constraint_test(deps: &Deps) {
-    let admin = deps.admin();
+async fn undeploy_component_constraint_test(deps: &EnvBasedTestDependencies) {
+    let admin = deps.admin().await;
     let project = admin.default_project().await;
 
-    let component_id = admin.component("shopping-cart").unique().store().await;
+    let (component_id, component_name) = admin
+        .component("shopping-cart")
+        .unique()
+        .store_and_get_name()
+        .await;
 
     fn new_api_definition_id(prefix: &str) -> String {
         format!("{}-{}", prefix, Uuid::new_v4())
@@ -942,7 +934,7 @@ async fn undeploy_component_constraint_test(deps: &Deps) {
         deps,
         &admin.token,
         &project,
-        &component_id,
+        &component_name.0,
         new_api_definition_id("a"),
         "1".to_string(),
         "/path-undeploy".to_string(),
@@ -952,7 +944,7 @@ async fn undeploy_component_constraint_test(deps: &Deps) {
     let request = ApiDeploymentRequest {
         project_id: project.0,
         api_definitions: vec![ApiDefinitionInfo {
-            id: api_definition_1.id.as_ref().unwrap().value.clone(),
+            id: api_definition_1.id.clone(),
             version: api_definition_1.version.clone(),
         }],
         site: ApiSite {
@@ -995,7 +987,7 @@ async fn undeploy_component_constraint_test(deps: &Deps) {
             &admin.token,
             &project,
             "undeploy-test.localhost",
-            &api_definition_1.id.as_ref().unwrap().value,
+            &api_definition_1.id,
             &api_definition_1.version,
         )
         .await
diff --git a/integration-tests/tests/api/api_security.rs b/integration-tests/tests/api/api_security.rs
index 2c0b4ce7..fb279bac 100644
--- a/integration-tests/tests/api/api_security.rs
+++ b/integration-tests/tests/api/api_security.rs
@@ -12,25 +12,21 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use crate::{Deps, Tracing};
+use crate::Tracing;
 use assert2::assert;
 use golem_client::model::{Provider, SecuritySchemeData};
-use golem_test_framework::config::{GolemClientProtocol, TestDependencies};
+use golem_test_framework::config::{EnvBasedTestDependencies, TestDependencies};
 use golem_test_framework::dsl::TestDsl;
 use test_r::{inherit_test_dep, test};
 use uuid::Uuid;
 
 inherit_test_dep!(Tracing);
-inherit_test_dep!(Deps);
+inherit_test_dep!(EnvBasedTestDependencies);
 
 #[test]
 #[tracing::instrument]
-async fn create_api_security_scheme(deps: &Deps) {
-    if deps.worker_service().client_protocol() != GolemClientProtocol::Http {
-        return assert!(false, "Test requires to select HTTP golem client protocol");
-    }
-
-    let admin = deps.admin();
+async fn create_api_security_scheme(deps: &EnvBasedTestDependencies) {
+    let admin = deps.admin().await;
     let project = admin.default_project().await.unwrap();
     let security_scheme = new_security_scheme();
 
@@ -45,12 +41,8 @@ async fn create_api_security_scheme(deps: &Deps) {
 
 #[test]
 #[tracing::instrument]
-async fn get_api_security_scheme(deps: &Deps) {
-    if deps.worker_service().client_protocol() != GolemClientProtocol::Http {
-        return assert!(false, "Test requires to select HTTP golem client protocol");
-    }
-
-    let admin = deps.admin();
+async fn get_api_security_scheme(deps: &EnvBasedTestDependencies) {
+    let admin = deps.admin().await;
     let project = admin.default_project().await.unwrap();
     let security_scheme = new_security_scheme();
 
diff --git a/integration-tests/tests/api/component.rs b/integration-tests/tests/api/component.rs
index 827e1ece..d74cfb87 100644
--- a/integration-tests/tests/api/component.rs
+++ b/integration-tests/tests/api/component.rs
@@ -12,7 +12,7 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use crate::{Deps, Tracing};
+use crate::Tracing;
 use assert2::{assert, check};
 use golem_api_grpc::proto::golem::component::v1::{
     GetComponentRequest, GetComponentsRequest, GetLatestComponentRequest,
@@ -24,7 +24,7 @@ use golem_common::model::component_metadata::{
 use golem_common::model::{
     ComponentFilePermissions, ComponentId, ComponentType, InitialComponentFile,
 };
-use golem_test_framework::config::TestDependencies;
+use golem_test_framework::config::{EnvBasedTestDependencies, TestDependencies};
 use golem_test_framework::dsl::TestDslUnsafe;
 use std::collections::HashMap;
 use test_r::{inherit_test_dep, test};
@@ -32,11 +32,11 @@ use tokio::join;
 use uuid::Uuid;
 
 inherit_test_dep!(Tracing);
-inherit_test_dep!(Deps);
+inherit_test_dep!(EnvBasedTestDependencies);
 
 #[test]
 #[tracing::instrument]
-async fn get_components_many_component(deps: &Deps) {
+async fn get_components_many_component(deps: &EnvBasedTestDependencies) {
     let user = deps.user().await;
 
     // Create some components
@@ -214,7 +214,7 @@ async fn get_components_many_component(deps: &Deps) {
 
 #[test]
 #[tracing::instrument]
-async fn get_components_many_versions(deps: &Deps) {
+async fn get_components_many_versions(deps: &EnvBasedTestDependencies) {
     let user = deps.user().await;
 
     // Create component
@@ -267,8 +267,8 @@ async fn get_components_many_versions(deps: &Deps) {
 
 #[test]
 #[tracing::instrument]
-async fn get_component_latest_version(deps: &Deps) {
-    let admin = deps.admin();
+async fn get_component_latest_version(deps: &EnvBasedTestDependencies) {
+    let admin = deps.admin().await;
 
     // Create component
     let (component_id, _) = admin
@@ -300,8 +300,8 @@ async fn get_component_latest_version(deps: &Deps) {
 
 #[test]
 #[tracing::instrument]
-async fn get_component_metadata_all_versions(deps: &Deps) {
-    let admin = deps.admin();
+async fn get_component_metadata_all_versions(deps: &EnvBasedTestDependencies) {
+    let admin = deps.admin().await;
 
     // Create component
     let (component_id, component_name) = admin
diff --git a/integration-tests/tests/api/invocation_context.rs b/integration-tests/tests/api/invocation_context.rs
index 3398397e..f52ed02f 100644
--- a/integration-tests/tests/api/invocation_context.rs
+++ b/integration-tests/tests/api/invocation_context.rs
@@ -12,27 +12,21 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use crate::{Deps, Tracing};
+use crate::Tracing;
 use assert2::check;
 use axum::http::HeaderMap;
 use axum::routing::post;
 use axum::{Json, Router};
-use golem_api_grpc::proto::golem::apidefinition::v1::{
-    api_definition_request, create_api_definition_request, ApiDefinitionRequest,
-    CreateApiDefinitionRequest,
+use golem_client::model::{
+    ApiDefinitionInfo, ApiDeploymentRequest, ApiSite, GatewayBindingComponent, GatewayBindingData,
+    GatewayBindingType, HttpApiDefinitionRequest, MethodPattern, RouteRequestData,
 };
-use golem_api_grpc::proto::golem::apidefinition::{
-    ApiDefinitionId, GatewayBinding, GatewayBindingType, HttpApiDefinition, HttpMethod, HttpRoute,
-};
-use golem_api_grpc::proto::golem::component::VersionedComponentId;
-use golem_api_grpc::proto::golem::rib::Expr;
-use golem_client::model::{ApiDefinitionInfo, ApiDeploymentRequest, ApiSite};
 use golem_common::model::component_metadata::{
     DynamicLinkedInstance, DynamicLinkedWasmRpc, WasmRpcTarget,
 };
 use golem_common::model::invocation_context::{SpanId, TraceId};
 use golem_common::model::ComponentType;
-use golem_test_framework::config::TestDependencies;
+use golem_test_framework::config::{EnvBasedTestDependencies, TestDependencies};
 use golem_test_framework::dsl::TestDslUnsafe;
 use reqwest::header::HeaderValue;
 use reqwest::Client;
@@ -45,14 +39,14 @@ use tracing::{info, Instrument};
 use uuid::Uuid;
 
 inherit_test_dep!(Tracing);
-inherit_test_dep!(Deps);
+inherit_test_dep!(EnvBasedTestDependencies);
 
 #[test]
 #[tracing::instrument]
 #[timeout(120000)]
 #[allow(clippy::await_holding_lock)]
-async fn invocation_context_test(deps: &Deps) {
-    let admin = deps.admin();
+async fn invocation_context_test(deps: &EnvBasedTestDependencies) {
+    let admin = deps.admin().await;
     let host_http_port = 8588;
 
     let contexts = Arc::new(Mutex::new(Vec::new()));
@@ -97,7 +91,7 @@ async fn invocation_context_test(deps: &Deps) {
     let mut env = HashMap::new();
     env.insert("PORT".to_string(), host_http_port.to_string());
 
-    let component_id = admin
+    let (component_id, component_name) = admin
         .component("golem_ictest")
         .with_dynamic_linking(&[(
             "golem:ictest-client/golem-ictest-client",
@@ -112,79 +106,69 @@ async fn invocation_context_test(deps: &Deps) {
                 )]),
             }),
         )])
-        .store()
+        .store_and_get_name()
         .await;
+
     let _worker_id = admin
-        .start_worker_with(&component_id, "w1", vec![], env.clone())
+        .start_worker_with(&component_id, "w1", vec![], env.clone(), vec![])
         .await;
 
-    let api_definition_id = ApiDefinitionId {
-        value: Uuid::new_v4().to_string(),
-    };
-    let request = ApiDefinitionRequest {
-        id: Some(api_definition_id.clone()),
+    let api_definition_id = Uuid::new_v4().to_string();
+
+    let request = HttpApiDefinitionRequest {
+        id: api_definition_id.clone(),
         version: "1".to_string(),
         draft: true,
-        definition: Some(api_definition_request::Definition::Http(
-            HttpApiDefinition {
-                routes: vec![HttpRoute {
-                    method: HttpMethod::Post as i32,
-                    path: "/test-path-1/{name}".to_string(),
-                    binding: Some(GatewayBinding {
-                        component: Some(VersionedComponentId {
-                            component_id: Some(component_id.clone().into()),
-                            version: 0,
-                        }),
-                        worker_name: Some(to_grpc_rib_expr(r#""counter""#)),
-                        response: Some(to_grpc_rib_expr(
-                            r#"
-                                let worker = instance("w1");
-                                worker.test1();
-                                {
-                                   body: "ok",
-                                   status: 200,
-                                   headers: { Content-Type: "application/json" }
-                                }
-                            "#,
-                        )),
-                        idempotency_key: None,
-                        binding_type: Some(GatewayBindingType::Default as i32),
-                        static_binding: None,
-                        invocation_context: Some(to_grpc_rib_expr(
-                            r#"
-                                {
-                                    name: request.path.name,
-                                    source: "rib"
-                                }
-                            "#,
-                        )),
-                    }),
-                    middleware: None,
-                }],
+        security: None,
+        routes: vec![RouteRequestData {
+            method: MethodPattern::Post,
+            path: "/test-path-1/{name}".to_string(),
+            binding: GatewayBindingData {
+                component: Some(GatewayBindingComponent {
+                    name: component_name.0,
+                    version: Some(0),
+                }),
+                worker_name: None,
+                response: Some(
+                    r#"
+                        let worker = instance("w1");
+                        worker.test1();
+                        {
+                            body: "ok",
+                            status: 200,
+                            headers: { Content-Type: "application/json" }
+                        }
+                    "#
+                    .to_string(),
+                ),
+                idempotency_key: None,
+                binding_type: Some(GatewayBindingType::Default),
+                invocation_context: Some(
+                    r#"
+                        {
+                            name: request.path.name,
+                            source: "rib"
+                        }
+                    "#
+                    .to_string(),
+                ),
             },
-        )),
+            security: None,
+        }],
     };
 
     let project_id = admin.default_project().await;
 
     let _ = deps
         .worker_service()
-        .create_api_definition(
-            &admin.token,
-            &project_id,
-            CreateApiDefinitionRequest {
-                api_definition: Some(create_api_definition_request::ApiDefinition::Definition(
-                    request.clone(),
-                )),
-            },
-        )
+        .create_api_definition(&admin.token, &project_id, &request)
         .await
         .unwrap();
 
     let request = ApiDeploymentRequest {
         project_id: project_id.0,
         api_definitions: vec![ApiDefinitionInfo {
-            id: api_definition_id.value,
+            id: api_definition_id,
             version: "1".to_string(),
         }],
         site: ApiSite {
@@ -328,7 +312,3 @@ async fn invocation_context_test(deps: &Deps) {
         dump[2].as_object().unwrap().get("trace_id") == Some(&Value::String(format!("{trace_id}")))
     ); // coming from the custom invocation context rib
 }
-
-pub fn to_grpc_rib_expr(expr: &str) -> Expr {
-    rib::Expr::from_text(expr).unwrap().into()
-}
diff --git a/integration-tests/tests/api/lib.rs b/integration-tests/tests/api/lib.rs
index 8627a61f..65d1d1eb 100644
--- a/integration-tests/tests/api/lib.rs
+++ b/integration-tests/tests/api/lib.rs
@@ -22,12 +22,10 @@ mod plugins;
 mod worker;
 
 use golem_api_grpc::proto::golem::rib::Expr;
-use golem_common::model::AccountId;
 use golem_common::tracing::{init_tracing_with_default_debug_env_filter, TracingConfig};
 use golem_test_framework::config::{
-    EnvBasedTestDependencies, EnvBasedTestDependenciesConfig, TestDependencies, TestDependenciesDsl,
+    EnvBasedTestDependencies, EnvBasedTestDependenciesConfig, TestDependencies,
 };
-use std::ops::Deref;
 use test_r::{tag_suite, test_dep};
 
 test_r::enable!();
@@ -40,21 +38,6 @@ tag_suite!(invocation_context, http_only);
 
 pub struct Tracing;
 
-pub struct Deps(pub TestDependenciesDsl<EnvBasedTestDependencies>);
-
-impl Deref for Deps {
-    type Target = EnvBasedTestDependencies;
-    fn deref(&self) -> &Self::Target {
-        &self.0.deps
-    }
-}
-
-impl std::fmt::Debug for Deps {
-    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
-        f.debug_struct("Deps").finish_non_exhaustive()
-    }
-}
-
 impl Tracing {
     pub fn init() -> Self {
         init_tracing_with_default_debug_env_filter(
@@ -65,26 +48,21 @@ impl Tracing {
 }
 
 #[test_dep]
-pub async fn create_deps(_tracing: &Tracing) -> Deps {
-    let deps = EnvBasedTestDependencies::new(EnvBasedTestDependenciesConfig {
-        worker_executor_cluster_size: 3,
-        ..EnvBasedTestDependenciesConfig::new()
-    })
+pub async fn create_deps(_tracing: &Tracing) -> EnvBasedTestDependencies {
+    let deps = EnvBasedTestDependencies::new(
+        EnvBasedTestDependenciesConfig {
+            number_of_shards_override: Some(3),
+            ..EnvBasedTestDependenciesConfig::new()
+        }
+        .with_env_overrides(),
+    )
     .await;
 
     deps.redis_monitor().assert_valid();
 
-    let deps2 = TestDependenciesDsl {
-        deps,
-        account_id: AccountId {
-            value: "".to_string(),
-        },
-        account_email: "".to_string(),
-        token: Default::default(),
-    };
-
-    Deps(deps2)
+    deps
 }
+
 #[test_dep]
 pub fn tracing() -> Tracing {
     Tracing::init()
diff --git a/integration-tests/tests/api/plugins.rs b/integration-tests/tests/api/plugins.rs
index 51d041e7..5c7467d3 100644
--- a/integration-tests/tests/api/plugins.rs
+++ b/integration-tests/tests/api/plugins.rs
@@ -12,7 +12,7 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use crate::{Deps, Tracing};
+use crate::Tracing;
 use assert2::let_assert;
 use axum::body::Bytes;
 use axum::extract::Multipart;
@@ -20,31 +20,35 @@ use axum::routing::post;
 use axum::Router;
 use base64::Engine;
 use golem_api_grpc::proto::golem::worker::{log_event, Log};
-use golem_client::api::PluginClient;
+use golem_client::api::{ComponentClient, PluginClient};
+use golem_client::model::BatchPluginInstallationUpdates;
 use golem_common::model::plugin::{
     AppPluginDefinition, ComponentTransformerDefinition, LibraryPluginDefinition,
-    OplogProcessorDefinition, PluginTypeSpecificDefinition,
+    OplogProcessorDefinition, PluginInstallationAction, PluginInstallationCreation,
+    PluginInstallationUpdateWithId, PluginTypeSpecificDefinition, PluginUninstallation,
 };
 use golem_common::model::plugin::{PluginScope, ProjectPluginScope};
 use golem_common::model::{ComponentFilePermissions, Empty, ScanCursor};
-use golem_test_framework::config::{TestDependencies, TestDependenciesDsl};
+use golem_test_framework::config::{
+    EnvBasedTestDependencies, TestDependencies, TestDependenciesDsl,
+};
 use golem_test_framework::dsl::TestDslUnsafe;
 use golem_test_framework::model::PluginDefinitionCreation;
 use golem_wasm_ast::analysis::{AnalysedExport, AnalysedInstance};
-use golem_wasm_rpc::{IntoValueAndType, Value};
+use golem_wasm_rpc::{IntoValueAndType, Record, Value};
 use reqwest::StatusCode;
 use serde_json::json;
-use std::collections::HashMap;
+use std::collections::{HashMap, HashSet};
 use test_r::{inherit_test_dep, tag, test};
 use tracing::{debug, info};
 use wac_graph::types::Package;
 use wac_graph::{plug, CompositionGraph, EncodeOptions, Processor};
 
 inherit_test_dep!(Tracing);
-inherit_test_dep!(Deps);
+inherit_test_dep!(EnvBasedTestDependencies);
 
 #[test]
-async fn component_transformer1(deps: &Deps, _tracing: &Tracing) {
+async fn component_transformer1(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
     fn transform_component(component: Bytes) -> anyhow::Result<Vec<u8>> {
         let mut graph = CompositionGraph::new();
         let component = Package::from_bytes("component", None, component, graph.types_mut())?;
@@ -106,7 +110,7 @@ async fn component_transformer1(deps: &Deps, _tracing: &Tracing) {
         axum::Json(response)
     }
 
-    let admin = deps.admin();
+    let admin = deps.admin().await;
 
     let app = Router::new().route("/transform", post(transform));
 
@@ -176,7 +180,7 @@ async fn component_transformer1(deps: &Deps, _tracing: &Tracing) {
 }
 
 #[test]
-async fn component_transformer2(deps: &Deps, _tracing: &Tracing) {
+async fn component_transformer2(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
     fn transform_component(plug_bytes: Bytes) -> anyhow::Result<Vec<u8>> {
         let mut graph = CompositionGraph::new();
         let plug = Package::from_bytes("component", None, plug_bytes, graph.types_mut())?;
@@ -237,7 +241,7 @@ async fn component_transformer2(deps: &Deps, _tracing: &Tracing) {
         axum::Json(response)
     }
 
-    let admin = deps.admin();
+    let admin = deps.admin().await;
 
     let app = Router::new().route("/transform", post(transform));
 
@@ -286,7 +290,7 @@ async fn component_transformer2(deps: &Deps, _tracing: &Tracing) {
 
     let patched_component_metadata = admin.get_latest_component_metadata(&component_id).await;
 
-    let exports = patched_component_metadata.exports;
+    let exports = patched_component_metadata.exports();
 
     assert_eq!(exports.len(), 1);
     assert!(matches!(
@@ -311,7 +315,7 @@ async fn component_transformer2(deps: &Deps, _tracing: &Tracing) {
 }
 
 #[test]
-async fn component_transformer_env_var(deps: &Deps, _tracing: &Tracing) {
+async fn component_transformer_env_var(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
     async fn transform(mut multipart: Multipart) -> axum::Json<serde_json::Value> {
         while let Some(field) = multipart.next_field().await.unwrap() {
             let name = field.name().unwrap().to_string();
@@ -343,7 +347,7 @@ async fn component_transformer_env_var(deps: &Deps, _tracing: &Tracing) {
         axum::Json(response)
     }
 
-    let admin = deps.admin();
+    let admin = deps.admin().await;
 
     let app = Router::new().route("/transform", post(transform));
 
@@ -397,6 +401,7 @@ async fn component_transformer_env_var(deps: &Deps, _tracing: &Tracing) {
             "worker1",
             vec![],
             HashMap::from_iter(vec![("TEST_ENV_VAR_3".to_string(), "value_3".to_string())]),
+            vec![],
         )
         .await;
 
@@ -406,7 +411,7 @@ async fn component_transformer_env_var(deps: &Deps, _tracing: &Tracing) {
         .unwrap();
 
     let response_map = {
-        assert!(response.len() == 1);
+        assert_eq!(response.len(), 1);
 
         let_assert!(Value::Result(Ok(Some(response))) = &response[0]);
         let_assert!(Value::List(response) = response.as_ref());
@@ -435,7 +440,7 @@ async fn component_transformer_env_var(deps: &Deps, _tracing: &Tracing) {
 }
 
 #[test]
-async fn component_transformer_ifs(deps: &Deps, _tracing: &Tracing) {
+async fn component_transformer_ifs(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
     async fn transform(mut multipart: Multipart) -> axum::Json<serde_json::Value> {
         while let Some(field) = multipart.next_field().await.unwrap() {
             let name = field.name().unwrap().to_string();
@@ -473,7 +478,7 @@ async fn component_transformer_ifs(deps: &Deps, _tracing: &Tracing) {
         axum::Json(response)
     }
 
-    let admin = deps.admin();
+    let admin = deps.admin().await;
 
     let app = Router::new().route("/transform", post(transform));
 
@@ -565,11 +570,11 @@ async fn component_transformer_ifs(deps: &Deps, _tracing: &Tracing) {
 }
 
 #[test]
-async fn component_transformer_failed(deps: &Deps, _tracing: &Tracing) {
+async fn component_transformer_failed(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
     async fn transform() -> StatusCode {
         StatusCode::INTERNAL_SERVER_ERROR
     }
-    let admin = deps.admin();
+    let admin = deps.admin().await;
 
     let app = Router::new().route("/transform", post(transform));
 
@@ -620,7 +625,7 @@ async fn component_transformer_failed(deps: &Deps, _tracing: &Tracing) {
 }
 
 #[test]
-async fn oplog_processor_global_scope(deps: &Deps, _tracing: &Tracing) {
+async fn oplog_processor_global_scope(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
     let user = deps.user().await;
 
     let plugin_component_id = user.component("oplog-processor").unique().store().await;
@@ -658,12 +663,12 @@ async fn oplog_processor_global_scope(deps: &Deps, _tracing: &Tracing) {
         .invoke_and_await(
             &worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1000".into_value_and_type()),
                 ("name", "Golem T-Shirt M".into_value_and_type()),
                 ("price", 100.0f32.into_value_and_type()),
                 ("quantity", 5u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -672,12 +677,12 @@ async fn oplog_processor_global_scope(deps: &Deps, _tracing: &Tracing) {
         .invoke_and_await(
             &worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1001".into_value_and_type()),
                 ("name", "Golem Cloud Subscription 1y".into_value_and_type()),
                 ("price", 999999.0f32.into_value_and_type()),
                 ("quantity", 1u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -686,12 +691,12 @@ async fn oplog_processor_global_scope(deps: &Deps, _tracing: &Tracing) {
         .invoke_and_await(
             &worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1002".into_value_and_type()),
                 ("name", "Mud Golem".into_value_and_type()),
                 ("price", 11.0f32.into_value_and_type()),
                 ("quantity", 10u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -779,7 +784,7 @@ async fn oplog_processor_global_scope(deps: &Deps, _tracing: &Tracing) {
 }
 
 #[test]
-async fn oplog_processor_project_scope(deps: &Deps, _tracing: &Tracing) {
+async fn oplog_processor_project_scope(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
     let user = deps.user().await;
     let project = user.create_project().await;
 
@@ -825,12 +830,12 @@ async fn oplog_processor_project_scope(deps: &Deps, _tracing: &Tracing) {
         .invoke_and_await(
             &worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1000".into_value_and_type()),
                 ("name", "Golem T-Shirt M".into_value_and_type()),
                 ("price", 100.0f32.into_value_and_type()),
                 ("quantity", 5u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -839,12 +844,12 @@ async fn oplog_processor_project_scope(deps: &Deps, _tracing: &Tracing) {
         .invoke_and_await(
             &worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1001".into_value_and_type()),
                 ("name", "Golem Cloud Subscription 1y".into_value_and_type()),
                 ("price", 999999.0f32.into_value_and_type()),
                 ("quantity", 1u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -853,12 +858,12 @@ async fn oplog_processor_project_scope(deps: &Deps, _tracing: &Tracing) {
         .invoke_and_await(
             &worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1002".into_value_and_type()),
                 ("name", "Mud Golem".into_value_and_type()),
                 ("price", 11.0f32.into_value_and_type()),
                 ("quantity", 10u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -946,8 +951,8 @@ async fn oplog_processor_project_scope(deps: &Deps, _tracing: &Tracing) {
 }
 
 #[test]
-async fn library_plugin(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn library_plugin(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
+    let admin = deps.admin().await;
     let component_id = admin
         .component("app_and_library_app")
         .unique()
@@ -988,8 +993,8 @@ async fn library_plugin(deps: &Deps, _tracing: &Tracing) {
 }
 
 #[test]
-async fn app_plugin(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn app_plugin(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
+    let admin = deps.admin().await;
 
     let component_id = admin
         .component("app_and_library_library")
@@ -1032,8 +1037,8 @@ async fn app_plugin(deps: &Deps, _tracing: &Tracing) {
 
 /// Test that a plugin can be recreated after deleting it
 #[test]
-async fn recreate_plugin(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn recreate_plugin(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
+    let admin = deps.admin().await;
 
     let component_id = admin
         .component("app_and_library_app")
@@ -1082,7 +1087,7 @@ async fn recreate_plugin(deps: &Deps, _tracing: &Tracing) {
 
 /// Test that a component can be invoked after a plugin is unregistered that it depends on
 #[test]
-async fn invoke_after_deleting_plugin(deps: &Deps, _tracing: &Tracing) {
+async fn invoke_after_deleting_plugin(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
     let user = deps.user().await;
 
     let component_id = user.component("app_and_library_app").unique().store().await;
@@ -1125,7 +1130,10 @@ async fn invoke_after_deleting_plugin(deps: &Deps, _tracing: &Tracing) {
 
 #[test]
 #[tag(http_only)]
-async fn querying_plugins_return_only_plugins_valid_in_scope(deps: &Deps, _tracing: &Tracing) {
+async fn querying_plugins_return_only_plugins_valid_in_scope(
+    deps: &EnvBasedTestDependencies,
+    _tracing: &Tracing,
+) {
     let user = deps.user().await;
 
     let project_1 = user.create_project().await;
@@ -1299,7 +1307,10 @@ async fn querying_plugins_return_only_plugins_valid_in_scope(deps: &Deps, _traci
 
 #[test]
 #[tag(http_only)]
-async fn install_global_plugin_in_shared_project(deps: &Deps, _tracing: &Tracing) {
+async fn install_global_plugin_in_shared_project(
+    deps: &EnvBasedTestDependencies,
+    _tracing: &Tracing,
+) {
     // user 1 defines a project and a global plugin, user 2 installs the plugin to a component in the project
 
     let user_1 = deps.user().await;
@@ -1352,7 +1363,10 @@ async fn install_global_plugin_in_shared_project(deps: &Deps, _tracing: &Tracing
 
 #[test]
 #[tag(http_only)]
-async fn install_project_plugin_in_shared_project(deps: &Deps, _tracing: &Tracing) {
+async fn install_project_plugin_in_shared_project(
+    deps: &EnvBasedTestDependencies,
+    _tracing: &Tracing,
+) {
     // user 1 defines a project, user 2 defines and installs the plugin to a component in the project
 
     let user_1 = deps.user().await;
@@ -1411,7 +1425,10 @@ async fn install_project_plugin_in_shared_project(deps: &Deps, _tracing: &Tracin
 
 #[test]
 #[tag(http_only)]
-async fn install_component_plugin_in_shared_project(deps: &Deps, _tracing: &Tracing) {
+async fn install_component_plugin_in_shared_project(
+    deps: &EnvBasedTestDependencies,
+    _tracing: &Tracing,
+) {
     // user 1 defines a project, user 2 defines and installs the plugin to a component in the project
 
     let user_1 = deps.user().await;
@@ -1466,3 +1483,142 @@ async fn install_component_plugin_in_shared_project(deps: &Deps, _tracing: &Trac
 
     assert_eq!(response, Ok(vec![Value::U64(2)]))
 }
+
+#[test]
+async fn batch_update_plugin_installations(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
+    let user = deps.user().await;
+    let component_id = user.component("app_and_library_app").unique().store().await;
+
+    let plugin_wasm_key = user.add_plugin_wasm("app_and_library_library").await;
+
+    user.create_plugin(PluginDefinitionCreation {
+        name: "library-plugin-1".to_string(),
+        version: "v1".to_string(),
+        description: "A test".to_string(),
+        icon: vec![],
+        homepage: "none".to_string(),
+        specs: PluginTypeSpecificDefinition::Library(LibraryPluginDefinition {
+            blob_storage_key: plugin_wasm_key.clone(),
+        }),
+        scope: PluginScope::Global(Empty {}),
+    })
+    .await;
+
+    user.create_plugin(PluginDefinitionCreation {
+        name: "library-plugin-2".to_string(),
+        version: "v1".to_string(),
+        description: "A test".to_string(),
+        icon: vec![],
+        homepage: "none".to_string(),
+        specs: PluginTypeSpecificDefinition::Library(LibraryPluginDefinition {
+            blob_storage_key: plugin_wasm_key.clone(),
+        }),
+        scope: PluginScope::Global(Empty {}),
+    })
+    .await;
+
+    user.create_plugin(PluginDefinitionCreation {
+        name: "library-plugin-3".to_string(),
+        version: "v1".to_string(),
+        description: "A test".to_string(),
+        icon: vec![],
+        homepage: "none".to_string(),
+        specs: PluginTypeSpecificDefinition::Library(LibraryPluginDefinition {
+            blob_storage_key: plugin_wasm_key.clone(),
+        }),
+        scope: PluginScope::Global(Empty {}),
+    })
+    .await;
+
+    user.create_plugin(PluginDefinitionCreation {
+        name: "library-plugin-4".to_string(),
+        version: "v1".to_string(),
+        description: "A test".to_string(),
+        icon: vec![],
+        homepage: "none".to_string(),
+        specs: PluginTypeSpecificDefinition::Library(LibraryPluginDefinition {
+            blob_storage_key: plugin_wasm_key,
+        }),
+        scope: PluginScope::Global(Empty {}),
+    })
+    .await;
+
+    let installation_id_1 = user
+        .install_plugin_to_component(&component_id, "library-plugin-1", "v1", 0, HashMap::new())
+        .await;
+
+    let installation_id_2 = user
+        .install_plugin_to_component(&component_id, "library-plugin-2", "v1", 1, HashMap::new())
+        .await;
+
+    let installation_id_3 = user
+        .install_plugin_to_component(&component_id, "library-plugin-3", "v1", 2, HashMap::new())
+        .await;
+
+    deps.component_service()
+        .component_http_client(&user.token)
+        .await
+        .batch_update_installed_plugins(
+            &component_id.0,
+            &BatchPluginInstallationUpdates {
+                actions: vec![
+                    PluginInstallationAction::Uninstall(PluginUninstallation {
+                        installation_id: installation_id_2.clone(),
+                    }),
+                    PluginInstallationAction::Update(PluginInstallationUpdateWithId {
+                        installation_id: installation_id_3.clone(),
+                        priority: 3,
+                        parameters: HashMap::from_iter(vec![(
+                            "foo".to_string(),
+                            "bar".to_string(),
+                        )]),
+                    }),
+                    PluginInstallationAction::Install(PluginInstallationCreation {
+                        name: "library-plugin-4".to_string(),
+                        version: "v1".to_string(),
+                        priority: 4,
+                        parameters: HashMap::new(),
+                    }),
+                ],
+            },
+        )
+        .await
+        .unwrap();
+
+    let latest_version = deps
+        .component_service()
+        .component_http_client(&user.token)
+        .await
+        .get_latest_component_metadata(&component_id.0)
+        .await
+        .unwrap()
+        .versioned_component_id
+        .version;
+
+    let installed_plugins = deps
+        .component_service()
+        .component_http_client(&user.token)
+        .await
+        .get_installed_plugins(&component_id.0, &latest_version.to_string())
+        .await
+        .unwrap();
+
+    assert_eq!(installed_plugins.len(), 3);
+    {
+        let mut priorities = installed_plugins
+            .iter()
+            .map(|ip| ip.priority)
+            .collect::<Vec<_>>();
+        priorities.sort();
+        assert_eq!(priorities, vec![0, 3, 4]);
+    }
+    {
+        let installation_ids = installed_plugins
+            .iter()
+            .map(|ip| ip.id)
+            .collect::<HashSet<_>>();
+        assert!(installation_ids.contains(&installation_id_1.0)); // untouched
+        assert!(!installation_ids.contains(&installation_id_2.0)); // uninstalled
+        assert!(installation_ids.contains(&installation_id_3.0)); // updated
+    }
+}
diff --git a/integration-tests/tests/api/worker.rs b/integration-tests/tests/api/worker.rs
index 8bd7a73a..0abe7775 100644
--- a/integration-tests/tests/api/worker.rs
+++ b/integration-tests/tests/api/worker.rs
@@ -12,7 +12,7 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use crate::{Deps, Tracing};
+use crate::Tracing;
 use assert2::{assert, check, let_assert};
 use futures_concurrency::future::Join;
 use golem_api_grpc::proto::golem::worker::v1::{
@@ -20,23 +20,23 @@ use golem_api_grpc::proto::golem::worker::v1::{
     InvokeAndAwaitResponse, LaunchNewWorkerRequest, LaunchNewWorkerResponse,
     LaunchNewWorkerSuccessResponse,
 };
-use golem_api_grpc::proto::golem::worker::{log_event, InvokeResult, LogEvent, TargetWorkerId};
-use golem_test_framework::config::TestDependencies;
+use golem_api_grpc::proto::golem::worker::{log_event, InvokeResult, LogEvent, WorkerId};
+use golem_test_framework::config::{EnvBasedTestDependencies, TestDependencies};
 use golem_test_framework::dsl::TestDslUnsafe;
 use golem_wasm_rpc::Value;
-use std::collections::HashMap;
+use std::collections::{BTreeMap, HashMap};
 use std::time::Duration;
 use test_r::{inherit_test_dep, test};
 use tracing::info;
 use uuid::Uuid;
 
 inherit_test_dep!(Tracing);
-inherit_test_dep!(Deps);
+inherit_test_dep!(EnvBasedTestDependencies);
 
 #[test]
 #[tracing::instrument]
-async fn add_and_invoke_worker_with_args_and_env(deps: &Deps) {
-    let admin = deps.admin();
+async fn add_and_invoke_worker_with_args_and_env(deps: &EnvBasedTestDependencies) {
+    let admin = deps.admin().await;
 
     let (component_id, _) = admin
         .component("environment-service")
@@ -62,6 +62,8 @@ async fn add_and_invoke_worker_with_args_and_env(deps: &Deps) {
                     ("TEST_ENV_VAR_1".to_string(), "value_1".to_string()),
                     ("TEST_ENV_VAR_2".to_string(), "value_2".to_string()),
                 ]),
+                wasi_config_vars: Some(BTreeMap::new().into()),
+                ignore_already_existing: false,
             },
         )
         .await
@@ -74,9 +76,9 @@ async fn add_and_invoke_worker_with_args_and_env(deps: &Deps) {
         .worker_service()
         .invoke_and_await(
             &admin.token,
-            TargetWorkerId {
+            WorkerId {
                 component_id: Some(component_id.clone().into()),
-                name: Some(create_result.worker_id.as_ref().unwrap().name.to_string()),
+                name: create_result.worker_id.as_ref().unwrap().name.to_string(),
             },
             None,
             "golem:it/api.{get-arguments}".to_string(),
@@ -102,9 +104,9 @@ async fn add_and_invoke_worker_with_args_and_env(deps: &Deps) {
         .worker_service()
         .invoke_and_await(
             &admin.token,
-            TargetWorkerId {
+            WorkerId {
                 component_id: Some(component_id.clone().into()),
-                name: Some(create_result.worker_id.as_ref().unwrap().name.to_string()),
+                name: create_result.worker_id.as_ref().unwrap().name.to_string(),
             },
             None,
             "golem:it/api.{get-environment}".to_string(),
@@ -144,7 +146,7 @@ async fn add_and_invoke_worker_with_args_and_env(deps: &Deps) {
 
 #[test]
 #[tracing::instrument]
-async fn stream_high_volume_log_output(deps: &Deps) {
+async fn stream_high_volume_log_output(deps: &EnvBasedTestDependencies) {
     let user = deps.user().await;
 
     let component_id = user
diff --git a/integration-tests/tests/fork.rs b/integration-tests/tests/fork.rs
index 94ae4c6c..909a4663 100644
--- a/integration-tests/tests/fork.rs
+++ b/integration-tests/tests/fork.rs
@@ -12,16 +12,16 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use crate::{Deps, Tracing};
+use crate::Tracing;
 use axum::extract::Path;
 use axum::routing::get;
 use axum::{Json, Router};
 use golem_common::model::oplog::OplogIndex;
 use golem_common::model::public_oplog::PublicOplogEntry;
 use golem_common::model::{IdempotencyKey, WorkerId, WorkerStatus};
-use golem_test_framework::config::TestDependencies;
+use golem_test_framework::config::{EnvBasedTestDependencies, TestDependencies};
 use golem_test_framework::dsl::TestDslUnsafe;
-use golem_wasm_rpc::{IntoValueAndType, Value};
+use golem_wasm_rpc::{IntoValueAndType, Record, Value};
 use std::collections::HashMap;
 use std::net::SocketAddr;
 use std::sync::{Arc, Mutex};
@@ -31,32 +31,13 @@ use tracing::{info, Instrument};
 use uuid::Uuid;
 
 inherit_test_dep!(Tracing);
-inherit_test_dep!(Deps);
-
-async fn resolve_host_address(host_http_port: u16) -> String {
-    let mut host = "localhost".to_string();
-
-    if option_env!("GOLEM_DOCKER_SERVICES").is_some_and( |x| x == "true" ) {
-        host = "host.docker.internal".to_string();
-
-        let addr = tokio::net::lookup_host((host, host_http_port))
-            .await
-            .expect("DNS lookup failed")
-            .find(|a| a.is_ipv4())
-            .expect("DNS lookup returned no IPv4 addresses");
-        dbg!(format!("resolved as {addr}"));
-
-        host = addr.ip().to_string();
-    }
-
-    host
-}
+inherit_test_dep!(EnvBasedTestDependencies);
 
 #[test]
 #[tracing::instrument]
 #[timeout(120000)]
-async fn fork_interrupted_worker(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn fork_interrupted_worker(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
+    let admin = deps.admin().await;
     let response = Arc::new(Mutex::new("initial".to_string()));
     let host_http_port = 8586;
 
@@ -67,10 +48,15 @@ async fn fork_interrupted_worker(deps: &Deps, _tracing: &Tracing) {
     let component_id = admin.component("http-client-2").store().await;
     let mut env = HashMap::new();
     env.insert("PORT".to_string(), host_http_port.to_string());
-    env.insert("HOST".to_string(), resolve_host_address(host_http_port).await);
 
     let worker_id = admin
-        .start_worker_with(&component_id, source_worker_name.as_str(), vec![], env)
+        .start_worker_with(
+            &component_id,
+            source_worker_name.as_str(),
+            vec![],
+            env,
+            vec![],
+        )
         .await;
 
     let target_worker_name = Uuid::new_v4().to_string();
@@ -130,8 +116,8 @@ async fn fork_interrupted_worker(deps: &Deps, _tracing: &Tracing) {
 #[test]
 #[tracing::instrument]
 #[timeout(120000)]
-async fn fork_running_worker_1(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn fork_running_worker_1(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
+    let admin = deps.admin().await;
 
     let component_id = admin.component("shopping-cart").store().await;
 
@@ -154,12 +140,12 @@ async fn fork_running_worker_1(deps: &Deps, _tracing: &Tracing) {
         .invoke_and_await(
             &source_worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1002".into_value_and_type()),
                 ("name", "Mud Golem".into_value_and_type()),
                 ("price", 11.0f32.into_value_and_type()),
                 ("quantity", 10u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -216,8 +202,8 @@ async fn fork_running_worker_1(deps: &Deps, _tracing: &Tracing) {
 #[tracing::instrument]
 #[flaky(5)]
 #[timeout(120000)]
-async fn fork_running_worker_2(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn fork_running_worker_2(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
+    let admin = deps.admin().await;
     let response = Arc::new(Mutex::new("initial".to_string()));
     let host_http_port = 8587;
     let http_server = run_http_server(&response, host_http_port);
@@ -225,11 +211,16 @@ async fn fork_running_worker_2(deps: &Deps, _tracing: &Tracing) {
     let component_id = admin.component("http-client-2").store().await;
     let mut env = HashMap::new();
     env.insert("PORT".to_string(), host_http_port.to_string());
-    env.insert("HOST".to_string(), resolve_host_address(host_http_port).await);
 
     let source_worker_name = Uuid::new_v4().to_string();
     let source_worker_id = admin
-        .start_worker_with(&component_id, source_worker_name.as_str(), vec![], env)
+        .start_worker_with(
+            &component_id,
+            source_worker_name.as_str(),
+            vec![],
+            env,
+            vec![],
+        )
         .await;
 
     let target_worker_name = Uuid::new_v4().to_string();
@@ -305,8 +296,8 @@ async fn fork_running_worker_2(deps: &Deps, _tracing: &Tracing) {
 #[test]
 #[tracing::instrument]
 #[timeout(120000)]
-async fn fork_idle_worker(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn fork_idle_worker(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
+    let admin = deps.admin().await;
     let component_id = admin.component("shopping-cart").store().await;
 
     let source_worker_name = Uuid::new_v4().to_string();
@@ -328,12 +319,12 @@ async fn fork_idle_worker(deps: &Deps, _tracing: &Tracing) {
         .invoke_and_await(
             &source_worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1001".into_value_and_type()),
                 ("name", "Golem Cloud Subscription 1y".into_value_and_type()),
                 ("price", 999999.0f32.into_value_and_type()),
                 ("quantity", 1u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -342,12 +333,12 @@ async fn fork_idle_worker(deps: &Deps, _tracing: &Tracing) {
         .invoke_and_await(
             &source_worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1002".into_value_and_type()),
                 ("name", "Mud Golem".into_value_and_type()),
                 ("price", 11.0f32.into_value_and_type()),
                 ("quantity", 10u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -385,12 +376,12 @@ async fn fork_idle_worker(deps: &Deps, _tracing: &Tracing) {
         .invoke_and_await(
             &target_worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1002".into_value_and_type()),
                 ("name", "Mud Golem".into_value_and_type()),
                 ("price", 11.0f32.into_value_and_type()),
                 ("quantity", 10u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -417,8 +408,11 @@ async fn fork_idle_worker(deps: &Deps, _tracing: &Tracing) {
 #[test]
 #[tracing::instrument]
 #[timeout(120000)]
-async fn fork_worker_when_target_already_exists(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn fork_worker_when_target_already_exists(
+    deps: &EnvBasedTestDependencies,
+    _tracing: &Tracing,
+) {
+    let admin = deps.admin().await;
     let component_id = admin.component("shopping-cart").store().await;
 
     let source_worker_name = Uuid::new_v4().to_string();
@@ -461,8 +455,11 @@ async fn fork_worker_when_target_already_exists(deps: &Deps, _tracing: &Tracing)
 #[test]
 #[tracing::instrument]
 #[timeout(120000)]
-async fn fork_worker_with_invalid_oplog_index_cut_off(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn fork_worker_with_invalid_oplog_index_cut_off(
+    deps: &EnvBasedTestDependencies,
+    _tracing: &Tracing,
+) {
+    let admin = deps.admin().await;
     let component_id = admin.component("shopping-cart").store().await;
 
     let source_worker_name = Uuid::new_v4().to_string();
@@ -503,8 +500,8 @@ async fn fork_worker_with_invalid_oplog_index_cut_off(deps: &Deps, _tracing: &Tr
 #[test]
 #[tracing::instrument]
 #[timeout(120000)]
-async fn fork_invalid_worker(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn fork_invalid_worker(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
+    let admin = deps.admin().await;
     let component_id = admin.component("shopping-cart").store().await;
 
     let source_worker_name = Uuid::new_v4().to_string();
@@ -538,8 +535,11 @@ async fn fork_invalid_worker(deps: &Deps, _tracing: &Tracing) {
 #[test]
 #[tracing::instrument]
 #[timeout(120000)]
-async fn fork_worker_ensures_zero_divergence_until_cut_off(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn fork_worker_ensures_zero_divergence_until_cut_off(
+    deps: &EnvBasedTestDependencies,
+    _tracing: &Tracing,
+) {
+    let admin = deps.admin().await;
     let component_id = admin.component("environment-service").store().await;
 
     let source_worker_name = Uuid::new_v4().to_string();
@@ -635,8 +635,8 @@ fn run_http_server(
 #[test]
 #[tracing::instrument]
 #[timeout(120000)]
-async fn fork_self(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn fork_self(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
+    let admin = deps.admin().await;
     let component_id = admin.component("golem-rust-tests").store().await;
 
     let (port_tx, port_rx) = tokio::sync::oneshot::channel::<u16>();
@@ -670,12 +670,11 @@ async fn fork_self(deps: &Deps, _tracing: &Tracing) {
     let port = port_rx.await.unwrap();
     let mut env = HashMap::new();
     env.insert("PORT".to_string(), port.to_string());
-    env.insert("HOST".to_string(), resolve_host_address(port).await);
 
     info!("Using environment: {:?}", env);
 
     let worker_id = admin
-        .start_worker_with(&component_id, "source-worker", vec![], env)
+        .start_worker_with(&component_id, "source-worker", vec![], env, vec![])
         .await;
 
     let _ = admin.log_output(&worker_id).await;
diff --git a/integration-tests/tests/lib.rs b/integration-tests/tests/lib.rs
index 5488f276..a2b1ae53 100644
--- a/integration-tests/tests/lib.rs
+++ b/integration-tests/tests/lib.rs
@@ -12,12 +12,10 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use golem_common::model::AccountId;
 use golem_common::tracing::{init_tracing_with_default_debug_env_filter, TracingConfig};
 use golem_test_framework::config::{
-    EnvBasedTestDependencies, EnvBasedTestDependenciesConfig, TestDependencies, TestDependenciesDsl,
+    EnvBasedTestDependencies, EnvBasedTestDependenciesConfig, TestDependencies,
 };
-use std::ops::Deref;
 use test_r::test_dep;
 
 test_r::enable!();
@@ -31,23 +29,6 @@ mod worker;
 #[derive(Debug)]
 pub struct Tracing;
 
-#[derive(Clone)]
-pub struct Deps(pub TestDependenciesDsl<EnvBasedTestDependencies>);
-
-impl std::fmt::Debug for Deps {
-    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
-        f.debug_struct("Deps").finish_non_exhaustive()
-    }
-}
-
-impl Deref for Deps {
-    type Target = EnvBasedTestDependencies;
-
-    fn deref(&self) -> &Self::Target {
-        &self.0.deps
-    }
-}
-
 impl Tracing {
     pub fn init() -> Self {
         init_tracing_with_default_debug_env_filter(
@@ -58,7 +39,7 @@ impl Tracing {
 }
 
 #[test_dep]
-pub async fn create_deps(_tracing: &Tracing) -> Deps {
+pub async fn create_deps(_tracing: &Tracing) -> EnvBasedTestDependencies {
     let deps = EnvBasedTestDependencies::new(EnvBasedTestDependenciesConfig {
         worker_executor_cluster_size: 3,
         ..EnvBasedTestDependenciesConfig::new()
@@ -67,16 +48,7 @@ pub async fn create_deps(_tracing: &Tracing) -> Deps {
 
     deps.redis_monitor().assert_valid();
 
-    let deps2 = TestDependenciesDsl {
-        deps,
-        account_id: AccountId {
-            value: "".to_string(),
-        },
-        account_email: "".to_string(),
-        token: Default::default(),
-    };
-
-    Deps(deps2)
+    deps
 }
 
 #[test_dep]
diff --git a/integration-tests/tests/rib.rs b/integration-tests/tests/rib.rs
index 7b13a046..5826f0ff 100644
--- a/integration-tests/tests/rib.rs
+++ b/integration-tests/tests/rib.rs
@@ -14,11 +14,11 @@
 
 use test_r::test;
 
-use crate::{Deps, Tracing};
+use crate::Tracing;
 use anyhow::anyhow;
 use async_trait::async_trait;
-use golem_common::model::{ComponentId, TargetWorkerId};
-use golem_test_framework::config::TestDependencies;
+use golem_common::model::{ComponentId, WorkerId};
+use golem_test_framework::config::{EnvBasedTestDependencies, TestDependencies};
 use golem_test_framework::dsl::TestDslUnsafe;
 use golem_wasm_ast::analysis::analysed_type::{f32, field, list, record, str, u32};
 use golem_wasm_ast::analysis::AnalysedType;
@@ -32,46 +32,46 @@ use std::sync::Arc;
 use test_r::inherit_test_dep;
 
 inherit_test_dep!(Tracing);
-inherit_test_dep!(Deps);
+inherit_test_dep!(EnvBasedTestDependencies);
 
 #[test]
 #[tracing::instrument]
-async fn test_rib_simple_without_worker_name(deps: &Deps) {
+async fn test_rib_simple_without_worker_name(deps: &EnvBasedTestDependencies) {
     test_simple_rib(deps, None).await;
 }
 
 #[test]
 #[tracing::instrument]
-async fn test_rib_simple_with_worker_name(deps: &Deps) {
+async fn test_rib_simple_with_worker_name(deps: &EnvBasedTestDependencies) {
     test_simple_rib(deps, Some("rib-simple-worker")).await;
 }
 
 #[test]
 #[tracing::instrument]
-async fn test_rib_complex_without_worker_name(deps: &Deps) {
+async fn test_rib_complex_without_worker_name(deps: &EnvBasedTestDependencies) {
     test_rib_for_loop(deps, None).await;
 }
 
 #[test]
 #[tracing::instrument]
-async fn test_rib_complex_with_worker_name(deps: &Deps) {
+async fn test_rib_complex_with_worker_name(deps: &EnvBasedTestDependencies) {
     test_rib_for_loop(deps, Some("rib-complex-worker")).await;
 }
 
 #[test]
 #[tracing::instrument]
-async fn test_rib_with_resource_methods_without_worker_param(deps: &Deps) {
+async fn test_rib_with_resource_methods_without_worker_param(deps: &EnvBasedTestDependencies) {
     test_rib_with_resource_methods(deps, None).await;
 }
 
 #[test]
 #[tracing::instrument]
-async fn test_rib_with_resource_methods_with_worker_param(deps: &Deps) {
+async fn test_rib_with_resource_methods_with_worker_param(deps: &EnvBasedTestDependencies) {
     test_rib_with_resource_methods(deps, Some("rib-with-resource-worker")).await;
 }
 
-async fn test_simple_rib(deps: &Deps, worker_name: Option<&str>) {
-    let admin = deps.admin();
+async fn test_simple_rib(deps: &EnvBasedTestDependencies, worker_name: Option<&str>) {
+    let admin = deps.admin().await;
     let component_id = admin.component("shopping-cart").store().await;
 
     let metadata = admin.get_latest_component_metadata(&component_id).await;
@@ -79,11 +79,12 @@ async fn test_simple_rib(deps: &Deps, worker_name: Option<&str>) {
     let component_dependency_key = ComponentDependencyKey {
         component_name: "shopping-cart".to_string(),
         component_id: component_id.0,
-        root_package_name: metadata.root_package_name,
-        root_package_version: metadata.root_package_version,
+        root_package_name: metadata.root_package_name().clone(),
+        root_package_version: metadata.root_package_version().clone(),
     };
 
-    let component_dependency = ComponentDependency::new(component_dependency_key, metadata.exports);
+    let component_dependency =
+        ComponentDependency::new(component_dependency_key, metadata.exports().to_vec());
 
     let compiler_config = RibCompilerConfig::new(vec![component_dependency], vec![]);
 
@@ -142,19 +143,23 @@ async fn test_simple_rib(deps: &Deps, worker_name: Option<&str>) {
                 Value::String("item1".to_string()),
                 Value::F32(10.0),
                 Value::U32(2),
-            ]),]),
-            list(record(vec![
-                field("product-id", str()),
-                field("name", str()),
-                field("price", f32()),
-                field("quantity", u32()),
-            ],),),
+            ])]),
+            list(
+                record(vec![
+                    field("product-id", str()),
+                    field("name", str()),
+                    field("price", f32()),
+                    field("quantity", u32()),
+                ])
+                .named("product-item")
+                .owned("golem:it/api")
+            ),
         ))
     );
 }
 
-async fn test_rib_for_loop(deps: &Deps, worker_name: Option<&str>) {
-    let admin = deps.admin();
+async fn test_rib_for_loop(deps: &EnvBasedTestDependencies, worker_name: Option<&str>) {
+    let admin = deps.admin().await;
     let component_id = admin.component("shopping-cart").store().await;
 
     let metadata = admin.get_latest_component_metadata(&component_id).await;
@@ -162,11 +167,12 @@ async fn test_rib_for_loop(deps: &Deps, worker_name: Option<&str>) {
     let component_dependency_key = ComponentDependencyKey {
         component_name: "shopping-cart".to_string(),
         component_id: component_id.0,
-        root_package_name: metadata.root_package_name,
-        root_package_version: metadata.root_package_version,
+        root_package_name: metadata.root_package_name().clone(),
+        root_package_version: metadata.root_package_version().clone(),
     };
 
-    let component_dependency = ComponentDependency::new(component_dependency_key, metadata.exports);
+    let component_dependency =
+        ComponentDependency::new(component_dependency_key, metadata.exports().to_vec());
 
     let compiler_config = RibCompilerConfig::new(vec![component_dependency], vec![]);
 
@@ -242,18 +248,25 @@ async fn test_rib_for_loop(deps: &Deps, worker_name: Option<&str>) {
                     Value::U32(2),
                 ]),
             ]),
-            list(record(vec![
-                field("product-id", str()),
-                field("name", str()),
-                field("price", f32()),
-                field("quantity", u32()),
-            ],),),
+            list(
+                record(vec![
+                    field("product-id", str()),
+                    field("name", str()),
+                    field("price", f32()),
+                    field("quantity", u32()),
+                ])
+                .named("product-item")
+                .owned("golem:it/api")
+            ),
         ))
     );
 }
 
-async fn test_rib_with_resource_methods(deps: &Deps, worker_name: Option<&str>) {
-    let admin = deps.admin();
+async fn test_rib_with_resource_methods(
+    deps: &EnvBasedTestDependencies,
+    worker_name: Option<&str>,
+) {
+    let admin = deps.admin().await;
     let component_id = admin.component("shopping-cart-resource").store().await;
 
     let metadata = admin.get_latest_component_metadata(&component_id).await;
@@ -261,11 +274,12 @@ async fn test_rib_with_resource_methods(deps: &Deps, worker_name: Option<&str>)
     let component_dependency_key = ComponentDependencyKey {
         component_name: "shopping-cart".to_string(),
         component_id: component_id.0,
-        root_package_name: metadata.root_package_name,
-        root_package_version: metadata.root_package_version,
+        root_package_name: metadata.root_package_name().clone(),
+        root_package_version: metadata.root_package_version().clone(),
     };
 
-    let component_dependency = ComponentDependency::new(component_dependency_key, metadata.exports);
+    let component_dependency =
+        ComponentDependency::new(component_dependency_key, metadata.exports().to_vec());
 
     let compiler_config = RibCompilerConfig::new(vec![component_dependency], vec![]);
 
@@ -341,22 +355,26 @@ async fn test_rib_with_resource_methods(deps: &Deps, worker_name: Option<&str>)
                     Value::U32(2),
                 ])
             ]),
-            list(record(vec![
-                field("product-id", str()),
-                field("name", str()),
-                field("price", f32()),
-                field("quantity", u32()),
-            ],),),
+            list(
+                record(vec![
+                    field("product-id", str()),
+                    field("name", str()),
+                    field("price", f32()),
+                    field("quantity", u32()),
+                ])
+                .named("product-item")
+                .owned("golem:it/api")
+            ),
         ))
     );
 }
 
 struct TestRibFunctionInvoke {
-    dependencies: Deps,
+    dependencies: EnvBasedTestDependencies,
 }
 
 impl TestRibFunctionInvoke {
-    fn new(dependencies: Deps) -> Self {
+    fn new(dependencies: EnvBasedTestDependencies) -> Self {
         Self { dependencies }
     }
 }
@@ -367,25 +385,21 @@ impl RibComponentFunctionInvoke for TestRibFunctionInvoke {
         &self,
         component_dependency_key: ComponentDependencyKey,
         _instruction_id: &InstructionId,
-        worker_name: Option<EvaluatedWorkerName>,
+        worker_name: EvaluatedWorkerName,
         function_name: EvaluatedFqFn,
         args: EvaluatedFnArgs,
         _return_type: Option<AnalysedType>,
     ) -> RibFunctionInvokeResult {
-        let target_worker_id = worker_name
-            .map(|w| TargetWorkerId {
-                component_id: ComponentId(component_dependency_key.component_id),
-                worker_name: Some(w.0),
-            })
-            .unwrap_or_else(|| TargetWorkerId {
-                component_id: ComponentId(component_dependency_key.component_id),
-                worker_name: None,
-            });
+        let worker_id = WorkerId {
+            component_id: ComponentId(component_dependency_key.component_id),
+            worker_name: worker_name.0,
+        };
 
         let result = self
             .dependencies
             .admin()
-            .invoke_and_await_typed(target_worker_id, function_name.0.as_str(), args.0)
+            .await
+            .invoke_and_await_typed(&worker_id, function_name.0.as_str(), args.0)
             .await;
 
         Ok(result.map_err(|err| {
diff --git a/integration-tests/tests/rib_repl.rs b/integration-tests/tests/rib_repl.rs
index 86e6c839..8a2f3e64 100644
--- a/integration-tests/tests/rib_repl.rs
+++ b/integration-tests/tests/rib_repl.rs
@@ -14,14 +14,14 @@
 
 use test_r::test;
 
-use crate::{Deps, Tracing};
+use crate::Tracing;
 use anyhow::anyhow;
 use async_trait::async_trait;
-use golem_common::model::{ComponentId, TargetWorkerId};
+use golem_common::model::{ComponentId, WorkerId};
 use golem_rib_repl::{ComponentSource, RibRepl};
 use golem_rib_repl::{ReplComponentDependencies, RibDependencyManager};
 use golem_rib_repl::{RibReplConfig, WorkerFunctionInvoke};
-use golem_test_framework::config::TestDependencies;
+use golem_test_framework::config::{EnvBasedTestDependencies, TestDependencies};
 use golem_test_framework::dsl::TestDslUnsafe;
 use golem_wasm_ast::analysis::analysed_type::{f32, field, list, record, str, u32};
 use golem_wasm_ast::analysis::AnalysedType;
@@ -33,33 +33,33 @@ use test_r::inherit_test_dep;
 use uuid::Uuid;
 
 inherit_test_dep!(Tracing);
-inherit_test_dep!(Deps);
+inherit_test_dep!(EnvBasedTestDependencies);
 
 #[test]
 #[tracing::instrument]
-async fn test_rib_repl(deps: &Deps) {
+async fn test_rib_repl(deps: &EnvBasedTestDependencies) {
     test_repl_invoking_functions(deps, Some("worker-repl-simple-test")).await;
 }
 
 #[test]
 #[tracing::instrument]
-async fn test_rib_repl_without_worker_param(deps: &Deps) {
+async fn test_rib_repl_without_worker_param(deps: &EnvBasedTestDependencies) {
     test_repl_invoking_functions(deps, None).await;
 }
 
 #[test]
 #[tracing::instrument]
-async fn test_rib_repl_with_resource(deps: &Deps) {
+async fn test_rib_repl_with_resource(deps: &EnvBasedTestDependencies) {
     test_repl_invoking_resource_methods(deps, Some("worker-repl-resource-test")).await;
 }
 
 #[test]
 #[tracing::instrument]
-async fn test_rib_repl_with_resource_without_param(deps: &Deps) {
+async fn test_rib_repl_with_resource_without_param(deps: &EnvBasedTestDependencies) {
     test_repl_invoking_resource_methods(deps, None).await;
 }
 
-async fn test_repl_invoking_functions(deps: &Deps, worker_name: Option<&str>) {
+async fn test_repl_invoking_functions(deps: &EnvBasedTestDependencies, worker_name: Option<&str>) {
     let mut rib_repl = RibRepl::bootstrap(RibReplConfig {
         history_file: None,
         dependency_manager: Arc::new(TestRibReplDependencyManager::new(deps.clone())),
@@ -122,12 +122,16 @@ async fn test_repl_invoking_functions(deps: &Deps, worker_name: Option<&str>) {
         result,
         Some(RibResult::Val(ValueAndType::new(
             Value::List(vec![]),
-            list(record(vec![
-                field("product-id", str()),
-                field("name", str()),
-                field("price", f32()),
-                field("quantity", u32()),
-            ],),),
+            list(
+                record(vec![
+                    field("product-id", str()),
+                    field("name", str()),
+                    field("price", f32()),
+                    field("quantity", u32()),
+                ])
+                .named("product-item")
+                .owned("golem:it/api")
+            ),
         )))
     );
 
@@ -154,17 +158,24 @@ async fn test_repl_invoking_functions(deps: &Deps, worker_name: Option<&str>) {
                 Value::F32(10.0),
                 Value::U32(2),
             ])]),
-            list(record(vec![
-                field("product-id", str()),
-                field("name", str()),
-                field("price", f32()),
-                field("quantity", u32()),
-            ],)),
+            list(
+                record(vec![
+                    field("product-id", str()),
+                    field("name", str()),
+                    field("price", f32()),
+                    field("quantity", u32()),
+                ])
+                .named("product-item")
+                .owned("golem:it/api")
+            ),
         )))
     );
 }
 
-async fn test_repl_invoking_resource_methods(deps: &Deps, worker_name: Option<&str>) {
+async fn test_repl_invoking_resource_methods(
+    deps: &EnvBasedTestDependencies,
+    worker_name: Option<&str>,
+) {
     let mut rib_repl = RibRepl::bootstrap(RibReplConfig {
         history_file: None,
         dependency_manager: Arc::new(TestRibReplDependencyManager::new(deps.clone())),
@@ -232,12 +243,16 @@ async fn test_repl_invoking_resource_methods(deps: &Deps, worker_name: Option<&s
         result,
         Some(RibResult::Val(ValueAndType::new(
             Value::List(vec![]),
-            list(record(vec![
-                field("product-id", str()),
-                field("name", str()),
-                field("price", f32()),
-                field("quantity", u32()),
-            ],),),
+            list(
+                record(vec![
+                    field("product-id", str()),
+                    field("name", str()),
+                    field("price", f32()),
+                    field("quantity", u32()),
+                ])
+                .named("product-item")
+                .owned("golem:it/api")
+            ),
         )))
     );
 
@@ -264,22 +279,26 @@ async fn test_repl_invoking_resource_methods(deps: &Deps, worker_name: Option<&s
                 Value::F32(10.0),
                 Value::U32(2),
             ])]),
-            list(record(vec![
-                field("product-id", str()),
-                field("name", str()),
-                field("price", f32()),
-                field("quantity", u32()),
-            ],)),
+            list(
+                record(vec![
+                    field("product-id", str()),
+                    field("name", str()),
+                    field("price", f32()),
+                    field("quantity", u32()),
+                ])
+                .named("product-item")
+                .owned("golem:it/api")
+            ),
         )))
     )
 }
 
 struct TestRibReplDependencyManager {
-    dependencies: Deps,
+    dependencies: EnvBasedTestDependencies,
 }
 
 impl TestRibReplDependencyManager {
-    fn new(dependencies: Deps) -> Self {
+    fn new(dependencies: EnvBasedTestDependencies) -> Self {
         Self { dependencies }
     }
 }
@@ -300,6 +319,7 @@ impl RibDependencyManager for TestRibReplDependencyManager {
         let component_id = self
             .dependencies
             .admin()
+            .await
             .component(component_name.as_str())
             .store()
             .await;
@@ -307,30 +327,31 @@ impl RibDependencyManager for TestRibReplDependencyManager {
         let metadata = self
             .dependencies
             .admin()
+            .await
             .get_latest_component_metadata(&component_id)
             .await;
 
         let component_dependency_key = ComponentDependencyKey {
             component_name,
             component_id: component_id.0,
-            root_package_name: metadata.root_package_name,
-            root_package_version: metadata.root_package_version,
+            root_package_name: metadata.root_package_name().clone(),
+            root_package_version: metadata.root_package_version().clone(),
         };
 
         Ok(ComponentDependency::new(
             component_dependency_key,
-            metadata.exports,
+            metadata.exports().to_vec(),
         ))
     }
 }
 
 // Embedded RibFunctionInvoke implementation
 pub struct TestRibReplWorkerFunctionInvoke {
-    embedded_worker_executor: Deps,
+    embedded_worker_executor: EnvBasedTestDependencies,
 }
 
 impl TestRibReplWorkerFunctionInvoke {
-    pub fn new(embedded_worker_executor: Deps) -> Self {
+    pub fn new(embedded_worker_executor: EnvBasedTestDependencies) -> Self {
         Self {
             embedded_worker_executor,
         }
@@ -343,25 +364,21 @@ impl WorkerFunctionInvoke for TestRibReplWorkerFunctionInvoke {
         &self,
         component_id: Uuid,
         _component_name: &str,
-        worker_name: Option<String>,
+        worker_name: &str,
         function_name: &str,
         args: Vec<ValueAndType>,
         _return_type: Option<AnalysedType>,
     ) -> anyhow::Result<Option<ValueAndType>> {
-        let target_worker_id = worker_name
-            .map(|w| TargetWorkerId {
-                component_id: ComponentId(component_id),
-                worker_name: Some(w),
-            })
-            .unwrap_or_else(|| TargetWorkerId {
-                component_id: ComponentId(component_id),
-                worker_name: None,
-            });
+        let worker_id = WorkerId {
+            component_id: ComponentId(component_id),
+            worker_name: worker_name.to_string(),
+        };
 
         let result = self
             .embedded_worker_executor
             .admin()
-            .invoke_and_await_typed(target_worker_id, function_name, args)
+            .await
+            .invoke_and_await_typed(&worker_id, function_name, args)
             .await;
 
         Ok(result.map_err(|err| {
diff --git a/integration-tests/tests/sharding.rs b/integration-tests/tests/sharding.rs
index 74acc491..6aa1f84d 100644
--- a/integration-tests/tests/sharding.rs
+++ b/integration-tests/tests/sharding.rs
@@ -389,7 +389,7 @@ mod tests {
         }
 
         async fn create_component_and_start_workers(&self, n: usize) -> Vec<WorkerId> {
-            let admin = self.admin();
+            let admin = self.admin().await;
             info!("Storing component");
             let component_id = admin.component("option-service").store().await;
             info!("ComponentId: {}", component_id);
@@ -415,7 +415,7 @@ mod tests {
         ) -> Result<(), worker::v1::worker_error::Error> {
             let mut tasks = JoinSet::new();
             for worker_id in workers {
-                let self_clone = self.clone().into_admin();
+                let self_clone = self.clone().into_admin().await;
                 tasks.spawn({
                     let worker_id = worker_id.clone();
                     async move {
diff --git a/integration-tests/tests/worker.rs b/integration-tests/tests/worker.rs
index 3468bf8c..f24836b9 100644
--- a/integration-tests/tests/worker.rs
+++ b/integration-tests/tests/worker.rs
@@ -17,25 +17,28 @@ use test_r::{flaky, inherit_test_dep, test, timeout};
 use assert2::check;
 
 use golem_test_framework::dsl::TestDslUnsafe;
-use golem_wasm_rpc::{IntoValueAndType, Value, ValueAndType};
+use golem_wasm_rpc::{IntoValueAndType, Record, Value, ValueAndType};
 use std::collections::{HashMap, HashSet};
 use std::net::SocketAddr;
 use std::sync::{Arc, Mutex};
 use tracing::Instrument;
 
-use crate::{Deps, Tracing};
+use crate::Tracing;
 use axum::extract::Query;
 use axum::routing::get;
 use axum::Router;
-use golem_common::model::oplog::{OplogIndex, WorkerResourceId};
+use golem_client::model::AnalysedType;
+use golem_common::model::oplog::OplogIndex;
 use golem_common::model::public_oplog::{ExportedFunctionInvokedParameters, PublicOplogEntry};
 use golem_common::model::{
     ComponentFilePermissions, ComponentFileSystemNode, ComponentFileSystemNodeDetails, ComponentId,
-    FilterComparator, IdempotencyKey, ScanCursor, StringFilterComparator, TargetWorkerId,
-    Timestamp, WorkerFilter, WorkerId, WorkerMetadata, WorkerResourceDescription, WorkerStatus,
+    FilterComparator, IdempotencyKey, ScanCursor, StringFilterComparator, Timestamp, WorkerFilter,
+    WorkerId, WorkerMetadata, WorkerResourceDescription, WorkerStatus,
+};
+use golem_test_framework::config::{EnvBasedTestDependencies, TestDependencies};
+use golem_wasm_ast::analysis::{
+    analysed_type, AnalysedResourceId, AnalysedResourceMode, TypeHandle,
 };
-use golem_test_framework::config::TestDependencies;
-use golem_wasm_ast::analysis::analysed_type;
 use rand::seq::IteratorRandom;
 use serde_json::json;
 use std::time::{Duration, SystemTime};
@@ -43,13 +46,13 @@ use tokio::time::sleep;
 use tracing::log::info;
 
 inherit_test_dep!(Tracing);
-inherit_test_dep!(Deps);
+inherit_test_dep!(EnvBasedTestDependencies);
 
 #[test]
 #[tracing::instrument]
 #[timeout(120000)]
-async fn dynamic_worker_creation(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn dynamic_worker_creation(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
+    let admin = deps.admin().await;
     let component_id = admin.component("environment-service").store().await;
     let worker_id = WorkerId {
         component_id: component_id.clone(),
@@ -84,140 +87,11 @@ async fn dynamic_worker_creation(deps: &Deps, _tracing: &Tracing) {
     );
 }
 
-fn get_env_result(env: Vec<Value>) -> HashMap<String, String> {
-    match env.into_iter().next() {
-        Some(Value::Result(Ok(Some(inner)))) => match *inner {
-            Value::List(items) => {
-                let pairs = items
-                    .into_iter()
-                    .filter_map(|item| match item {
-                        Value::Tuple(values) if values.len() == 2 => {
-                            let mut iter = values.into_iter();
-                            let key = iter.next();
-                            let value = iter.next();
-                            match (key, value) {
-                                (Some(Value::String(key)), Some(Value::String(value))) => {
-                                    Some((key, value))
-                                }
-                                _ => None,
-                            }
-                        }
-                        _ => None,
-                    })
-                    .collect::<Vec<(String, String)>>();
-                HashMap::from_iter(pairs)
-            }
-            _ => panic!("Unexpected result value"),
-        },
-        _ => panic!("Unexpected result value"),
-    }
-}
-
-#[test]
-#[tracing::instrument]
-#[timeout(120000)]
-async fn dynamic_worker_creation_without_name(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
-    let component_id = admin.component("environment-service").store().await;
-    let worker_id = TargetWorkerId {
-        component_id: component_id.clone(),
-        worker_name: None,
-    };
-
-    let env1 = admin
-        .invoke_and_await(worker_id.clone(), "golem:it/api.{get-environment}", vec![])
-        .await
-        .unwrap();
-    let env2 = admin
-        .invoke_and_await(worker_id.clone(), "golem:it/api.{get-environment}", vec![])
-        .await
-        .unwrap();
-
-    let env1 = get_env_result(env1);
-    let env2 = get_env_result(env2);
-
-    check!(env1.contains_key("GOLEM_WORKER_NAME"));
-    check!(env1.get("GOLEM_COMPONENT_ID") == Some(&component_id.to_string()));
-    check!(env1.get("GOLEM_COMPONENT_VERSION") == Some(&"0".to_string()));
-    check!(env2.contains_key("GOLEM_WORKER_NAME"));
-    check!(env2.get("GOLEM_COMPONENT_ID") == Some(&component_id.to_string()));
-    check!(env2.get("GOLEM_COMPONENT_VERSION") == Some(&"0".to_string()));
-    check!(env1.get("GOLEM_WORKER_NAME") != env2.get("GOLEM_WORKER_NAME"));
-}
-
-#[test]
-#[tracing::instrument]
-#[timeout(120000)]
-async fn ephemeral_worker_creation_without_name(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
-    let component_id = admin
-        .component("environment-service")
-        .ephemeral()
-        .store()
-        .await;
-    let worker_id = TargetWorkerId {
-        component_id: component_id.clone(),
-        worker_name: None,
-    };
-
-    let env1 = admin
-        .invoke_and_await(worker_id.clone(), "golem:it/api.{get-environment}", vec![])
-        .await
-        .unwrap();
-    let env2 = admin
-        .invoke_and_await(worker_id.clone(), "golem:it/api.{get-environment}", vec![])
-        .await
-        .unwrap();
-
-    let env1 = get_env_result(env1);
-    let env2 = get_env_result(env2);
-
-    check!(env1.contains_key("GOLEM_WORKER_NAME"));
-    check!(env1.get("GOLEM_COMPONENT_ID") == Some(&component_id.to_string()));
-    check!(env1.get("GOLEM_COMPONENT_VERSION") == Some(&"0".to_string()));
-    check!(env2.contains_key("GOLEM_WORKER_NAME"));
-    check!(env2.get("GOLEM_COMPONENT_ID") == Some(&component_id.to_string()));
-    check!(env2.get("GOLEM_COMPONENT_VERSION") == Some(&"0".to_string()));
-    check!(env1.get("GOLEM_WORKER_NAME") != env2.get("GOLEM_WORKER_NAME"));
-}
-
-#[test]
-#[tracing::instrument]
-#[timeout(120000)]
-async fn ephemeral_worker_creation_with_name_is_not_persistent(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
-    let component_id = admin.component("counters").ephemeral().store().await;
-    let worker_id = TargetWorkerId {
-        component_id: component_id.clone(),
-        worker_name: Some("test".to_string()),
-    };
-
-    let _ = admin
-        .invoke_and_await(
-            worker_id.clone(),
-            "rpc:counters-exports/api.{inc-global-by}",
-            vec![2u64.into_value_and_type()],
-        )
-        .await
-        .unwrap();
-
-    let result = admin
-        .invoke_and_await(
-            worker_id.clone(),
-            "rpc:counters-exports/api.{get-global-value}",
-            vec![],
-        )
-        .await
-        .unwrap();
-
-    check!(result == vec![Value::U64(0)]);
-}
-
 #[test]
 #[tracing::instrument]
 #[timeout(120000)]
-async fn counter_resource_test_1(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn counter_resource_test_1(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
+    let admin = deps.admin().await;
     let component_id = admin.component("counters").unique().store().await;
     let worker_id = admin.start_worker(&component_id, "counters-1").await;
     admin.log_output(&worker_id).await;
@@ -296,7 +170,7 @@ async fn counter_resource_test_1(deps: &Deps, _tracing: &Tracing) {
         .iter()
         .map(|(k, v)| {
             (
-                *k,
+                k.to_string(),
                 WorkerResourceDescription {
                     created_at: ts,
                     ..v.clone()
@@ -304,14 +178,15 @@ async fn counter_resource_test_1(deps: &Deps, _tracing: &Tracing) {
             )
         })
         .collect::<Vec<_>>();
-    resources1.sort_by_key(|(k, _v)| *k);
+    resources1.sort_by_key(|(k, _v)| k.clone());
     check!(
         resources1
             == vec![(
-                WorkerResourceId(0),
+                "0".to_string(),
                 WorkerResourceDescription {
                     created_at: ts,
-                    indexed_resource_key: None
+                    resource_owner: "rpc:counters-exports/api".to_string(),
+                    resource_name: "counter".to_string(),
                 }
             ),]
     );
@@ -322,7 +197,7 @@ async fn counter_resource_test_1(deps: &Deps, _tracing: &Tracing) {
         .iter()
         .map(|(k, v)| {
             (
-                *k,
+                k.to_string(),
                 WorkerResourceDescription {
                     created_at: ts,
                     ..v.clone()
@@ -336,8 +211,8 @@ async fn counter_resource_test_1(deps: &Deps, _tracing: &Tracing) {
 #[test]
 #[tracing::instrument]
 #[timeout(120000)]
-async fn counter_resource_test_1_json(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn counter_resource_test_1_json(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
+    let admin = deps.admin().await;
     let component_id = admin.component("counters").unique().store().await;
     let worker_id = admin.start_worker(&component_id, "counters-1j").await;
     admin.log_output(&worker_id).await;
@@ -453,7 +328,7 @@ async fn counter_resource_test_1_json(deps: &Deps, _tracing: &Tracing) {
         .iter()
         .map(|(k, v)| {
             (
-                *k,
+                k.to_string(),
                 WorkerResourceDescription {
                     created_at: ts,
                     ..v.clone()
@@ -461,14 +336,15 @@ async fn counter_resource_test_1_json(deps: &Deps, _tracing: &Tracing) {
             )
         })
         .collect::<Vec<_>>();
-    resources1.sort_by_key(|(k, _v)| *k);
+    resources1.sort_by_key(|(k, _v)| k.clone());
     check!(
         resources1
             == vec![(
-                WorkerResourceId(0),
+                "0".to_string(),
                 WorkerResourceDescription {
                     created_at: ts,
-                    indexed_resource_key: None
+                    resource_owner: "rpc:counters-exports/api".to_string(),
+                    resource_name: "counter".to_string(),
                 }
             ),]
     );
@@ -479,7 +355,7 @@ async fn counter_resource_test_1_json(deps: &Deps, _tracing: &Tracing) {
         .iter()
         .map(|(k, v)| {
             (
-                *k,
+                k.to_string(),
                 WorkerResourceDescription {
                     created_at: ts,
                     ..v.clone()
@@ -493,283 +369,118 @@ async fn counter_resource_test_1_json(deps: &Deps, _tracing: &Tracing) {
 #[test]
 #[tracing::instrument]
 #[timeout(120000)]
-async fn counter_resource_test_2(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
-    let component_id = admin.component("counters").unique().store().await;
-    let worker_id = admin.start_worker(&component_id, "counters-2").await;
-    admin.log_output(&worker_id).await;
-
-    let _ = admin
-        .invoke_and_await(
-            &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter1\").inc-by}",
-            vec![5u64.into_value_and_type()],
-        )
-        .await;
-
-    let _ = admin
-        .invoke_and_await(
-            &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter2\").inc-by}",
-            vec![1u64.into_value_and_type()],
-        )
-        .await;
-    let _ = admin
-        .invoke_and_await(
-            &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter2\").inc-by}",
-            vec![2u64.into_value_and_type()],
-        )
-        .await;
-
-    let result1 = admin
-        .invoke_and_await(
-            &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter1\").get-value}",
-            vec![],
-        )
-        .await;
-    let result2 = admin
-        .invoke_and_await(
-            &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter2\").get-value}",
-            vec![],
-        )
-        .await;
-
-    let _ = admin
-        .invoke_and_await(
-            &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter1\").drop}",
-            vec![],
-        )
-        .await;
-    let _ = admin
-        .invoke_and_await(
-            &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter2\").drop}",
-            vec![],
-        )
-        .await;
-
-    let result3 = admin
-        .invoke_and_await(
-            &worker_id,
-            "rpc:counters-exports/api.{get-all-dropped}",
-            vec![],
-        )
-        .await;
-
-    check!(result1 == Ok(vec![Value::U64(5)]));
-    check!(result2 == Ok(vec![Value::U64(3)]));
-    check!(
-        result3
-            == Ok(vec![Value::List(vec![
-                Value::Tuple(vec![Value::String("counter1".to_string()), Value::U64(5)]),
-                Value::Tuple(vec![Value::String("counter2".to_string()), Value::U64(3)])
-            ])])
-    );
-}
-
-#[test]
-#[tracing::instrument]
-#[timeout(120000)]
-async fn counter_resource_test_2_json(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn counter_resource_test_2_json_no_types(
+    deps: &EnvBasedTestDependencies,
+    _tracing: &Tracing,
+) {
+    let admin = deps.admin().await;
     let component_id = admin.component("counters").unique().store().await;
     let worker_id = admin.start_worker(&component_id, "counters-2j").await;
     admin.log_output(&worker_id).await;
 
-    let _ = admin
-        .invoke_and_await_json(
-            &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter1\").inc-by}",
-            vec![json!(
-                {
-                    "typ": { "type": "U64" }, "value": 5
-                }
-            )],
-        )
-        .await;
-
-    let _ = admin
-        .invoke_and_await_json(
-            &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter2\").inc-by}",
-            vec![json!(
-                {
-                    "typ": { "type": "U64" }, "value": 1
-                }
-            )],
-        )
-        .await;
-    let _ = admin
+    let counter1 = admin
         .invoke_and_await_json(
             &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter2\").inc-by}",
-            vec![json!(
-                {
-                    "typ": { "type": "U64" }, "value": 2
-                }
-            )],
+            "rpc:counters-exports/api.{[constructor]counter}",
+            vec![json!({ "typ": { "type": "Str" }, "value": "counter1" })],
         )
-        .await;
+        .await
+        .unwrap();
 
-    let result1 = admin
-        .invoke_and_await_json(
-            &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter1\").get-value}",
-            vec![],
-        )
-        .await;
-    let result2 = admin
-        .invoke_and_await_json(
-            &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter2\").get-value}",
-            vec![],
-        )
-        .await;
+    let counter1_value = counter1.as_object().unwrap().get("value").unwrap();
+    let counter1 = json!(
+        {
+            "value": counter1_value
+        }
+    );
 
-    let _ = admin
-        .invoke_and_await_json(
-            &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter1\").drop}",
-            vec![],
-        )
-        .await;
-    let _ = admin
+    let counter2 = admin
         .invoke_and_await_json(
             &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter2\").drop}",
-            vec![],
-        )
-        .await;
-
-    let result3 = admin
-        .invoke_and_await_json(
-            &worker_id,
-            "rpc:counters-exports/api.{get-all-dropped}",
-            vec![],
+            "rpc:counters-exports/api.{[constructor]counter}",
+            vec![json!({ "typ": { "type": "Str" }, "value": "counter2" })],
         )
-        .await;
+        .await
+        .unwrap();
 
-    check!(
-        result1
-            == Ok(json!(
-                {
-                    "typ": { "type": "U64" },
-                    "value": 5
-                }
-            ))
-    );
-    check!(
-        result2
-            == Ok(json!(
-                {
-                    "typ": { "type": "U64" },
-                    "value": 3
-                }
-            ))
+    let counter2_value = counter2.as_object().unwrap().get("value").unwrap();
+    let counter2 = json!(
+        {
+            "value": counter2_value
+        }
     );
 
-    check!(
-        result3
-            == Ok(json!(
-                {
-              "typ": {
-                    "type": "List",
-                    "inner": {
-                      "type": "Tuple",
-                      "items": [
-                        {
-                          "type": "Str"
-                        },
-                        {
-                          "type": "U64"
-                        }
-                      ]
-                    }
-                },
-                "value": [
-                    ["counter1",5],
-                    ["counter2",3]
-                ]
-            }
-            ))
-    );
-}
-
-#[test]
-#[tracing::instrument]
-#[timeout(120000)]
-async fn counter_resource_test_2_json_no_types(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
-    let component_id = admin.component("counters").unique().store().await;
-    let worker_id = admin.start_worker(&component_id, "counters-2j").await;
-    admin.log_output(&worker_id).await;
-
     let _ = admin
         .invoke_and_await_json(
             &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter1\").inc-by}",
-            vec![json!(
-                {
-                    "value": 5
-                }
-            )],
+            "rpc:counters-exports/api.{[method]counter.inc-by}",
+            vec![
+                counter1.clone(),
+                json!(
+                    {
+                        "value": 5
+                    }
+                ),
+            ],
         )
         .await;
 
     let _ = admin
         .invoke_and_await_json(
             &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter2\").inc-by}",
-            vec![json!(
-                {
-                    "value": 1
-                }
-            )],
+            "rpc:counters-exports/api.{[method]counter.inc-by}",
+            vec![
+                counter2.clone(),
+                json!(
+                    {
+                        "value": 1
+                    }
+                ),
+            ],
         )
         .await;
     let _ = admin
         .invoke_and_await_json(
             &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter2\").inc-by}",
-            vec![json!(
-                {
-                    "value": 2
-                }
-            )],
+            "rpc:counters-exports/api.{[method]counter.inc-by}",
+            vec![
+                counter2.clone(),
+                json!(
+                    {
+                        "value": 2
+                    }
+                ),
+            ],
         )
         .await;
 
     let result1 = admin
         .invoke_and_await_json(
             &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter1\").get-value}",
-            vec![],
+            "rpc:counters-exports/api.{[method]counter.get-value}",
+            vec![counter1.clone()],
         )
         .await;
     let result2 = admin
         .invoke_and_await_json(
             &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter2\").get-value}",
-            vec![],
+            "rpc:counters-exports/api.{[method]counter.get-value}",
+            vec![counter2.clone()],
         )
         .await;
 
     let _ = admin
         .invoke_and_await_json(
             &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter1\").drop}",
-            vec![],
+            "rpc:counters-exports/api.{[drop]counter}",
+            vec![counter1.clone()],
         )
         .await;
     let _ = admin
         .invoke_and_await_json(
             &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter2\").drop}",
-            vec![],
+            "rpc:counters-exports/api.{[drop]counter}",
+            vec![counter2.clone()],
         )
         .await;
 
@@ -832,8 +543,8 @@ async fn counter_resource_test_2_json_no_types(deps: &Deps, _tracing: &Tracing)
 #[test]
 #[tracing::instrument]
 #[timeout(120000)]
-async fn shopping_cart_example(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn shopping_cart_example(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
+    let admin = deps.admin().await;
     let component_id = admin.component("shopping-cart").store().await;
     let worker_id = admin.start_worker(&component_id, "shopping-cart-1").await;
 
@@ -849,12 +560,12 @@ async fn shopping_cart_example(deps: &Deps, _tracing: &Tracing) {
         .invoke_and_await(
             &worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1000".into_value_and_type()),
                 ("name", "Golem T-Shirt M".into_value_and_type()),
                 ("price", 100.0f32.into_value_and_type()),
                 ("quantity", 5u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -863,12 +574,12 @@ async fn shopping_cart_example(deps: &Deps, _tracing: &Tracing) {
         .invoke_and_await(
             &worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1001".into_value_and_type()),
                 ("name", "Golem Cloud Subscription 1y".into_value_and_type()),
                 ("price", 999999.0f32.into_value_and_type()),
                 ("quantity", 1u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -877,12 +588,12 @@ async fn shopping_cart_example(deps: &Deps, _tracing: &Tracing) {
         .invoke_and_await(
             &worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1002".into_value_and_type()),
                 ("name", "Mud Golem".into_value_and_type()),
                 ("price", 11.0f32.into_value_and_type()),
                 ("quantity", 10u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -931,8 +642,8 @@ async fn shopping_cart_example(deps: &Deps, _tracing: &Tracing) {
 #[test]
 #[tracing::instrument]
 #[timeout(120000)]
-async fn auction_example_1(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn auction_example_1(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
+    let admin = deps.admin().await;
     let registry_component_id = admin.component("auction_registry_composed").store().await;
     let auction_component_id = admin.component("auction").store().await;
 
@@ -942,7 +653,13 @@ async fn auction_example_1(deps: &Deps, _tracing: &Tracing) {
         auction_component_id.to_string(),
     );
     let registry_worker_id = admin
-        .start_worker_with(&registry_component_id, "auction-registry-1", vec![], env)
+        .start_worker_with(
+            &registry_component_id,
+            "auction-registry-1",
+            vec![],
+            env,
+            vec![],
+        )
         .await;
 
     let _ = admin.log_output(&registry_worker_id).await;
@@ -995,8 +712,8 @@ fn get_worker_ids(workers: Vec<(WorkerMetadata, Option<String>)>) -> HashSet<Wor
 #[test]
 #[tracing::instrument]
 #[timeout(120000)]
-async fn get_workers(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn get_workers(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
+    let admin = deps.admin().await;
     let component_id = admin.component("shopping-cart").store().await;
 
     let workers_count = 150;
@@ -1095,8 +812,8 @@ async fn get_workers(deps: &Deps, _tracing: &Tracing) {
 #[tracing::instrument]
 #[timeout(120000)]
 #[flaky(10)] // TODO: stabilize test
-async fn get_running_workers(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn get_running_workers(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
+    let admin = deps.admin().await;
     let component_id = admin.component("http-client-2").unique().store().await;
     let host_http_port = 8585;
 
@@ -1148,6 +865,7 @@ async fn get_running_workers(deps: &Deps, _tracing: &Tracing) {
                 &format!("worker-http-client-{i}"),
                 vec![],
                 env.clone(),
+                vec![],
             )
             .await;
 
@@ -1228,8 +946,8 @@ async fn get_running_workers(deps: &Deps, _tracing: &Tracing) {
 #[test]
 #[tracing::instrument]
 #[timeout(300000)]
-async fn auto_update_on_idle(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn auto_update_on_idle(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
+    let admin = deps.admin().await;
     let component_id = admin.component("update-test-v1").unique().store().await;
     let worker_id = admin
         .start_worker(&component_id, "auto_update_on_idle")
@@ -1263,8 +981,11 @@ async fn auto_update_on_idle(deps: &Deps, _tracing: &Tracing) {
 #[test]
 #[tracing::instrument]
 #[timeout(300000)]
-async fn auto_update_on_idle_via_host_function(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn auto_update_on_idle_via_host_function(
+    deps: &EnvBasedTestDependencies,
+    _tracing: &Tracing,
+) {
+    let admin = deps.admin().await;
     let component_id = admin.component("update-test-v1").unique().store().await;
     let worker_id = admin
         .start_worker(&component_id, "auto_update_on_idle_via_host_function")
@@ -1288,24 +1009,24 @@ async fn auto_update_on_idle_via_host_function(deps: &Deps, _tracing: &Tracing)
             &runtime_svc_worker,
             "golem:it/api.{update-worker}",
             vec![
-                vec![
+                Record(vec![
                     (
                         "component-id",
-                        vec![(
+                        Record(vec![(
                             "uuid",
-                            vec![
+                            Record(vec![
                                 ("high-bits", high_bits.into_value_and_type()),
                                 ("low-bits", low_bits.into_value_and_type()),
-                            ]
+                            ])
                             .into_value_and_type(),
-                        )]
+                        )])
                         .into_value_and_type(),
                     ),
                     (
                         "worker-name",
                         worker_id.worker_name.clone().into_value_and_type(),
                     ),
-                ]
+                ])
                 .into_value_and_type(),
                 target_version.into_value_and_type(),
                 ValueAndType {
@@ -1336,8 +1057,8 @@ async fn auto_update_on_idle_via_host_function(deps: &Deps, _tracing: &Tracing)
 #[test]
 #[tracing::instrument]
 #[timeout(120000)]
-async fn get_oplog_1(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn get_oplog_1(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
+    let admin = deps.admin().await;
     let component_id = admin.component("runtime-service").store().await;
 
     let worker_id = WorkerId {
@@ -1350,7 +1071,7 @@ async fn get_oplog_1(deps: &Deps, _tracing: &Tracing) {
 
     let _ = admin
         .invoke_and_await(
-            worker_id.clone(),
+            &worker_id,
             "golem:it/api.{generate-idempotency-keys}",
             vec![],
         )
@@ -1358,7 +1079,7 @@ async fn get_oplog_1(deps: &Deps, _tracing: &Tracing) {
         .unwrap();
     let _ = admin
         .invoke_and_await_with_key(
-            worker_id.clone(),
+            &worker_id,
             &idempotency_key1,
             "golem:it/api.{generate-idempotency-keys}",
             vec![],
@@ -1367,7 +1088,7 @@ async fn get_oplog_1(deps: &Deps, _tracing: &Tracing) {
         .unwrap();
     let _ = admin
         .invoke_and_await_with_key(
-            worker_id.clone(),
+            &worker_id,
             &idempotency_key2,
             "golem:it/api.{generate-idempotency-keys}",
             vec![],
@@ -1398,8 +1119,8 @@ async fn get_oplog_1(deps: &Deps, _tracing: &Tracing) {
 #[test]
 #[tracing::instrument]
 #[timeout(120000)]
-async fn search_oplog_1(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn search_oplog_1(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
+    let admin = deps.admin().await;
     let component_id = admin.component("shopping-cart").store().await;
 
     let worker_id = WorkerId {
@@ -1419,12 +1140,12 @@ async fn search_oplog_1(deps: &Deps, _tracing: &Tracing) {
         .invoke_and_await(
             &worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1000".into_value_and_type()),
                 ("name", "Golem T-Shirt M".into_value_and_type()),
                 ("price", 100.0f32.into_value_and_type()),
                 ("quantity", 5u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -1433,12 +1154,12 @@ async fn search_oplog_1(deps: &Deps, _tracing: &Tracing) {
         .invoke_and_await(
             &worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1001".into_value_and_type()),
                 ("name", "Golem Cloud Subscription 1y".into_value_and_type()),
                 ("price", 999999.0f32.into_value_and_type()),
                 ("quantity", 1u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -1447,12 +1168,12 @@ async fn search_oplog_1(deps: &Deps, _tracing: &Tracing) {
         .invoke_and_await(
             &worker_id,
             "golem:it/api.{add-item}",
-            vec![vec![
+            vec![Record(vec![
                 ("product-id", "G1002".into_value_and_type()),
                 ("name", "Mud Golem".into_value_and_type()),
                 ("price", 11.0f32.into_value_and_type()),
                 ("quantity", 10u32.into_value_and_type()),
-            ]
+            ])
             .into_value_and_type()],
         )
         .await;
@@ -1491,20 +1212,38 @@ async fn search_oplog_1(deps: &Deps, _tracing: &Tracing) {
 #[test]
 #[tracing::instrument]
 #[timeout(600000)]
-async fn worker_recreation(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn worker_recreation(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
+    let admin = deps.admin().await;
     let component_id = admin.component("counters").unique().store().await;
     let worker_id = admin
         .start_worker(&component_id, "counters-recreation")
         .await;
 
+    let counter1 = admin
+        .invoke_and_await(
+            &worker_id,
+            "rpc:counters-exports/api.{[constructor]counter}",
+            vec!["counter1".into_value_and_type()],
+        )
+        .await
+        .unwrap();
+    let counter1 = ValueAndType::new(
+        counter1[0].clone(),
+        AnalysedType::Handle(TypeHandle {
+            name: None,
+            owner: None,
+            resource_id: AnalysedResourceId(0),
+            mode: AnalysedResourceMode::Borrowed,
+        }),
+    );
+
     // Doing many requests, so parts of the oplog gets archived
     for _ in 1..=1200 {
         let _ = admin
             .invoke_and_await(
                 &worker_id,
-                "rpc:counters-exports/api.{counter(\"counter1\").inc-by}",
-                vec![1u64.into_value_and_type()],
+                "rpc:counters-exports/api.{[method]counter.inc-by}",
+                vec![counter1.clone(), 1u64.into_value_and_type()],
             )
             .await;
     }
@@ -1512,8 +1251,8 @@ async fn worker_recreation(deps: &Deps, _tracing: &Tracing) {
     let result1 = admin
         .invoke_and_await(
             &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter1\").get-value}",
-            vec![],
+            "rpc:counters-exports/api.{[method]counter.get-value}",
+            vec![counter1.clone()],
         )
         .await;
 
@@ -1522,19 +1261,37 @@ async fn worker_recreation(deps: &Deps, _tracing: &Tracing) {
     admin.delete_worker(&worker_id).await;
 
     // Invoking again should create a new worker
+    let counter1 = admin
+        .invoke_and_await(
+            &worker_id,
+            "rpc:counters-exports/api.{[constructor]counter}",
+            vec!["counter1".into_value_and_type()],
+        )
+        .await
+        .unwrap();
+    let counter1 = ValueAndType::new(
+        counter1[0].clone(),
+        AnalysedType::Handle(TypeHandle {
+            name: None,
+            owner: None,
+            resource_id: AnalysedResourceId(0),
+            mode: AnalysedResourceMode::Borrowed,
+        }),
+    );
+
     let _ = admin
         .invoke_and_await(
             &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter1\").inc-by}",
-            vec![1u64.into_value_and_type()],
+            "rpc:counters-exports/api.{[method]counter.inc-by}",
+            vec![counter1.clone(), 1u64.into_value_and_type()],
         )
         .await;
 
     let result2 = admin
         .invoke_and_await(
             &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter1\").get-value}",
-            vec![],
+            "rpc:counters-exports/api.{[method]counter.get-value}",
+            vec![counter1.clone()],
         )
         .await;
 
@@ -1545,11 +1302,29 @@ async fn worker_recreation(deps: &Deps, _tracing: &Tracing) {
         .start_worker(&component_id, "counters-recreation")
         .await;
 
+    let counter1 = admin
+        .invoke_and_await(
+            &worker_id,
+            "rpc:counters-exports/api.{[constructor]counter}",
+            vec!["counter1".into_value_and_type()],
+        )
+        .await
+        .unwrap();
+    let counter1 = ValueAndType::new(
+        counter1[0].clone(),
+        AnalysedType::Handle(TypeHandle {
+            name: None,
+            owner: None,
+            resource_id: AnalysedResourceId(0),
+            mode: AnalysedResourceMode::Borrowed,
+        }),
+    );
+
     let result3 = admin
         .invoke_and_await(
             &worker_id,
-            "rpc:counters-exports/api.{counter(\"counter1\").get-value}",
-            vec![],
+            "rpc:counters-exports/api.{[method]counter.get-value}",
+            vec![counter1.clone()],
         )
         .await;
 
@@ -1561,8 +1336,8 @@ async fn worker_recreation(deps: &Deps, _tracing: &Tracing) {
 #[test]
 #[tracing::instrument]
 #[timeout(600000)]
-async fn worker_use_initial_files(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn worker_use_initial_files(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
+    let admin = deps.admin().await;
     let component_files = admin
         .add_initial_component_files(&[
             (
@@ -1609,8 +1384,8 @@ async fn worker_use_initial_files(deps: &Deps, _tracing: &Tracing) {
 #[test]
 #[tracing::instrument]
 #[timeout(600000)]
-async fn worker_list_files(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn worker_list_files(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
+    let admin = deps.admin().await;
     let component_files = admin
         .add_initial_component_files(&[
             (
@@ -1642,7 +1417,7 @@ async fn worker_list_files(deps: &Deps, _tracing: &Tracing) {
         .start_worker(&component_id, "initial-file-read-write-1")
         .await;
 
-    let result = admin.list_directory(&worker_id, "/").await;
+    let result = admin.get_file_system_node(&worker_id, "/").await;
 
     let mut result = result
         .into_iter()
@@ -1680,13 +1455,61 @@ async fn worker_list_files(deps: &Deps, _tracing: &Tracing) {
                 },
             ]
     );
+
+    let result = admin.get_file_system_node(&worker_id, "/bar").await;
+
+    let mut result = result
+        .into_iter()
+        .map(|e| ComponentFileSystemNode {
+            last_modified: SystemTime::UNIX_EPOCH,
+            ..e
+        })
+        .collect::<Vec<_>>();
+
+    result.sort_by_key(|e| e.name.clone());
+
+    check!(
+        result
+            == vec![ComponentFileSystemNode {
+                name: "baz.txt".to_string(),
+                last_modified: SystemTime::UNIX_EPOCH,
+                details: ComponentFileSystemNodeDetails::File {
+                    permissions: ComponentFilePermissions::ReadWrite,
+                    size: 4,
+                }
+            },]
+    );
+
+    let result = admin.get_file_system_node(&worker_id, "/baz.txt").await;
+
+    let mut result = result
+        .into_iter()
+        .map(|e| ComponentFileSystemNode {
+            last_modified: SystemTime::UNIX_EPOCH,
+            ..e
+        })
+        .collect::<Vec<_>>();
+
+    result.sort_by_key(|e| e.name.clone());
+
+    check!(
+        result
+            == vec![ComponentFileSystemNode {
+                name: "baz.txt".to_string(),
+                last_modified: SystemTime::UNIX_EPOCH,
+                details: ComponentFileSystemNodeDetails::File {
+                    permissions: ComponentFilePermissions::ReadWrite,
+                    size: 4,
+                }
+            },]
+    );
 }
 
 #[test]
 #[tracing::instrument]
 #[timeout(600000)]
-async fn worker_read_files(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn worker_read_files(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
+    let admin = deps.admin().await;
     let component_files = admin
         .add_initial_component_files(&[
             (
@@ -1733,8 +1556,11 @@ async fn worker_read_files(deps: &Deps, _tracing: &Tracing) {
 #[test]
 #[tracing::instrument]
 #[timeout(600000)]
-async fn worker_initial_files_after_automatic_worker_update(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn worker_initial_files_after_automatic_worker_update(
+    deps: &EnvBasedTestDependencies,
+    _tracing: &Tracing,
+) {
+    let admin = deps.admin().await;
     let component_files_1 = admin
         .add_initial_component_files(&[
             (
@@ -1814,8 +1640,8 @@ async fn worker_initial_files_after_automatic_worker_update(deps: &Deps, _tracin
 /// Test resolving a component_id from the name.
 #[test]
 #[tracing::instrument]
-async fn resolve_components_from_name(deps: &Deps, _tracing: &Tracing) {
-    let admin = deps.admin();
+async fn resolve_components_from_name(deps: &EnvBasedTestDependencies, _tracing: &Tracing) {
+    let admin = deps.admin().await;
 
     // Make sure the name is unique
     let counter_component_id = admin
diff --git a/local-run/nginx.conf b/local-run/nginx.conf
index 05b31143..25ffd21e 100644
--- a/local-run/nginx.conf
+++ b/local-run/nginx.conf
@@ -9,43 +9,62 @@ http {
     access_log /dev/stdout;
     client_max_body_size 52428800; # Increase this especially if your component size is higher than this
 
+    upstream cloud-service {
+        server 127.0.0.1:8080 fail_timeout=0 max_fails=0;
+    }
+
+    upstream component-service {
+        server 127.0.0.1:8082 fail_timeout=0 max_fails=0;
+    }
+
+    upstream worker-service {
+        server 127.0.0.1:8085 fail_timeout=0 max_fails=0;
+    }
+
+    upstream debugging-service {
+        server 127.0.0.1:8087 fail_timeout=0 max_fails=0;
+    }
+
     server {
         listen 9881;
         server_name localhost;
 
         location ~ /v1/components/[^/]+/workers/[^/]+/connect$ {
-            proxy_pass http://localhost:8085;
+            proxy_pass http://worker-service;
             proxy_http_version 1.1;
             proxy_set_header Upgrade "websocket";
             proxy_set_header Connection "upgrade";
+
+            proxy_read_timeout 3600s;
+            proxy_send_timeout 3600s;
         }
 
         location /v1/api {
-            proxy_pass http://localhost:8085;
+            proxy_pass http://worker-service;
         }
 
         location ~ /v1/components/[^/]+/workers(.*)$ {
-            proxy_pass http://localhost:8085;
+            proxy_pass http://worker-service;
         }
 
         location ~ /v1/components/[^/]+/invoke$ {
-            proxy_pass http://localhost:8085;
+            proxy_pass http://worker-service;
         }
 
         location ~ /v1/components/[^/]+/invoke-and-await$ {
-            proxy_pass http://localhost:8085;
+            proxy_pass http://worker-service;
         }
 
         location /v1/components {
-            proxy_pass http://localhost:8082;
+            proxy_pass http://component-service;
         }
 
         location /v1/plugins {
-            proxy_pass http://localhost:8082;
+            proxy_pass http://component-service;
         }
 
         location /v1/debugger {
-            proxy_pass http://localhost:8087;
+            proxy_pass http://debugging-service;
             proxy_http_version 1.1;
             proxy_set_header Upgrade "websocket";
             proxy_set_header Connection "upgrade";
@@ -55,7 +74,7 @@ http {
         }
 
         location / {
-            proxy_pass http://localhost:8080;
+            proxy_pass http://cloud-service;
         }
     }
 }
diff --git a/openapi/cloud-spec.yaml b/openapi/cloud-spec.yaml
index 11f114c9..619cff7b 100644
--- a/openapi/cloud-spec.yaml
+++ b/openapi/cloud-spec.yaml
@@ -7,6 +7,8 @@ tags:
 - name: Account
   description: The account API allows users to query and manipulate their own account data.
 - name: AccountSummary
+- name: AgentTypes
+  description: API working on registered agent types
 - name: ApiCertificate
 - name: ApiDefinition
 - name: ApiDeployment
@@ -2015,7 +2017,7 @@ paths:
       security:
       - Cookie: []
       - Token: []
-      operationId: bath_update_installed_plugins_of_project
+      operationId: batch_update_installed_plugins_of_project
   /v1/projects/{project_id}/grants:
     get:
       tags:
@@ -3163,6 +3165,7 @@ components:
       - CreatePluginDefinition
       - UpdatePluginDefinition
       - DeletePluginDefinition
+      - ExportApiDefinition
     ProjectPolicy:
       type: object
       title: ProjectPolicy
diff --git a/openapi/golem-component-service.yaml b/openapi/golem-component-service.yaml
index 36550227..13713018 100644
--- a/openapi/golem-component-service.yaml
+++ b/openapi/golem-component-service.yaml
@@ -7,6 +7,8 @@ tags:
 - name: Account
   description: The account API allows users to query and manipulate their own account data.
 - name: AccountSummary
+- name: AgentTypes
+  description: API working on registered agent types
 - name: ApiCertificate
 - name: ApiDefinition
 - name: ApiDeployment
@@ -248,6 +250,8 @@ paths:
                   $ref: '#/components/schemas/DynamicLinking'
                 env:
                   $ref: '#/components/schemas/ComponentEnv'
+                agentTypes:
+                  $ref: '#/components/schemas/AgentTypes'
         required: true
       responses:
         '200':
@@ -329,6 +333,8 @@ paths:
                   $ref: '#/components/schemas/DynamicLinking'
                 env:
                   $ref: '#/components/schemas/ComponentEnv'
+                agentTypes:
+                  $ref: '#/components/schemas/AgentTypes'
         required: true
       responses:
         '200':
@@ -1057,7 +1063,7 @@ paths:
       security:
       - Cookie: []
       - Token: []
-      operationId: bath_update_installed_plugins
+      operationId: batch_update_installed_plugins
   /v1/components/{component_id}/versions/{version}/file-contents/{file_path}:
     get:
       tags:
@@ -1566,8 +1572,223 @@ paths:
       - Cookie: []
       - Token: []
       operationId: create_app_plugin
+  /v1/agent-types:
+    get:
+      tags:
+      - AgentTypes
+      parameters:
+      - name: project-id
+        schema:
+          type: string
+          format: uuid
+        in: query
+        required: false
+        deprecated: false
+        explode: true
+      responses:
+        '200':
+          description: ''
+          content:
+            application/json; charset=utf-8:
+              schema:
+                type: array
+                items:
+                  $ref: '#/components/schemas/RegisteredAgentType'
+        '400':
+          description: Invalid request, returning with a list of issues detected in the request
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorsBody'
+        '401':
+          description: Unauthorized
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+        '403':
+          description: Maximum number of components exceeded
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+        '404':
+          description: Component not found
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+        '409':
+          description: Component already exists
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+        '500':
+          description: Internal server error
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+      security:
+      - Cookie: []
+      - Token: []
+      operationId: get_all_agent_types
+  /v1/agent-types/{agent-type}:
+    get:
+      tags:
+      - AgentTypes
+      parameters:
+      - name: agent-type
+        schema:
+          type: string
+        in: path
+        required: true
+        deprecated: false
+        explode: true
+      - name: project-id
+        schema:
+          type: string
+          format: uuid
+        in: query
+        required: false
+        deprecated: false
+        explode: true
+      responses:
+        '200':
+          description: ''
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/RegisteredAgentType'
+        '400':
+          description: Invalid request, returning with a list of issues detected in the request
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorsBody'
+        '401':
+          description: Unauthorized
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+        '403':
+          description: Maximum number of components exceeded
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+        '404':
+          description: Component not found
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+        '409':
+          description: Component already exists
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+        '500':
+          description: Internal server error
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+      security:
+      - Cookie: []
+      - Token: []
+      operationId: get_agent_type
 components:
   schemas:
+    AgentConstructor:
+      type: object
+      title: AgentConstructor
+      required:
+      - description
+      - inputSchema
+      properties:
+        name:
+          type: string
+        description:
+          type: string
+        promptHint:
+          type: string
+        inputSchema:
+          $ref: '#/components/schemas/DataSchema'
+    AgentDependency:
+      type: object
+      title: AgentDependency
+      required:
+      - typeName
+      - constructor
+      - methods
+      properties:
+        typeName:
+          type: string
+        description:
+          type: string
+        constructor:
+          $ref: '#/components/schemas/AgentConstructor'
+        methods:
+          type: array
+          items:
+            $ref: '#/components/schemas/AgentMethod'
+    AgentMethod:
+      type: object
+      title: AgentMethod
+      required:
+      - name
+      - description
+      - inputSchema
+      - outputSchema
+      properties:
+        name:
+          type: string
+        description:
+          type: string
+        promptHint:
+          type: string
+        inputSchema:
+          $ref: '#/components/schemas/DataSchema'
+        outputSchema:
+          $ref: '#/components/schemas/DataSchema'
+    AgentType:
+      type: object
+      title: AgentType
+      required:
+      - typeName
+      - description
+      - constructor
+      - methods
+      - dependencies
+      properties:
+        typeName:
+          type: string
+        description:
+          type: string
+        constructor:
+          $ref: '#/components/schemas/AgentConstructor'
+        methods:
+          type: array
+          items:
+            $ref: '#/components/schemas/AgentMethod'
+        dependencies:
+          type: array
+          items:
+            $ref: '#/components/schemas/AgentDependency'
+    AgentTypes:
+      type: object
+      title: AgentTypes
+      required:
+      - types
+      properties:
+        types:
+          type: array
+          items:
+            $ref: '#/components/schemas/AgentType'
     AnalysedExport:
       type: object
       oneOf:
@@ -1986,6 +2207,22 @@ components:
           type: array
           items:
             $ref: '#/components/schemas/PluginInstallationAction'
+    BinaryDescriptor:
+      type: object
+      title: BinaryDescriptor
+      properties:
+        restrictions:
+          type: array
+          items:
+            $ref: '#/components/schemas/BinaryType'
+    BinaryType:
+      type: object
+      title: BinaryType
+      required:
+      - mimeType
+      properties:
+        mimeType:
+          type: string
     Component:
       type: object
       title: Component
@@ -2079,6 +2316,7 @@ components:
       - memories
       - binaryWit
       - dynamicLinking
+      - agentTypes
       properties:
         exports:
           type: array
@@ -2103,6 +2341,18 @@ components:
           type: object
           additionalProperties:
             $ref: '#/components/schemas/DynamicLinkedInstance'
+        agentTypes:
+          type: array
+          items:
+            $ref: '#/components/schemas/AgentType'
+    ComponentModelElementSchema:
+      type: object
+      title: ComponentModelElementSchema
+      required:
+      - elementType
+      properties:
+        elementType:
+          $ref: '#/components/schemas/AnalysedType'
     ComponentPluginScope:
       type: object
       title: ComponentPluginScope
@@ -2167,6 +2417,28 @@ components:
       enum:
       - Durable
       - Ephemeral
+    DataSchema:
+      type: object
+      oneOf:
+      - $ref: '#/components/schemas/DataSchema_NamedElementSchemas'
+      - $ref: '#/components/schemas/DataSchema_NamedElementSchemas'
+      discriminator:
+        propertyName: type
+        mapping:
+          Tuple: '#/components/schemas/DataSchema_NamedElementSchemas'
+          Multimodal: '#/components/schemas/DataSchema_NamedElementSchemas'
+    DataSchema_NamedElementSchemas:
+      allOf:
+      - type: object
+        required:
+        - type
+        properties:
+          type:
+            type: string
+            enum:
+            - Multimodal
+            example: Multimodal
+      - $ref: '#/components/schemas/NamedElementSchemas'
     DynamicLinkedInstance:
       type: object
       oneOf:
@@ -2208,6 +2480,54 @@ components:
           type: object
           additionalProperties:
             $ref: '#/components/schemas/DynamicLinkedInstance'
+    ElementSchema:
+      type: object
+      oneOf:
+      - $ref: '#/components/schemas/ElementSchema_ComponentModelElementSchema'
+      - $ref: '#/components/schemas/ElementSchema_TextDescriptor'
+      - $ref: '#/components/schemas/ElementSchema_BinaryDescriptor'
+      discriminator:
+        propertyName: type
+        mapping:
+          ComponentModel: '#/components/schemas/ElementSchema_ComponentModelElementSchema'
+          UnstructuredText: '#/components/schemas/ElementSchema_TextDescriptor'
+          UnstructuredBinary: '#/components/schemas/ElementSchema_BinaryDescriptor'
+    ElementSchema_BinaryDescriptor:
+      allOf:
+      - type: object
+        required:
+        - type
+        properties:
+          type:
+            type: string
+            enum:
+            - UnstructuredBinary
+            example: UnstructuredBinary
+      - $ref: '#/components/schemas/BinaryDescriptor'
+    ElementSchema_ComponentModelElementSchema:
+      allOf:
+      - type: object
+        required:
+        - type
+        properties:
+          type:
+            type: string
+            enum:
+            - ComponentModel
+            example: ComponentModel
+      - $ref: '#/components/schemas/ComponentModelElementSchema'
+    ElementSchema_TextDescriptor:
+      allOf:
+      - type: object
+        required:
+        - type
+        properties:
+          type:
+            type: string
+            enum:
+            - UnstructuredText
+            example: UnstructuredText
+      - $ref: '#/components/schemas/TextDescriptor'
     Empty:
       type: object
       title: Empty
@@ -2293,6 +2613,27 @@ components:
           type: string
         typ:
           $ref: '#/components/schemas/AnalysedType'
+    NamedElementSchema:
+      type: object
+      title: NamedElementSchema
+      required:
+      - name
+      - schema
+      properties:
+        name:
+          type: string
+        schema:
+          $ref: '#/components/schemas/ElementSchema'
+    NamedElementSchemas:
+      type: object
+      title: NamedElementSchemas
+      required:
+      - elements
+      properties:
+        elements:
+          type: array
+          items:
+            $ref: '#/components/schemas/NamedElementSchema'
     OplogProcessorDefinition:
       type: object
       title: OplogProcessorDefinition
@@ -2696,6 +3037,34 @@ components:
         projectId:
           type: string
           format: uuid
+    RegisteredAgentType:
+      type: object
+      title: RegisteredAgentType
+      required:
+      - agentType
+      - implementedBy
+      properties:
+        agentType:
+          $ref: '#/components/schemas/AgentType'
+        implementedBy:
+          type: string
+          format: uuid
+    TextDescriptor:
+      type: object
+      title: TextDescriptor
+      properties:
+        restrictions:
+          type: array
+          items:
+            $ref: '#/components/schemas/TextType'
+    TextType:
+      type: object
+      title: TextType
+      required:
+      - languageCode
+      properties:
+        languageCode:
+          type: string
     TypeBool:
       type: object
       title: TypeBool
@@ -2708,6 +3077,10 @@ components:
       required:
       - cases
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         cases:
           type: array
           items:
@@ -2724,6 +3097,10 @@ components:
       required:
       - names
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         names:
           type: array
           items:
@@ -2735,6 +3112,10 @@ components:
       - resource_id
       - mode
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         resource_id:
           type: integer
           format: uint64
@@ -2746,6 +3127,10 @@ components:
       required:
       - inner
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         inner:
           $ref: '#/components/schemas/AnalysedType'
     TypeOption:
@@ -2754,6 +3139,10 @@ components:
       required:
       - inner
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         inner:
           $ref: '#/components/schemas/AnalysedType'
     TypeRecord:
@@ -2762,6 +3151,10 @@ components:
       required:
       - fields
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         fields:
           type: array
           items:
@@ -2770,6 +3163,10 @@ components:
       type: object
       title: TypeResult
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         ok:
           $ref: '#/components/schemas/AnalysedType'
         err:
@@ -2795,6 +3192,10 @@ components:
       required:
       - items
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         items:
           type: array
           items:
@@ -2817,6 +3218,10 @@ components:
       required:
       - cases
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         cases:
           type: array
           items:
diff --git a/openapi/golem-service.yaml b/openapi/golem-service.yaml
index b1675649..a01ffd7d 100644
--- a/openapi/golem-service.yaml
+++ b/openapi/golem-service.yaml
@@ -1950,7 +1950,7 @@ paths:
       tags:
       - Project
       summary: Applies a batch of changes to the installed plugins of a component
-      operationId: bath_update_installed_plugins_of_project
+      operationId: batch_update_installed_plugins_of_project
       parameters:
       - in: path
         name: project_id
@@ -2890,6 +2890,8 @@ paths:
                   $ref: '#/components/schemas/DynamicLinking'
                 env:
                   $ref: '#/components/schemas/ComponentEnv'
+                agentTypes:
+                  $ref: '#/components/schemas/AgentTypes'
               required:
               - component
         required: true
@@ -3042,6 +3044,8 @@ paths:
                   $ref: '#/components/schemas/DynamicLinking'
                 env:
                   $ref: '#/components/schemas/ComponentEnv'
+                agentTypes:
+                  $ref: '#/components/schemas/AgentTypes'
               required:
               - query
               - component
@@ -3650,7 +3654,7 @@ paths:
       tags:
       - Component
       summary: Applies a batch of changes to the installed plugins of a component
-      operationId: bath_update_installed_plugins
+      operationId: batch_update_installed_plugins
       parameters:
       - in: path
         name: component_id
@@ -4231,6 +4235,136 @@ paths:
       security:
       - Cookie: []
       - Token: []
+  /v1/agent-types:
+    get:
+      tags:
+      - AgentTypes
+      operationId: get_all_agent_types
+      parameters:
+      - in: query
+        name: project-id
+        deprecated: false
+        schema:
+          type: string
+          format: uuid
+        explode: true
+        style: form
+      responses:
+        '200':
+          description: ''
+          content:
+            application/json; charset=utf-8:
+              schema:
+                type: array
+                items:
+                  $ref: '#/components/schemas/RegisteredAgentType'
+        '400':
+          description: Invalid request, returning with a list of issues detected in the request
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorsBody'
+        '401':
+          description: Unauthorized
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+        '403':
+          description: Maximum number of components exceeded
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+        '404':
+          description: Component not found
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+        '409':
+          description: Component already exists
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+        '500':
+          description: Internal server error
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+      security:
+      - Cookie: []
+      - Token: []
+  /v1/agent-types/{agent-type}:
+    get:
+      tags:
+      - AgentTypes
+      operationId: get_agent_type
+      parameters:
+      - in: path
+        name: agent-type
+        required: true
+        deprecated: false
+        schema:
+          type: string
+        explode: true
+        style: simple
+      - in: query
+        name: project-id
+        deprecated: false
+        schema:
+          type: string
+          format: uuid
+        explode: true
+        style: form
+      responses:
+        '200':
+          description: ''
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/RegisteredAgentType'
+        '400':
+          description: Invalid request, returning with a list of issues detected in the request
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorsBody'
+        '401':
+          description: Unauthorized
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+        '403':
+          description: Maximum number of components exceeded
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+        '404':
+          description: Component not found
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+        '409':
+          description: Component already exists
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+        '500':
+          description: Internal server error
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+      security:
+      - Cookie: []
+      - Token: []
   /v1/components/{component_id}/workers:
     get:
       tags:
@@ -4670,92 +4804,6 @@ paths:
       security:
       - Cookie: []
       - Token: []
-  /v1/components/{component_id}/invoke-and-await:
-    post:
-      tags:
-      - Worker
-      summary: Invoke a function and await its resolution on a new worker with a random generated name
-      description: |-
-        Ideal for invoking ephemeral components, but works with durable ones as well.
-        Supply the parameters in the request body as JSON.
-      operationId: invoke_and_await_function_without_name
-      parameters:
-      - in: path
-        name: component_id
-        required: true
-        deprecated: false
-        schema:
-          type: string
-          format: uuid
-        explode: true
-        style: simple
-      - in: header
-        name: Idempotency-Key
-        deprecated: false
-        schema:
-          type: string
-        explode: true
-        style: simple
-      - in: query
-        name: function
-        required: true
-        deprecated: false
-        schema:
-          type: string
-        explode: true
-        style: form
-      requestBody:
-        content:
-          application/json; charset=utf-8:
-            schema:
-              $ref: '#/components/schemas/InvokeParameters'
-        required: true
-      responses:
-        '200':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/InvokeResult'
-        '400':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorsBody'
-        '401':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorBody'
-        '403':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorBody'
-        '404':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorBody'
-        '409':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorBody'
-        '500':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorBodyWithOptionalWorkerError'
-      security:
-      - Cookie: []
-      - Token: []
   /v1/components/{component_id}/workers/{worker_name}/invoke:
     post:
       tags:
@@ -4849,93 +4897,6 @@ paths:
       security:
       - Cookie: []
       - Token: []
-  /v1/components/{component_id}/invoke:
-    post:
-      tags:
-      - Worker
-      summary: Invoke a function on a new worker with a random generated name
-      description: |-
-        Ideal for invoking ephemeral components, but works with durable ones as well.
-        A simpler version of the previously defined invoke and await endpoint just triggers the execution of a function and immediately returns.
-      operationId: invoke_function_without_name
-      parameters:
-      - in: path
-        name: component_id
-        required: true
-        deprecated: false
-        schema:
-          type: string
-          format: uuid
-        explode: true
-        style: simple
-      - in: header
-        name: Idempotency-Key
-        deprecated: false
-        schema:
-          type: string
-        explode: true
-        style: simple
-      - in: query
-        name: function
-        description: name of the exported function to be invoked
-        required: true
-        deprecated: false
-        schema:
-          type: string
-        explode: true
-        style: form
-      requestBody:
-        content:
-          application/json; charset=utf-8:
-            schema:
-              $ref: '#/components/schemas/InvokeParameters'
-        required: true
-      responses:
-        '200':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/InvokeResponse'
-        '400':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorsBody'
-        '401':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorBody'
-        '403':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorBody'
-        '404':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorBody'
-        '409':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorBody'
-        '500':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorBodyWithOptionalWorkerError'
-      security:
-      - Cookie: []
-      - Token: []
   /v1/components/{component_id}/workers/{worker_name}/complete:
     post:
       tags:
@@ -6437,6 +6398,85 @@ paths:
       security:
       - Cookie: []
       - Token: []
+  /v1/api/definitions/{project_id}/{id}/{version}/export:
+    get:
+      tags:
+      - ApiDefinition
+      summary: Export an API definition in OpenAPI format
+      description: Exports an API definition by its API definition ID and version in OpenAPI format.
+      operationId: export_definition
+      parameters:
+      - in: path
+        name: project_id
+        required: true
+        deprecated: false
+        schema:
+          type: string
+          format: uuid
+        explode: true
+        style: simple
+      - in: path
+        name: id
+        required: true
+        deprecated: false
+        schema:
+          type: string
+        explode: true
+        style: simple
+      - in: path
+        name: version
+        required: true
+        deprecated: false
+        schema:
+          type: string
+        explode: true
+        style: simple
+      responses:
+        '200':
+          description: ''
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/OpenApiHttpApiDefinitionResponse'
+        '400':
+          description: ''
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorsBody'
+        '401':
+          description: ''
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+        '403':
+          description: ''
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+        '404':
+          description: ''
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+        '409':
+          description: ''
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+        '500':
+          description: ''
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBodyWithOptionalWorkerError'
+      security:
+      - Cookie: []
+      - Token: []
   /v1/api/deployments/deploy:
     post:
       tags:
@@ -7808,6 +7848,7 @@ components:
       - CreatePluginDefinition
       - UpdatePluginDefinition
       - DeletePluginDefinition
+      - ExportApiDefinition
     ProjectPolicy:
       title: ProjectPolicy
       type: object
@@ -7922,6 +7963,92 @@ components:
     WebFlowCallbackSuccessResponse:
       title: WebFlowCallbackSuccessResponse
       type: object
+    AgentConstructor:
+      title: AgentConstructor
+      type: object
+      properties:
+        name:
+          type: string
+        description:
+          type: string
+        promptHint:
+          type: string
+        inputSchema:
+          $ref: '#/components/schemas/DataSchema'
+      required:
+      - description
+      - inputSchema
+    AgentDependency:
+      title: AgentDependency
+      type: object
+      properties:
+        typeName:
+          type: string
+        description:
+          type: string
+        constructor:
+          $ref: '#/components/schemas/AgentConstructor'
+        methods:
+          type: array
+          items:
+            $ref: '#/components/schemas/AgentMethod'
+      required:
+      - typeName
+      - constructor
+      - methods
+    AgentMethod:
+      title: AgentMethod
+      type: object
+      properties:
+        name:
+          type: string
+        description:
+          type: string
+        promptHint:
+          type: string
+        inputSchema:
+          $ref: '#/components/schemas/DataSchema'
+        outputSchema:
+          $ref: '#/components/schemas/DataSchema'
+      required:
+      - name
+      - description
+      - inputSchema
+      - outputSchema
+    AgentType:
+      title: AgentType
+      type: object
+      properties:
+        typeName:
+          type: string
+        description:
+          type: string
+        constructor:
+          $ref: '#/components/schemas/AgentConstructor'
+        methods:
+          type: array
+          items:
+            $ref: '#/components/schemas/AgentMethod'
+        dependencies:
+          type: array
+          items:
+            $ref: '#/components/schemas/AgentDependency'
+      required:
+      - typeName
+      - description
+      - constructor
+      - methods
+      - dependencies
+    AgentTypes:
+      title: AgentTypes
+      type: object
+      properties:
+        types:
+          type: array
+          items:
+            $ref: '#/components/schemas/AgentType'
+      required:
+      - types
     AnalysedExport:
       discriminator:
         propertyName: type
@@ -8329,7 +8456,23 @@ components:
         blobStorageKey:
           type: string
       required:
-      - blobStorageKey
+      - blobStorageKey
+    BinaryDescriptor:
+      title: BinaryDescriptor
+      type: object
+      properties:
+        restrictions:
+          type: array
+          items:
+            $ref: '#/components/schemas/BinaryType'
+    BinaryType:
+      title: BinaryType
+      type: object
+      properties:
+        mimeType:
+          type: string
+      required:
+      - mimeType
     Component:
       title: Component
       type: object
@@ -8441,12 +8584,25 @@ components:
           type: object
           additionalProperties:
             $ref: '#/components/schemas/DynamicLinkedInstance'
+        agentTypes:
+          type: array
+          items:
+            $ref: '#/components/schemas/AgentType'
       required:
       - exports
       - producers
       - memories
       - binaryWit
       - dynamicLinking
+      - agentTypes
+    ComponentModelElementSchema:
+      title: ComponentModelElementSchema
+      type: object
+      properties:
+        elementType:
+          $ref: '#/components/schemas/AnalysedType'
+      required:
+      - elementType
     ComponentPluginScope:
       title: ComponentPluginScope
       type: object
@@ -8511,6 +8667,28 @@ components:
       enum:
       - Durable
       - Ephemeral
+    DataSchema:
+      discriminator:
+        propertyName: type
+        mapping:
+          Tuple: '#/components/schemas/DataSchema_NamedElementSchemas'
+          Multimodal: '#/components/schemas/DataSchema_NamedElementSchemas'
+      type: object
+      oneOf:
+      - $ref: '#/components/schemas/DataSchema_NamedElementSchemas'
+      - $ref: '#/components/schemas/DataSchema_NamedElementSchemas'
+    DataSchema_NamedElementSchemas:
+      allOf:
+      - type: object
+        properties:
+          type:
+            example: Multimodal
+            type: string
+            enum:
+            - Multimodal
+        required:
+        - type
+      - $ref: '#/components/schemas/NamedElementSchemas'
     DynamicLinkedInstance:
       discriminator:
         propertyName: type
@@ -8552,6 +8730,54 @@ components:
             $ref: '#/components/schemas/DynamicLinkedInstance'
       required:
       - dynamicLinking
+    ElementSchema:
+      discriminator:
+        propertyName: type
+        mapping:
+          ComponentModel: '#/components/schemas/ElementSchema_ComponentModelElementSchema'
+          UnstructuredText: '#/components/schemas/ElementSchema_TextDescriptor'
+          UnstructuredBinary: '#/components/schemas/ElementSchema_BinaryDescriptor'
+      type: object
+      oneOf:
+      - $ref: '#/components/schemas/ElementSchema_ComponentModelElementSchema'
+      - $ref: '#/components/schemas/ElementSchema_TextDescriptor'
+      - $ref: '#/components/schemas/ElementSchema_BinaryDescriptor'
+    ElementSchema_BinaryDescriptor:
+      allOf:
+      - type: object
+        properties:
+          type:
+            example: UnstructuredBinary
+            type: string
+            enum:
+            - UnstructuredBinary
+        required:
+        - type
+      - $ref: '#/components/schemas/BinaryDescriptor'
+    ElementSchema_ComponentModelElementSchema:
+      allOf:
+      - type: object
+        properties:
+          type:
+            example: ComponentModel
+            type: string
+            enum:
+            - ComponentModel
+        required:
+        - type
+      - $ref: '#/components/schemas/ComponentModelElementSchema'
+    ElementSchema_TextDescriptor:
+      allOf:
+      - type: object
+        properties:
+          type:
+            example: UnstructuredText
+            type: string
+            enum:
+            - UnstructuredText
+        required:
+        - type
+      - $ref: '#/components/schemas/TextDescriptor'
     InitialComponentFile:
       title: InitialComponentFile
       type: object
@@ -8613,6 +8839,27 @@ components:
       required:
       - name
       - typ
+    NamedElementSchema:
+      title: NamedElementSchema
+      type: object
+      properties:
+        name:
+          type: string
+        schema:
+          $ref: '#/components/schemas/ElementSchema'
+      required:
+      - name
+      - schema
+    NamedElementSchemas:
+      title: NamedElementSchemas
+      type: object
+      properties:
+        elements:
+          type: array
+          items:
+            $ref: '#/components/schemas/NamedElementSchema'
+      required:
+      - elements
     OplogProcessorDefinition:
       title: OplogProcessorDefinition
       type: object
@@ -8878,6 +9125,34 @@ components:
           format: uuid
       required:
       - projectId
+    RegisteredAgentType:
+      title: RegisteredAgentType
+      type: object
+      properties:
+        agentType:
+          $ref: '#/components/schemas/AgentType'
+        implementedBy:
+          type: string
+          format: uuid
+      required:
+      - agentType
+      - implementedBy
+    TextDescriptor:
+      title: TextDescriptor
+      type: object
+      properties:
+        restrictions:
+          type: array
+          items:
+            $ref: '#/components/schemas/TextType'
+    TextType:
+      title: TextType
+      type: object
+      properties:
+        languageCode:
+          type: string
+      required:
+      - languageCode
     TypeBool:
       title: TypeBool
       type: object
@@ -8888,6 +9163,10 @@ components:
       title: TypeEnum
       type: object
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         cases:
           type: array
           items:
@@ -8904,6 +9183,10 @@ components:
       title: TypeFlags
       type: object
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         names:
           type: array
           items:
@@ -8914,6 +9197,10 @@ components:
       title: TypeHandle
       type: object
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         resource_id:
           type: integer
           format: uint64
@@ -8926,6 +9213,10 @@ components:
       title: TypeList
       type: object
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         inner:
           $ref: '#/components/schemas/AnalysedType'
       required:
@@ -8934,6 +9225,10 @@ components:
       title: TypeOption
       type: object
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         inner:
           $ref: '#/components/schemas/AnalysedType'
       required:
@@ -8942,6 +9237,10 @@ components:
       title: TypeRecord
       type: object
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         fields:
           type: array
           items:
@@ -8952,6 +9251,10 @@ components:
       title: TypeResult
       type: object
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         ok:
           $ref: '#/components/schemas/AnalysedType'
         err:
@@ -8975,6 +9278,10 @@ components:
       title: TypeTuple
       type: object
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         items:
           type: array
           items:
@@ -8997,6 +9304,10 @@ components:
       title: TypeVariant
       type: object
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         cases:
           type: array
           items:
@@ -9250,8 +9561,15 @@ components:
           type: object
           additionalProperties:
             type: string
-        accountId:
+        projectId:
           type: string
+          format: uuid
+        createdBy:
+          type: string
+        wasiConfigVars:
+          type: array
+          items:
+            $ref: '#/components/schemas/WasiConfigVarsEntry'
         parent:
           $ref: '#/components/schemas/WorkerId'
         componentSize:
@@ -9270,7 +9588,9 @@ components:
       - componentVersion
       - args
       - env
-      - accountId
+      - projectId
+      - createdBy
+      - wasiConfigVars
       - componentSize
       - initialTotalLinearMemorySize
       - initialActivePlugins
@@ -9292,27 +9612,6 @@ components:
     DeleteWorkerResponse:
       title: DeleteWorkerResponse
       type: object
-    DescribeResourceParameters:
-      title: DescribeResourceParameters
-      type: object
-      properties:
-        timestamp:
-          type: string
-          format: date-time
-        id:
-          type: integer
-          format: uint64
-        resourceName:
-          type: string
-        resourceParams:
-          type: array
-          items:
-            $ref: '#/components/schemas/ValueAndType'
-      required:
-      - timestamp
-      - id
-      - resourceName
-      - resourceParams
     DomainRequest:
       title: DomainRequest
       type: object
@@ -9440,6 +9739,18 @@ components:
       - traceId
       - traceStates
       - invocationContext
+    ExportedResourceMetadata:
+      title: ExportedResourceMetadata
+      type: object
+      properties:
+        key:
+          type: integer
+          format: uint64
+        description:
+          $ref: '#/components/schemas/WorkerResourceDescription'
+      required:
+      - key
+      - description
     FailedUpdate:
       title: FailedUpdate
       type: object
@@ -9580,6 +9891,7 @@ components:
       - file-server
       - http-handler
       - cors-preflight
+      - swagger-ui
     GetFilesResponse:
       title: GetFilesResponse
       type: object
@@ -9702,27 +10014,14 @@ components:
           $ref: '#/components/schemas/ValueAndType'
         response:
           $ref: '#/components/schemas/ValueAndType'
-        wrappedFunctionType:
+        durableFunctionType:
           $ref: '#/components/schemas/PublicDurableFunctionType'
       required:
       - timestamp
       - functionName
       - request
       - response
-      - wrappedFunctionType
-    IndexedWorkerMetadata:
-      title: IndexedWorkerMetadata
-      type: object
-      properties:
-        resourceName:
-          type: string
-        resourceParams:
-          type: array
-          items:
-            type: string
-      required:
-      - resourceName
-      - resourceParams
+      - durableFunctionType
     InterruptResponse:
       title: InterruptResponse
       type: object
@@ -9744,7 +10043,7 @@ components:
       type: object
       properties:
         result:
-          $ref: '#/components/schemas/TypeAnnotatedValue'
+          $ref: '#/components/schemas/ValueAndType'
     JumpParameters:
       title: JumpParameters
       type: object
@@ -9808,6 +10107,20 @@ components:
       - Options
       - Trace
       - Head
+    OpenApiHttpApiDefinitionResponse:
+      title: OpenApiHttpApiDefinitionResponse
+      type: object
+      properties:
+        id:
+          type: string
+        version:
+          type: string
+        openapi_yaml:
+          type: string
+      required:
+      - id
+      - version
+      - openapi_yaml
     OplogCursor:
       title: OplogCursor
       type: object
@@ -10050,7 +10363,6 @@ components:
           GrowMemory: '#/components/schemas/PublicOplogEntry_GrowMemoryParameters'
           CreateResource: '#/components/schemas/PublicOplogEntry_ResourceParameters'
           DropResource: '#/components/schemas/PublicOplogEntry_ResourceParameters'
-          DescribeResource: '#/components/schemas/PublicOplogEntry_DescribeResourceParameters'
           Log: '#/components/schemas/PublicOplogEntry_LogParameters'
           Restart: '#/components/schemas/PublicOplogEntry_TimestampParameter'
           ActivatePlugin: '#/components/schemas/PublicOplogEntry_ActivatePluginParameters'
@@ -10085,7 +10397,6 @@ components:
       - $ref: '#/components/schemas/PublicOplogEntry_GrowMemoryParameters'
       - $ref: '#/components/schemas/PublicOplogEntry_ResourceParameters'
       - $ref: '#/components/schemas/PublicOplogEntry_ResourceParameters'
-      - $ref: '#/components/schemas/PublicOplogEntry_DescribeResourceParameters'
       - $ref: '#/components/schemas/PublicOplogEntry_LogParameters'
       - $ref: '#/components/schemas/PublicOplogEntry_TimestampParameter'
       - $ref: '#/components/schemas/PublicOplogEntry_ActivatePluginParameters'
@@ -10234,27 +10545,6 @@ components:
         required:
         - type
       - $ref: '#/components/schemas/DeactivatePluginParameters'
-    PublicOplogEntry_DescribeResourceParameters:
-      description: |-
-        A mirror of the core `OplogEntry` type, without the undefined arbitrary payloads.
-
-        Instead, it encodes all payloads with wasm-rpc `Value` types. This makes this the base type
-        for exposing oplog entries through various APIs such as gRPC, REST and WIT.
-
-        The rest of the system will always use `OplogEntry` internally - the only point where the
-        oplog payloads are decoded and re-encoded as `Value` is in this module, and it should only be used
-        before exposing an oplog entry through a public API.
-      allOf:
-      - type: object
-        properties:
-          type:
-            example: DescribeResource
-            type: string
-            enum:
-            - DescribeResource
-        required:
-        - type
-      - $ref: '#/components/schemas/DescribeResourceParameters'
     PublicOplogEntry_EndRegionParameters:
       description: |-
         A mirror of the core `OplogEntry` type, without the undefined arbitrary payloads.
@@ -10771,17 +11061,6 @@ components:
       required:
       - name
       - version
-    ResourceMetadata:
-      title: ResourceMetadata
-      type: object
-      properties:
-        createdAt:
-          type: string
-          format: date-time
-        indexed:
-          $ref: '#/components/schemas/IndexedWorkerMetadata'
-      required:
-      - createdAt
     ResourceParameters:
       title: ResourceParameters
       type: object
@@ -10792,9 +11071,15 @@ components:
         id:
           type: integer
           format: uint64
+        name:
+          type: string
+        owner:
+          type: string
       required:
       - timestamp
       - id
+      - name
+      - owner
     ResumeResponse:
       title: ResumeResponse
       type: object
@@ -11062,15 +11347,6 @@ components:
           format: date-time
       required:
       - timestamp
-    TypeAnnotatedValue:
-      type: object
-      properties:
-        typ:
-          $ref: '#/components/schemas/AnalysedType'
-        value: {}
-      required:
-      - typ
-      - value
     UpdateRecord:
       discriminator:
         propertyName: type
@@ -11151,6 +11427,17 @@ components:
       required:
       - typ
       - value
+    WasiConfigVarsEntry:
+      title: WasiConfigVarsEntry
+      type: object
+      properties:
+        key:
+          type: string
+        value:
+          type: string
+      required:
+      - key
+      - value
     WorkerAndFilter:
       title: WorkerAndFilter
       type: object
@@ -11187,6 +11474,11 @@ components:
           type: object
           additionalProperties:
             type: string
+        wasiConfigVars:
+          default: []
+          type: array
+          items:
+            $ref: '#/components/schemas/WasiConfigVarsEntry'
       required:
       - name
       - args
@@ -11243,6 +11535,7 @@ components:
           And: '#/components/schemas/WorkerFilter_WorkerAndFilter'
           Or: '#/components/schemas/WorkerFilter_WorkerOrFilter'
           Not: '#/components/schemas/WorkerFilter_WorkerNotFilter'
+          WasiConfigVars: '#/components/schemas/WorkerFilter_WorkerWasiConfigVarsFilter'
       type: object
       oneOf:
       - $ref: '#/components/schemas/WorkerFilter_WorkerNameFilter'
@@ -11253,6 +11546,7 @@ components:
       - $ref: '#/components/schemas/WorkerFilter_WorkerAndFilter'
       - $ref: '#/components/schemas/WorkerFilter_WorkerOrFilter'
       - $ref: '#/components/schemas/WorkerFilter_WorkerNotFilter'
+      - $ref: '#/components/schemas/WorkerFilter_WorkerWasiConfigVarsFilter'
     WorkerFilter_WorkerAndFilter:
       allOf:
       - type: object
@@ -11349,6 +11643,18 @@ components:
         required:
         - type
       - $ref: '#/components/schemas/WorkerVersionFilter'
+    WorkerFilter_WorkerWasiConfigVarsFilter:
+      allOf:
+      - type: object
+        properties:
+          type:
+            example: WasiConfigVars
+            type: string
+            enum:
+            - WasiConfigVars
+        required:
+        - type
+      - $ref: '#/components/schemas/WorkerWasiConfigVarsFilter'
     WorkerId:
       title: WorkerId
       type: object
@@ -11367,7 +11673,10 @@ components:
       properties:
         workerId:
           $ref: '#/components/schemas/WorkerId'
-        accountId:
+        projectId:
+          type: string
+          format: uuid
+        createdBy:
           type: string
         args:
           type: array
@@ -11377,6 +11686,10 @@ components:
           type: object
           additionalProperties:
             type: string
+        wasiConfigVars:
+          type: array
+          items:
+            $ref: '#/components/schemas/WasiConfigVarsEntry'
         status:
           $ref: '#/components/schemas/WorkerStatus'
         componentVersion:
@@ -11403,10 +11716,10 @@ components:
         totalLinearMemorySize:
           type: integer
           format: uint64
-        ownedResources:
-          type: object
-          additionalProperties:
-            $ref: '#/components/schemas/ResourceMetadata'
+        exportedResourceInstances:
+          type: array
+          items:
+            $ref: '#/components/schemas/ExportedResourceMetadata'
         activePlugins:
           type: array
           items:
@@ -11427,9 +11740,11 @@ components:
             $ref: '#/components/schemas/OplogRegion'
       required:
       - workerId
-      - accountId
+      - projectId
+      - createdBy
       - args
       - env
+      - wasiConfigVars
       - status
       - componentVersion
       - retryCount
@@ -11438,7 +11753,7 @@ components:
       - createdAt
       - componentSize
       - totalLinearMemorySize
-      - ownedResources
+      - exportedResourceInstances
       - activePlugins
       - skippedRegions
       - deletedRegions
@@ -11471,6 +11786,21 @@ components:
             $ref: '#/components/schemas/WorkerFilter'
       required:
       - filters
+    WorkerResourceDescription:
+      title: WorkerResourceDescription
+      type: object
+      properties:
+        createdAt:
+          type: string
+          format: date-time
+        resourceOwner:
+          type: string
+        resourceName:
+          type: string
+      required:
+      - createdAt
+      - resourceOwner
+      - resourceName
     WorkerStatus:
       description: |-
         Represents last known status of a worker
@@ -11514,6 +11844,20 @@ components:
       required:
       - comparator
       - value
+    WorkerWasiConfigVarsFilter:
+      title: WorkerWasiConfigVarsFilter
+      type: object
+      properties:
+        name:
+          type: string
+        comparator:
+          $ref: '#/components/schemas/StringFilterComparator'
+        value:
+          type: string
+      required:
+      - name
+      - comparator
+      - value
     WorkersMetadataRequest:
       title: WorkersMetadataRequest
       type: object
@@ -11558,6 +11902,8 @@ tags:
 - name: Account
   description: The account API allows users to query and manipulate their own account data.
 - name: AccountSummary
+- name: AgentTypes
+  description: API working on registered agent types
 - name: ApiCertificate
 - name: ApiDefinition
 - name: ApiDeployment
diff --git a/openapi/golem-worker-service.yaml b/openapi/golem-worker-service.yaml
index 0778d56e..184d97a5 100644
--- a/openapi/golem-worker-service.yaml
+++ b/openapi/golem-worker-service.yaml
@@ -7,6 +7,8 @@ tags:
 - name: Account
   description: The account API allows users to query and manipulate their own account data.
 - name: AccountSummary
+- name: AgentTypes
+  description: API working on registered agent types
 - name: ApiCertificate
 - name: ApiDefinition
 - name: ApiDeployment
@@ -521,96 +523,6 @@ paths:
       - Cookie: []
       - Token: []
       operationId: invoke_and_await_function
-  /v1/components/{component_id}/invoke-and-await:
-    post:
-      tags:
-      - Worker
-      summary: Invoke a function and await its resolution on a new worker with a random generated name
-      description: |-
-        Ideal for invoking ephemeral components, but works with durable ones as well.
-        Supply the parameters in the request body as JSON.
-      parameters:
-      - name: component_id
-        schema:
-          type: string
-          format: uuid
-        in: path
-        required: true
-        deprecated: false
-        explode: true
-      - name: Idempotency-Key
-        schema:
-          type: string
-        in: header
-        required: false
-        deprecated: false
-        explode: true
-      - name: function
-        schema:
-          type: string
-        in: query
-        required: true
-        deprecated: false
-        explode: true
-      requestBody:
-        content:
-          application/json; charset=utf-8:
-            schema:
-              $ref: '#/components/schemas/InvokeParameters'
-        required: true
-      responses:
-        '200':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/InvokeResult'
-        '400':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorsBody'
-        '401':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorBody'
-        '403':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorBody'
-        '403':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorBody'
-        '404':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorBody'
-        '409':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorBody'
-        '500':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorBodyWithOptionalWorkerError'
-      security:
-      - Cookie: []
-      - Token: []
-      operationId: invoke_and_await_function_without_name
   /v1/components/{component_id}/workers/{worker_name}/invoke:
     post:
       tags:
@@ -707,97 +619,6 @@ paths:
       - Cookie: []
       - Token: []
       operationId: invoke_function
-  /v1/components/{component_id}/invoke:
-    post:
-      tags:
-      - Worker
-      summary: Invoke a function on a new worker with a random generated name
-      description: |-
-        Ideal for invoking ephemeral components, but works with durable ones as well.
-        A simpler version of the previously defined invoke and await endpoint just triggers the execution of a function and immediately returns.
-      parameters:
-      - name: component_id
-        schema:
-          type: string
-          format: uuid
-        in: path
-        required: true
-        deprecated: false
-        explode: true
-      - name: Idempotency-Key
-        schema:
-          type: string
-        in: header
-        required: false
-        deprecated: false
-        explode: true
-      - name: function
-        schema:
-          type: string
-        in: query
-        description: name of the exported function to be invoked
-        required: true
-        deprecated: false
-        explode: true
-      requestBody:
-        content:
-          application/json; charset=utf-8:
-            schema:
-              $ref: '#/components/schemas/InvokeParameters'
-        required: true
-      responses:
-        '200':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/InvokeResponse'
-        '400':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorsBody'
-        '401':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorBody'
-        '403':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorBody'
-        '403':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorBody'
-        '404':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorBody'
-        '409':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorBody'
-        '500':
-          description: ''
-          content:
-            application/json; charset=utf-8:
-              schema:
-                $ref: '#/components/schemas/ErrorBodyWithOptionalWorkerError'
-      security:
-      - Cookie: []
-      - Token: []
-      operationId: invoke_function_without_name
   /v1/components/{component_id}/workers/{worker_name}/complete:
     post:
       tags:
@@ -2370,6 +2191,88 @@ paths:
       - Cookie: []
       - Token: []
       operationId: delete_definition
+  /v1/api/definitions/{project_id}/{id}/{version}/export:
+    get:
+      tags:
+      - ApiDefinition
+      summary: Export an API definition in OpenAPI format
+      description: Exports an API definition by its API definition ID and version in OpenAPI format.
+      parameters:
+      - name: project_id
+        schema:
+          type: string
+          format: uuid
+        in: path
+        required: true
+        deprecated: false
+        explode: true
+      - name: id
+        schema:
+          type: string
+        in: path
+        required: true
+        deprecated: false
+        explode: true
+      - name: version
+        schema:
+          type: string
+        in: path
+        required: true
+        deprecated: false
+        explode: true
+      responses:
+        '200':
+          description: ''
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/OpenApiHttpApiDefinitionResponse'
+        '400':
+          description: ''
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorsBody'
+        '401':
+          description: ''
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+        '403':
+          description: ''
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+        '403':
+          description: ''
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+        '404':
+          description: ''
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+        '409':
+          description: ''
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBody'
+        '500':
+          description: ''
+          content:
+            application/json; charset=utf-8:
+              schema:
+                $ref: '#/components/schemas/ErrorBodyWithOptionalWorkerError'
+      security:
+      - Cookie: []
+      - Token: []
+      operationId: export_definition
   /v1/api/deployments/deploy:
     post:
       tags:
@@ -3853,7 +3756,9 @@ components:
       - componentVersion
       - args
       - env
-      - accountId
+      - projectId
+      - createdBy
+      - wasiConfigVars
       - componentSize
       - initialTotalLinearMemorySize
       - initialActivePlugins
@@ -3874,8 +3779,15 @@ components:
           type: object
           additionalProperties:
             type: string
-        accountId:
+        projectId:
           type: string
+          format: uuid
+        createdBy:
+          type: string
+        wasiConfigVars:
+          type: array
+          items:
+            $ref: '#/components/schemas/WasiConfigVarsEntry'
         parent:
           $ref: '#/components/schemas/WorkerId'
         componentSize:
@@ -3906,27 +3818,6 @@ components:
     DeleteWorkerResponse:
       type: object
       title: DeleteWorkerResponse
-    DescribeResourceParameters:
-      type: object
-      title: DescribeResourceParameters
-      required:
-      - timestamp
-      - id
-      - resourceName
-      - resourceParams
-      properties:
-        timestamp:
-          type: string
-          format: date-time
-        id:
-          type: integer
-          format: uint64
-        resourceName:
-          type: string
-        resourceParams:
-          type: array
-          items:
-            $ref: '#/components/schemas/ValueAndType'
     DomainRequest:
       type: object
       title: DomainRequest
@@ -4075,6 +3966,18 @@ components:
             type: array
             items:
               $ref: '#/components/schemas/PublicSpanData'
+    ExportedResourceMetadata:
+      type: object
+      title: ExportedResourceMetadata
+      required:
+      - key
+      - description
+      properties:
+        key:
+          type: integer
+          format: uint64
+        description:
+          $ref: '#/components/schemas/WorkerResourceDescription'
     FailedUpdate:
       type: object
       title: FailedUpdate
@@ -4215,6 +4118,7 @@ components:
       - file-server
       - http-handler
       - cors-preflight
+      - swagger-ui
     GetFilesResponse:
       type: object
       title: GetFilesResponse
@@ -4335,7 +4239,7 @@ components:
       - functionName
       - request
       - response
-      - wrappedFunctionType
+      - durableFunctionType
       properties:
         timestamp:
           type: string
@@ -4346,21 +4250,8 @@ components:
           $ref: '#/components/schemas/ValueAndType'
         response:
           $ref: '#/components/schemas/ValueAndType'
-        wrappedFunctionType:
+        durableFunctionType:
           $ref: '#/components/schemas/PublicDurableFunctionType'
-    IndexedWorkerMetadata:
-      type: object
-      title: IndexedWorkerMetadata
-      required:
-      - resourceName
-      - resourceParams
-      properties:
-        resourceName:
-          type: string
-        resourceParams:
-          type: array
-          items:
-            type: string
     InterruptResponse:
       type: object
       title: InterruptResponse
@@ -4382,7 +4273,7 @@ components:
       title: InvokeResult
       properties:
         result:
-          $ref: '#/components/schemas/TypeAnnotatedValue'
+          $ref: '#/components/schemas/ValueAndType'
     JumpParameters:
       type: object
       title: JumpParameters
@@ -4467,6 +4358,20 @@ components:
           type: string
         typ:
           $ref: '#/components/schemas/AnalysedType'
+    OpenApiHttpApiDefinitionResponse:
+      type: object
+      title: OpenApiHttpApiDefinitionResponse
+      required:
+      - id
+      - version
+      - openapi_yaml
+      properties:
+        id:
+          type: string
+        version:
+          type: string
+        openapi_yaml:
+          type: string
     OplogCursor:
       type: object
       title: OplogCursor
@@ -4708,7 +4613,6 @@ components:
       - $ref: '#/components/schemas/PublicOplogEntry_GrowMemoryParameters'
       - $ref: '#/components/schemas/PublicOplogEntry_ResourceParameters'
       - $ref: '#/components/schemas/PublicOplogEntry_ResourceParameters'
-      - $ref: '#/components/schemas/PublicOplogEntry_DescribeResourceParameters'
       - $ref: '#/components/schemas/PublicOplogEntry_LogParameters'
       - $ref: '#/components/schemas/PublicOplogEntry_TimestampParameter'
       - $ref: '#/components/schemas/PublicOplogEntry_ActivatePluginParameters'
@@ -4744,7 +4648,6 @@ components:
           GrowMemory: '#/components/schemas/PublicOplogEntry_GrowMemoryParameters'
           CreateResource: '#/components/schemas/PublicOplogEntry_ResourceParameters'
           DropResource: '#/components/schemas/PublicOplogEntry_ResourceParameters'
-          DescribeResource: '#/components/schemas/PublicOplogEntry_DescribeResourceParameters'
           Log: '#/components/schemas/PublicOplogEntry_LogParameters'
           Restart: '#/components/schemas/PublicOplogEntry_TimestampParameter'
           ActivatePlugin: '#/components/schemas/PublicOplogEntry_ActivatePluginParameters'
@@ -4893,27 +4796,6 @@ components:
             - DeactivatePlugin
             example: DeactivatePlugin
       - $ref: '#/components/schemas/DeactivatePluginParameters'
-    PublicOplogEntry_DescribeResourceParameters:
-      description: |-
-        A mirror of the core `OplogEntry` type, without the undefined arbitrary payloads.
-
-        Instead, it encodes all payloads with wasm-rpc `Value` types. This makes this the base type
-        for exposing oplog entries through various APIs such as gRPC, REST and WIT.
-
-        The rest of the system will always use `OplogEntry` internally - the only point where the
-        oplog payloads are decoded and re-encoded as `Value` is in this module, and it should only be used
-        before exposing an oplog entry through a public API.
-      allOf:
-      - type: object
-        required:
-        - type
-        properties:
-          type:
-            type: string
-            enum:
-            - DescribeResource
-            example: DescribeResource
-      - $ref: '#/components/schemas/DescribeResourceParameters'
     PublicOplogEntry_EndRegionParameters:
       description: |-
         A mirror of the core `OplogEntry` type, without the undefined arbitrary payloads.
@@ -5430,23 +5312,14 @@ components:
         version:
           type: integer
           format: uint64
-    ResourceMetadata:
-      type: object
-      title: ResourceMetadata
-      required:
-      - createdAt
-      properties:
-        createdAt:
-          type: string
-          format: date-time
-        indexed:
-          $ref: '#/components/schemas/IndexedWorkerMetadata'
     ResourceParameters:
       type: object
       title: ResourceParameters
       required:
       - timestamp
       - id
+      - name
+      - owner
       properties:
         timestamp:
           type: string
@@ -5454,6 +5327,10 @@ components:
         id:
           type: integer
           format: uint64
+        name:
+          type: string
+        owner:
+          type: string
     ResumeResponse:
       type: object
       title: ResumeResponse
@@ -5721,15 +5598,6 @@ components:
         timestamp:
           type: string
           format: date-time
-    TypeAnnotatedValue:
-      type: object
-      required:
-      - typ
-      - value
-      properties:
-        typ:
-          $ref: '#/components/schemas/AnalysedType'
-        value: {}
     TypeBool:
       type: object
       title: TypeBool
@@ -5742,6 +5610,10 @@ components:
       required:
       - cases
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         cases:
           type: array
           items:
@@ -5758,6 +5630,10 @@ components:
       required:
       - names
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         names:
           type: array
           items:
@@ -5769,6 +5645,10 @@ components:
       - resource_id
       - mode
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         resource_id:
           type: integer
           format: uint64
@@ -5780,6 +5660,10 @@ components:
       required:
       - inner
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         inner:
           $ref: '#/components/schemas/AnalysedType'
     TypeOption:
@@ -5788,6 +5672,10 @@ components:
       required:
       - inner
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         inner:
           $ref: '#/components/schemas/AnalysedType'
     TypeRecord:
@@ -5796,6 +5684,10 @@ components:
       required:
       - fields
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         fields:
           type: array
           items:
@@ -5804,6 +5696,10 @@ components:
       type: object
       title: TypeResult
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         ok:
           $ref: '#/components/schemas/AnalysedType'
         err:
@@ -5829,6 +5725,10 @@ components:
       required:
       - items
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         items:
           type: array
           items:
@@ -5851,6 +5751,10 @@ components:
       required:
       - cases
       properties:
+        name:
+          type: string
+        owner:
+          type: string
         cases:
           type: array
           items:
@@ -5943,6 +5847,17 @@ components:
       properties:
         version:
           type: string
+    WasiConfigVarsEntry:
+      type: object
+      title: WasiConfigVarsEntry
+      required:
+      - key
+      - value
+      properties:
+        key:
+          type: string
+        value:
+          type: string
     WorkerAndFilter:
       type: object
       title: WorkerAndFilter
@@ -5983,6 +5898,11 @@ components:
           type: object
           additionalProperties:
             type: string
+        wasiConfigVars:
+          type: array
+          default: []
+          items:
+            $ref: '#/components/schemas/WasiConfigVarsEntry'
     WorkerCreationResponse:
       type: object
       title: WorkerCreationResponse
@@ -6034,6 +5954,7 @@ components:
       - $ref: '#/components/schemas/WorkerFilter_WorkerAndFilter'
       - $ref: '#/components/schemas/WorkerFilter_WorkerOrFilter'
       - $ref: '#/components/schemas/WorkerFilter_WorkerNotFilter'
+      - $ref: '#/components/schemas/WorkerFilter_WorkerWasiConfigVarsFilter'
       discriminator:
         propertyName: type
         mapping:
@@ -6045,6 +5966,7 @@ components:
           And: '#/components/schemas/WorkerFilter_WorkerAndFilter'
           Or: '#/components/schemas/WorkerFilter_WorkerOrFilter'
           Not: '#/components/schemas/WorkerFilter_WorkerNotFilter'
+          WasiConfigVars: '#/components/schemas/WorkerFilter_WorkerWasiConfigVarsFilter'
     WorkerFilter_WorkerAndFilter:
       allOf:
       - type: object
@@ -6141,6 +6063,18 @@ components:
             - Version
             example: Version
       - $ref: '#/components/schemas/WorkerVersionFilter'
+    WorkerFilter_WorkerWasiConfigVarsFilter:
+      allOf:
+      - type: object
+        required:
+        - type
+        properties:
+          type:
+            type: string
+            enum:
+            - WasiConfigVars
+            example: WasiConfigVars
+      - $ref: '#/components/schemas/WorkerWasiConfigVarsFilter'
     WorkerId:
       type: object
       title: WorkerId
@@ -6158,9 +6092,11 @@ components:
       title: WorkerMetadata
       required:
       - workerId
-      - accountId
+      - projectId
+      - createdBy
       - args
       - env
+      - wasiConfigVars
       - status
       - componentVersion
       - retryCount
@@ -6169,14 +6105,17 @@ components:
       - createdAt
       - componentSize
       - totalLinearMemorySize
-      - ownedResources
+      - exportedResourceInstances
       - activePlugins
       - skippedRegions
       - deletedRegions
       properties:
         workerId:
           $ref: '#/components/schemas/WorkerId'
-        accountId:
+        projectId:
+          type: string
+          format: uuid
+        createdBy:
           type: string
         args:
           type: array
@@ -6186,6 +6125,10 @@ components:
           type: object
           additionalProperties:
             type: string
+        wasiConfigVars:
+          type: array
+          items:
+            $ref: '#/components/schemas/WasiConfigVarsEntry'
         status:
           $ref: '#/components/schemas/WorkerStatus'
         componentVersion:
@@ -6212,10 +6155,10 @@ components:
         totalLinearMemorySize:
           type: integer
           format: uint64
-        ownedResources:
-          type: object
-          additionalProperties:
-            $ref: '#/components/schemas/ResourceMetadata'
+        exportedResourceInstances:
+          type: array
+          items:
+            $ref: '#/components/schemas/ExportedResourceMetadata'
         activePlugins:
           type: array
           items:
@@ -6263,6 +6206,21 @@ components:
           type: array
           items:
             $ref: '#/components/schemas/WorkerFilter'
+    WorkerResourceDescription:
+      type: object
+      title: WorkerResourceDescription
+      required:
+      - createdAt
+      - resourceOwner
+      - resourceName
+      properties:
+        createdAt:
+          type: string
+          format: date-time
+        resourceOwner:
+          type: string
+        resourceName:
+          type: string
     WorkerStatus:
       type: string
       description: |-
@@ -6306,6 +6264,20 @@ components:
         value:
           type: integer
           format: uint64
+    WorkerWasiConfigVarsFilter:
+      type: object
+      title: WorkerWasiConfigVarsFilter
+      required:
+      - name
+      - comparator
+      - value
+      properties:
+        name:
+          type: string
+        comparator:
+          $ref: '#/components/schemas/StringFilterComparator'
+        value:
+          type: string
     WorkersMetadataRequest:
       type: object
       title: WorkersMetadataRequest
diff --git a/wasm-ast/src/analysis/mod.rs b/wasm-ast/src/analysis/mod.rs
index eb18de80..3f3d2e0e 100644
--- a/wasm-ast/src/analysis/mod.rs
+++ b/wasm-ast/src/analysis/mod.rs
@@ -32,7 +32,6 @@ use crate::core::Mem;
 use crate::AstCustomization;
 use mappable_rc::Mrc;
 use std::cell::RefCell;
-use std::collections::HashMap;
 use std::fmt::Debug;
 use std::rc::Rc;
 
@@ -41,16 +40,12 @@ pub type AnalysisResult<A> = Result<A, AnalysisFailure>;
 #[derive(Debug, Clone)]
 struct ComponentStackItem<Ast: AstCustomization + 'static> {
     component: Mrc<Component<Ast>>,
-    component_idx: Option<ComponentIdx>,
 }
 
-type ResourceIdMap = HashMap<(Vec<ComponentIdx>, ComponentTypeIdx), AnalysedResourceId>;
-
 #[derive(Debug, Clone)]
 pub struct AnalysisContext<Ast: AstCustomization + 'static> {
     component_stack: Vec<ComponentStackItem<Ast>>,
     warnings: Rc<RefCell<Vec<AnalysisWarning>>>,
-    resource_ids: Rc<RefCell<ResourceIdMap>>,
 }
 
 impl<Ast: AstCustomization + 'static> AnalysisContext<Ast> {
@@ -61,43 +56,11 @@ impl<Ast: AstCustomization + 'static> AnalysisContext<Ast> {
     /// Initializes an analyzer for a given component
     pub fn from_rc(component: Mrc<Component<Ast>>) -> AnalysisContext<Ast> {
         AnalysisContext {
-            component_stack: vec![ComponentStackItem {
-                component,
-                component_idx: None,
-            }],
+            component_stack: vec![ComponentStackItem { component }],
             warnings: Rc::new(RefCell::new(Vec::new())),
-            resource_ids: Rc::new(RefCell::new(HashMap::new())),
         }
     }
 
-    /// Get all top-level exports from the component with all the type information gathered from
-    /// the component AST.
-    pub fn get_top_level_exports(&self) -> AnalysisResult<Vec<AnalysedExport>> {
-        let component = self.get_component();
-        let mut result = Vec::new();
-        for export in component.exports() {
-            match export.kind {
-                ComponentExternalKind::Func => {
-                    let export = self.analyse_func_export(export.name.as_string(), export.idx)?;
-                    result.push(AnalysedExport::Function(export));
-                }
-                ComponentExternalKind::Instance => {
-                    let instance =
-                        self.analyse_instance_export(export.name.as_string(), export.idx)?;
-                    result.push(AnalysedExport::Instance(instance));
-                }
-                _ => self.warning(AnalysisWarning::UnsupportedExport(
-                    UnsupportedExportWarning {
-                        kind: export.kind.clone(),
-                        name: export.name.as_string(),
-                    },
-                )),
-            }
-        }
-
-        Ok(result)
-    }
-
     /// Gets all the memories (not just the exported ones) from all modules within the WASM component
     pub fn get_all_memories(&self) -> AnalysisResult<Vec<Mem>> {
         let mut result = Vec::new();
@@ -120,574 +83,9 @@ impl<Ast: AstCustomization + 'static> AnalysisContext<Ast> {
         self.warnings.borrow().clone()
     }
 
-    fn warning(&self, warning: AnalysisWarning) {
-        self.warnings.borrow_mut().push(warning);
-    }
-
-    fn get_resource_id(&self, type_idx: &ComponentTypeIdx) -> AnalysedResourceId {
-        let new_unique_id = self.resource_ids.borrow().len() as u64;
-        let mut resource_ids = self.resource_ids.borrow_mut();
-        let path = self
-            .component_stack
-            .iter()
-            .filter_map(|item| item.component_idx)
-            .collect();
-        let key = (path, *type_idx);
-        resource_ids
-            .entry(key)
-            .or_insert_with(|| {
-                AnalysedResourceId(new_unique_id) // We don't to associate all IDs in each component, so this simple method can always generate a unique one
-            })
-            .clone()
-    }
-
-    fn analyse_func_export(
-        &self,
-        name: String,
-        idx: ComponentFuncIdx,
-    ) -> AnalysisResult<AnalysedFunction> {
-        let (function_section, next_ctx) = self
-            .get_final_referenced(format!("component function {idx}"), |component| {
-                component.get_component_func(idx)
-            })?;
-        let (func_type_section, next_ctx) = match &*function_section {
-            ComponentSection::Canon(Canon::Lift { function_type, .. }) => next_ctx
-                .get_final_referenced(
-                    format!("component function type {function_type}"),
-                    |component| component.get_component_type(*function_type),
-                ),
-            ComponentSection::Import(ComponentImport {
-                desc: ComponentTypeRef::Func(func_type_idx),
-                ..
-            }) => next_ctx.get_final_referenced(
-                format!("component function type {func_type_idx}"),
-                |component| component.get_component_type(*func_type_idx),
-            ),
-            ComponentSection::Import(ComponentImport { desc, .. }) => Err(AnalysisFailure::failed(
-                format!("Expected function import, but got {desc:?} instead"),
-            )),
-            _ => Err(AnalysisFailure::failed(format!(
-                "Expected canonical lift function or function import, but got {} instead",
-                function_section.type_name()
-            ))),
-        }?;
-        match &*func_type_section {
-            ComponentSection::Type(ComponentType::Func(func_type)) => {
-                next_ctx.analyse_component_func_type(name, func_type)
-            }
-            _ => Err(AnalysisFailure::failed(format!(
-                "Expected function type, but got {} instead",
-                func_type_section.type_name()
-            ))),
-        }
-    }
-
-    fn analyse_component_func_type(
-        &self,
-        name: String,
-        func_type: &ComponentFuncType,
-    ) -> AnalysisResult<AnalysedFunction> {
-        let mut params: Vec<AnalysedFunctionParameter> = Vec::new();
-        for (param_name, param_type) in &func_type.params {
-            params.push(AnalysedFunctionParameter {
-                name: param_name.clone(),
-                typ: self.analyse_component_val_type(param_type)?,
-            })
-        }
-
-        let result: Option<AnalysedFunctionResult> = func_type
-            .result
-            .as_ref()
-            .map(|tpe| {
-                self.analyse_component_val_type(tpe)
-                    .map(|typ| AnalysedFunctionResult { typ })
-            })
-            .transpose()?;
-
-        Ok(AnalysedFunction {
-            name,
-            parameters: params,
-            result,
-        })
-    }
-
-    fn analyse_component_type_idx(
-        &self,
-        component_type_idx: &ComponentTypeIdx,
-        analysed_resource_mode: Option<AnalysedResourceMode>,
-    ) -> AnalysisResult<AnalysedType> {
-        let (component_type_section, next_ctx) = self.get_final_referenced(
-            format!("component type {component_type_idx}"),
-            |component| component.get_component_type(*component_type_idx),
-        )?;
-        match &*component_type_section {
-            ComponentSection::Type(ComponentType::Defined(component_defined_type)) => {
-                next_ctx.analyse_component_defined_type(component_defined_type)
-            }
-            ComponentSection::Type(ComponentType::Func(_)) => Err(AnalysisFailure::failed(
-                "Passing functions in exported functions is not supported",
-            )),
-            ComponentSection::Type(ComponentType::Component(_)) => Err(AnalysisFailure::failed(
-                "Passing components in exported functions is not supported",
-            )),
-            ComponentSection::Type(ComponentType::Instance(_)) => Err(AnalysisFailure::failed(
-                "Passing instances in exported functions is not supported",
-            )),
-            ComponentSection::Type(ComponentType::Resource { .. }) => Err(AnalysisFailure::failed(
-                "Passing resources in exported functions is not supported",
-            )),
-            ComponentSection::Import(ComponentImport { desc, .. }) => match desc {
-                ComponentTypeRef::Type(TypeBounds::Eq(component_type_idx)) => {
-                    self.analyse_component_type_idx(component_type_idx, analysed_resource_mode)
-                }
-                ComponentTypeRef::Type(TypeBounds::SubResource) => {
-                    match analysed_resource_mode {
-                        Some(resource_mode) => {
-                            let id = next_ctx.get_resource_id(component_type_idx);
-                            Ok(AnalysedType::Handle(TypeHandle {
-                                resource_id: id,
-                                mode: resource_mode,
-                            }))
-                        }
-                        None => Err(AnalysisFailure::failed("Reached a sub-resource type bound without a surrounding borrowed/owned resource type")),
-                    }
-                }
-                _ => Err(AnalysisFailure::failed(format!(
-                    "Imports {desc:?} is not supported as a defined type"
-                ))),
-            },
-            _ => Err(AnalysisFailure::failed(format!(
-                "Expected component type, but got {} instead",
-                component_type_section.type_name()
-            ))),
-        }
-    }
-
-    fn analyse_component_val_type(&self, tpe: &ComponentValType) -> AnalysisResult<AnalysedType> {
-        match tpe {
-            ComponentValType::Primitive(primitive_value_type) => Ok(primitive_value_type.into()),
-            ComponentValType::Defined(component_type_idx) => {
-                self.analyse_component_type_idx(component_type_idx, None)
-            }
-        }
-    }
-
-    fn analyse_component_defined_type(
-        &self,
-        defined_type: &ComponentDefinedType,
-    ) -> AnalysisResult<AnalysedType> {
-        match defined_type {
-            ComponentDefinedType::Primitive { typ } => Ok(typ.into()),
-            ComponentDefinedType::Record { fields } => {
-                let mut result = Vec::new();
-                for (name, typ) in fields {
-                    result.push(NameTypePair {
-                        name: name.clone(),
-                        typ: self.analyse_component_val_type(typ)?,
-                    });
-                }
-                Ok(AnalysedType::Record(TypeRecord { fields: result }))
-            }
-            ComponentDefinedType::Variant { cases } => {
-                let mut result = Vec::new();
-                for case in cases {
-                    result.push(NameOptionTypePair {
-                        name: case.name.clone(),
-                        typ: case
-                            .typ
-                            .as_ref()
-                            .map(|t| self.analyse_component_val_type(t))
-                            .transpose()?,
-                    });
-                }
-                Ok(AnalysedType::Variant(TypeVariant { cases: result }))
-            }
-            ComponentDefinedType::List { elem } => Ok(AnalysedType::List(TypeList {
-                inner: Box::new(self.analyse_component_val_type(elem)?),
-            })),
-            ComponentDefinedType::Tuple { elems } => {
-                let mut result = Vec::new();
-                for elem in elems {
-                    result.push(self.analyse_component_val_type(elem)?);
-                }
-                Ok(AnalysedType::Tuple(TypeTuple { items: result }))
-            }
-            ComponentDefinedType::Flags { names } => Ok(AnalysedType::Flags(TypeFlags {
-                names: names.clone(),
-            })),
-            ComponentDefinedType::Enum { names } => Ok(AnalysedType::Enum(TypeEnum {
-                cases: names.clone(),
-            })),
-            ComponentDefinedType::Option { typ } => Ok(AnalysedType::Option(TypeOption {
-                inner: Box::new(self.analyse_component_val_type(typ)?),
-            })),
-            ComponentDefinedType::Result { ok, err } => Ok(AnalysedType::Result(TypeResult {
-                ok: ok
-                    .as_ref()
-                    .map(|t| self.analyse_component_val_type(t).map(Box::new))
-                    .transpose()?,
-                err: err
-                    .as_ref()
-                    .map(|t| self.analyse_component_val_type(t).map(Box::new))
-                    .transpose()?,
-            })),
-            ComponentDefinedType::Owned { type_idx } => {
-                self.analyse_component_type_idx(type_idx, Some(AnalysedResourceMode::Owned))
-            }
-            ComponentDefinedType::Borrowed { type_idx } => {
-                self.analyse_component_type_idx(type_idx, Some(AnalysedResourceMode::Borrowed))
-            }
-            ComponentDefinedType::Future { .. } => Err(AnalysisFailure::failed(
-                "Future types are not supported yet",
-            )),
-            ComponentDefinedType::Stream { .. } => Err(AnalysisFailure::failed(
-                "Stream types are not supported yet",
-            )),
-        }
-    }
-
-    fn analyse_instance_export(
-        &self,
-        name: String,
-        idx: InstanceIdx,
-    ) -> AnalysisResult<AnalysedInstance> {
-        let (instance_section, next_ctx) = self
-            .get_final_referenced(format!("instance {idx}"), |component| {
-                component.get_instance_wrapped(idx)
-            })?;
-        match &*instance_section {
-            ComponentSection::Instance(instance) => match instance {
-                ComponentInstance::Instantiate { component_idx, .. } => {
-                    let (component_section, next_ctx) = next_ctx.get_final_referenced(
-                        format!("component {component_idx}"),
-                        |component| component.get_component(*component_idx),
-                    )?;
-
-                    match &*component_section {
-                        ComponentSection::Component(referenced_component) => {
-                            let next_ctx = next_ctx.push_component(
-                                Mrc::map(component_section.clone(), |c| c.as_component()),
-                                *component_idx,
-                            );
-                            let mut funcs = Vec::new();
-                            for export in referenced_component.exports() {
-                                match export.kind {
-                                    ComponentExternalKind::Func => {
-                                        let func = next_ctx.analyse_func_export(
-                                            export.name.as_string(),
-                                            export.idx,
-                                        )?;
-                                        funcs.push(func);
-                                    }
-                                    _ => next_ctx.warning(AnalysisWarning::UnsupportedExport(
-                                        UnsupportedExportWarning {
-                                            kind: export.kind.clone(),
-                                            name: export.name.as_string(),
-                                        },
-                                    )),
-                                }
-                            }
-
-                            Ok(AnalysedInstance {
-                                name,
-                                functions: funcs,
-                            })
-                        }
-                        _ => Err(AnalysisFailure::failed(format!(
-                            "Expected component, but got {} instead",
-                            component_section.type_name()
-                        ))),
-                    }
-                }
-                ComponentInstance::FromExports { .. } => Err(AnalysisFailure::failed(
-                    "Instance defined directly from exports are not supported",
-                )),
-            },
-            _ => Err(AnalysisFailure::failed(format!(
-                "Expected instance, but got {} instead",
-                instance_section.type_name()
-            ))),
-        }
-    }
-
     fn get_component(&self) -> Mrc<Component<Ast>> {
         self.component_stack.last().unwrap().component.clone()
     }
-
-    fn get_components_from_stack(&self, count: u32) -> Vec<ComponentStackItem<Ast>> {
-        self.component_stack
-            .iter()
-            .skip(self.component_stack.len() - count as usize - 1)
-            .cloned()
-            .collect()
-    }
-
-    fn push_component(
-        &self,
-        component: Mrc<Component<Ast>>,
-        component_idx: ComponentIdx,
-    ) -> AnalysisContext<Ast> {
-        let mut component_stack = self.component_stack.clone();
-        component_stack.push(ComponentStackItem {
-            component,
-            component_idx: Some(component_idx),
-        });
-        self.with_component_stack(component_stack)
-    }
-
-    fn with_component_stack(
-        &self,
-        component_stack: Vec<ComponentStackItem<Ast>>,
-    ) -> AnalysisContext<Ast> {
-        AnalysisContext {
-            component_stack,
-            warnings: self.warnings.clone(),
-            resource_ids: self.resource_ids.clone(),
-        }
-    }
-
-    fn get_final_referenced<F>(
-        &self,
-        description: impl AsRef<str>,
-        f: F,
-    ) -> AnalysisResult<(Mrc<ComponentSection<Ast>>, AnalysisContext<Ast>)>
-    where
-        F: Fn(&Component<Ast>) -> Option<Mrc<ComponentSection<Ast>>>,
-    {
-        let component = self.get_component();
-        let direct_section = AnalysisFailure::fail_on_missing(f(&component), description)?;
-        self.follow_redirects(direct_section)
-    }
-
-    fn follow_redirects(
-        &self,
-        section: Mrc<ComponentSection<Ast>>,
-    ) -> AnalysisResult<(Mrc<ComponentSection<Ast>>, AnalysisContext<Ast>)> {
-        let component = self.get_component();
-        match &*section {
-            ComponentSection::Export(ComponentExport { kind, idx, .. }) => {
-                let next = match kind {
-                    ComponentExternalKind::Module => AnalysisFailure::fail_on_missing(
-                        component.get_module(*idx),
-                        format!("module {idx}"),
-                    )?,
-                    ComponentExternalKind::Func => AnalysisFailure::fail_on_missing(
-                        component.get_component_func(*idx),
-                        format!("function {idx}"),
-                    )?,
-                    ComponentExternalKind::Value => AnalysisFailure::fail_on_missing(
-                        component.get_value(*idx),
-                        format!("value {idx}"),
-                    )?,
-                    ComponentExternalKind::Type => AnalysisFailure::fail_on_missing(
-                        component.get_component_type(*idx),
-                        format!("type {idx}"),
-                    )?,
-                    ComponentExternalKind::Instance => AnalysisFailure::fail_on_missing(
-                        component.get_instance_wrapped(*idx),
-                        format!("instance {idx}"),
-                    )?,
-                    ComponentExternalKind::Component => AnalysisFailure::fail_on_missing(
-                        component.get_component(*idx),
-                        format!("component {idx}"),
-                    )?,
-                };
-                self.follow_redirects(next)
-            }
-            ComponentSection::Alias(Alias::InstanceExport {
-                instance_idx, name, ..
-            }) => {
-                let (instance_section, next_ctx) = self
-                    .get_final_referenced(format!("instance {instance_idx}"), |component| {
-                        component.get_instance_wrapped(*instance_idx)
-                    })?;
-                next_ctx.find_instance_export(instance_section, name)
-            }
-            ComponentSection::Import(ComponentImport {
-                desc: ComponentTypeRef::Type(TypeBounds::Eq(idx)),
-                ..
-            }) => {
-                let maybe_tpe = component.get_component_type(*idx);
-                let tpe = AnalysisFailure::fail_on_missing(maybe_tpe, format!("type {idx}"))?;
-                self.follow_redirects(tpe)
-            }
-            ComponentSection::Alias(Alias::Outer {
-                kind,
-                target: AliasTarget { count, index },
-            }) => {
-                let referenced_components = self.get_components_from_stack(*count);
-                let referenced_component = referenced_components
-                    .first()
-                    .ok_or(AnalysisFailure::failed(format!(
-                        "Component stack underflow (count={count}, size={}",
-                        self.component_stack.len()
-                    )))?
-                    .component
-                    .clone();
-                match kind {
-                    OuterAliasKind::CoreModule => Err(AnalysisFailure::failed(
-                        "Core module aliases are not supported",
-                    )),
-                    OuterAliasKind::CoreType => Err(AnalysisFailure::failed(
-                        "Core type aliases are not supported",
-                    )),
-                    OuterAliasKind::Type => {
-                        let maybe_tpe = referenced_component.get_component_type(*index);
-                        let tpe =
-                            AnalysisFailure::fail_on_missing(maybe_tpe, format!("type {index}"))?;
-                        let next_ctx = self.with_component_stack(referenced_components);
-                        next_ctx.follow_redirects(tpe)
-                    }
-                    OuterAliasKind::Component => {
-                        let maybe_component = referenced_component.get_component(*index);
-                        let component = AnalysisFailure::fail_on_missing(
-                            maybe_component,
-                            format!("component {index}"),
-                        )?;
-                        let next_ctx = self.with_component_stack(referenced_components);
-                        next_ctx.follow_redirects(component)
-                    }
-                }
-            }
-            // TODO: support other redirections if needed
-            _ => Ok((section, self.clone())),
-        }
-    }
-
-    fn find_instance_export(
-        &self,
-        instance_section: Mrc<ComponentSection<Ast>>,
-        name: &String,
-    ) -> AnalysisResult<(Mrc<ComponentSection<Ast>>, AnalysisContext<Ast>)> {
-        match &*instance_section {
-            ComponentSection::Instance(_) => {
-                let instance = Mrc::map(instance_section, |s| s.as_instance());
-                let (maybe_export, next_ctx) = self.find_export_by_name(&instance, name)?;
-                let export = AnalysisFailure::fail_on_missing(
-                    maybe_export,
-                    format!("missing aliased instance export {name} from instance"),
-                )?;
-                let wrapped = Mrc::new(ComponentSection::Export((*export).clone()));
-                next_ctx.follow_redirects(wrapped)
-            }
-            ComponentSection::Import(ComponentImport {
-                desc: ComponentTypeRef::Instance(type_idx),
-                ..
-            }) => {
-                let maybe_tpe = self.get_component().get_component_type(*type_idx);
-                let tpe = AnalysisFailure::fail_on_missing(maybe_tpe, format!("type {type_idx}"))?;
-                let (tpe, next_ctx) = self.follow_redirects(tpe)?;
-                next_ctx.find_instance_export(tpe, name)
-            }
-            ComponentSection::Type(ComponentType::Instance(decls)) => {
-                match decls.find_export(name) {
-                    Some(decl) => {
-                        match decl {
-                            ComponentTypeRef::Module(type_idx) => {
-                                let maybe_tpe = self.get_component().get_component_type(*type_idx);
-                                let tpe = AnalysisFailure::fail_on_missing(
-                                    maybe_tpe,
-                                    format!("type {type_idx}"),
-                                )?;
-                                self.follow_redirects(tpe)
-                            }
-                            ComponentTypeRef::Func(type_idx) => {
-                                let maybe_tpe = self.get_component().get_component_type(*type_idx);
-                                let tpe = AnalysisFailure::fail_on_missing(
-                                    maybe_tpe,
-                                    format!("type {type_idx}"),
-                                )?;
-                                self.follow_redirects(tpe)
-                            }
-                            ComponentTypeRef::Val(_val_type) => {
-                                todo!()
-                            }
-                            ComponentTypeRef::Type(type_bounds) => {
-                                match type_bounds {
-                                    TypeBounds::Eq(component_type_idx) => {
-                                        let decl = decls.get_component_type(*component_type_idx);
-                                        let decl = AnalysisFailure::fail_on_missing(decl, format!("type {component_type_idx}"))?;
-
-                                        match decl {
-                                            InstanceTypeDeclaration::Core(_) => {
-                                                Err(AnalysisFailure::failed("Core type aliases are not supported"))
-                                            }
-                                            InstanceTypeDeclaration::Type(component_type) => {
-                                                Ok((Mrc::new(ComponentSection::Type(component_type.clone())), self.clone()))
-                                            }
-                                            InstanceTypeDeclaration::Alias(alias) => {
-                                                let component_idx = self.component_stack.last().expect("Component stack is empty").component_idx.unwrap_or_default();
-                                                let new_ctx = self.push_component(self.get_component(), component_idx);
-                                                // Emulating an inner scope by duplicating the current component on the stack (TODO: refactor this)
-                                                // Note: because we not in an inner component, but an inner instance declaration and the current analysis stack
-                                                //       does not have this concept.
-                                                new_ctx.follow_redirects(Mrc::new(ComponentSection::Alias(alias.clone())))
-                                            }
-                                            InstanceTypeDeclaration::Export { .. } => {
-                                                todo!()
-                                            }
-                                        }
-                                    }
-                                    TypeBounds::SubResource => {
-                                        Err(AnalysisFailure::failed("Reached a sub-resource type bound without a surrounding borrowed/owned resource type in find_instance_export"))
-                                    }
-                                }
-                            }
-                            ComponentTypeRef::Instance(type_idx) => {
-                                let maybe_tpe = self.get_component().get_component_type(*type_idx);
-                                let tpe = AnalysisFailure::fail_on_missing(
-                                    maybe_tpe,
-                                    format!("type {type_idx}"),
-                                )?;
-                                self.follow_redirects(tpe)
-                            }
-                            ComponentTypeRef::Component(type_idx) => {
-                                let maybe_tpe = self.get_component().get_component_type(*type_idx);
-                                let tpe = AnalysisFailure::fail_on_missing(
-                                    maybe_tpe,
-                                    format!("type {type_idx}"),
-                                )?;
-                                self.follow_redirects(tpe)
-                            }
-                        }
-                    }
-                    None => Err(AnalysisFailure::failed(format!(
-                        "Could not find exported element {name} in instance type declaration"
-                    ))),
-                }
-            }
-            _ => Err(AnalysisFailure::failed(format!(
-                "Expected instance or imported instance, but got {} instead",
-                instance_section.type_name()
-            ))),
-        }
-    }
-
-    fn find_export_by_name(
-        &self,
-        instance: &ComponentInstance,
-        name: &String,
-    ) -> AnalysisResult<(Option<Mrc<ComponentExport>>, AnalysisContext<Ast>)> {
-        match instance {
-            ComponentInstance::Instantiate { component_idx, .. } => {
-                let (component, next_ctx) = self
-                    .get_final_referenced(format!("component {component_idx}"), |component| {
-                        component.get_component(*component_idx)
-                    })?;
-                let component = Mrc::map(component, |c| c.as_component());
-                let export = component
-                    .exports()
-                    .iter()
-                    .find(|export| export.name == *name)
-                    .cloned();
-                Ok((export, next_ctx.push_component(component, *component_idx)))
-            }
-            ComponentInstance::FromExports { exports } => {
-                let export = exports.iter().find(|export| export.name == *name).cloned();
-                Ok((export.map(Mrc::new), self.clone()))
-            }
-        }
-    }
 }
 
 #[cfg(test)]
diff --git a/wasm-ast/src/analysis/wave.rs b/wasm-ast/src/analysis/wave.rs
index c8c6d80a..871983a0 100644
--- a/wasm-ast/src/analysis/wave.rs
+++ b/wasm-ast/src/analysis/wave.rs
@@ -35,7 +35,7 @@ impl WasmType for AnalysedType {
     }
 
     fn list_element_type(&self) -> Option<Self> {
-        if let AnalysedType::List(TypeList { inner: ty }) = self {
+        if let AnalysedType::List(TypeList { inner: ty, .. }) = self {
             Some(*ty.clone())
         } else {
             None
@@ -43,7 +43,7 @@ impl WasmType for AnalysedType {
     }
 
     fn record_fields(&self) -> Box<dyn Iterator<Item = (Cow<'_, str>, Self)> + '_> {
-        if let AnalysedType::Record(TypeRecord { fields }) = self {
+        if let AnalysedType::Record(TypeRecord { fields, .. }) = self {
             Box::new(
                 fields
                     .iter()
@@ -55,7 +55,7 @@ impl WasmType for AnalysedType {
     }
 
     fn tuple_element_types(&self) -> Box<dyn Iterator<Item = Self> + '_> {
-        if let AnalysedType::Tuple(TypeTuple { items }) = self {
+        if let AnalysedType::Tuple(TypeTuple { items, .. }) = self {
             Box::new(items.clone().into_iter())
         } else {
             Box::new(std::iter::empty())
@@ -63,7 +63,7 @@ impl WasmType for AnalysedType {
     }
 
     fn variant_cases(&self) -> Box<dyn Iterator<Item = (Cow<'_, str>, Option<Self>)> + '_> {
-        if let AnalysedType::Variant(TypeVariant { cases }) = self {
+        if let AnalysedType::Variant(TypeVariant { cases, .. }) = self {
             Box::new(
                 cases
                     .iter()
@@ -75,7 +75,7 @@ impl WasmType for AnalysedType {
     }
 
     fn enum_cases(&self) -> Box<dyn Iterator<Item = Cow<'_, str>> + '_> {
-        if let AnalysedType::Enum(TypeEnum { cases }) = self {
+        if let AnalysedType::Enum(TypeEnum { cases, .. }) = self {
             Box::new(cases.iter().map(|name| Cow::Borrowed(name.as_str())))
         } else {
             Box::new(std::iter::empty())
@@ -83,7 +83,7 @@ impl WasmType for AnalysedType {
     }
 
     fn option_some_type(&self) -> Option<Self> {
-        if let AnalysedType::Option(TypeOption { inner }) = self {
+        if let AnalysedType::Option(TypeOption { inner, .. }) = self {
             Some(*inner.clone())
         } else {
             None
@@ -91,7 +91,7 @@ impl WasmType for AnalysedType {
     }
 
     fn result_types(&self) -> Option<(Option<Self>, Option<Self>)> {
-        if let AnalysedType::Result(TypeResult { ok, err }) = self {
+        if let AnalysedType::Result(TypeResult { ok, err, .. }) = self {
             Some((
                 ok.as_ref().map(|t| *t.clone()),
                 err.as_ref().map(|t| *t.clone()),
@@ -102,7 +102,7 @@ impl WasmType for AnalysedType {
     }
 
     fn flags_names(&self) -> Box<dyn Iterator<Item = Cow<'_, str>> + '_> {
-        if let AnalysedType::Flags(TypeFlags { names }) = self {
+        if let AnalysedType::Flags(TypeFlags { names, .. }) = self {
             Box::new(names.iter().map(|name| Cow::Borrowed(name.as_str())))
         } else {
             Box::new(std::iter::empty())
diff --git a/wasm-ast/src/analysis/wit_parser.rs b/wasm-ast/src/analysis/wit_parser.rs
index 9fe609ab..0551255f 100644
--- a/wasm-ast/src/analysis/wit_parser.rs
+++ b/wasm-ast/src/analysis/wit_parser.rs
@@ -209,10 +209,9 @@ impl GetResourceId for WitAnalysisContext {
         let mut resource_ids = self.resource_ids.borrow_mut();
 
         Some(
-            resource_ids
+            *resource_ids
                 .entry(type_id)
-                .or_insert_with(|| AnalysedResourceId(new_unique_id))
-                .clone(),
+                .or_insert_with(|| AnalysedResourceId(new_unique_id)),
         )
     }
 }
@@ -265,7 +264,9 @@ impl ToAnalysedType for TypeDef {
                             })
                     })
                     .collect::<Result<_, _>>()?,
-            )),
+            )
+            .with_optional_name(self.name.clone())
+            .with_optional_owner(get_owner_name(resolve, &self.owner))),
             TypeDefKind::Resource => {
                 Err("to_analysed_type not implemented for resource type".to_string())
             }
@@ -275,14 +276,22 @@ impl ToAnalysedType for TypeDef {
                     Some(resource_id) => Ok(AnalysedType::Handle(TypeHandle {
                         resource_id,
                         mode: AnalysedResourceMode::Owned,
-                    })),
+                        name: self.name.clone(),
+                        owner: None,
+                    })
+                    .with_optional_name(get_type_name(resolve, type_id))
+                    .with_optional_owner(get_type_owner(resolve, type_id))),
                     None => Err("to_analysed_type not implemented for handle type".to_string()),
                 },
                 Handle::Borrow(type_id) => match resource_map.get_resource_id(*type_id) {
                     Some(resource_id) => Ok(AnalysedType::Handle(TypeHandle {
                         resource_id,
                         mode: AnalysedResourceMode::Borrowed,
-                    })),
+                        name: self.name.clone(),
+                        owner: None,
+                    })
+                    .with_optional_name(get_type_name(resolve, type_id))
+                    .with_optional_owner(get_type_owner(resolve, type_id))),
                     None => Err("to_analysed_type not implemented for handle type".to_string()),
                 },
             },
@@ -292,14 +301,18 @@ impl ToAnalysedType for TypeDef {
                     .iter()
                     .map(|flag| flag.name.as_str())
                     .collect::<Vec<_>>(),
-            )),
+            )
+            .with_optional_name(self.name.clone())
+            .with_optional_owner(get_owner_name(resolve, &self.owner))),
             TypeDefKind::Tuple(tuple) => Ok(analysed_type::tuple(
                 tuple
                     .types
                     .iter()
                     .map(|typ| typ.to_analysed_type(resolve, resource_map))
                     .collect::<Result<_, _>>()?,
-            )),
+            )
+            .with_optional_name(self.name.clone())
+            .with_optional_owner(get_owner_name(resolve, &self.owner))),
             TypeDefKind::Variant(variant) => Ok(analysed_type::variant(
                 variant
                     .cases
@@ -314,33 +327,52 @@ impl ToAnalysedType for TypeDef {
                             })
                     })
                     .collect::<Result<_, _>>()?,
-            )),
+            )
+            .with_optional_name(self.name.clone())
+            .with_optional_owner(get_owner_name(resolve, &self.owner))),
             TypeDefKind::Enum(enum_) => Ok(analysed_type::r#enum(
                 &enum_
                     .cases
                     .iter()
                     .map(|case| case.name.as_str())
                     .collect::<Vec<_>>(),
-            )),
+            )
+            .with_optional_name(self.name.clone())
+            .with_optional_owner(get_owner_name(resolve, &self.owner))),
             TypeDefKind::Option(inner) => Ok(analysed_type::option(
                 inner.to_analysed_type(resolve, resource_map)?,
-            )),
+            )
+            .with_optional_name(self.name.clone())
+            .with_optional_owner(get_owner_name(resolve, &self.owner))),
             TypeDefKind::Result(result) => match (result.ok, result.err) {
                 (Some(ok), Some(err)) => Ok(analysed_type::result(
                     ok.to_analysed_type(resolve, resource_map)?,
                     err.to_analysed_type(resolve, resource_map)?,
-                )),
+                )
+                .with_optional_name(self.name.clone())
+                .with_optional_owner(get_owner_name(resolve, &self.owner))),
                 (Some(ok), None) => Ok(analysed_type::result_ok(
                     ok.to_analysed_type(resolve, resource_map)?,
-                )),
+                )
+                .with_optional_name(self.name.clone())
+                .with_optional_owner(get_owner_name(resolve, &self.owner))),
                 (None, Some(err)) => Ok(analysed_type::result_err(
                     err.to_analysed_type(resolve, resource_map)?,
-                )),
+                )
+                .with_optional_name(self.name.clone())
+                .with_optional_owner(get_owner_name(resolve, &self.owner))),
                 (None, None) => Err("result type with no ok or err case".to_string()),
             },
             TypeDefKind::List(ty) => Ok(analysed_type::list(
                 ty.to_analysed_type(resolve, resource_map)?,
-            )),
+            )
+            .with_optional_name(self.name.clone())
+            .with_optional_owner(get_owner_name(resolve, &self.owner))),
+            TypeDefKind::FixedSizeList(ty, _) => Ok(analysed_type::list(
+                ty.to_analysed_type(resolve, resource_map)?,
+            )
+            .with_optional_name(self.name.clone())
+            .with_optional_owner(get_owner_name(resolve, &self.owner))),
             TypeDefKind::Future(_) => {
                 Err("to_analysed_type not implemented for future type".to_string())
             }
@@ -383,6 +415,56 @@ impl ToAnalysedType for Type {
     }
 }
 
+fn follow_aliases(resolve: &Resolve, type_id: &TypeId) -> TypeId {
+    let mut current_id = *type_id;
+    while let Some(type_def) = resolve.types.get(current_id) {
+        if let TypeDefKind::Type(Type::Id(alias_type_id)) = &type_def.kind {
+            current_id = *alias_type_id;
+        } else {
+            break;
+        }
+    }
+    current_id
+}
+
+fn get_type_name(resolve: &Resolve, type_id: &TypeId) -> Option<String> {
+    resolve
+        .types
+        .get(follow_aliases(resolve, type_id))
+        .and_then(|type_def| type_def.name.clone())
+}
+
+fn get_type_owner(resolve: &Resolve, type_id: &TypeId) -> Option<String> {
+    resolve
+        .types
+        .get(follow_aliases(resolve, type_id))
+        .and_then(|type_def| get_owner_name(resolve, &type_def.owner))
+}
+
+fn get_owner_name(resolve: &Resolve, owner: &wit_parser::TypeOwner) -> Option<String> {
+    match owner {
+        wit_parser::TypeOwner::World(world_id) => resolve
+            .worlds
+            .get(*world_id)
+            .map(|world| world.name.clone()),
+        wit_parser::TypeOwner::Interface(iface_id) => resolve
+            .interfaces
+            .get(*iface_id)
+            .and_then(|iface| iface.name.clone().map(|name| (iface.package, name)))
+            .and_then(|(package_id, name)| {
+                if let Some(package_id) = package_id {
+                    resolve
+                        .packages
+                        .get(package_id)
+                        .map(|package| format!("{}/{}", package.name, name))
+                } else {
+                    Some(name)
+                }
+            }),
+        wit_parser::TypeOwner::None => None,
+    }
+}
+
 #[derive(Debug, Hash, PartialEq, Eq)]
 pub enum TypeOwner {
     World(String),
diff --git a/wasm-ast/src/component/parser.rs b/wasm-ast/src/component/parser.rs
index 44ccc119..23f364b8 100644
--- a/wasm-ast/src/component/parser.rs
+++ b/wasm-ast/src/component/parser.rs
@@ -440,6 +440,9 @@ impl TryFrom<wasmparser::ComponentDefinedType<'_>> for ComponentDefinedType {
             wasmparser::ComponentDefinedType::Stream(tpe) => Ok(ComponentDefinedType::Stream {
                 inner: tpe.map(|tpe| tpe.try_into()).transpose()?,
             }),
+            wasmparser::ComponentDefinedType::FixedSizeList(_, _) => {
+                Err("Fixed-size lists are not supported".to_string())
+            }
         }
     }
 }
@@ -583,6 +586,10 @@ impl TryFrom<wasmparser::CanonicalOption> for CanonicalOption {
             wasmparser::CanonicalOption::Callback(func_idx) => {
                 Ok(CanonicalOption::Callback(func_idx))
             }
+            wasmparser::CanonicalOption::CoreType(_) => {
+                Err("GC proposal is not supported".to_string())
+            }
+            wasmparser::CanonicalOption::Gc => Err("GC proposal is not supported".to_string()),
         }
     }
 }
@@ -623,7 +630,7 @@ impl TryFrom<wasmparser::CanonicalFunction> for Canon {
             wasmparser::CanonicalFunction::ResourceRep { resource } => {
                 Ok(Canon::ResourceRep { type_idx: resource })
             }
-            CanonicalFunction::ThreadSpawn { .. } => {
+            CanonicalFunction::ThreadSpawnRef { .. } => {
                 Err("Threads proposal is not supported".to_string())
             }
             CanonicalFunction::ResourceDropAsync { .. } => {
@@ -659,10 +666,10 @@ impl TryFrom<wasmparser::CanonicalFunction> for Canon {
             CanonicalFunction::StreamCancelWrite { .. } => {
                 Err("WASI P3 future and stream support is not supported yet".to_string())
             }
-            CanonicalFunction::StreamCloseReadable { .. } => {
+            CanonicalFunction::StreamDropReadable { .. } => {
                 Err("WASI P3 future and stream support is not supported yet".to_string())
             }
-            CanonicalFunction::StreamCloseWritable { .. } => {
+            CanonicalFunction::StreamDropWritable { .. } => {
                 Err("WASI P3 future and stream support is not supported yet".to_string())
             }
             CanonicalFunction::FutureNew { .. } => {
@@ -680,10 +687,10 @@ impl TryFrom<wasmparser::CanonicalFunction> for Canon {
             CanonicalFunction::FutureCancelWrite { .. } => {
                 Err("WASI P3 future and stream support is not supported yet".to_string())
             }
-            CanonicalFunction::FutureCloseReadable { .. } => {
+            CanonicalFunction::FutureDropReadable { .. } => {
                 Err("WASI P3 future and stream support is not supported yet".to_string())
             }
-            CanonicalFunction::FutureCloseWritable { .. } => {
+            CanonicalFunction::FutureDropWritable { .. } => {
                 Err("WASI P3 future and stream support is not supported yet".to_string())
             }
             CanonicalFunction::ErrorContextNew { .. } => {
@@ -710,6 +717,21 @@ impl TryFrom<wasmparser::CanonicalFunction> for Canon {
             CanonicalFunction::WaitableJoin => {
                 Err("WASI P3 future and stream support is not supported yet".to_string())
             }
+            CanonicalFunction::ThreadSpawnIndirect { .. } => {
+                Err("Threads proposal is not supported".to_string())
+            }
+            CanonicalFunction::TaskCancel => {
+                Err("WASI P3 future and stream support is not supported yet".to_string())
+            }
+            CanonicalFunction::ContextGet(_) => {
+                Err("WASI P3 future and stream support is not supported yet".to_string())
+            }
+            CanonicalFunction::ContextSet(_) => {
+                Err("WASI P3 future and stream support is not supported yet".to_string())
+            }
+            CanonicalFunction::SubtaskCancel { .. } => {
+                Err("WASI P3 future and stream support is not supported yet".to_string())
+            }
         }
     }
 }
diff --git a/wasm-rpc/src/json/impl.rs b/wasm-rpc/src/json/impl.rs
index 1b8a1fad..ca4204bc 100644
--- a/wasm-rpc/src/json/impl.rs
+++ b/wasm-rpc/src/json/impl.rs
@@ -12,24 +12,20 @@
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
-use std::collections::HashMap;
-use std::ops::Deref;
-use std::str::FromStr;
-
+use crate::json::ValueAndTypeJsonExtensions;
+use crate::{IntoValueAndType, Value, ValueAndType};
 use bigdecimal::{BigDecimal, FromPrimitive, ToPrimitive};
+use golem_wasm_ast::analysis::analysed_type::{list, option, record, tuple, variant};
 use golem_wasm_ast::analysis::{
     AnalysedResourceId, AnalysedResourceMode, AnalysedType, NameOptionTypePair, NameTypePair,
     TypeEnum, TypeFlags, TypeHandle, TypeList, TypeOption, TypeRecord, TypeResult, TypeTuple,
     TypeVariant,
 };
 use serde_json::{Number, Value as JsonValue};
+use std::collections::{HashMap, HashSet};
+use std::str::FromStr;
 
-use crate::json::TypeAnnotatedValueJsonExtensions;
-use crate::protobuf;
-use crate::protobuf::type_annotated_value::TypeAnnotatedValue;
-use crate::protobuf::typed_result::ResultValue;
-
-impl TypeAnnotatedValueJsonExtensions for TypeAnnotatedValue {
+impl ValueAndTypeJsonExtensions for ValueAndType {
     fn parse_with_type(json_val: &JsonValue, typ: &AnalysedType) -> Result<Self, Vec<String>> {
         match typ {
             AnalysedType::Bool(_) => get_bool(json_val),
@@ -45,137 +41,201 @@ impl TypeAnnotatedValueJsonExtensions for TypeAnnotatedValue {
             AnalysedType::F32(_) => get_f32(json_val),
             AnalysedType::Chr(_) => get_char(json_val),
             AnalysedType::Str(_) => get_string(json_val),
-            AnalysedType::Enum(TypeEnum { cases }) => get_enum(json_val, cases),
-            AnalysedType::Flags(TypeFlags { names }) => get_flag(json_val, names),
-            AnalysedType::List(TypeList { inner }) => get_list(json_val, inner),
-            AnalysedType::Option(TypeOption { inner }) => get_option(json_val, inner),
-            AnalysedType::Result(TypeResult { ok, err }) => get_result(json_val, ok, err),
-            AnalysedType::Record(TypeRecord { fields }) => get_record(json_val, fields),
-            AnalysedType::Variant(TypeVariant { cases }) => get_variant(json_val, cases),
-            AnalysedType::Tuple(TypeTuple { items }) => get_tuple(json_val, items),
-            AnalysedType::Handle(TypeHandle { resource_id, mode }) => {
-                get_handle(json_val, resource_id.clone(), mode.clone())
-            }
+            AnalysedType::Enum(TypeEnum { cases, .. }) => get_enum(json_val, cases),
+            AnalysedType::Flags(TypeFlags { names, .. }) => get_flag(json_val, names),
+            AnalysedType::List(TypeList { inner, .. }) => get_list(json_val, inner),
+            AnalysedType::Option(TypeOption { inner, .. }) => get_option(json_val, inner),
+            AnalysedType::Result(TypeResult { ok, err, .. }) => get_result(json_val, ok, err),
+            AnalysedType::Record(TypeRecord { fields, .. }) => get_record(json_val, fields),
+            AnalysedType::Variant(TypeVariant { cases, .. }) => get_variant(json_val, cases),
+            AnalysedType::Tuple(TypeTuple { items, .. }) => get_tuple(json_val, items),
+            AnalysedType::Handle(TypeHandle {
+                resource_id, mode, ..
+            }) => get_handle(json_val, *resource_id, mode.clone()),
         }
     }
 
-    fn to_json_value(&self) -> JsonValue {
-        match self {
-            TypeAnnotatedValue::Bool(bool) => JsonValue::Bool(*bool),
-            TypeAnnotatedValue::Flags(protobuf::TypedFlags { typ: _, values }) => JsonValue::Array(
-                values
-                    .iter()
-                    .map(|x| JsonValue::String(x.clone()))
-                    .collect(),
-            ),
-            TypeAnnotatedValue::S8(value) => JsonValue::Number(Number::from(*value)),
-            TypeAnnotatedValue::U8(value) => JsonValue::Number(Number::from(*value)),
-            TypeAnnotatedValue::S16(value) => JsonValue::Number(Number::from(*value)),
-            TypeAnnotatedValue::U16(value) => JsonValue::Number(Number::from(*value)),
-            TypeAnnotatedValue::S32(value) => JsonValue::Number(Number::from(*value)),
-            TypeAnnotatedValue::U32(value) => JsonValue::Number(Number::from(*value)),
-            TypeAnnotatedValue::S64(value) => JsonValue::Number(Number::from(*value)),
-            TypeAnnotatedValue::U64(value) => JsonValue::Number(Number::from(*value)),
-            TypeAnnotatedValue::F32(value) => {
-                JsonValue::Number(Number::from_f64(*value as f64).unwrap())
+    fn to_json_value(&self) -> Result<JsonValue, String> {
+        match (&self.typ, &self.value) {
+            (AnalysedType::Bool(_), Value::Bool(bool_val)) => Ok(JsonValue::Bool(*bool_val)),
+            (AnalysedType::S8(_), Value::S8(value)) => Ok(JsonValue::Number(Number::from(*value))),
+            (AnalysedType::U8(_), Value::U8(value)) => Ok(JsonValue::Number(Number::from(*value))),
+            (AnalysedType::S16(_), Value::S16(value)) => {
+                Ok(JsonValue::Number(Number::from(*value)))
             }
-            TypeAnnotatedValue::F64(value) => JsonValue::Number(Number::from_f64(*value).unwrap()),
-            TypeAnnotatedValue::Char(value) => JsonValue::Number(Number::from(*value as u32)),
-            TypeAnnotatedValue::Str(value) => JsonValue::String(value.clone()),
-            TypeAnnotatedValue::Enum(protobuf::TypedEnum { typ: _, value }) => {
-                JsonValue::String(value.clone())
+            (AnalysedType::U16(_), Value::U16(value)) => {
+                Ok(JsonValue::Number(Number::from(*value)))
             }
-            TypeAnnotatedValue::Option(option) => match &option.value {
-                Some(value) => value.clone().type_annotated_value.unwrap().to_json_value(),
-                None => JsonValue::Null,
-            },
-            TypeAnnotatedValue::Tuple(protobuf::TypedTuple { typ: _, value }) => {
-                let values: Vec<serde_json::Value> = value
-                    .iter()
-                    .map(|v| v.type_annotated_value.clone().unwrap().to_json_value())
-                    .collect();
-                JsonValue::Array(values)
+            (AnalysedType::S32(_), Value::S32(value)) => {
+                Ok(JsonValue::Number(Number::from(*value)))
             }
-            TypeAnnotatedValue::List(protobuf::TypedList { typ: _, values }) => {
-                let values: Vec<serde_json::Value> = values
+            (AnalysedType::U32(_), Value::U32(value)) => {
+                Ok(JsonValue::Number(Number::from(*value)))
+            }
+            (AnalysedType::S64(_), Value::S64(value)) => {
+                Ok(JsonValue::Number(Number::from(*value)))
+            }
+            (AnalysedType::U64(_), Value::U64(value)) => {
+                Ok(JsonValue::Number(Number::from(*value)))
+            }
+            (AnalysedType::F32(_), Value::F32(value)) => Ok(JsonValue::Number(
+                Number::from_f64(*value as f64)
+                    .ok_or_else(|| "Failed to encode f32 as JSON number".to_string())?,
+            )),
+            (AnalysedType::F64(_), Value::F64(value)) => Ok(JsonValue::Number(
+                Number::from_f64(*value)
+                    .ok_or_else(|| "Failed to encode f64 as JSON number".to_string())?,
+            )),
+            (AnalysedType::Chr(_), Value::Char(value)) => {
+                Ok(JsonValue::Number(Number::from(*value as u32)))
+            }
+            (AnalysedType::Str(_), Value::String(value)) => Ok(JsonValue::String(value.clone())),
+            (AnalysedType::Enum(TypeEnum { cases, .. }), Value::Enum(value)) => {
+                if let Some(case) = cases.get(*value as usize) {
+                    Ok(JsonValue::String(case.clone()))
+                } else {
+                    Err(format!("Invalid enum index '{value}'"))
+                }
+            }
+            (AnalysedType::Flags(TypeFlags { names, .. }), Value::Flags(value)) => {
+                let values: Vec<JsonValue> = value
                     .iter()
-                    .map(|v| v.type_annotated_value.clone().unwrap().to_json_value())
+                    .zip(names)
+                    .filter_map(|(enabled, name)| {
+                        if *enabled {
+                            Some(JsonValue::String(name.clone()))
+                        } else {
+                            None
+                        }
+                    })
                     .collect();
-                JsonValue::Array(values)
+                Ok(JsonValue::Array(values))
             }
-
-            TypeAnnotatedValue::Record(protobuf::TypedRecord { typ: _, value }) => {
-                let mut map = serde_json::Map::new();
-                for name_value in value {
-                    map.insert(
-                        name_value.name.clone(),
-                        name_value
-                            .value
-                            .clone()
-                            .unwrap()
-                            .type_annotated_value
-                            .unwrap()
-                            .to_json_value(),
-                    );
+            (AnalysedType::Option(TypeOption { inner, .. }), Value::Option(value)) => {
+                if let Some(inner_value) = value {
+                    let inner_vnt = ValueAndType::new((**inner_value).clone(), (**inner).clone());
+                    inner_vnt.to_json_value()
+                } else {
+                    Ok(JsonValue::Null)
                 }
-                JsonValue::Object(map)
             }
-
-            TypeAnnotatedValue::Variant(variant) => {
-                let mut map = serde_json::Map::new();
-                map.insert(
-                    variant.case_name.clone(),
-                    variant
-                        .case_value
-                        .as_ref()
-                        .map(|x| {
-                            let value = x.clone().deref().type_annotated_value.clone().unwrap();
-                            value.to_json_value()
-                        })
-                        .unwrap_or(JsonValue::Null),
-                );
-                JsonValue::Object(map)
+            (AnalysedType::Tuple(TypeTuple { items, .. }), Value::Tuple(values)) => {
+                let item_jsons = items
+                    .iter()
+                    .zip(values)
+                    .map(|(item_type, item_value)| {
+                        let item_vnt = ValueAndType::new(item_value.clone(), item_type.clone());
+                        item_vnt.to_json_value()
+                    })
+                    .collect::<Result<Vec<_>, _>>()?;
+                Ok(JsonValue::Array(item_jsons))
             }
-
-            TypeAnnotatedValue::Result(result0) => {
-                let mut map = serde_json::Map::new();
-
-                let result_value = result0.result_value.clone().unwrap();
-
-                match result_value {
-                    ResultValue::OkValue(value) => {
-                        map.insert(
-                            "ok".to_string(),
-                            value
-                                .type_annotated_value
-                                .map_or(JsonValue::Null, |v| v.to_json_value()),
-                        );
+            (AnalysedType::List(TypeList { inner, .. }), Value::List(values)) => {
+                let item_jsons = values
+                    .iter()
+                    .map(|item_value| {
+                        let item_vnt = ValueAndType::new(item_value.clone(), (**inner).clone());
+                        item_vnt.to_json_value()
+                    })
+                    .collect::<Result<Vec<_>, _>>()?;
+                Ok(JsonValue::Array(item_jsons))
+            }
+            (AnalysedType::Record(TypeRecord { fields, .. }), Value::Record(field_values)) => {
+                let fields = fields
+                    .iter()
+                    .zip(field_values)
+                    .map(|(field_type, field_value)| {
+                        let field_vnt =
+                            ValueAndType::new(field_value.clone(), field_type.typ.clone());
+                        field_vnt
+                            .to_json_value()
+                            .map(|json| (field_type.name.clone(), json))
+                    })
+                    .collect::<Result<Vec<_>, _>>()?;
+                Ok(JsonValue::Object(fields.into_iter().collect()))
+            }
+            (
+                AnalysedType::Variant(TypeVariant { cases, .. }),
+                Value::Variant {
+                    case_idx,
+                    case_value,
+                },
+            ) => {
+                if let Some(case) = cases.get(*case_idx as usize) {
+                    let mut map = serde_json::Map::new();
+                    match &case.typ {
+                        Some(case_typ) => {
+                            if let Some(value) = case_value {
+                                let value_vnt =
+                                    ValueAndType::new((**value).clone(), case_typ.clone());
+                                map.insert(case.name.clone(), value_vnt.to_json_value()?);
+                            } else {
+                                map.insert(case.name.clone(), JsonValue::Null);
+                            }
+                        }
+                        None => {
+                            map.insert(case.name.clone(), JsonValue::Null);
+                        }
                     }
-                    ResultValue::ErrorValue(value) => {
-                        map.insert(
-                            "err".to_string(),
-                            value
-                                .type_annotated_value
-                                .map_or(JsonValue::Null, |v| v.to_json_value()),
-                        );
+                    Ok(JsonValue::Object(map))
+                } else {
+                    Err(format!("Invalid variant index '{case_idx}'"))
+                }
+            }
+            (AnalysedType::Result(TypeResult { ok, err, .. }), Value::Result(result)) => {
+                match result {
+                    Ok(None) => Ok(JsonValue::Object(
+                        vec![("ok".to_string(), JsonValue::Null)]
+                            .into_iter()
+                            .collect(),
+                    )),
+                    Ok(Some(ok_value)) => {
+                        if let Some(ok_type) = ok {
+                            let ok_vnt =
+                                ValueAndType::new((**ok_value).clone(), (**ok_type).clone());
+                            Ok(JsonValue::Object(
+                                vec![("ok".to_string(), ok_vnt.to_json_value()?)]
+                                    .into_iter()
+                                    .collect(),
+                            ))
+                        } else {
+                            Err("Missing ok value in Result".to_string())
+                        }
+                    }
+                    Err(None) => Ok(JsonValue::Object(
+                        vec![("err".to_string(), JsonValue::Null)]
+                            .into_iter()
+                            .collect(),
+                    )),
+                    Err(Some(err_value)) => {
+                        if let Some(err_type) = err {
+                            let err_vnt =
+                                ValueAndType::new((**err_value).clone(), (**err_type).clone());
+                            Ok(JsonValue::Object(
+                                vec![("err".to_string(), err_vnt.to_json_value()?)]
+                                    .into_iter()
+                                    .collect(),
+                            ))
+                        } else {
+                            Err("Missing err value in Result".to_string())
+                        }
                     }
                 }
-
-                JsonValue::Object(map)
             }
-
-            TypeAnnotatedValue::Handle(protobuf::TypedHandle {
-                typ: _,
-                uri,
-                resource_id,
-            }) => JsonValue::String(format!("{uri}/{resource_id}")),
+            (AnalysedType::Handle(TypeHandle { .. }), Value::Handle { uri, resource_id }) => {
+                Ok(JsonValue::String(format!("{uri}/{resource_id}")))
+            }
+            _ => Err(format!(
+                "Type and value mismatch (type is {:?}, value is {:?})",
+                self.typ, self.value
+            )),
         }
     }
 }
 
-fn get_bool(json: &JsonValue) -> Result<TypeAnnotatedValue, Vec<String>> {
+fn get_bool(json: &JsonValue) -> Result<ValueAndType, Vec<String>> {
     match json {
-        JsonValue::Bool(bool_val) => Ok(TypeAnnotatedValue::Bool(*bool_val)),
+        JsonValue::Bool(bool_val) => Ok(bool_val.into_value_and_type()),
         _ => {
             let type_description = type_description(json);
             Err(vec![format!("expected bool, found {}", type_description)])
@@ -183,92 +243,123 @@ fn get_bool(json: &JsonValue) -> Result<TypeAnnotatedValue, Vec<String>> {
     }
 }
 
-fn get_s8(json: &JsonValue) -> Result<TypeAnnotatedValue, Vec<String>> {
+fn get_s8(json: &JsonValue) -> Result<ValueAndType, Vec<String>> {
     ensure_range(
         json,
         BigDecimal::from_i8(i8::MIN).expect("Failed to convert i8::MIN to BigDecimal"),
         BigDecimal::from_i8(i8::MAX).expect("Failed to convert i8::MAX to BigDecimal"),
     )
-    .map(|num| TypeAnnotatedValue::S8(num.to_i32().expect("Failed to convert BigDecimal to i8")))
+    .and_then(|num| {
+        num.to_i8()
+            .ok_or_else(|| vec!["Failed to convert number to i8".to_string()])
+    })
+    .map(|num| num.into_value_and_type())
 }
 
-fn get_u8(json: &JsonValue) -> Result<TypeAnnotatedValue, Vec<String>> {
+fn get_u8(json: &JsonValue) -> Result<ValueAndType, Vec<String>> {
     ensure_range(
         json,
         BigDecimal::from_u8(u8::MIN).expect("Failed to convert u8::MIN to BigDecimal"),
         BigDecimal::from_u8(u8::MAX).expect("Failed to convert u8::MAX to BigDecimal"),
     )
-    .map(|num| TypeAnnotatedValue::U8(num.to_u32().expect("Failed to convert BigDecimal to u8")))
+    .and_then(|num| {
+        num.to_u8()
+            .ok_or_else(|| vec!["Failed to convert number to u8".to_string()])
+    })
+    .map(|num| num.into_value_and_type())
 }
 
-fn get_s16(json: &JsonValue) -> Result<TypeAnnotatedValue, Vec<String>> {
+fn get_s16(json: &JsonValue) -> Result<ValueAndType, Vec<String>> {
     ensure_range(
         json,
         BigDecimal::from_i16(i16::MIN).expect("Failed to convert i16::MIN to BigDecimal"),
         BigDecimal::from_i16(i16::MAX).expect("Failed to convert i16::MAX to BigDecimal"),
     )
-    .map(|num| TypeAnnotatedValue::S16(num.to_i32().expect("Failed to convert BigDecimal to i16")))
+    .and_then(|num| {
+        num.to_i16()
+            .ok_or_else(|| vec!["Failed to convert number to i16".to_string()])
+    })
+    .map(|num| num.into_value_and_type())
 }
 
-fn get_u16(json: &JsonValue) -> Result<TypeAnnotatedValue, Vec<String>> {
+fn get_u16(json: &JsonValue) -> Result<ValueAndType, Vec<String>> {
     ensure_range(
         json,
         BigDecimal::from_u16(u16::MIN).expect("Failed to convert u16::MIN to BigDecimal"),
         BigDecimal::from_u16(u16::MAX).expect("Failed to convert u16::MAX to BigDecimal"),
     )
-    .map(|num| TypeAnnotatedValue::U16(num.to_u32().expect("Failed to convert BigDecimal to u16")))
+    .and_then(|num| {
+        num.to_u16()
+            .ok_or_else(|| vec!["Failed to convert number to u16".to_string()])
+    })
+    .map(|num| num.into_value_and_type())
 }
 
-fn get_s32(json: &JsonValue) -> Result<TypeAnnotatedValue, Vec<String>> {
+fn get_s32(json: &JsonValue) -> Result<ValueAndType, Vec<String>> {
     ensure_range(
         json,
         BigDecimal::from_i32(i32::MIN).expect("Failed to convert i32::MIN to BigDecimal"),
         BigDecimal::from_i32(i32::MAX).expect("Failed to convert i32::MAX to BigDecimal"),
     )
-    .map(|num| TypeAnnotatedValue::S32(num.to_i32().expect("Failed to convert BigDecimal to i32")))
+    .and_then(|num| {
+        num.to_i32()
+            .ok_or_else(|| vec!["Failed to convert number to i32".to_string()])
+    })
+    .map(|num| num.into_value_and_type())
 }
 
-fn get_u32(json: &JsonValue) -> Result<TypeAnnotatedValue, Vec<String>> {
+fn get_u32(json: &JsonValue) -> Result<ValueAndType, Vec<String>> {
     ensure_range(
         json,
         BigDecimal::from_u32(u32::MIN).expect("Failed to convert u32::MIN to BigDecimal"),
         BigDecimal::from_u32(u32::MAX).expect("Failed to convert u32::MAX to BigDecimal"),
     )
-    .map(|num| TypeAnnotatedValue::U32(num.to_u32().expect("Failed to convert BigDecimal to u32")))
+    .and_then(|num| {
+        num.to_u32()
+            .ok_or_else(|| vec!["Failed to convert number to u32".to_string()])
+    })
+    .map(|num| num.into_value_and_type())
 }
 
-fn get_s64(json: &JsonValue) -> Result<TypeAnnotatedValue, Vec<String>> {
+fn get_s64(json: &JsonValue) -> Result<ValueAndType, Vec<String>> {
     ensure_range(
         json,
         BigDecimal::from_i64(i64::MIN).expect("Failed to convert i64::MIN to BigDecimal"),
         BigDecimal::from_i64(i64::MAX).expect("Failed to convert i64::MAX to BigDecimal"),
     )
-    .map(|num| TypeAnnotatedValue::S64(num.to_i64().expect("Failed to convert BigDecimal to i64")))
+    .and_then(|num| {
+        num.to_i64()
+            .ok_or_else(|| vec!["Failed to convert number to i64".to_string()])
+    })
+    .map(|num| num.into_value_and_type())
 }
 
-fn get_f32(json: &JsonValue) -> Result<TypeAnnotatedValue, Vec<String>> {
+fn get_f32(json: &JsonValue) -> Result<ValueAndType, Vec<String>> {
     ensure_range(
         json,
         BigDecimal::from_f32(f32::MIN).expect("Failed to convert f32::MIN to BigDecimal"),
         BigDecimal::from_f32(f32::MAX).expect("Failed to convert f32::MAX to BigDecimal"),
     )
-    .map(|num| TypeAnnotatedValue::F32(num.to_f32().expect("Failed to convert BigDecimal to f32")))
+    .and_then(|num| {
+        num.to_f32()
+            .ok_or_else(|| vec!["Failed to convert number to f32".to_string()])
+    })
+    .map(|num| num.into_value_and_type())
 }
 
-fn get_f64(json_val: &JsonValue) -> Result<TypeAnnotatedValue, Vec<String>> {
+fn get_f64(json_val: &JsonValue) -> Result<ValueAndType, Vec<String>> {
     let num = get_big_decimal(json_val)?;
-    let value = TypeAnnotatedValue::F64(
-        num.to_string()
-            .parse()
-            .map_err(|err| vec![format!("Failed to parse f64: {}", err)])?,
-    );
-    Ok(value)
+    let num: f64 = num
+        .to_string()
+        .parse()
+        .map_err(|err| vec![format!("Failed to convert number to f64: {err}")])?;
+    Ok(num.into_value_and_type())
 }
 
-fn get_string(json: &JsonValue) -> Result<TypeAnnotatedValue, Vec<String>> {
+fn get_string(json: &JsonValue) -> Result<ValueAndType, Vec<String>> {
     if let Some(str_value) = json.as_str() {
         // If the JSON value is a string, return it
-        Ok(TypeAnnotatedValue::Str(str_value.to_string()))
+        Ok(str_value.to_string().into_value_and_type())
     } else {
         // If the JSON value is not a string, return an error with type information
         let type_description = type_description(json);
@@ -276,15 +367,20 @@ fn get_string(json: &JsonValue) -> Result<TypeAnnotatedValue, Vec<String>> {
     }
 }
 
-fn get_char(json: &JsonValue) -> Result<TypeAnnotatedValue, Vec<String>> {
+fn get_char(json: &JsonValue) -> Result<ValueAndType, Vec<String>> {
     if let Some(num_u64) = json.as_u64() {
         if num_u64 > u32::MAX as u64 {
             Err(vec![format!(
                 "The value {} is too large to be converted to a char",
                 num_u64
             )])
+        } else if let Some(ch) = char::from_u32(num_u64 as u32) {
+            Ok(ch.into_value_and_type())
         } else {
-            Ok(TypeAnnotatedValue::Char(num_u64 as i32))
+            Err(vec![format!(
+                "The value {} cannot be converted to a char",
+                num_u64
+            )])
         }
     } else {
         let type_description = type_description(json);
@@ -293,10 +389,7 @@ fn get_char(json: &JsonValue) -> Result<TypeAnnotatedValue, Vec<String>> {
     }
 }
 
-fn get_tuple(
-    input_json: &JsonValue,
-    types: &[AnalysedType],
-) -> Result<TypeAnnotatedValue, Vec<String>> {
+fn get_tuple(input_json: &JsonValue, types: &[AnalysedType]) -> Result<ValueAndType, Vec<String>> {
     let json_array = input_json.as_array().ok_or(vec![format!(
         "Input {} is not an array representing tuple",
         input_json
@@ -310,109 +403,85 @@ fn get_tuple(
     }
 
     let mut errors: Vec<String> = vec![];
-    let mut vals: Vec<TypeAnnotatedValue> = vec![];
+    let mut vals: Vec<Value> = vec![];
+    let mut tpes: Vec<AnalysedType> = vec![];
 
     for (json, tpe) in json_array.iter().zip(types.iter()) {
-        match TypeAnnotatedValue::parse_with_type(json, tpe) {
-            Ok(result) => vals.push(result),
+        match ValueAndType::parse_with_type(json, tpe) {
+            Ok(result) => {
+                vals.push(result.value);
+                tpes.push(result.typ);
+            }
             Err(errs) => errors.extend(errs),
         }
     }
 
-    let tuple = protobuf::TypedTuple {
-        typ: types.iter().map(|t| t.into()).collect(),
-        value: vals
-            .iter()
-            .map(|v| protobuf::TypeAnnotatedValue {
-                type_annotated_value: Some(v.clone()),
-            })
-            .collect(),
-    };
-
     if errors.is_empty() {
-        Ok(TypeAnnotatedValue::Tuple(tuple))
+        Ok(ValueAndType::new(Value::Tuple(vals), tuple(tpes)))
     } else {
         Err(errors)
     }
 }
 
-fn get_option(
-    input_json: &JsonValue,
-    tpe: &AnalysedType,
-) -> Result<TypeAnnotatedValue, Vec<String>> {
+fn get_option(input_json: &JsonValue, tpe: &AnalysedType) -> Result<ValueAndType, Vec<String>> {
     match input_json.as_null() {
-        Some(_) => {
-            let option = protobuf::TypedOption {
-                typ: Some(tpe.into()),
-                value: None,
-            };
-
-            Ok(TypeAnnotatedValue::Option(Box::new(option)))
-        }
-
-        None => TypeAnnotatedValue::parse_with_type(input_json, tpe).map(|result| {
-            let option = protobuf::TypedOption {
-                typ: Some(tpe.into()),
-                value: Some(Box::new(protobuf::TypeAnnotatedValue {
-                    type_annotated_value: Some(result),
-                })),
-            };
+        Some(_) => Ok(ValueAndType::new(Value::Option(None), option(tpe.clone()))),
 
-            TypeAnnotatedValue::Option(Box::new(option))
+        None => ValueAndType::parse_with_type(input_json, tpe).map(|result| {
+            ValueAndType::new(
+                Value::Option(Some(Box::new(result.value))),
+                option(tpe.clone()),
+            )
         }),
     }
 }
 
-fn get_list(input_json: &JsonValue, tpe: &AnalysedType) -> Result<TypeAnnotatedValue, Vec<String>> {
+fn get_list(input_json: &JsonValue, tpe: &AnalysedType) -> Result<ValueAndType, Vec<String>> {
     let json_array = input_json
         .as_array()
         .ok_or(vec![format!("Input {} is not an array", input_json)])?;
 
     let mut errors: Vec<String> = vec![];
-    let mut vals: Vec<TypeAnnotatedValue> = vec![];
+    let mut vals: Vec<Value> = vec![];
 
     for json in json_array {
-        match TypeAnnotatedValue::parse_with_type(json, tpe) {
-            Ok(result) => vals.push(result),
+        match ValueAndType::parse_with_type(json, tpe) {
+            Ok(result) => vals.push(result.value),
             Err(errs) => errors.extend(errs),
         }
     }
 
-    let list = protobuf::TypedList {
-        typ: Some(tpe.into()),
-        values: vals
-            .iter()
-            .map(|v| protobuf::TypeAnnotatedValue {
-                type_annotated_value: Some(v.clone()),
-            })
-            .collect(),
-    };
-
     if errors.is_empty() {
-        Ok(TypeAnnotatedValue::List(list))
+        Ok(ValueAndType::new(Value::List(vals), list(tpe.clone())))
     } else {
         Err(errors)
     }
 }
 
-fn get_enum(input_json: &JsonValue, names: &[String]) -> Result<TypeAnnotatedValue, Vec<String>> {
+fn get_enum(input_json: &JsonValue, names: &[String]) -> Result<ValueAndType, Vec<String>> {
     let input_enum_value = input_json
         .as_str()
         .ok_or(vec![format!("Input {} is not string", input_json)])?;
 
-    let enum_value = protobuf::TypedEnum {
-        typ: names.to_vec(),
-        value: input_enum_value.to_string(),
-    };
-    if names.contains(&input_enum_value.to_string()) {
-        Ok(TypeAnnotatedValue::Enum(enum_value))
-    } else {
-        Err(vec![format!(
-            "Invalid input {}. Valid values are {}",
-            input_enum_value,
-            names.join(",")
-        )])
-    }
+    let enum_value = names
+        .iter()
+        .position(|n| n == input_enum_value)
+        .ok_or_else(|| {
+            vec![format!(
+                "Invalid input {}. Valid values are {}",
+                input_enum_value,
+                names.join(",")
+            )]
+        })?;
+
+    Ok(ValueAndType::new(
+        Value::Enum(enum_value as u32),
+        AnalysedType::Enum(TypeEnum {
+            name: None,
+            owner: None,
+            cases: names.to_vec(),
+        }),
+    ))
 }
 
 #[allow(clippy::type_complexity)]
@@ -420,13 +489,13 @@ fn get_result(
     input_json: &JsonValue,
     ok_type: &Option<Box<AnalysedType>>,
     err_type: &Option<Box<AnalysedType>>,
-) -> Result<TypeAnnotatedValue, Vec<String>> {
+) -> Result<ValueAndType, Vec<String>> {
     fn validate(
         typ: &Option<Box<AnalysedType>>,
         input_json: &JsonValue,
-    ) -> Result<Option<Box<TypeAnnotatedValue>>, Vec<String>> {
+    ) -> Result<Option<Box<Value>>, Vec<String>> {
         if let Some(typ) = typ {
-            TypeAnnotatedValue::parse_with_type(input_json, typ).map(|v| Some(Box::new(v)))
+            ValueAndType::parse_with_type(input_json, typ).map(|v| Some(Box::new(v.value)))
         } else if input_json.is_null() {
             Ok(None)
         } else {
@@ -440,34 +509,29 @@ fn get_result(
         Some(value) => {
             let value = validate(ok_type, value)?;
 
-            let result_value = ResultValue::OkValue(Box::new(protobuf::TypeAnnotatedValue {
-                type_annotated_value: value.map(|value| value.deref().clone()),
-            }));
-
-            let typed_result = protobuf::TypedResult {
-                ok: ok_type.clone().map(|x| x.deref().into()),
-                error: err_type.clone().map(|x| x.deref().into()),
-                result_value: Some(result_value),
-            };
-
-            Ok(TypeAnnotatedValue::Result(Box::new(typed_result)))
+            Ok(ValueAndType::new(
+                Value::Result(Ok(value)),
+                AnalysedType::Result(TypeResult {
+                    ok: ok_type.clone(),
+                    err: err_type.clone(),
+                    name: None,
+                    owner: None,
+                }),
+            ))
         }
         None => match input_json.get("err") {
             Some(value) => {
                 let value = validate(err_type, value)?;
 
-                let result_value =
-                    ResultValue::ErrorValue(Box::new(protobuf::TypeAnnotatedValue {
-                        type_annotated_value: value.map(|value| value.deref().clone()),
-                    }));
-
-                let typed_result = protobuf::TypedResult {
-                    ok: ok_type.clone().map(|x| x.deref().into()),
-                    error: err_type.clone().map(|x| x.deref().into()),
-                    result_value: Some(result_value),
-                };
-
-                Ok(TypeAnnotatedValue::Result(Box::new(typed_result)))
+                Ok(ValueAndType::new(
+                    Value::Result(Err(value)),
+                    AnalysedType::Result(TypeResult {
+                        ok: ok_type.clone(),
+                        err: err_type.clone(),
+                        name: None,
+                        owner: None,
+                    }),
+                ))
             }
             None => Err(vec![
                 "Failed to retrieve either ok value or err value".to_string()
@@ -479,19 +543,19 @@ fn get_result(
 fn get_record(
     input_json: &JsonValue,
     name_type_pairs: &[NameTypePair],
-) -> Result<TypeAnnotatedValue, Vec<String>> {
+) -> Result<ValueAndType, Vec<String>> {
     let json_map = input_json.as_object().ok_or(vec![format!(
         "The input {} is not a json object",
         input_json
     )])?;
 
     let mut errors: Vec<String> = vec![];
-    let mut vals: Vec<(String, TypeAnnotatedValue)> = vec![];
+    let mut vals: Vec<Value> = vec![];
 
     for NameTypePair { name, typ } in name_type_pairs {
         if let Some(json_value) = json_map.get(name) {
-            match TypeAnnotatedValue::parse_with_type(json_value, typ) {
-                Ok(result) => vals.push((name.clone(), result)),
+            match ValueAndType::parse_with_type(json_value, typ) {
+                Ok(result) => vals.push(result.value),
                 Err(value_errors) => errors.extend(
                     value_errors
                         .iter()
@@ -502,12 +566,7 @@ fn get_record(
         } else {
             match typ {
                 AnalysedType::Option(_) => {
-                    let option = protobuf::TypedOption {
-                        typ: Some(typ.into()),
-                        value: None,
-                    };
-
-                    vals.push((name.clone(), TypeAnnotatedValue::Option(Box::new(option))))
+                    vals.push(Value::Option(None));
                 }
                 _ => errors.push(format!("key '{name}' not found")),
             }
@@ -515,42 +574,22 @@ fn get_record(
     }
 
     if errors.is_empty() {
-        let name_type_pairs = name_type_pairs
-            .iter()
-            .map(|pair| protobuf::NameTypePair {
-                name: pair.name.clone(),
-                typ: Some((&pair.typ).into()),
-            })
-            .collect::<Vec<_>>();
-
-        let name_value_pairs = vals
-            .iter()
-            .map(|(name, value)| protobuf::NameValuePair {
-                name: name.clone(),
-                value: Some(protobuf::TypeAnnotatedValue {
-                    type_annotated_value: Some(value.clone()),
-                }),
-            })
-            .collect::<Vec<_>>();
-
-        let record = protobuf::TypedRecord {
-            typ: name_type_pairs,
-            value: name_value_pairs,
-        };
-
-        Ok(TypeAnnotatedValue::Record(record))
+        Ok(ValueAndType::new(
+            Value::Record(vals),
+            record(name_type_pairs.to_vec()),
+        ))
     } else {
         Err(errors)
     }
 }
 
-fn get_flag(input_json: &JsonValue, names: &[String]) -> Result<TypeAnnotatedValue, Vec<String>> {
+fn get_flag(input_json: &JsonValue, names: &[String]) -> Result<ValueAndType, Vec<String>> {
     let json_array = input_json
         .as_array()
         .ok_or(vec![format!("Input {} is not an array", input_json)])?;
 
     let mut errors: Vec<String> = vec![];
-    let mut vals: Vec<String> = vec![];
+    let mut vals: HashSet<String> = HashSet::new();
 
     for json in json_array.iter() {
         let flag: String = json
@@ -564,7 +603,7 @@ fn get_flag(input_json: &JsonValue, names: &[String]) -> Result<TypeAnnotatedVal
             )])?;
 
         if names.contains(&flag) {
-            vals.push(flag);
+            vals.insert(flag);
         } else {
             errors.push(format!(
                 "Invalid input {}. Valid values are {}",
@@ -575,11 +614,19 @@ fn get_flag(input_json: &JsonValue, names: &[String]) -> Result<TypeAnnotatedVal
     }
 
     if errors.is_empty() {
-        let flags = protobuf::TypedFlags {
-            typ: names.to_vec(),
-            values: vals,
-        };
-        Ok(TypeAnnotatedValue::Flags(flags))
+        let mut bitmap = vec![false; names.len()];
+        for (i, name) in names.iter().enumerate() {
+            bitmap[i] = vals.contains(name);
+        }
+
+        Ok(ValueAndType::new(
+            Value::Flags(bitmap),
+            AnalysedType::Flags(TypeFlags {
+                names: names.to_vec(),
+                name: None,
+                owner: None,
+            }),
+        ))
     } else {
         Err(errors)
     }
@@ -588,7 +635,7 @@ fn get_flag(input_json: &JsonValue, names: &[String]) -> Result<TypeAnnotatedVal
 fn get_variant(
     input_json: &JsonValue,
     types: &[NameOptionTypePair],
-) -> Result<TypeAnnotatedValue, Vec<String>> {
+) -> Result<ValueAndType, Vec<String>> {
     let mut possible_mapping_indexed: HashMap<&String, &Option<AnalysedType>> = HashMap::new();
 
     for NameOptionTypePair {
@@ -609,44 +656,31 @@ fn get_variant(
         Ok(json_obj.iter().next().unwrap())
     }?;
 
+    let case_idx = types
+        .iter()
+        .position(|pair| pair.name == *key)
+        .ok_or_else(|| vec![format!("Unknown key {key} in the variant")])?
+        as u32;
+
     match possible_mapping_indexed.get(key) {
         Some(Some(tpe)) => {
-            let result = TypeAnnotatedValue::parse_with_type(json, tpe)?;
-            let variant = protobuf::TypedVariant {
-                typ: Some(protobuf::TypeVariant {
-                    cases: types
-                        .iter()
-                        .map(|pair| protobuf::NameOptionTypePair {
-                            name: pair.name.clone(),
-                            typ: pair.typ.as_ref().map(|t| t.into()),
-                        })
-                        .collect(),
-                }),
-                case_name: key.clone(),
-                case_value: Some(Box::new(protobuf::TypeAnnotatedValue {
-                    type_annotated_value: Some(result),
-                })),
-            };
-
-            Ok(TypeAnnotatedValue::Variant(Box::new(variant)))
+            let result = ValueAndType::parse_with_type(json, tpe)?;
+
+            Ok(ValueAndType::new(
+                Value::Variant {
+                    case_idx,
+                    case_value: Some(Box::new(result.value)),
+                },
+                variant(types.to_vec()),
+            ))
         }
-        Some(None) if json.is_null() => {
-            let variant = protobuf::TypedVariant {
-                typ: Some(protobuf::TypeVariant {
-                    cases: types
-                        .iter()
-                        .map(|pair| protobuf::NameOptionTypePair {
-                            name: pair.name.clone(),
-                            typ: pair.typ.as_ref().map(|t| t.into()),
-                        })
-                        .collect(),
-                }),
-                case_name: key.clone(),
+        Some(None) if json.is_null() => Ok(ValueAndType::new(
+            Value::Variant {
+                case_idx,
                 case_value: None,
-            };
-
-            Ok(TypeAnnotatedValue::Variant(Box::new(variant)))
-        }
+            },
+            variant(types.to_vec()),
+        )),
         Some(None) => Err(vec![format!("Unit variant {key} has non-null JSON value")]),
         None => Err(vec![format!("Unknown key {key} in the variant")]),
     }
@@ -656,7 +690,7 @@ fn get_handle(
     value: &JsonValue,
     id: AnalysedResourceId,
     resource_mode: AnalysedResourceMode,
-) -> Result<TypeAnnotatedValue, Vec<String>> {
+) -> Result<ValueAndType, Vec<String>> {
     match value.as_str() {
         Some(str) => {
             // not assuming much about the url format, just checking it ends with a /<resource-id-u64>
@@ -666,18 +700,15 @@ fn get_handle(
                     Ok(resource_id) => {
                         let uri = parts[0..(parts.len() - 1)].join("/");
 
-                        let handle = protobuf::TypedHandle {
-                            typ: Some(protobuf::TypeHandle {
-                                resource_id: id.0,
-                                mode: match resource_mode {
-                                    AnalysedResourceMode::Owned => 1,
-                                    AnalysedResourceMode::Borrowed => 2,
-                                },
+                        Ok(ValueAndType::new(
+                            Value::Handle { resource_id, uri },
+                            AnalysedType::Handle(TypeHandle {
+                                resource_id: id,
+                                mode: resource_mode,
+                                name: None,
+                                owner: None,
                             }),
-                            uri,
-                            resource_id,
-                        };
-                        Ok(TypeAnnotatedValue::Handle(handle))
+                        ))
                     }
                     Err(err) => Err(vec![format!(
                         "Failed to parse resource-id section of the handle value: {}",
@@ -741,11 +772,11 @@ fn get_big_decimal(value: &JsonValue) -> Result<BigDecimal, Vec<String>> {
     }
 }
 
-fn get_u64(value: &JsonValue) -> Result<TypeAnnotatedValue, Vec<String>> {
+fn get_u64(value: &JsonValue) -> Result<ValueAndType, Vec<String>> {
     match value {
         JsonValue::Number(num) => {
             if let Some(u64) = num.as_u64() {
-                Ok(TypeAnnotatedValue::U64(u64))
+                Ok(u64.into_value_and_type())
             } else {
                 Err(vec![format!("Cannot convert {} to u64", num)])
             }
@@ -771,26 +802,24 @@ mod tests {
     use proptest::prelude::*;
     use serde_json::{Number, Value as JsonValue};
 
-    use crate::json::TypeAnnotatedValueJsonExtensions;
-    use crate::protobuf::type_annotated_value::TypeAnnotatedValue;
-    use crate::{TypeAnnotatedValueConstructors, Value};
+    use crate::json::ValueAndTypeJsonExtensions;
+    use crate::{Value, ValueAndType};
 
     fn validate_function_result(
         val: Value,
         expected_type: &AnalysedType,
     ) -> Result<JsonValue, Vec<String>> {
-        TypeAnnotatedValue::create(&val, expected_type).map(|result| result.to_json_value())
+        ValueAndType::new(val, expected_type.clone())
+            .to_json_value()
+            .map_err(|s| vec![s])
     }
 
     fn validate_function_parameter(
         json: &JsonValue,
         expected_type: &AnalysedType,
     ) -> Result<Value, Vec<String>> {
-        match TypeAnnotatedValue::parse_with_type(json, expected_type) {
-            Ok(result) => match Value::try_from(result) {
-                Ok(value) => Ok(value),
-                Err(err) => Err(vec![err]),
-            },
+        match ValueAndType::parse_with_type(json, expected_type) {
+            Ok(result) => Ok(result.value),
             Err(err) => Err(err),
         }
     }
diff --git a/wasm-rpc/src/text.rs b/wasm-rpc/src/text.rs
index 7f9868f5..55229689 100644
--- a/wasm-rpc/src/text.rs
+++ b/wasm-rpc/src/text.rs
@@ -16,14 +16,8 @@ use crate::{IntoValueAndType, Value, ValueAndType};
 use golem_wasm_ast::analysis::AnalysedType;
 use std::borrow::Cow;
 use std::collections::HashSet;
-use std::io;
-use wasm_wave::from_str;
 use wasm_wave::wasm::{WasmType, WasmTypeKind, WasmValue, WasmValueError};
-use wasm_wave::writer as wave_writer;
-use wasm_wave::writer::WriterError;
-
-#[cfg(all(feature = "typeinfo", feature = "protobuf"))]
-pub use type_annotated_value::*;
+use wasm_wave::{from_str, to_string};
 
 pub fn parse_value_and_type(
     analysed_type: &AnalysedType,
@@ -34,99 +28,11 @@ pub fn parse_value_and_type(
 }
 
 pub fn print_value_and_type(value: &ValueAndType) -> Result<String, String> {
-    let mut buf = vec![];
-    let inner_writer = wave_writer::Writer::new(&mut buf);
-    let mut text_writer = TextWriter::new(inner_writer);
-
-    text_writer
-        .write_value(value)
-        .map_err(|err| err.to_string())?;
-    Ok(String::from_utf8(buf).unwrap_or_else(|err| panic!("invalid UTF-8: {err:?}")))
-}
-
-/// A writer that serializes `WasmValue` implementors to the WAVE text format,
-/// by wrapping an existing `wasm_wave::writer::Writer`.
-pub struct TextWriter<W: io::Write> {
-    inner_wave_writer: wave_writer::Writer<W>,
-}
-
-impl<W: io::Write> TextWriter<W> {
-    /// Creates a new `TextWriter` from an existing `wave_writer::Writer<W>` instance.
-    /// The `wave_writer::Writer` itself wraps an `io::Write` sink.
-    pub fn new(inner_wave_writer: wave_writer::Writer<W>) -> Self {
-        Self { inner_wave_writer }
-    }
-
-    #[allow(clippy::only_used_in_recursion)]
-    fn has_unsupported<V>(&mut self, val: &V) -> bool
-    where
-        V: WasmValue,
-    {
-        match val.kind() {
-            WasmTypeKind::List => val
-                .unwrap_list()
-                .any(|item_cow| self.has_unsupported(item_cow.as_ref())),
-            WasmTypeKind::Record => val
-                .unwrap_record()
-                .any(|(_, item_cow)| self.has_unsupported(item_cow.as_ref())),
-            WasmTypeKind::Tuple => val
-                .unwrap_tuple()
-                .any(|item_cow| self.has_unsupported(item_cow.as_ref())),
-            WasmTypeKind::Variant => val
-                .unwrap_variant()
-                .1
-                .is_some_and(|inner_val_cow| self.has_unsupported(inner_val_cow.as_ref())),
-            WasmTypeKind::Option => val
-                .unwrap_option()
-                .is_some_and(|inner_val_cow| self.has_unsupported(inner_val_cow.as_ref())),
-            WasmTypeKind::Result => {
-                match val.unwrap_result() {
-                    Ok(Some(ok_val_cow)) => self.has_unsupported(ok_val_cow.as_ref()),
-                    Err(Some(err_val_cow)) => self.has_unsupported(err_val_cow.as_ref()),
-                    _ => false, // Ok(None) or Err(None)
-                }
-            }
-            WasmTypeKind::Unsupported => true,
-            _ => false, // Primitives and other types
-        }
+    if value.typ.contains_handle() {
+        Err("Cannot print handle type".to_string())
+    } else {
+        to_string(value).map_err(|err| err.to_string())
     }
-
-    /// Writes a `WasmValue` to the underlying stream in WAVE text format.
-    ///
-    /// This method directly delegates to the `write_value` method of the wrapped
-    /// `wasm_wave::writer::Writer`.
-    ///
-    /// # Arguments
-    /// * `val`: A reference to a value that implements `WasmValue`.
-    ///
-    /// # Errors
-    /// Returns a `TextWriterError` if writing fails, typically by propagating
-    /// an error from the underlying `wasm-wave` writer or an IO error.
-    pub fn write_value<V>(&mut self, val: &V) -> Result<(), WriterError>
-    where
-        V: WasmValue,
-    {
-        if self.has_unsupported(val) {
-            let placeholder_value_and_type =
-                ValueAndType::make_string(Cow::Borrowed("<unsupported>"));
-            return self
-                .inner_wave_writer
-                .write_value(&placeholder_value_and_type);
-        }
-        self.inner_wave_writer.write_value(val)?;
-        Ok(())
-    }
-
-    // /// Gets a mutable reference to the underlying `io::Write` sink
-    // /// originally wrapped by the `wave_writer::Writer`.
-    // pub fn get_mut(&mut self) -> &mut W {
-    //     self.inner_wave_writer.as_mut()
-    // }
-    //
-    // /// Unwraps this `TextWriter`, returning the underlying `wasm_wave::writer::Writer<W>`.
-    // pub fn into_wave_writer(self) -> wave_writer::Writer<W> {
-    //     self.inner_wave_writer
-    // }
 }
 
 impl WasmValue for ValueAndType {
@@ -184,7 +90,7 @@ impl WasmValue for ValueAndType {
         val.into_value_and_type()
     }
 
-    fn make_string(val: Cow<'_, str>) -> Self {
+    fn make_string(val: Cow<str>) -> Self {
         val.to_string().into_value_and_type()
     }
 
@@ -542,37 +448,21 @@ impl WasmValue for ValueAndType {
 mod tests {
     use test_r::test;
 
-    use crate::text::{parse_value_and_type, print_value_and_type, TextWriter};
+    use crate::text::{parse_value_and_type, print_value_and_type};
     use crate::{Value, ValueAndType};
     use golem_wasm_ast::analysis::analysed_type::{
         bool, case, chr, f32, f64, field, flags, list, option, r#enum, record, result_err,
         result_ok, s16, s32, s64, s8, str, tuple, u16, u32, u64, u8, unit_case, variant,
     };
     use golem_wasm_ast::analysis::AnalysedType;
-    use wasm_wave::writer as wave_writer; // For creating the wave_writer::Writer
 
     fn round_trip(value: Value, typ: AnalysedType) {
         let typed_value = ValueAndType::new(value.clone(), typ.clone());
 
-        let s_via_to_string = print_value_and_type(&typed_value).unwrap();
-        let round_trip_value_from_string: ValueAndType =
-            parse_value_and_type(&typ, &s_via_to_string).unwrap();
-        assert_eq!(value, Value::from(round_trip_value_from_string));
-
-        let mut buffer = Vec::new();
-        let inner_writer = wave_writer::Writer::new(&mut buffer);
-        let mut text_writer = TextWriter::new(inner_writer);
-        text_writer.write_value(&typed_value).unwrap();
-        let s_via_writer = String::from_utf8(buffer).unwrap();
-
-        assert_eq!(
-            s_via_to_string, s_via_writer,
-            "Output from to_string and TextWriter should match"
-        );
-
-        let round_trip_value_from_writer: ValueAndType =
-            parse_value_and_type(&typ, &s_via_writer).unwrap();
-        assert_eq!(value, Value::from(round_trip_value_from_writer));
+        let s = print_value_and_type(&typed_value).unwrap();
+        let round_trip_value: ValueAndType = parse_value_and_type(&typ, &s).unwrap();
+        let result: Value = Value::from(round_trip_value);
+        assert_eq!(value, result);
     }
 
     #[test]
@@ -732,741 +622,3 @@ mod tests {
         );
     }
 }
-
-#[cfg(all(feature = "typeinfo", feature = "protobuf"))]
-mod type_annotated_value {
-    use crate::protobuf::type_annotated_value::TypeAnnotatedValue;
-    use crate::protobuf::typed_result::ResultValue;
-    use crate::protobuf::{
-        NameValuePair, TypedEnum, TypedFlags, TypedList, TypedOption, TypedRecord, TypedTuple,
-        TypedVariant,
-    };
-    use crate::protobuf::{TypeAnnotatedValue as RootTypeAnnotatedValue, TypedResult};
-    use crate::text::TextWriter;
-    use golem_wasm_ast::analysis::{protobuf, TypeEnum, TypeFlags};
-    use golem_wasm_ast::analysis::{AnalysedType, TypeList, TypeRecord, TypeTuple, TypeVariant};
-    use std::borrow::Cow;
-    use std::ops::Deref;
-    use wasm_wave::from_str;
-    use wasm_wave::wasm::{WasmType, WasmTypeKind, WasmValue, WasmValueError};
-    use wasm_wave::writer::Writer;
-
-    pub fn parse_type_annotated_value(
-        analysed_type: &AnalysedType,
-        input: &str,
-    ) -> Result<TypeAnnotatedValue, String> {
-        let parsed_typed_value: TypeAnnotatedValuePrintable =
-            from_str(analysed_type, input).map_err(|err| err.to_string())?;
-
-        Ok(parsed_typed_value.0)
-    }
-
-    pub fn print_type_annotated_value(value: &TypeAnnotatedValue) -> Result<String, String> {
-        let mut buf = vec![];
-        let inner_writer = Writer::new(&mut buf);
-        let mut text_writer = TextWriter::new(inner_writer);
-
-        let printable_typed_value = TypeAnnotatedValuePrintable(value.clone());
-        text_writer
-            .write_value(&printable_typed_value)
-            .map_err(|err| err.to_string())?;
-
-        Ok(String::from_utf8(buf).unwrap_or_else(|err| panic!("invalid UTF-8: {err:?}")))
-    }
-
-    #[derive(Debug, Clone)]
-    pub struct TypeAnnotatedValuePrintable(pub TypeAnnotatedValue);
-
-    impl WasmValue for TypeAnnotatedValuePrintable {
-        type Type = AnalysedType;
-
-        fn kind(&self) -> WasmTypeKind {
-            let analysed_type = AnalysedType::try_from(&self.0)
-                .expect("Failed to retrieve AnalysedType from TypeAnnotatedValue");
-            analysed_type.kind()
-        }
-
-        fn make_bool(val: bool) -> Self {
-            TypeAnnotatedValuePrintable(TypeAnnotatedValue::Bool(val))
-        }
-
-        fn make_s8(val: i8) -> Self {
-            TypeAnnotatedValuePrintable(TypeAnnotatedValue::S8(val as i32))
-        }
-
-        fn make_s16(val: i16) -> Self {
-            TypeAnnotatedValuePrintable(TypeAnnotatedValue::S16(val as i32))
-        }
-
-        fn make_s32(val: i32) -> Self {
-            TypeAnnotatedValuePrintable(TypeAnnotatedValue::S32(val))
-        }
-
-        fn make_s64(val: i64) -> Self {
-            TypeAnnotatedValuePrintable(TypeAnnotatedValue::S64(val))
-        }
-
-        fn make_u8(val: u8) -> Self {
-            TypeAnnotatedValuePrintable(TypeAnnotatedValue::U8(val as u32))
-        }
-
-        fn make_u16(val: u16) -> Self {
-            TypeAnnotatedValuePrintable(TypeAnnotatedValue::U16(val as u32))
-        }
-
-        fn make_u32(val: u32) -> Self {
-            TypeAnnotatedValuePrintable(TypeAnnotatedValue::U32(val))
-        }
-
-        fn make_u64(val: u64) -> Self {
-            TypeAnnotatedValuePrintable(TypeAnnotatedValue::U64(val))
-        }
-
-        fn make_f32(val: f32) -> Self {
-            TypeAnnotatedValuePrintable(TypeAnnotatedValue::F32(val))
-        }
-
-        fn make_f64(val: f64) -> Self {
-            TypeAnnotatedValuePrintable(TypeAnnotatedValue::F64(val))
-        }
-
-        fn make_char(val: char) -> Self {
-            TypeAnnotatedValuePrintable(TypeAnnotatedValue::Char(val as i32))
-        }
-
-        fn make_string(val: Cow<'_, str>) -> Self {
-            TypeAnnotatedValuePrintable(TypeAnnotatedValue::Str(val.to_string()))
-        }
-
-        fn make_list(
-            ty: &Self::Type,
-            vals: impl IntoIterator<Item = Self>,
-        ) -> Result<Self, WasmValueError> {
-            if let AnalysedType::List(TypeList { inner: typ }) = ty {
-                let list = TypedList {
-                    values: vals
-                        .into_iter()
-                        .map(|v| RootTypeAnnotatedValue {
-                            type_annotated_value: Some(v.0),
-                        })
-                        .collect(),
-                    typ: Some(typ.deref().into()),
-                };
-
-                Ok(TypeAnnotatedValuePrintable(TypeAnnotatedValue::List(list)))
-            } else {
-                Err(WasmValueError::WrongTypeKind {
-                    kind: ty.kind(),
-                    ty: format!("{ty:?}"),
-                })
-            }
-        }
-
-        fn make_record<'a>(
-            ty: &Self::Type,
-            fields: impl IntoIterator<Item = (&'a str, Self)>,
-        ) -> Result<Self, WasmValueError> {
-            if let AnalysedType::Record(TypeRecord { fields: types }) = ty {
-                let record = TypedRecord {
-                    value: fields
-                        .into_iter()
-                        .map(|(name, value)| NameValuePair {
-                            name: name.to_string(),
-                            value: Some(RootTypeAnnotatedValue {
-                                type_annotated_value: Some(value.0),
-                            }),
-                        })
-                        .collect(),
-                    typ: types
-                        .iter()
-                        .map(|pair| protobuf::NameTypePair {
-                            name: pair.name.clone(),
-                            typ: Some((&pair.typ).into()),
-                        })
-                        .collect(),
-                };
-                Ok(TypeAnnotatedValuePrintable(TypeAnnotatedValue::Record(
-                    record,
-                )))
-            } else {
-                Err(WasmValueError::WrongTypeKind {
-                    kind: ty.kind(),
-                    ty: format!("{ty:?}"),
-                })
-            }
-        }
-
-        fn make_tuple(
-            ty: &Self::Type,
-            vals: impl IntoIterator<Item = Self>,
-        ) -> Result<Self, WasmValueError> {
-            if let AnalysedType::Tuple(TypeTuple { items: types }) = ty {
-                let tuple = TypedTuple {
-                    value: vals
-                        .into_iter()
-                        .map(|v| RootTypeAnnotatedValue {
-                            type_annotated_value: Some(v.0),
-                        })
-                        .collect(),
-                    typ: types.iter().map(|t| t.into()).collect(),
-                };
-                Ok(TypeAnnotatedValuePrintable(TypeAnnotatedValue::Tuple(
-                    tuple,
-                )))
-            } else {
-                Err(WasmValueError::WrongTypeKind {
-                    kind: ty.kind(),
-                    ty: format!("{ty:?}"),
-                })
-            }
-        }
-
-        fn make_variant(
-            ty: &Self::Type,
-            case: &str,
-            val: Option<Self>,
-        ) -> Result<Self, WasmValueError> {
-            if let AnalysedType::Variant(TypeVariant { cases }) = ty {
-                let case_type = cases.iter().find_map(|pair| {
-                    if pair.name == case {
-                        Some(&pair.typ)
-                    } else {
-                        None
-                    }
-                });
-                if case_type.is_some() {
-                    let variant = TypedVariant {
-                        typ: Some(protobuf::TypeVariant {
-                            cases: cases
-                                .iter()
-                                .map(|pair| protobuf::NameOptionTypePair {
-                                    name: pair.name.clone(),
-                                    typ: pair.typ.as_ref().map(|v| v.into()),
-                                })
-                                .collect(),
-                        }),
-                        case_name: case.to_string(),
-                        case_value: val.map(|v| {
-                            Box::new(RootTypeAnnotatedValue {
-                                type_annotated_value: Some(v.0),
-                            })
-                        }),
-                    };
-                    Ok(TypeAnnotatedValuePrintable(TypeAnnotatedValue::Variant(
-                        Box::new(variant),
-                    )))
-                } else {
-                    Err(WasmValueError::UnknownCase(case.to_string()))
-                }
-            } else {
-                Err(WasmValueError::WrongTypeKind {
-                    kind: ty.kind(),
-                    ty: format!("{ty:?}"),
-                })
-            }
-        }
-
-        fn make_enum(ty: &Self::Type, case: &str) -> Result<Self, WasmValueError> {
-            if let AnalysedType::Enum(TypeEnum { cases }) = ty {
-                if cases.contains(&case.to_string()) {
-                    let enum_value = TypedEnum {
-                        typ: cases.to_vec(),
-                        value: case.to_string(),
-                    };
-                    Ok(TypeAnnotatedValuePrintable(TypeAnnotatedValue::Enum(
-                        enum_value,
-                    )))
-                } else {
-                    Err(WasmValueError::UnknownCase(case.to_string()))
-                }
-            } else {
-                Err(WasmValueError::WrongTypeKind {
-                    kind: ty.kind(),
-                    ty: format!("{ty:?}"),
-                })
-            }
-        }
-
-        fn make_option(ty: &Self::Type, val: Option<Self>) -> Result<Self, WasmValueError> {
-            let option = TypedOption {
-                typ: Some(match ty {
-                    AnalysedType::Option(opt_inner) => opt_inner.inner.as_ref().into(),
-                    _ => ty.into(),
-                }),
-                value: val.map(|v| {
-                    Box::new(RootTypeAnnotatedValue {
-                        type_annotated_value: Some(v.0),
-                    })
-                }),
-            };
-
-            Ok(TypeAnnotatedValuePrintable(TypeAnnotatedValue::Option(
-                Box::new(option),
-            )))
-        }
-
-        fn make_result(
-            ty: &Self::Type,
-            val: Result<Option<Self>, Option<Self>>,
-        ) -> Result<Self, WasmValueError> {
-            if let AnalysedType::Result(golem_wasm_ast::analysis::TypeResult { ok, err }) = ty {
-                let result0 = TypedResult {
-                    ok: ok.clone().map(|v| v.deref().into()),
-                    error: err.clone().map(|v| v.deref().into()),
-                    result_value: match val {
-                        Ok(Some(v)) => {
-                            Some(ResultValue::OkValue(Box::new(RootTypeAnnotatedValue {
-                                type_annotated_value: Some(v.0),
-                            })))
-                        }
-                        Ok(None) => None,
-                        Err(Some(v)) => {
-                            Some(ResultValue::ErrorValue(Box::new(RootTypeAnnotatedValue {
-                                type_annotated_value: Some(v.0),
-                            })))
-                        }
-                        Err(None) => None,
-                    },
-                };
-                Ok(TypeAnnotatedValuePrintable(TypeAnnotatedValue::Result(
-                    Box::new(result0),
-                )))
-            } else {
-                Err(WasmValueError::WrongTypeKind {
-                    kind: ty.kind(),
-                    ty: format!("{ty:?}"),
-                })
-            }
-        }
-
-        fn make_flags<'a>(
-            ty: &Self::Type,
-            names: impl IntoIterator<Item = &'a str>,
-        ) -> Result<Self, WasmValueError> {
-            if let AnalysedType::Flags(TypeFlags { names: all_names }) = ty {
-                let names: Vec<String> = names.into_iter().map(|name| name.to_string()).collect();
-
-                let invalid_names: Vec<String> = names
-                    .iter()
-                    .filter(|&name| !all_names.contains(&name.to_string()))
-                    .cloned()
-                    .collect();
-
-                if invalid_names.is_empty() {
-                    let flags = TypedFlags {
-                        typ: all_names.to_vec(),
-                        values: names.to_vec(),
-                    };
-
-                    Ok(TypeAnnotatedValuePrintable(TypeAnnotatedValue::Flags(
-                        flags,
-                    )))
-                } else {
-                    Err(WasmValueError::UnknownCase(invalid_names.join(", ")))
-                }
-            } else {
-                Err(WasmValueError::WrongTypeKind {
-                    kind: ty.kind(),
-                    ty: format!("{ty:?}"),
-                })
-            }
-        }
-
-        fn unwrap_bool(&self) -> bool {
-            match self.0 {
-                TypeAnnotatedValue::Bool(value) => value,
-                _ => panic!("Expected bool, found {self:?}"),
-            }
-        }
-
-        fn unwrap_s8(&self) -> i8 {
-            match self.0 {
-                TypeAnnotatedValue::S8(value) => value as i8,
-                _ => panic!("Expected s8, found {self:?}"),
-            }
-        }
-
-        fn unwrap_s16(&self) -> i16 {
-            match self.0 {
-                TypeAnnotatedValue::S16(value) => value as i16,
-                _ => panic!("Expected s16, found {self:?}"),
-            }
-        }
-
-        fn unwrap_s32(&self) -> i32 {
-            match self.0 {
-                TypeAnnotatedValue::S32(value) => value,
-                _ => panic!("Expected s32, found {self:?}"),
-            }
-        }
-
-        fn unwrap_s64(&self) -> i64 {
-            match self.0 {
-                TypeAnnotatedValue::S64(value) => value,
-                _ => panic!("Expected s64, found {self:?}"),
-            }
-        }
-
-        fn unwrap_u8(&self) -> u8 {
-            match self.0 {
-                TypeAnnotatedValue::U8(value) => value as u8,
-                _ => panic!("Expected u8, found {self:?}"),
-            }
-        }
-
-        fn unwrap_u16(&self) -> u16 {
-            match self.0 {
-                TypeAnnotatedValue::U16(value) => value as u16,
-                _ => panic!("Expected u16, found {self:?}"),
-            }
-        }
-
-        fn unwrap_u32(&self) -> u32 {
-            match self.0 {
-                TypeAnnotatedValue::U32(value) => value,
-                _ => panic!("Expected u32, found {self:?}"),
-            }
-        }
-
-        fn unwrap_u64(&self) -> u64 {
-            match self.0 {
-                TypeAnnotatedValue::U64(value) => value,
-                _ => panic!("Expected u64, found {self:?}"),
-            }
-        }
-
-        fn unwrap_f32(&self) -> f32 {
-            match self.0 {
-                TypeAnnotatedValue::F32(value) => value,
-                _ => panic!("Expected f32, found {self:?}"),
-            }
-        }
-
-        fn unwrap_f64(&self) -> f64 {
-            match self.0 {
-                TypeAnnotatedValue::F64(value) => value,
-                _ => panic!("Expected f64, found {self:?}"),
-            }
-        }
-
-        fn unwrap_char(&self) -> char {
-            match self.0 {
-                TypeAnnotatedValue::Char(value) => char::from_u32(value as u32)
-                    .unwrap_or_else(|| panic!("Invalid char value: {value}")),
-                _ => panic!("Expected chr, found {self:?}"),
-            }
-        }
-
-        fn unwrap_string(&self) -> Cow<'_, str> {
-            match &self.0 {
-                TypeAnnotatedValue::Str(value) => Cow::Borrowed(value),
-                _ => panic!("Expected string, found {self:?}"),
-            }
-        }
-
-        fn unwrap_list(&self) -> Box<dyn Iterator<Item = Cow<'_, Self>> + '_> {
-            match &self.0 {
-                TypeAnnotatedValue::List(TypedList { typ: _, values }) => {
-                    Box::new(values.iter().map(|v| {
-                        Cow::Owned(TypeAnnotatedValuePrintable(
-                            v.type_annotated_value
-                                .as_ref()
-                                .expect("List item value missing")
-                                .clone(),
-                        ))
-                    }))
-                }
-                _ => panic!("Expected list, found {self:?}"),
-            }
-        }
-
-        fn unwrap_record(&self) -> Box<dyn Iterator<Item = (Cow<'_, str>, Cow<'_, Self>)> + '_> {
-            match &self.0 {
-                TypeAnnotatedValue::Record(TypedRecord { typ: _, value }) => {
-                    Box::new(value.iter().map(|name_value| {
-                        let name = Cow::Borrowed(name_value.name.as_str());
-                        let type_annotated_value = name_value
-                            .value
-                            .as_ref()
-                            .expect("Record field value missing")
-                            .type_annotated_value
-                            .as_ref()
-                            .expect("Record field inner value missing")
-                            .clone();
-                        (
-                            name,
-                            Cow::Owned(TypeAnnotatedValuePrintable(type_annotated_value)),
-                        )
-                    }))
-                }
-                _ => panic!("Expected record, found {self:?}"),
-            }
-        }
-
-        fn unwrap_tuple(&self) -> Box<dyn Iterator<Item = Cow<'_, Self>> + '_> {
-            match &self.0 {
-                TypeAnnotatedValue::Tuple(TypedTuple { typ: _, value }) => {
-                    Box::new(value.iter().map(|x| {
-                        if let Some(ref v) = x.type_annotated_value {
-                            Cow::Owned(TypeAnnotatedValuePrintable(v.clone()))
-                        } else {
-                            panic!("Expected value in tuple element, found None")
-                        }
-                    }))
-                }
-                _ => panic!("Expected tuple, found {self:?}"),
-            }
-        }
-
-        fn unwrap_variant(&self) -> (Cow<'_, str>, Option<Cow<'_, Self>>) {
-            match &self.0 {
-                TypeAnnotatedValue::Variant(variant) => {
-                    let case_name = Cow::Borrowed(variant.case_name.as_str());
-                    let case_value = variant.case_value.as_ref().map(|v| {
-                        Cow::Owned(TypeAnnotatedValuePrintable(
-                            v.type_annotated_value
-                                .as_ref()
-                                .expect("Variant inner value missing")
-                                .clone(),
-                        ))
-                    });
-                    (case_name, case_value)
-                }
-                _ => panic!("Expected variant, found {self:?}"),
-            }
-        }
-
-        fn unwrap_enum(&self) -> Cow<'_, str> {
-            match &self.0 {
-                TypeAnnotatedValue::Enum(TypedEnum { typ: _, value }) => Cow::Borrowed(value),
-                _ => panic!("Expected enum, found {self:?}"),
-            }
-        }
-
-        fn unwrap_option(&self) -> Option<Cow<'_, Self>> {
-            match &self.0 {
-                TypeAnnotatedValue::Option(option) => option.value.as_ref().and_then(|v| {
-                    v.type_annotated_value
-                        .as_ref()
-                        .map(|inner| Cow::Owned(TypeAnnotatedValuePrintable(inner.clone())))
-                }),
-                _ => panic!("Expected option, found {self:?}"),
-            }
-        }
-
-        fn unwrap_result(&self) -> Result<Option<Cow<'_, Self>>, Option<Cow<'_, Self>>> {
-            match &self.0 {
-                TypeAnnotatedValue::Result(result0) => match result0.result_value.as_ref() {
-                    Some(result) => match result {
-                        ResultValue::OkValue(ok) => match ok.type_annotated_value.as_ref() {
-                            Some(ok_value) => Ok(Some(Cow::Owned(TypeAnnotatedValuePrintable(
-                                ok_value.clone(),
-                            )))),
-                            None => Ok(None),
-                        },
-                        ResultValue::ErrorValue(error) => match error.type_annotated_value.as_ref()
-                        {
-                            Some(error_value) => Err(Some(Cow::Owned(
-                                TypeAnnotatedValuePrintable(error_value.clone()),
-                            ))),
-                            None => Err(None),
-                        },
-                    },
-                    None => Ok(None),
-                },
-                _ => panic!("Expected result, found {self:?}"),
-            }
-        }
-
-        fn unwrap_flags(&self) -> Box<dyn Iterator<Item = Cow<'_, str>> + '_> {
-            match &self.0 {
-                TypeAnnotatedValue::Flags(TypedFlags { typ: _, values }) => {
-                    Box::new(values.iter().map(|s| Cow::Borrowed(s.as_str())))
-                }
-                _ => panic!("Expected flags, found {self:?}"),
-            }
-        }
-    }
-
-    #[cfg(test)]
-    mod tests {
-        use test_r::test;
-
-        use crate::protobuf::type_annotated_value::TypeAnnotatedValue;
-        use crate::text::parse_type_annotated_value;
-        use crate::{print_type_annotated_value, TypeAnnotatedValueConstructors, Value};
-        use golem_wasm_ast::analysis::analysed_type::{
-            bool, case, chr, f32, f64, field, flags, list, option, r#enum, record, result_err,
-            result_ok, s16, s32, s64, s8, str, tuple, u16, u32, u64, u8, unit_case, variant,
-        };
-        use golem_wasm_ast::analysis::AnalysedType;
-
-        fn round_trip(value: Value, typ: AnalysedType) {
-            let typed_value = TypeAnnotatedValue::create(&value, &typ).unwrap();
-
-            let s = print_type_annotated_value(&typed_value).unwrap();
-            let round_trip_value: TypeAnnotatedValue =
-                parse_type_annotated_value(&AnalysedType::try_from(&typed_value).unwrap(), &s)
-                    .unwrap();
-            let result: Value = Value::try_from(round_trip_value).unwrap();
-            assert_eq!(value, result);
-        }
-
-        #[test]
-        fn round_trip_u8() {
-            round_trip(Value::U8(42), u8());
-        }
-
-        #[test]
-        fn round_trip_u16() {
-            round_trip(Value::U16(1234), u16());
-        }
-
-        #[test]
-        fn round_trip_u32() {
-            round_trip(Value::U32(123456), u32());
-        }
-
-        #[test]
-        fn round_trip_u64() {
-            round_trip(Value::U64(1234567890123456), u64());
-        }
-
-        #[test]
-        fn round_trip_s8() {
-            round_trip(Value::S8(-42), s8());
-        }
-
-        #[test]
-        fn round_trip_s16() {
-            round_trip(Value::S16(-1234), s16());
-        }
-
-        #[test]
-        fn round_trip_s32() {
-            round_trip(Value::S32(-123456), s32());
-        }
-
-        #[test]
-        fn round_trip_s64() {
-            round_trip(Value::S64(-1234567890123456), s64());
-        }
-
-        #[test]
-        fn round_trip_f32() {
-            round_trip(Value::F32(1234.5678), f32());
-        }
-
-        #[test]
-        fn round_trip_f64() {
-            round_trip(Value::F64(1_234_567_890_123_456.8), f64());
-        }
-
-        #[test]
-        fn round_trip_bool() {
-            round_trip(Value::Bool(true), bool());
-        }
-
-        #[test]
-        fn round_trip_char() {
-            round_trip(Value::Char('a'), chr());
-        }
-
-        #[test]
-        fn round_trip_string() {
-            round_trip(Value::String("hello".to_string()), str());
-        }
-
-        #[test]
-        fn round_trip_list_1() {
-            round_trip(
-                Value::List(vec![Value::U8(1), Value::U8(2), Value::U8(3)]),
-                list(u8()),
-            );
-        }
-
-        #[test]
-        fn round_trip_list_2() {
-            round_trip(
-                Value::List(vec![Value::List(vec![
-                    Value::String("hello".to_string()),
-                    Value::String("world".to_string()),
-                ])]),
-                list(list(str())),
-            );
-        }
-
-        #[test]
-        fn round_trip_record() {
-            round_trip(
-                Value::Record(vec![
-                    Value::U8(1),
-                    Value::String("hello".to_string()),
-                    Value::Bool(true),
-                ]),
-                record(vec![
-                    field("a", u8()),
-                    field("b", str()),
-                    field("c", bool()),
-                ]),
-            );
-        }
-
-        #[test]
-        fn round_trip_tuple() {
-            round_trip(
-                Value::Tuple(vec![
-                    Value::U8(1),
-                    Value::String("hello".to_string()),
-                    Value::Bool(true),
-                ]),
-                tuple(vec![u8(), str(), bool()]),
-            );
-        }
-
-        #[test]
-        fn round_trip_variant() {
-            round_trip(
-                Value::Variant {
-                    case_idx: 1,
-                    case_value: Some(Box::new(Value::String("hello".to_string()))),
-                },
-                variant(vec![unit_case("A"), case("B", str())]),
-            );
-        }
-
-        #[test]
-        fn round_trip_enum() {
-            round_trip(Value::Enum(1), r#enum(&["A", "B"]));
-        }
-
-        #[test]
-        fn round_trip_option() {
-            round_trip(Value::Option(Some(Box::new(Value::U8(1)))), option(u8()));
-        }
-
-        #[test]
-        fn round_trip_result_ok() {
-            round_trip(
-                Value::Result(Ok(Some(Box::new(Value::U8(1))))),
-                result_ok(u8()),
-            );
-        }
-
-        #[test]
-        fn round_trip_result_err() {
-            round_trip(
-                Value::Result(Err(Some(Box::new(Value::U8(1))))),
-                result_err(u8()),
-            );
-        }
-
-        #[test]
-        fn round_trip_flags() {
-            round_trip(
-                Value::Flags(vec![true, false, true]),
-                flags(&["A", "B", "C"]),
-            );
-        }
-    }
-}
diff --git a/wasm-rpc/src/wasmtime.rs b/wasm-rpc/src/wasmtime.rs
index 1a666994..5dbd9345 100644
--- a/wasm-rpc/src/wasmtime.rs
+++ b/wasm-rpc/src/wasmtime.rs
@@ -43,12 +43,21 @@ impl Display for EncodingError {
     }
 }
 
+#[derive(Debug, Clone, PartialEq, Eq, Hash)]
+#[cfg_attr(feature = "bincode", derive(bincode::Encode, bincode::Decode))]
+pub struct ResourceTypeId {
+    /// Name of the WIT resource
+    pub name: String,
+    /// Owner of the resource, either an interface in a WIT package or a name of a world
+    pub owner: String,
+}
+
 #[async_trait]
 pub trait ResourceStore {
     fn self_uri(&self) -> Uri;
-    async fn add(&mut self, resource: ResourceAny) -> u64;
-    async fn get(&mut self, resource_id: u64) -> Option<ResourceAny>;
-    async fn borrow(&self, resource_id: u64) -> Option<ResourceAny>;
+    async fn add(&mut self, resource: ResourceAny, name: ResourceTypeId) -> u64;
+    async fn get(&mut self, resource_id: u64) -> Option<(ResourceTypeId, ResourceAny)>;
+    async fn borrow(&self, resource_id: u64) -> Option<(ResourceTypeId, ResourceAny)>;
 }
 
 pub struct DecodeParamResult {
@@ -436,7 +445,7 @@ async fn decode_param_impl(
                     let uri = Uri { value: uri.clone() };
                     if resource_store.self_uri() == uri {
                         match resource_store.get(*resource_id).await {
-                            Some(resource) => Ok(DecodeParamResult {
+                            Some((_, resource)) => Ok(DecodeParamResult {
                                 val: Val::Resource(resource),
                                 resources_to_drop: vec![resource],
                             }),
@@ -446,8 +455,8 @@ async fn decode_param_impl(
                         }
                     } else {
                         Err(EncodingError::ValueMismatch {
-                        details: format!("in {context} cannot resolve handle belonging to a different worker"),
-                    })
+                            details: format!("in {context} cannot resolve handle belonging to a different worker"),
+                        })
                     }
                 }
                 _ => Err(EncodingError::ParamTypeMismatch {
@@ -463,7 +472,9 @@ async fn decode_param_impl(
                 let uri = Uri { value: uri.clone() };
                 if resource_store.self_uri() == uri {
                     match resource_store.borrow(*resource_id).await {
-                        Some(resource) => Ok(DecodeParamResult::simple(Val::Resource(resource))),
+                        Some((_, resource)) => {
+                            Ok(DecodeParamResult::simple(Val::Resource(resource)))
+                        }
                         None => Err(EncodingError::ValueMismatch {
                             details: format!("in {context} resource not found"),
                         }),
@@ -491,6 +502,7 @@ async fn decode_param_impl(
 pub async fn encode_output(
     value: &Val,
     typ: &Type,
+    analysed_typ: &AnalysedType,
     resource_store: &mut (impl ResourceStore + Send),
 ) -> Result<Value, EncodingError> {
     match value {
@@ -510,9 +522,19 @@ pub async fn encode_output(
         Val::List(list) => {
             if let Type::List(list_type) = typ {
                 let mut encoded_values = Vec::new();
+                let inner_analysed_typ = if let AnalysedType::List(inner) = analysed_typ {
+                    Ok(&*inner.inner)
+                } else {
+                    Err(EncodingError::ValueMismatch {
+                        details: "Expected a List type for list value".to_string(),
+                    })
+                }?;
+
                 for value in (*list).iter() {
-                    encoded_values
-                        .push(encode_output(value, &list_type.ty(), resource_store).await?);
+                    encoded_values.push(
+                        encode_output(value, &list_type.ty(), inner_analysed_typ, resource_store)
+                            .await?,
+                    );
                 }
                 Ok(Value::List(encoded_values))
             } else {
@@ -524,8 +546,20 @@ pub async fn encode_output(
         Val::Record(record) => {
             if let Type::Record(record_type) = typ {
                 let mut encoded_values = Vec::new();
-                for ((_name, value), field) in record.iter().zip(record_type.fields()) {
-                    let field = encode_output(value, &field.ty, resource_store).await?;
+                for (idx, ((_name, value), field)) in
+                    record.iter().zip(record_type.fields()).enumerate()
+                {
+                    let field_analysed_type = if let AnalysedType::Record(inner) = analysed_typ {
+                        Ok(&inner.fields[idx].typ)
+                    } else {
+                        Err(EncodingError::ValueMismatch {
+                            details: "Expected a Record type for record value".to_string(),
+                        })
+                    }?;
+
+                    let field =
+                        encode_output(value, &field.ty, field_analysed_type, resource_store)
+                            .await?;
                     encoded_values.push(field);
                 }
                 Ok(Value::Record(encoded_values))
@@ -538,8 +572,16 @@ pub async fn encode_output(
         Val::Tuple(tuple) => {
             if let Type::Tuple(tuple_type) = typ {
                 let mut encoded_values = Vec::new();
-                for (v, t) in tuple.iter().zip(tuple_type.types()) {
-                    let value = encode_output(v, &t, resource_store).await?;
+                for (idx, (v, t)) in tuple.iter().zip(tuple_type.types()).enumerate() {
+                    let item_analysed_type = if let AnalysedType::Tuple(inner) = analysed_typ {
+                        Ok(&inner.items[idx])
+                    } else {
+                        Err(EncodingError::ValueMismatch {
+                            details: "Expected a Tuple type for tuple value".to_string(),
+                        })
+                    }?;
+
+                    let value = encode_output(v, &t, item_analysed_type, resource_store).await?;
                     encoded_values.push(value);
                 }
                 Ok(Value::Tuple(encoded_values))
@@ -551,10 +593,20 @@ pub async fn encode_output(
         }
         Val::Variant(name, value) => {
             if let Type::Variant(variant_type) = typ {
-                let (discriminant, case) = variant_type
+                let (discriminant, case, analysed_case_type) = variant_type
                     .cases()
                     .enumerate()
                     .find(|(_idx, case)| case.name == *name)
+                    .map(|(idx, case)| {
+                        if let AnalysedType::Variant(inner) = analysed_typ {
+                            Ok((idx, case, &inner.cases[idx].typ))
+                        } else {
+                            Err(EncodingError::ValueMismatch {
+                                details: "Expected a Variant type for variant value".to_string(),
+                            })
+                        }
+                    })
+                    .transpose()?
                     .ok_or(EncodingError::ValueMismatch {
                         details: format!("Could not find case for variant {name}"),
                     })?;
@@ -566,6 +618,11 @@ pub async fn encode_output(
                             &case.ty.ok_or(EncodingError::ValueMismatch {
                                 details: "Could not get type information for case".to_string(),
                             })?,
+                            analysed_case_type
+                                .as_ref()
+                                .ok_or(EncodingError::ValueMismatch {
+                                    details: "Could not get type information for case".to_string(),
+                                })?,
                             resource_store,
                         )
                         .await?,
@@ -602,8 +659,21 @@ pub async fn encode_output(
         Val::Option(option) => match option {
             Some(value) => {
                 if let Type::Option(option_type) = typ {
-                    let encoded_output =
-                        encode_output(value, &option_type.ty(), resource_store).await?;
+                    let analysed_inner_type = if let AnalysedType::Option(inner) = analysed_typ {
+                        Ok(&*inner.inner)
+                    } else {
+                        Err(EncodingError::ValueMismatch {
+                            details: "Expected an Option type for option value".to_string(),
+                        })
+                    }?;
+
+                    let encoded_output = encode_output(
+                        value,
+                        &option_type.ty(),
+                        analysed_inner_type,
+                        resource_store,
+                    )
+                    .await?;
                     Ok(Value::Option(Some(Box::new(encoded_output))))
                 } else {
                     Err(EncodingError::ValueMismatch {
@@ -623,7 +693,22 @@ pub async fn encode_output(
                                     details: "Could not get ok type for result".to_string(),
                                 })?;
 
-                                Some(encode_output(v, &t, resource_store).await?)
+                                let analysed_ok_type =
+                                    if let AnalysedType::Result(inner) = analysed_typ {
+                                        Ok(inner.ok.as_ref().ok_or_else(|| {
+                                            EncodingError::ValueMismatch {
+                                                details: "Expected a Result type for result value"
+                                                    .to_string(),
+                                            }
+                                        })?)
+                                    } else {
+                                        Err(EncodingError::ValueMismatch {
+                                            details: "Expected a Result type for result value"
+                                                .to_string(),
+                                        })
+                                    }?;
+
+                                Some(encode_output(v, &t, analysed_ok_type, resource_store).await?)
                             }
                             None => None,
                         };
@@ -635,7 +720,23 @@ pub async fn encode_output(
                                 let t = result_type.err().ok_or(EncodingError::ValueMismatch {
                                     details: "Could not get error type for result".to_string(),
                                 })?;
-                                Some(encode_output(v, &t, resource_store).await?)
+
+                                let analysed_err_type =
+                                    if let AnalysedType::Result(inner) = analysed_typ {
+                                        Ok(inner.err.as_ref().ok_or_else(|| {
+                                            EncodingError::ValueMismatch {
+                                                details: "Expected a Result type for result value"
+                                                    .to_string(),
+                                            }
+                                        })?)
+                                    } else {
+                                        Err(EncodingError::ValueMismatch {
+                                            details: "Expected a Result type for result value"
+                                                .to_string(),
+                                        })
+                                    }?;
+
+                                Some(encode_output(v, &t, analysed_err_type, resource_store).await?)
                             }
                             None => None,
                         };
@@ -666,7 +767,19 @@ pub async fn encode_output(
             }
         }
         Val::Resource(resource) => {
-            let id = resource_store.add(*resource).await;
+            let type_id = analysed_typ
+                .name()
+                .and_then(|name| {
+                    analysed_typ.owner().map(|owner| ResourceTypeId {
+                        name: name.to_string(),
+                        owner: owner.to_string(),
+                    })
+                })
+                .ok_or_else(|| EncodingError::ValueMismatch {
+                    details: "Resource type information is missing for resource value".to_string(),
+                })?;
+
+            let id = resource_store.add(*resource, type_id).await;
             Ok(Value::Handle {
                 uri: resource_store.self_uri().value,
                 resource_id: id,
@@ -732,7 +845,12 @@ pub fn type_to_analysed_type(typ: &Type) -> Result<AnalysedType, String> {
                 Some(ty) => Some(Box::new(type_to_analysed_type(&ty)?)),
                 None => None,
             };
-            Ok(AnalysedType::Result(TypeResult { ok, err }))
+            Ok(AnalysedType::Result(TypeResult {
+                ok,
+                err,
+                name: None,
+                owner: None,
+            }))
         }
         Type::Flags(wflags) => Ok(flags(&wflags.names().collect::<Vec<_>>())),
         Type::Own(_) => Err("Cannot extract information about owned resource type".to_string()),
